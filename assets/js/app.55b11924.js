(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var r,i,l=e[0],s=e[1],c=e[2],u=0,p=[];u<l.length;u++)i=l[u],Object.prototype.hasOwnProperty.call(o,i)&&o[i]&&p.push(o[i][0]),o[i]=0;for(r in s)Object.prototype.hasOwnProperty.call(s,r)&&(n[r]=s[r]);for(d&&d(e);p.length;)p.shift()();return a.push.apply(a,c||[]),t()}function t(){for(var n,e=0;e<a.length;e++){for(var t=a[e],r=!0,l=1;l<t.length;l++){var s=t[l];0!==o[s]&&(r=!1)}r&&(a.splice(e--,1),n=i(i.s=t[0]))}return n}var r={},o={1:0},a=[];function i(e){if(r[e])return r[e].exports;var t=r[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,i),t.l=!0,t.exports}i.e=function(n){var e=[],t=o[n];if(0!==t)if(t)e.push(t[2]);else{var r=new Promise((function(e,r){t=o[n]=[e,r]}));e.push(t[2]=r);var a,l=document.createElement("script");l.charset="utf-8",l.timeout=120,i.nc&&l.setAttribute("nonce",i.nc),l.src=function(n){return i.p+"assets/js/"+({}[n]||n)+"."+{2:"73d4029d",3:"ceab01f3",4:"a6d97bd6",5:"2729aef4",6:"18289d2c",7:"9ce784ab",8:"5a0ba8cc",9:"e78313b5",10:"2b19092b",11:"5d2d3328",12:"758d1773",13:"83080798",14:"cad064bf",15:"ce67be64",16:"7c331707",17:"353aa3a5",18:"812e388f",19:"bea0f1aa",20:"ae2220ed",21:"8b82ed1e",22:"97d63dbe",23:"79033cfd",24:"96ca227f",25:"90813872",26:"b18aba27",27:"f9995d4b",28:"31b6825c",29:"94237f71",30:"8269ef59",31:"c18e7c44",32:"06171ecb",33:"a33f1b11",34:"3e39f435",35:"6d245714",36:"c4063459",37:"5bbb13b5",38:"924e8c19",39:"e99c2fc3",40:"b8d5bbf4",41:"ea4edc48",42:"772aa8ee",43:"bb7e9285",44:"45df278e",45:"d55cceca",46:"0c8c51d9",47:"0e96e931",48:"7cd0eba4",49:"e46e4b79",50:"92ba3da6",51:"0202291b",52:"f92048a9",53:"07ceccc9",54:"4e07b215",55:"2e2bb8d4",56:"45e214fe",57:"4ce4a530",58:"f5cb3725",59:"d876d40f",60:"23938f5e",61:"80196175",62:"5f2ced9c",63:"424361b5",64:"63e35c1a",65:"dc44ac45",66:"bac24f77",67:"f2e38f54",68:"8eab7a58",69:"73bfbfca"}[n]+".js"}(n);var s=new Error;a=function(e){l.onerror=l.onload=null,clearTimeout(c);var t=o[n];if(0!==t){if(t){var r=e&&("load"===e.type?"missing":e.type),a=e&&e.target&&e.target.src;s.message="Loading chunk "+n+" failed.\n("+r+": "+a+")",s.name="ChunkLoadError",s.type=r,s.request=a,t[1](s)}o[n]=void 0}};var c=setTimeout((function(){a({type:"timeout",target:l})}),12e4);l.onerror=l.onload=a,document.head.appendChild(l)}return Promise.all(e)},i.m=n,i.c=r,i.d=function(n,e,t){i.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},i.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},i.t=function(n,e){if(1&e&&(n=i(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(i.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var r in n)i.d(t,r,function(e){return n[e]}.bind(null,r));return t},i.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return i.d(e,"a",e),e},i.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},i.p="/",i.oe=function(n){throw console.error(n),n};var l=window.webpackJsonp=window.webpackJsonp||[],s=l.push.bind(l);l.push=e,l=l.slice();for(var c=0;c<l.length;c++)e(l[c]);var d=s;a.push([103,0]),t()}([function(n,e,t){var r=t(55),o=r.all;n.exports=r.IS_HTMLDDA?function(n){return"function"==typeof n||n===o}:function(n){return"function"==typeof n}},function(n,e,t){var r=t(27),o=Function.prototype,a=o.call,i=r&&o.bind.bind(a,a);n.exports=r?i:function(n){return function(){return a.apply(n,arguments)}}},function(n,e){var t=function(n){return n&&n.Math==Math&&n};n.exports=t("object"==typeof globalThis&&globalThis)||t("object"==typeof window&&window)||t("object"==typeof self&&self)||t("object"==typeof global&&global)||function(){return this}()||this||Function("return this")()},function(n,e){n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e,t){var r=t(3);n.exports=!r((function(){return 7!=Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){var r=t(69),o="object"==typeof self&&self&&self.Object===Object&&self,a=r||o||Function("return this")();n.exports=a},function(n,e,t){"use strict";function r(n,e,t,r,o,a,i,l){var s,c="function"==typeof n?n.options:n;if(e&&(c.render=e,c.staticRenderFns=t,c._compiled=!0),r&&(c.functional=!0),a&&(c._scopeId="data-v-"+a),i?(s=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),o&&o.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(i)},c._ssrRegister=s):o&&(s=l?function(){o.call(this,(c.functional?this.parent:this).$root.$options.shadowRoot)}:o),s)if(c.functional){c._injectStyles=s;var d=c.render;c.render=function(n,e){return s.call(e),d(n,e)}}else{var u=c.beforeCreate;c.beforeCreate=u?[].concat(u,s):[s]}return{exports:n,options:c}}t.d(e,"a",(function(){return r}))},function(n,e,t){var r=t(1),o=t(32),a=r({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return a(o(n),e)}},function(n,e,t){var r=t(0),o=t(55),a=o.all;n.exports=o.IS_HTMLDDA?function(n){return"object"==typeof n?null!==n:r(n)||n===a}:function(n){return"object"==typeof n?null!==n:r(n)}},function(n,e,t){var r=t(163),o=t(166);n.exports=function(n,e){var t=o(n,e);return r(t)?t:void 0}},function(n,e,t){"use strict";t.d(e,"e",(function(){return r})),t.d(e,"b",(function(){return a})),t.d(e,"j",(function(){return i})),t.d(e,"g",(function(){return s})),t.d(e,"h",(function(){return c})),t.d(e,"i",(function(){return d})),t.d(e,"c",(function(){return u})),t.d(e,"f",(function(){return p})),t.d(e,"l",(function(){return g})),t.d(e,"m",(function(){return h})),t.d(e,"d",(function(){return m})),t.d(e,"k",(function(){return b})),t.d(e,"n",(function(){return x})),t.d(e,"a",(function(){return y}));t(16);const r=/#.*$/,o=/\.(md|html)$/,a=/\/$/,i=/^[a-z]+:/i;function l(n){return decodeURI(n).replace(r,"").replace(o,"")}function s(n){return i.test(n)}function c(n){return/^mailto:/.test(n)}function d(n){return/^tel:/.test(n)}function u(n){if(s(n))return n;if(!n)return"404";const e=n.match(r),t=e?e[0]:"",o=l(n);return a.test(o)?n:o+".html"+t}function p(n,e){const t=n.hash,o=function(n){const e=n&&n.match(r);if(e)return e[0]}(e);if(o&&t!==o)return!1;return l(n.path)===l(e)}function g(n,e,t){if(s(e))return{type:"external",path:e};t&&(e=function(n,e,t){const r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;const o=e.split("/");t&&o[o.length-1]||o.pop();const a=n.replace(/^\//,"").split("/");for(let n=0;n<a.length;n++){const e=a[n];".."===e?o.pop():"."!==e&&o.push(e)}""!==o[0]&&o.unshift("");return o.join("/")}(e,t));const r=l(e);for(let e=0;e<n.length;e++)if(l(n[e].regularPath)===r)return Object.assign({},n[e],{type:"page",path:u(n[e].path)});return console.error(`[vuepress] No matching page found for sidebar item "${e}"`),{}}function h(n,e,t,r){const{pages:o,themeConfig:a}=t,i=r&&a.locales&&a.locales[r]||a;if("auto"===(n.frontmatter.sidebar||i.sidebar||a.sidebar))return f(n);const l=i.sidebar||a.sidebar;if(l){const{base:t,config:r}=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(const r in e)if(0===(t=n,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(r)))return{base:r,config:e[r]};var t;return{}}(e,l);return"auto"===r?f(n):r?r.map(n=>function n(e,t,r,o=1){if("string"==typeof e)return g(t,e,r);if(Array.isArray(e))return Object.assign(g(t,e[0],r),{title:e[1]});{o>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const a=e.children||[];return 0===a.length&&e.path?Object.assign(g(t,e.path,r),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:a.map(e=>n(e,t,r,o+1)),collapsable:!1!==e.collapsable}}}(n,o,t)):[]}return[]}function f(n){const e=m(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map(e=>({type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}))}]}function m(n){let e;return(n=n.map(n=>Object.assign({},n))).forEach(n=>{2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)}),n.filter(n=>2===n.level)}function b(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function x(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function v(n){let e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function y(n,e){return v(e)-v(n)}},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){var r=t(15),o=t(148),a=t(149),i=r?r.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":i&&i in Object(n)?o(n):a(n)}},function(n,e,t){var r=t(4),o=t(17),a=t(35);n.exports=r?function(n,e,t){return o.f(n,e,a(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){var r=t(6).Symbol;n.exports=r},function(n,e,t){"use strict";var r=t(26),o=t(32),a=t(33),i=t(127),l=t(129);r({target:"Array",proto:!0,arity:1,forced:t(3)((function(){return 4294967297!==[].push.call({length:4294967296},1)}))||!function(){try{Object.defineProperty([],"length",{writable:!1}).push()}catch(n){return n instanceof TypeError}}()},{push:function(n){var e=o(this),t=a(e),r=arguments.length;l(t+r);for(var s=0;s<r;s++)e[t]=arguments[s],t++;return i(e,t),t}})},function(n,e,t){var r=t(4),o=t(64),a=t(98),i=t(25),l=t(54),s=TypeError,c=Object.defineProperty,d=Object.getOwnPropertyDescriptor;e.f=r?a?function(n,e,t){if(i(n),e=l(e),i(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var r=d(n,e);r&&r.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:r.configurable,enumerable:"enumerable"in t?t.enumerable:r.enumerable,writable:!1})}return c(n,e,t)}:c:function(n,e,t){if(i(n),e=l(e),i(t),o)try{return c(n,e,t)}catch(n){}if("get"in t||"set"in t)throw s("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var r=t(1),o=r({}.toString),a=r("".slice);n.exports=function(n){return a(o(n),8,-1)}},function(n,e,t){var r=t(153),o=t(154),a=t(155),i=t(156),l=t(157);function s(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}s.prototype.clear=r,s.prototype.delete=o,s.prototype.get=a,s.prototype.has=i,s.prototype.set=l,n.exports=s},function(n,e,t){var r=t(71);n.exports=function(n,e){for(var t=n.length;t--;)if(r(n[t][0],e))return t;return-1}},function(n,e,t){var r=t(10)(Object,"create");n.exports=r},function(n,e,t){var r=t(175);n.exports=function(n,e){var t=n.__data__;return r(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var r=t(45);n.exports=function(n){if("string"==typeof n||r(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var r,o;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(o="function"==typeof(r=function(){var n,e,t={version:"0.2.0"},r=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function o(n,e,t){return n<e?e:n>t?t:n}function a(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(r[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=o(n,r.minimum,1),t.status=1===n?null:n;var s=t.render(!e),c=s.querySelector(r.barSelector),d=r.speed,u=r.easing;return s.offsetWidth,i((function(e){""===r.positionUsing&&(r.positionUsing=t.getPositioningCSS()),l(c,function(n,e,t){var o;return(o="translate3d"===r.positionUsing?{transform:"translate3d("+a(n)+"%,0,0)"}:"translate"===r.positionUsing?{transform:"translate("+a(n)+"%,0)"}:{"margin-left":a(n)+"%"}).transition="all "+e+"ms "+t,o}(n,d,u)),1===n?(l(s,{transition:"none",opacity:1}),s.offsetWidth,setTimeout((function(){l(s,{transition:"all "+d+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),d)}),d)):setTimeout(e,d)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),r.trickleSpeed)};return r.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*o(Math.random()*e,.1,.95)),e=o(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*r.trickleRate)},n=0,e=0,t.promise=function(r){return r&&"resolved"!==r.state()?(0===e&&t.start(),n++,e++,r.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");c(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=r.template;var o,i=e.querySelector(r.barSelector),s=n?"-100":a(t.status||0),d=document.querySelector(r.parent);return l(i,{transition:"all 0 linear",transform:"translate3d("+s+"%,0,0)"}),r.showSpinner||(o=e.querySelector(r.spinnerSelector))&&p(o),d!=document.body&&c(d,"nprogress-custom-parent"),d.appendChild(e),e},t.remove=function(){d(document.documentElement,"nprogress-busy"),d(document.querySelector(r.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&p(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var i=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),l=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var r,o=n.length,a=e.charAt(0).toUpperCase()+e.slice(1);o--;)if((r=n[o]+a)in t)return r;return e}(t))}function r(n,e,r){e=t(e),n.style[e]=r}return function(n,e){var t,o,a=arguments;if(2==a.length)for(t in e)void 0!==(o=e[t])&&e.hasOwnProperty(t)&&r(n,t,o);else r(n,a[1],a[2])}}();function s(n,e){return("string"==typeof n?n:u(n)).indexOf(" "+e+" ")>=0}function c(n,e){var t=u(n),r=t+e;s(t,e)||(n.className=r.substring(1))}function d(n,e){var t,r=u(n);s(n,e)&&(t=r.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function u(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function p(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?r.call(e,t,e,n):r)||(n.exports=o)},function(n,e,t){var r=t(9),o=String,a=TypeError;n.exports=function(n){if(r(n))return n;throw a(o(n)+" is not an object")}},function(n,e,t){var r=t(2),o=t(51).f,a=t(14),i=t(111),l=t(37),s=t(65),c=t(123);n.exports=function(n,e){var t,d,u,p,g,h=n.target,f=n.global,m=n.stat;if(t=f?r:m?r[h]||l(h,{}):(r[h]||{}).prototype)for(d in e){if(p=e[d],u=n.dontCallGetSet?(g=o(t,d))&&g.value:t[d],!c(f?d:h+(m?".":"#")+d,n.forced)&&void 0!==u){if(typeof p==typeof u)continue;s(p,u)}(n.sham||u&&u.sham)&&a(p,"sham",!0),i(t,d,p,n)}}},function(n,e,t){var r=t(3);n.exports=!r((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e,t){var r=t(47),o=t(52);n.exports=function(n){return r(o(n))}},function(n,e,t){var r=t(2),o=t(0),a=function(n){return o(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?a(r[n]):r[n]&&r[n][e]}},function(n,e,t){var r=t(0),o=t(109),a=TypeError;n.exports=function(n){if(r(n))return n;throw a(o(n)+" is not a function")}},function(n,e,t){var r=t(2),o=t(61),a=t(8),i=t(63),l=t(59),s=t(58),c=r.Symbol,d=o("wks"),u=s?c.for||c:c&&c.withoutSetter||i;n.exports=function(n){return a(d,n)||(d[n]=l&&a(c,n)?c[n]:u("Symbol."+n)),d[n]}},function(n,e,t){var r=t(52),o=Object;n.exports=function(n){return o(r(n))}},function(n,e,t){var r=t(121);n.exports=function(n){return r(n.length)}},function(n,e,t){var r=t(27),o=Function.prototype.call;n.exports=r?o.bind(o):function(){return o.apply(o,arguments)}},function(n,e){n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){var r=t(2),o=t(37),a=r["__core-js_shared__"]||o("__core-js_shared__",{});n.exports=a},function(n,e,t){var r=t(2),o=Object.defineProperty;n.exports=function(n,e){try{o(r,n,{value:e,configurable:!0,writable:!0})}catch(t){r[n]=e}return e}},function(n,e,t){var r=t(147),o=t(12),a=Object.prototype,i=a.hasOwnProperty,l=a.propertyIsEnumerable,s=r(function(){return arguments}())?r:function(n){return o(n)&&i.call(n,"callee")&&!l.call(n,"callee")};n.exports=s},function(n,e,t){var r=t(10)(t(6),"Map");n.exports=r},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var r=t(167),o=t(174),a=t(176),i=t(177),l=t(178);function s(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}s.prototype.clear=r,s.prototype.delete=o,s.prototype.get=a,s.prototype.has=i,s.prototype.set=l,n.exports=s},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var r=t(5),o=t(45),a=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,i=/^\w*$/;n.exports=function(n,e){if(r(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!o(n))||(i.test(n)||!a.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var r=t(13),o=t(12);n.exports=function(n){return"symbol"==typeof n||o(n)&&"[object Symbol]"==r(n)}},function(n,e){n.exports=function(n){return n}},function(n,e,t){var r=t(1),o=t(3),a=t(18),i=Object,l=r("".split);n.exports=o((function(){return!i("z").propertyIsEnumerable(0)}))?function(n){return"String"==a(n)?l(n,""):i(n)}:i},function(n,e){n.exports={}},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e){var t=/^\s+|\s+$/g,r=/^[-+]0x[0-9a-f]+$/i,o=/^0b[01]+$/i,a=/^0o[0-7]+$/i,i=parseInt,l="object"==typeof global&&global&&global.Object===Object&&global,s="object"==typeof self&&self&&self.Object===Object&&self,c=l||s||Function("return this")(),d=Object.prototype.toString,u=Math.max,p=Math.min,g=function(){return c.Date.now()};function h(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function f(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==d.call(n)}(n))return NaN;if(h(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=h(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var l=o.test(n);return l||a.test(n)?i(n.slice(2),l?2:8):r.test(n)?NaN:+n}n.exports=function(n,e,t){var r,o,a,i,l,s,c=0,d=!1,m=!1,b=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function x(e){var t=r,a=o;return r=o=void 0,c=e,i=n.apply(a,t)}function v(n){return c=n,l=setTimeout(k,e),d?x(n):i}function y(n){var t=n-s;return void 0===s||t>=e||t<0||m&&n-c>=a}function k(){var n=g();if(y(n))return w(n);l=setTimeout(k,function(n){var t=e-(n-s);return m?p(t,a-(n-c)):t}(n))}function w(n){return l=void 0,b&&r?x(n):(r=o=void 0,i)}function S(){var n=g(),t=y(n);if(r=arguments,o=this,s=n,t){if(void 0===l)return v(s);if(m)return l=setTimeout(k,e),x(s)}return void 0===l&&(l=setTimeout(k,e)),i}return e=f(e)||0,h(t)&&(d=!!t.leading,a=(m="maxWait"in t)?u(f(t.maxWait)||0,e):a,b="trailing"in t?!!t.trailing:b),S.cancel=function(){void 0!==l&&clearTimeout(l),c=0,r=s=o=l=void 0},S.flush=function(){return void 0===l?i:w(g())},S}},function(n,e,t){var r=t(4),o=t(34),a=t(105),i=t(35),l=t(28),s=t(54),c=t(8),d=t(64),u=Object.getOwnPropertyDescriptor;e.f=r?u:function(n,e){if(n=l(n),e=s(e),d)try{return u(n,e)}catch(n){}if(c(n,e))return i(!o(a.f,n,e),n[e])}},function(n,e,t){var r=t(53),o=TypeError;n.exports=function(n){if(r(n))throw o("Can't call method on "+n);return n}},function(n,e){n.exports=function(n){return null==n}},function(n,e,t){var r=t(106),o=t(56);n.exports=function(n){var e=r(n,"string");return o(e)?e:e+""}},function(n,e){var t="object"==typeof document&&document.all,r=void 0===t&&void 0!==t;n.exports={all:t,IS_HTMLDDA:r}},function(n,e,t){var r=t(29),o=t(0),a=t(57),i=t(58),l=Object;n.exports=i?function(n){return"symbol"==typeof n}:function(n){var e=r("Symbol");return o(e)&&a(e.prototype,l(n))}},function(n,e,t){var r=t(1);n.exports=r({}.isPrototypeOf)},function(n,e,t){var r=t(59);n.exports=r&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){var r=t(60),o=t(3),a=t(2).String;n.exports=!!Object.getOwnPropertySymbols&&!o((function(){var n=Symbol();return!a(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&r&&r<41}))},function(n,e,t){var r,o,a=t(2),i=t(107),l=a.process,s=a.Deno,c=l&&l.versions||s&&s.version,d=c&&c.v8;d&&(o=(r=d.split("."))[0]>0&&r[0]<4?1:+(r[0]+r[1])),!o&&i&&(!(r=i.match(/Edge\/(\d+)/))||r[1]>=74)&&(r=i.match(/Chrome\/(\d+)/))&&(o=+r[1]),n.exports=o},function(n,e,t){var r=t(62),o=t(36);(n.exports=function(n,e){return o[n]||(o[n]=void 0!==e?e:{})})("versions",[]).push({version:"3.30.2",mode:r?"pure":"global",copyright:"© 2014-2023 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.30.2/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e){n.exports=!1},function(n,e,t){var r=t(1),o=0,a=Math.random(),i=r(1..toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+i(++o+a,36)}},function(n,e,t){var r=t(4),o=t(3),a=t(97);n.exports=!r&&!o((function(){return 7!=Object.defineProperty(a("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){var r=t(8),o=t(116),a=t(51),i=t(17);n.exports=function(n,e,t){for(var l=o(e),s=i.f,c=a.f,d=0;d<l.length;d++){var u=l[d];r(n,u)||t&&r(t,u)||s(n,u,c(e,u))}}},function(n,e,t){var r=t(120);n.exports=function(n){var e=+n;return e!=e||0===e?0:r(e)}},function(n,e,t){var r=t(133),o=t(25),a=t(134);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=r(Object.prototype,"__proto__","set"))(t,[]),e=t instanceof Array}catch(n){}return function(t,r){return o(t),a(r),e?n(t,r):t.__proto__=r,t}}():void 0)},function(n,e){n.exports=function(n,e){for(var t=-1,r=e.length,o=n.length;++t<r;)n[o+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var r=t(19),o=t(158),a=t(159),i=t(160),l=t(161),s=t(162);function c(n){var e=this.__data__=new r(n);this.size=e.size}c.prototype.clear=o,c.prototype.delete=a,c.prototype.get=i,c.prototype.has=l,c.prototype.set=s,n.exports=c},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var r=t(13),o=t(40);n.exports=function(n){if(!o(n))return!1;var e=r(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var r=t(179),o=t(12);n.exports=function n(e,t,a,i,l){return e===t||(null==e||null==t||!o(e)&&!o(t)?e!=e&&t!=t:r(e,t,a,i,n,l))}},function(n,e,t){var r=t(76),o=t(182),a=t(77);n.exports=function(n,e,t,i,l,s){var c=1&t,d=n.length,u=e.length;if(d!=u&&!(c&&u>d))return!1;var p=s.get(n),g=s.get(e);if(p&&g)return p==e&&g==n;var h=-1,f=!0,m=2&t?new r:void 0;for(s.set(n,e),s.set(e,n);++h<d;){var b=n[h],x=e[h];if(i)var v=c?i(x,b,h,e,n,s):i(b,x,h,n,e,s);if(void 0!==v){if(v)continue;f=!1;break}if(m){if(!o(e,(function(n,e){if(!a(m,e)&&(b===n||l(b,n,t,i,s)))return m.push(e)}))){f=!1;break}}else if(b!==x&&!l(b,x,t,i,s)){f=!1;break}}return s.delete(n),s.delete(e),f}},function(n,e,t){var r=t(41),o=t(180),a=t(181);function i(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new r;++e<t;)this.add(n[e])}i.prototype.add=i.prototype.push=o,i.prototype.has=a,n.exports=i},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var r=t(192),o=t(198),a=t(82);n.exports=function(n){return a(n)?r(n):o(n)}},function(n,e,t){(function(n){var r=t(6),o=t(194),a=e&&!e.nodeType&&e,i=a&&"object"==typeof n&&n&&!n.nodeType&&n,l=i&&i.exports===a?r.Buffer:void 0,s=(l?l.isBuffer:void 0)||o;n.exports=s}).call(this,t(49)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var r=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==r||"symbol"!=r&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var r=t(195),o=t(196),a=t(197),i=a&&a.isTypedArray,l=i?o(i):r;n.exports=l},function(n,e,t){var r=t(72),o=t(43);n.exports=function(n){return null!=n&&o(n.length)&&!r(n)}},function(n,e,t){var r=t(10)(t(6),"Set");n.exports=r},function(n,e,t){var r=t(40);n.exports=function(n){return n==n&&!r(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var r=t(87),o=t(23);n.exports=function(n,e){for(var t=0,a=(e=r(e,n)).length;null!=n&&t<a;)n=n[o(e[t++])];return t&&t==a?n:void 0}},function(n,e,t){var r=t(5),o=t(44),a=t(209),i=t(212);n.exports=function(n,e){return r(n)?n:o(n,e)?[n]:a(i(n))}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(145),o=t(150),a=t(221),i=t(229),l=t(238),s=t(102),c=a((function(n){var e=s(n);return l(e)&&(e=void 0),i(r(n,1,l,!0),o(e,2))}));n.exports=c},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var r=/["'&<>]/;n.exports=function(n){var e,t=""+n,o=r.exec(t);if(!o)return t;var a="",i=0,l=0;for(i=o.index;i<t.length;i++){switch(t.charCodeAt(i)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}l!==i&&(a+=t.substring(l,i)),l=i+1,a+=e}return l!==i?a+t.substring(l,i):a}},function(n,e,t){"use strict";t.r(e);var r={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},o=(t(241),t(7)),a=Object(o.a)(r,(function(){return(0,this._self._c)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);e.default=a.exports},function(n,e,t){"use strict";t.r(e);var r={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(n){this.codeTabs.forEach(n=>{n.elm.classList.remove("theme-code-block__active")}),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(n=>Boolean(n.componentOptions)).map((n,e)=>(""===n.componentOptions.propsData.active&&(this.activeCodeTabIndex=e),{title:n.componentOptions.propsData.title,elm:n.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(n){this.activeCodeTabIndex=n}}},o=(t(242),t(7)),a=Object(o.a)(r,(function(){var n=this,e=n._self._c;return e("div",{staticClass:"theme-code-group"},[e("div",{staticClass:"theme-code-group__nav"},[e("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(t,r){return e("li",{key:t.title,staticClass:"theme-code-group__li"},[e("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":r===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(r)}}},[n._v("\n            "+n._s(t.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?e("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"2f5f1757",null);e.default=a.exports},function(n,e){n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){var r=t(2),o=t(9),a=r.document,i=o(a)&&o(a.createElement);n.exports=function(n){return i?a.createElement(n):{}}},function(n,e,t){var r=t(4),o=t(3);n.exports=r&&o((function(){return 42!=Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){var r=t(1),o=t(3),a=t(0),i=t(8),l=t(4),s=t(112).CONFIGURABLE,c=t(113),d=t(114),u=d.enforce,p=d.get,g=String,h=Object.defineProperty,f=r("".slice),m=r("".replace),b=r([].join),x=l&&!o((function(){return 8!==h((function(){}),"length",{value:8}).length})),v=String(String).split("String"),y=n.exports=function(n,e,t){"Symbol("===f(g(e),0,7)&&(e="["+m(g(e),/^Symbol\(([^)]*)\)/,"$1")+"]"),t&&t.getter&&(e="get "+e),t&&t.setter&&(e="set "+e),(!i(n,"name")||s&&n.name!==e)&&(l?h(n,"name",{value:e,configurable:!0}):n.name=e),x&&t&&i(t,"arity")&&n.length!==t.arity&&h(n,"length",{value:t.arity});try{t&&i(t,"constructor")&&t.constructor?l&&h(n,"prototype",{writable:!1}):n.prototype&&(n.prototype=void 0)}catch(n){}var r=u(n);return i(r,"source")||(r.source=b(v,"string"==typeof e?e:"")),n};Function.prototype.toString=y((function(){return a(this)&&p(this).source||c(this)}),"toString")},function(n,e,t){var r=t(61),o=t(63),a=r("keys");n.exports=function(n){return a[n]||(a[n]=o(n))}},function(n,e,t){var r=t(1),o=t(8),a=t(28),i=t(118).indexOf,l=t(48),s=r([].push);n.exports=function(n,e){var t,r=a(n),c=0,d=[];for(t in r)!o(l,t)&&o(r,t)&&s(d,t);for(;e.length>c;)o(r,t=e[c++])&&(~i(d,t)||s(d,t));return d}},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){n.exports=t(247)},function(n,e,t){"use strict";var r=t(26),o=t(124).left,a=t(125),i=t(60);r({target:"Array",proto:!0,forced:!t(126)&&i>79&&i<83||!a("reduce")},{reduce:function(n){var e=arguments.length;return o(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r={}.propertyIsEnumerable,o=Object.getOwnPropertyDescriptor,a=o&&!r.call({1:2},1);e.f=a?function(n){var e=o(this,n);return!!e&&e.enumerable}:r},function(n,e,t){var r=t(34),o=t(9),a=t(56),i=t(108),l=t(110),s=t(31),c=TypeError,d=s("toPrimitive");n.exports=function(n,e){if(!o(n)||a(n))return n;var t,s=i(n,d);if(s){if(void 0===e&&(e="default"),t=r(s,n,e),!o(t)||a(t))return t;throw c("Can't convert object to primitive value")}return void 0===e&&(e="number"),l(n,e)}},function(n,e){n.exports="undefined"!=typeof navigator&&String(navigator.userAgent)||""},function(n,e,t){var r=t(30),o=t(53);n.exports=function(n,e){var t=n[e];return o(t)?void 0:r(t)}},function(n,e){var t=String;n.exports=function(n){try{return t(n)}catch(n){return"Object"}}},function(n,e,t){var r=t(34),o=t(0),a=t(9),i=TypeError;n.exports=function(n,e){var t,l;if("string"===e&&o(t=n.toString)&&!a(l=r(t,n)))return l;if(o(t=n.valueOf)&&!a(l=r(t,n)))return l;if("string"!==e&&o(t=n.toString)&&!a(l=r(t,n)))return l;throw i("Can't convert object to primitive value")}},function(n,e,t){var r=t(0),o=t(17),a=t(99),i=t(37);n.exports=function(n,e,t,l){l||(l={});var s=l.enumerable,c=void 0!==l.name?l.name:e;if(r(t)&&a(t,c,l),l.global)s?n[e]=t:i(e,t);else{try{l.unsafe?n[e]&&(s=!0):delete n[e]}catch(n){}s?n[e]=t:o.f(n,e,{value:t,enumerable:!1,configurable:!l.nonConfigurable,writable:!l.nonWritable})}return n}},function(n,e,t){var r=t(4),o=t(8),a=Function.prototype,i=r&&Object.getOwnPropertyDescriptor,l=o(a,"name"),s=l&&"something"===function(){}.name,c=l&&(!r||r&&i(a,"name").configurable);n.exports={EXISTS:l,PROPER:s,CONFIGURABLE:c}},function(n,e,t){var r=t(1),o=t(0),a=t(36),i=r(Function.toString);o(a.inspectSource)||(a.inspectSource=function(n){return i(n)}),n.exports=a.inspectSource},function(n,e,t){var r,o,a,i=t(115),l=t(2),s=t(9),c=t(14),d=t(8),u=t(36),p=t(100),g=t(48),h=l.TypeError,f=l.WeakMap;if(i||u.state){var m=u.state||(u.state=new f);m.get=m.get,m.has=m.has,m.set=m.set,r=function(n,e){if(m.has(n))throw h("Object already initialized");return e.facade=n,m.set(n,e),e},o=function(n){return m.get(n)||{}},a=function(n){return m.has(n)}}else{var b=p("state");g[b]=!0,r=function(n,e){if(d(n,b))throw h("Object already initialized");return e.facade=n,c(n,b,e),e},o=function(n){return d(n,b)?n[b]:{}},a=function(n){return d(n,b)}}n.exports={set:r,get:o,has:a,enforce:function(n){return a(n)?o(n):r(n,{})},getterFor:function(n){return function(e){var t;if(!s(e)||(t=o(e)).type!==n)throw h("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){var r=t(2),o=t(0),a=r.WeakMap;n.exports=o(a)&&/native code/.test(String(a))},function(n,e,t){var r=t(29),o=t(1),a=t(117),i=t(122),l=t(25),s=o([].concat);n.exports=r("Reflect","ownKeys")||function(n){var e=a.f(l(n)),t=i.f;return t?s(e,t(n)):e}},function(n,e,t){var r=t(101),o=t(96).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return r(n,o)}},function(n,e,t){var r=t(28),o=t(119),a=t(33),i=function(n){return function(e,t,i){var l,s=r(e),c=a(s),d=o(i,c);if(n&&t!=t){for(;c>d;)if((l=s[d++])!=l)return!0}else for(;c>d;d++)if((n||d in s)&&s[d]===t)return n||d||0;return!n&&-1}};n.exports={includes:i(!0),indexOf:i(!1)}},function(n,e,t){var r=t(66),o=Math.max,a=Math.min;n.exports=function(n,e){var t=r(n);return t<0?o(t+e,0):a(t,e)}},function(n,e){var t=Math.ceil,r=Math.floor;n.exports=Math.trunc||function(n){var e=+n;return(e>0?r:t)(e)}},function(n,e,t){var r=t(66),o=Math.min;n.exports=function(n){return n>0?o(r(n),9007199254740991):0}},function(n,e){e.f=Object.getOwnPropertySymbols},function(n,e,t){var r=t(3),o=t(0),a=/#|\.prototype\./,i=function(n,e){var t=s[l(n)];return t==d||t!=c&&(o(e)?r(e):!!e)},l=i.normalize=function(n){return String(n).replace(a,".").toLowerCase()},s=i.data={},c=i.NATIVE="N",d=i.POLYFILL="P";n.exports=i},function(n,e,t){var r=t(30),o=t(32),a=t(47),i=t(33),l=TypeError,s=function(n){return function(e,t,s,c){r(t);var d=o(e),u=a(d),p=i(d),g=n?p-1:0,h=n?-1:1;if(s<2)for(;;){if(g in u){c=u[g],g+=h;break}if(g+=h,n?g<0:p<=g)throw l("Reduce of empty array with no initial value")}for(;n?g>=0:p>g;g+=h)g in u&&(c=t(c,u[g],g,d));return c}};n.exports={left:s(!1),right:s(!0)}},function(n,e,t){"use strict";var r=t(3);n.exports=function(n,e){var t=[][n];return!!t&&r((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){var r=t(18);n.exports="undefined"!=typeof process&&"process"==r(process)},function(n,e,t){"use strict";var r=t(4),o=t(128),a=TypeError,i=Object.getOwnPropertyDescriptor,l=r&&!function(){if(void 0!==this)return!0;try{Object.defineProperty([],"length",{writable:!1}).length=1}catch(n){return n instanceof TypeError}}();n.exports=l?function(n,e){if(o(n)&&!i(n,"length").writable)throw a("Cannot set read only .length");return n.length=e}:function(n,e){return n.length=e}},function(n,e,t){var r=t(18);n.exports=Array.isArray||function(n){return"Array"==r(n)}},function(n,e){var t=TypeError;n.exports=function(n){if(n>9007199254740991)throw t("Maximum allowed index exceeded");return n}},function(n,e,t){var r=t(26),o=t(2),a=t(131),i=t(132),l=o.WebAssembly,s=7!==Error("e",{cause:7}).cause,c=function(n,e){var t={};t[n]=i(n,e,s),r({global:!0,constructor:!0,arity:1,forced:s},t)},d=function(n,e){if(l&&l[n]){var t={};t[n]=i("WebAssembly."+n,e,s),r({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:s},t)}};c("Error",(function(n){return function(e){return a(n,this,arguments)}})),c("EvalError",(function(n){return function(e){return a(n,this,arguments)}})),c("RangeError",(function(n){return function(e){return a(n,this,arguments)}})),c("ReferenceError",(function(n){return function(e){return a(n,this,arguments)}})),c("SyntaxError",(function(n){return function(e){return a(n,this,arguments)}})),c("TypeError",(function(n){return function(e){return a(n,this,arguments)}})),c("URIError",(function(n){return function(e){return a(n,this,arguments)}})),d("CompileError",(function(n){return function(e){return a(n,this,arguments)}})),d("LinkError",(function(n){return function(e){return a(n,this,arguments)}})),d("RuntimeError",(function(n){return function(e){return a(n,this,arguments)}}))},function(n,e,t){var r=t(27),o=Function.prototype,a=o.apply,i=o.call;n.exports="object"==typeof Reflect&&Reflect.apply||(r?i.bind(a):function(){return i.apply(a,arguments)})},function(n,e,t){"use strict";var r=t(29),o=t(8),a=t(14),i=t(57),l=t(67),s=t(65),c=t(135),d=t(136),u=t(137),p=t(141),g=t(142),h=t(4),f=t(62);n.exports=function(n,e,t,m){var b=m?2:1,x=n.split("."),v=x[x.length-1],y=r.apply(null,x);if(y){var k=y.prototype;if(!f&&o(k,"cause")&&delete k.cause,!t)return y;var w=r("Error"),S=e((function(n,e){var t=u(m?e:n,void 0),r=m?new y(n):new y;return void 0!==t&&a(r,"message",t),g(r,S,r.stack,2),this&&i(k,this)&&d(r,this,S),arguments.length>b&&p(r,arguments[b]),r}));if(S.prototype=k,"Error"!==v?l?l(S,w):s(S,w,{name:!0}):h&&"stackTraceLimit"in y&&(c(S,y,"stackTraceLimit"),c(S,y,"prepareStackTrace")),s(S,y),!f)try{k.name!==v&&a(k,"name",v),k.constructor=S}catch(n){}return S}}},function(n,e,t){var r=t(1),o=t(30);n.exports=function(n,e,t){try{return r(o(Object.getOwnPropertyDescriptor(n,e)[t]))}catch(n){}}},function(n,e,t){var r=t(0),o=String,a=TypeError;n.exports=function(n){if("object"==typeof n||r(n))return n;throw a("Can't set "+o(n)+" as a prototype")}},function(n,e,t){var r=t(17).f;n.exports=function(n,e,t){t in n||r(n,t,{configurable:!0,get:function(){return e[t]},set:function(n){e[t]=n}})}},function(n,e,t){var r=t(0),o=t(9),a=t(67);n.exports=function(n,e,t){var i,l;return a&&r(i=e.constructor)&&i!==t&&o(l=i.prototype)&&l!==t.prototype&&a(n,l),n}},function(n,e,t){var r=t(138);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:r(n)}},function(n,e,t){var r=t(139),o=String;n.exports=function(n){if("Symbol"===r(n))throw TypeError("Cannot convert a Symbol value to a string");return o(n)}},function(n,e,t){var r=t(140),o=t(0),a=t(18),i=t(31)("toStringTag"),l=Object,s="Arguments"==a(function(){return arguments}());n.exports=r?a:function(n){var e,t,r;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=l(n),i))?t:s?a(e):"Object"==(r=a(e))&&o(e.callee)?"Arguments":r}},function(n,e,t){var r={};r[t(31)("toStringTag")]="z",n.exports="[object z]"===String(r)},function(n,e,t){var r=t(9),o=t(14);n.exports=function(n,e){r(e)&&"cause"in e&&o(n,"cause",e.cause)}},function(n,e,t){var r=t(14),o=t(143),a=t(144),i=Error.captureStackTrace;n.exports=function(n,e,t,l){a&&(i?i(n,e):r(n,"stack",o(t,l)))}},function(n,e,t){var r=t(1),o=Error,a=r("".replace),i=String(o("zxcasd").stack),l=/\n\s*at [^:]*:[^\n]*/,s=l.test(i);n.exports=function(n,e){if(s&&"string"==typeof n&&!o.prepareStackTrace)for(;e--;)n=a(n,l,"");return n}},function(n,e,t){var r=t(3),o=t(35);n.exports=!r((function(){var n=Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",o(1,7)),7!==n.stack)}))},function(n,e,t){var r=t(68),o=t(146);n.exports=function n(e,t,a,i,l){var s=-1,c=e.length;for(a||(a=o),l||(l=[]);++s<c;){var d=e[s];t>0&&a(d)?t>1?n(d,t-1,a,i,l):r(l,d):i||(l[l.length]=d)}return l}},function(n,e,t){var r=t(15),o=t(38),a=t(5),i=r?r.isConcatSpreadable:void 0;n.exports=function(n){return a(n)||o(n)||!!(i&&n&&n[i])}},function(n,e,t){var r=t(13),o=t(12);n.exports=function(n){return o(n)&&"[object Arguments]"==r(n)}},function(n,e,t){var r=t(15),o=Object.prototype,a=o.hasOwnProperty,i=o.toString,l=r?r.toStringTag:void 0;n.exports=function(n){var e=a.call(n,l),t=n[l];try{n[l]=void 0;var r=!0}catch(n){}var o=i.call(n);return r&&(e?n[l]=t:delete n[l]),o}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var r=t(151),o=t(207),a=t(46),i=t(5),l=t(218);n.exports=function(n){return"function"==typeof n?n:null==n?a:"object"==typeof n?i(n)?o(n[0],n[1]):r(n):l(n)}},function(n,e,t){var r=t(152),o=t(206),a=t(85);n.exports=function(n){var e=o(n);return 1==e.length&&e[0][2]?a(e[0][0],e[0][1]):function(t){return t===n||r(t,n,e)}}},function(n,e,t){var r=t(70),o=t(74);n.exports=function(n,e,t,a){var i=t.length,l=i,s=!a;if(null==n)return!l;for(n=Object(n);i--;){var c=t[i];if(s&&c[2]?c[1]!==n[c[0]]:!(c[0]in n))return!1}for(;++i<l;){var d=(c=t[i])[0],u=n[d],p=c[1];if(s&&c[2]){if(void 0===u&&!(d in n))return!1}else{var g=new r;if(a)var h=a(u,p,d,n,e,g);if(!(void 0===h?o(p,u,3,a,g):h))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var r=t(20),o=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=r(e,n);return!(t<0)&&(t==e.length-1?e.pop():o.call(e,t,1),--this.size,!0)}},function(n,e,t){var r=t(20);n.exports=function(n){var e=this.__data__,t=r(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var r=t(20);n.exports=function(n){return r(this.__data__,n)>-1}},function(n,e,t){var r=t(20);n.exports=function(n,e){var t=this.__data__,o=r(t,n);return o<0?(++this.size,t.push([n,e])):t[o][1]=e,this}},function(n,e,t){var r=t(19);n.exports=function(){this.__data__=new r,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var r=t(19),o=t(39),a=t(41);n.exports=function(n,e){var t=this.__data__;if(t instanceof r){var i=t.__data__;if(!o||i.length<199)return i.push([n,e]),this.size=++t.size,this;t=this.__data__=new a(i)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var r=t(72),o=t(164),a=t(40),i=t(73),l=/^\[object .+?Constructor\]$/,s=Function.prototype,c=Object.prototype,d=s.toString,u=c.hasOwnProperty,p=RegExp("^"+d.call(u).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!a(n)||o(n))&&(r(n)?p:l).test(i(n))}},function(n,e,t){var r,o=t(165),a=(r=/[^.]+$/.exec(o&&o.keys&&o.keys.IE_PROTO||""))?"Symbol(src)_1."+r:"";n.exports=function(n){return!!a&&a in n}},function(n,e,t){var r=t(6)["__core-js_shared__"];n.exports=r},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var r=t(168),o=t(19),a=t(39);n.exports=function(){this.size=0,this.__data__={hash:new r,map:new(a||o),string:new r}}},function(n,e,t){var r=t(169),o=t(170),a=t(171),i=t(172),l=t(173);function s(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}s.prototype.clear=r,s.prototype.delete=o,s.prototype.get=a,s.prototype.has=i,s.prototype.set=l,n.exports=s},function(n,e,t){var r=t(21);n.exports=function(){this.__data__=r?r(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var r=t(21),o=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(r){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return o.call(e,n)?e[n]:void 0}},function(n,e,t){var r=t(21),o=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return r?void 0!==e[n]:o.call(e,n)}},function(n,e,t){var r=t(21);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=r&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var r=t(22);n.exports=function(n){var e=r(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var r=t(22);n.exports=function(n){return r(this,n).get(n)}},function(n,e,t){var r=t(22);n.exports=function(n){return r(this,n).has(n)}},function(n,e,t){var r=t(22);n.exports=function(n,e){var t=r(this,n),o=t.size;return t.set(n,e),this.size+=t.size==o?0:1,this}},function(n,e,t){var r=t(70),o=t(75),a=t(183),i=t(186),l=t(202),s=t(5),c=t(79),d=t(81),u="[object Object]",p=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,g,h,f){var m=s(n),b=s(e),x=m?"[object Array]":l(n),v=b?"[object Array]":l(e),y=(x="[object Arguments]"==x?u:x)==u,k=(v="[object Arguments]"==v?u:v)==u,w=x==v;if(w&&c(n)){if(!c(e))return!1;m=!0,y=!1}if(w&&!y)return f||(f=new r),m||d(n)?o(n,e,t,g,h,f):a(n,e,x,t,g,h,f);if(!(1&t)){var S=y&&p.call(n,"__wrapped__"),j=k&&p.call(e,"__wrapped__");if(S||j){var T=S?n.value():n,_=j?e.value():e;return f||(f=new r),h(T,_,t,g,f)}}return!!w&&(f||(f=new r),i(n,e,t,g,h,f))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length;++t<r;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var r=t(15),o=t(184),a=t(71),i=t(75),l=t(185),s=t(42),c=r?r.prototype:void 0,d=c?c.valueOf:void 0;n.exports=function(n,e,t,r,c,u,p){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!u(new o(n),new o(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return a(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var g=l;case"[object Set]":var h=1&r;if(g||(g=s),n.size!=e.size&&!h)return!1;var f=p.get(n);if(f)return f==e;r|=2,p.set(n,e);var m=i(g(n),g(e),r,c,u,p);return p.delete(n),m;case"[object Symbol]":if(d)return d.call(n)==d.call(e)}return!1}},function(n,e,t){var r=t(6).Uint8Array;n.exports=r},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,r){t[++e]=[r,n]})),t}},function(n,e,t){var r=t(187),o=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,a,i,l){var s=1&t,c=r(n),d=c.length;if(d!=r(e).length&&!s)return!1;for(var u=d;u--;){var p=c[u];if(!(s?p in e:o.call(e,p)))return!1}var g=l.get(n),h=l.get(e);if(g&&h)return g==e&&h==n;var f=!0;l.set(n,e),l.set(e,n);for(var m=s;++u<d;){var b=n[p=c[u]],x=e[p];if(a)var v=s?a(x,b,p,e,n,l):a(b,x,p,n,e,l);if(!(void 0===v?b===x||i(b,x,t,a,l):v)){f=!1;break}m||(m="constructor"==p)}if(f&&!m){var y=n.constructor,k=e.constructor;y==k||!("constructor"in n)||!("constructor"in e)||"function"==typeof y&&y instanceof y&&"function"==typeof k&&k instanceof k||(f=!1)}return l.delete(n),l.delete(e),f}},function(n,e,t){var r=t(188),o=t(189),a=t(78);n.exports=function(n){return r(n,a,o)}},function(n,e,t){var r=t(68),o=t(5);n.exports=function(n,e,t){var a=e(n);return o(n)?a:r(a,t(n))}},function(n,e,t){var r=t(190),o=t(191),a=Object.prototype.propertyIsEnumerable,i=Object.getOwnPropertySymbols,l=i?function(n){return null==n?[]:(n=Object(n),r(i(n),(function(e){return a.call(n,e)})))}:o;n.exports=l},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,o=0,a=[];++t<r;){var i=n[t];e(i,t,n)&&(a[o++]=i)}return a}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var r=t(193),o=t(38),a=t(5),i=t(79),l=t(80),s=t(81),c=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=a(n),d=!t&&o(n),u=!t&&!d&&i(n),p=!t&&!d&&!u&&s(n),g=t||d||u||p,h=g?r(n.length,String):[],f=h.length;for(var m in n)!e&&!c.call(n,m)||g&&("length"==m||u&&("offset"==m||"parent"==m)||p&&("buffer"==m||"byteLength"==m||"byteOffset"==m)||l(m,f))||h.push(m);return h}},function(n,e){n.exports=function(n,e){for(var t=-1,r=Array(n);++t<n;)r[t]=e(t);return r}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var r=t(13),o=t(43),a=t(12),i={};i["[object Float32Array]"]=i["[object Float64Array]"]=i["[object Int8Array]"]=i["[object Int16Array]"]=i["[object Int32Array]"]=i["[object Uint8Array]"]=i["[object Uint8ClampedArray]"]=i["[object Uint16Array]"]=i["[object Uint32Array]"]=!0,i["[object Arguments]"]=i["[object Array]"]=i["[object ArrayBuffer]"]=i["[object Boolean]"]=i["[object DataView]"]=i["[object Date]"]=i["[object Error]"]=i["[object Function]"]=i["[object Map]"]=i["[object Number]"]=i["[object Object]"]=i["[object RegExp]"]=i["[object Set]"]=i["[object String]"]=i["[object WeakMap]"]=!1,n.exports=function(n){return a(n)&&o(n.length)&&!!i[r(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var r=t(69),o=e&&!e.nodeType&&e,a=o&&"object"==typeof n&&n&&!n.nodeType&&n,i=a&&a.exports===o&&r.process,l=function(){try{var n=a&&a.require&&a.require("util").types;return n||i&&i.binding&&i.binding("util")}catch(n){}}();n.exports=l}).call(this,t(49)(n))},function(n,e,t){var r=t(199),o=t(200),a=Object.prototype.hasOwnProperty;n.exports=function(n){if(!r(n))return o(n);var e=[];for(var t in Object(n))a.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var r=t(201)(Object.keys,Object);n.exports=r},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var r=t(203),o=t(39),a=t(204),i=t(83),l=t(205),s=t(13),c=t(73),d=c(r),u=c(o),p=c(a),g=c(i),h=c(l),f=s;(r&&"[object DataView]"!=f(new r(new ArrayBuffer(1)))||o&&"[object Map]"!=f(new o)||a&&"[object Promise]"!=f(a.resolve())||i&&"[object Set]"!=f(new i)||l&&"[object WeakMap]"!=f(new l))&&(f=function(n){var e=s(n),t="[object Object]"==e?n.constructor:void 0,r=t?c(t):"";if(r)switch(r){case d:return"[object DataView]";case u:return"[object Map]";case p:return"[object Promise]";case g:return"[object Set]";case h:return"[object WeakMap]"}return e}),n.exports=f},function(n,e,t){var r=t(10)(t(6),"DataView");n.exports=r},function(n,e,t){var r=t(10)(t(6),"Promise");n.exports=r},function(n,e,t){var r=t(10)(t(6),"WeakMap");n.exports=r},function(n,e,t){var r=t(84),o=t(78);n.exports=function(n){for(var e=o(n),t=e.length;t--;){var a=e[t],i=n[a];e[t]=[a,i,r(i)]}return e}},function(n,e,t){var r=t(74),o=t(208),a=t(215),i=t(44),l=t(84),s=t(85),c=t(23);n.exports=function(n,e){return i(n)&&l(e)?s(c(n),e):function(t){var i=o(t,n);return void 0===i&&i===e?a(t,n):r(e,i,3)}}},function(n,e,t){var r=t(86);n.exports=function(n,e,t){var o=null==n?void 0:r(n,e);return void 0===o?t:o}},function(n,e,t){var r=t(210),o=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,a=/\\(\\)?/g,i=r((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(o,(function(n,t,r,o){e.push(r?o.replace(a,"$1"):t||n)})),e}));n.exports=i},function(n,e,t){var r=t(211);n.exports=function(n){var e=r(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var r=t(41);function o(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var r=arguments,o=e?e.apply(this,r):r[0],a=t.cache;if(a.has(o))return a.get(o);var i=n.apply(this,r);return t.cache=a.set(o,i)||a,i};return t.cache=new(o.Cache||r),t}o.Cache=r,n.exports=o},function(n,e,t){var r=t(213);n.exports=function(n){return null==n?"":r(n)}},function(n,e,t){var r=t(15),o=t(214),a=t(5),i=t(45),l=r?r.prototype:void 0,s=l?l.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(a(e))return o(e,n)+"";if(i(e))return s?s.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,o=Array(r);++t<r;)o[t]=e(n[t],t,n);return o}},function(n,e,t){var r=t(216),o=t(217);n.exports=function(n,e){return null!=n&&o(n,e,r)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var r=t(87),o=t(38),a=t(5),i=t(80),l=t(43),s=t(23);n.exports=function(n,e,t){for(var c=-1,d=(e=r(e,n)).length,u=!1;++c<d;){var p=s(e[c]);if(!(u=null!=n&&t(n,p)))break;n=n[p]}return u||++c!=d?u:!!(d=null==n?0:n.length)&&l(d)&&i(p,d)&&(a(n)||o(n))}},function(n,e,t){var r=t(219),o=t(220),a=t(44),i=t(23);n.exports=function(n){return a(n)?r(i(n)):o(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var r=t(86);n.exports=function(n){return function(e){return r(e,n)}}},function(n,e,t){var r=t(46),o=t(222),a=t(224);n.exports=function(n,e){return a(o(n,e,r),n+"")}},function(n,e,t){var r=t(223),o=Math.max;n.exports=function(n,e,t){return e=o(void 0===e?n.length-1:e,0),function(){for(var a=arguments,i=-1,l=o(a.length-e,0),s=Array(l);++i<l;)s[i]=a[e+i];i=-1;for(var c=Array(e+1);++i<e;)c[i]=a[i];return c[e]=t(s),r(n,this,c)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var r=t(225),o=t(228)(r);n.exports=o},function(n,e,t){var r=t(226),o=t(227),a=t(46),i=o?function(n,e){return o(n,"toString",{configurable:!0,enumerable:!1,value:r(e),writable:!0})}:a;n.exports=i},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var r=t(10),o=function(){try{var n=r(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=o},function(n,e){var t=Date.now;n.exports=function(n){var e=0,r=0;return function(){var o=t(),a=16-(o-r);if(r=o,a>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var r=t(76),o=t(230),a=t(235),i=t(77),l=t(236),s=t(42);n.exports=function(n,e,t){var c=-1,d=o,u=n.length,p=!0,g=[],h=g;if(t)p=!1,d=a;else if(u>=200){var f=e?null:l(n);if(f)return s(f);p=!1,d=i,h=new r}else h=e?[]:g;n:for(;++c<u;){var m=n[c],b=e?e(m):m;if(m=t||0!==m?m:0,p&&b==b){for(var x=h.length;x--;)if(h[x]===b)continue n;e&&h.push(b),g.push(m)}else d(h,b,t)||(h!==g&&h.push(b),g.push(m))}return g}},function(n,e,t){var r=t(231);n.exports=function(n,e){return!!(null==n?0:n.length)&&r(n,e,0)>-1}},function(n,e,t){var r=t(232),o=t(233),a=t(234);n.exports=function(n,e,t){return e==e?a(n,e,t):r(n,o,t)}},function(n,e){n.exports=function(n,e,t,r){for(var o=n.length,a=t+(r?1:-1);r?a--:++a<o;)if(e(n[a],a,n))return a;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var r=t-1,o=n.length;++r<o;)if(n[r]===e)return r;return-1}},function(n,e){n.exports=function(n,e,t){for(var r=-1,o=null==n?0:n.length;++r<o;)if(t(e,n[r]))return!0;return!1}},function(n,e,t){var r=t(83),o=t(237),a=t(42),i=r&&1/a(new r([,-0]))[1]==1/0?function(n){return new r(n)}:o;n.exports=i},function(n,e){n.exports=function(){}},function(n,e,t){var r=t(82),o=t(12);n.exports=function(n){return o(n)&&r(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(88)},function(n,e,t){"use strict";t(89)},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(90)},function(n,e,t){"use strict";t(91)},function(n,e,t){"use strict";t.r(e);
/*!
 * Vue.js v2.7.14
 * (c) 2014-2022 Evan You
 * Released under the MIT License.
 */
var r=Object.freeze({}),o=Array.isArray;function a(n){return null==n}function i(n){return null!=n}function l(n){return!0===n}function s(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function c(n){return"function"==typeof n}function d(n){return null!==n&&"object"==typeof n}var u=Object.prototype.toString;function p(n){return"[object Object]"===u.call(n)}function g(n){return"[object RegExp]"===u.call(n)}function h(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function f(n){return i(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function m(n){return null==n?"":Array.isArray(n)||p(n)&&n.toString===u?JSON.stringify(n,null,2):String(n)}function b(n){var e=parseFloat(n);return isNaN(e)?n:e}function x(n,e){for(var t=Object.create(null),r=n.split(","),o=0;o<r.length;o++)t[r[o]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}x("slot,component",!0);var v=x("key,ref,slot,slot-scope,is");function y(n,e){var t=n.length;if(t){if(e===n[t-1])return void(n.length=t-1);var r=n.indexOf(e);if(r>-1)return n.splice(r,1)}}var k=Object.prototype.hasOwnProperty;function w(n,e){return k.call(n,e)}function S(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var j=/-(\w)/g,T=S((function(n){return n.replace(j,(function(n,e){return e?e.toUpperCase():""}))})),_=S((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),C=/\B([A-Z])/g,E=S((function(n){return n.replace(C,"-$1").toLowerCase()}));var I=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var r=arguments.length;return r?r>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function A(n,e){e=e||0;for(var t=n.length-e,r=new Array(t);t--;)r[t]=n[t+e];return r}function P(n,e){for(var t in e)n[t]=e[t];return n}function L(n){for(var e={},t=0;t<n.length;t++)n[t]&&P(e,n[t]);return e}function R(n,e,t){}var B=function(n,e,t){return!1},O=function(n){return n};function N(n,e){if(n===e)return!0;var t=d(n),r=d(e);if(!t||!r)return!t&&!r&&String(n)===String(e);try{var o=Array.isArray(n),a=Array.isArray(e);if(o&&a)return n.length===e.length&&n.every((function(n,t){return N(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(o||a)return!1;var i=Object.keys(n),l=Object.keys(e);return i.length===l.length&&i.every((function(t){return N(n[t],e[t])}))}catch(n){return!1}}function M(n,e){for(var t=0;t<n.length;t++)if(N(n[t],e))return t;return-1}function z(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}function D(n,e){return n===e?0===n&&1/n!=1/e:n==n||e==e}var q=["component","directive","filter"],J=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],F={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:B,isReservedAttr:B,isUnknownElement:B,getTagNamespace:R,parsePlatformTagName:O,mustUseProp:B,async:!0,_lifecycleHooks:J},U=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function H(n){var e=(n+"").charCodeAt(0);return 36===e||95===e}function X(n,e,t,r){Object.defineProperty(n,e,{value:t,enumerable:!!r,writable:!0,configurable:!0})}var $=new RegExp("[^".concat(U.source,".$_\\d]"));var W="__proto__"in{},Q="undefined"!=typeof window,G=Q&&window.navigator.userAgent.toLowerCase(),V=G&&/msie|trident/.test(G),K=G&&G.indexOf("msie 9.0")>0,Z=G&&G.indexOf("edge/")>0;G&&G.indexOf("android");var Y=G&&/iphone|ipad|ipod|ios/.test(G);G&&/chrome\/\d+/.test(G),G&&/phantomjs/.test(G);var nn,en=G&&G.match(/firefox\/(\d+)/),tn={}.watch,rn=!1;if(Q)try{var on={};Object.defineProperty(on,"passive",{get:function(){rn=!0}}),window.addEventListener("test-passive",null,on)}catch(n){}var an=function(){return void 0===nn&&(nn=!Q&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),nn},ln=Q&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function sn(n){return"function"==typeof n&&/native code/.test(n.toString())}var cn,dn="undefined"!=typeof Symbol&&sn(Symbol)&&"undefined"!=typeof Reflect&&sn(Reflect.ownKeys);cn="undefined"!=typeof Set&&sn(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var un=null;function pn(n){void 0===n&&(n=null),n||un&&un._scope.off(),un=n,n&&n._scope.on()}var gn=function(){function n(n,e,t,r,o,a,i,l){this.tag=n,this.data=e,this.children=t,this.text=r,this.elm=o,this.ns=void 0,this.context=a,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=i,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=l,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(n.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),n}(),hn=function(n){void 0===n&&(n="");var e=new gn;return e.text=n,e.isComment=!0,e};function fn(n){return new gn(void 0,void 0,void 0,String(n))}function mn(n){var e=new gn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}var bn=0,xn=[],vn=function(){function n(){this._pending=!1,this.id=bn++,this.subs=[]}return n.prototype.addSub=function(n){this.subs.push(n)},n.prototype.removeSub=function(n){this.subs[this.subs.indexOf(n)]=null,this._pending||(this._pending=!0,xn.push(this))},n.prototype.depend=function(e){n.target&&n.target.addDep(this)},n.prototype.notify=function(n){var e=this.subs.filter((function(n){return n}));for(var t=0,r=e.length;t<r;t++){0,e[t].update()}},n}();vn.target=null;var yn=[];function kn(n){yn.push(n),vn.target=n}function wn(){yn.pop(),vn.target=yn[yn.length-1]}var Sn=Array.prototype,jn=Object.create(Sn);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=Sn[n];X(jn,n,(function(){for(var t=[],r=0;r<arguments.length;r++)t[r]=arguments[r];var o,a=e.apply(this,t),i=this.__ob__;switch(n){case"push":case"unshift":o=t;break;case"splice":o=t.slice(2)}return o&&i.observeArray(o),i.dep.notify(),a}))}));var Tn=Object.getOwnPropertyNames(jn),_n={},Cn=!0;function En(n){Cn=n}var In={notify:R,depend:R,addSub:R,removeSub:R},An=function(){function n(n,e,t){if(void 0===e&&(e=!1),void 0===t&&(t=!1),this.value=n,this.shallow=e,this.mock=t,this.dep=t?In:new vn,this.vmCount=0,X(n,"__ob__",this),o(n)){if(!t)if(W)n.__proto__=jn;else for(var r=0,a=Tn.length;r<a;r++){X(n,l=Tn[r],jn[l])}e||this.observeArray(n)}else{var i=Object.keys(n);for(r=0;r<i.length;r++){var l;Ln(n,l=i[r],_n,void 0,e,t)}}}return n.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)Pn(n[e],!1,this.mock)},n}();function Pn(n,e,t){return n&&w(n,"__ob__")&&n.__ob__ instanceof An?n.__ob__:!Cn||!t&&an()||!o(n)&&!p(n)||!Object.isExtensible(n)||n.__v_skip||Dn(n)||n instanceof gn?void 0:new An(n,e,t)}function Ln(n,e,t,r,a,i){var l=new vn,s=Object.getOwnPropertyDescriptor(n,e);if(!s||!1!==s.configurable){var c=s&&s.get,d=s&&s.set;c&&!d||t!==_n&&2!==arguments.length||(t=n[e]);var u=!a&&Pn(t,!1,i);return Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=c?c.call(n):t;return vn.target&&(l.depend(),u&&(u.dep.depend(),o(e)&&On(e))),Dn(e)&&!a?e.value:e},set:function(e){var r=c?c.call(n):t;if(D(r,e)){if(d)d.call(n,e);else{if(c)return;if(!a&&Dn(r)&&!Dn(e))return void(r.value=e);t=e}u=!a&&Pn(e,!1,i),l.notify()}}}),l}}function Rn(n,e,t){if(!zn(n)){var r=n.__ob__;return o(n)&&h(e)?(n.length=Math.max(n.length,e),n.splice(e,1,t),r&&!r.shallow&&r.mock&&Pn(t,!1,!0),t):e in n&&!(e in Object.prototype)?(n[e]=t,t):n._isVue||r&&r.vmCount?t:r?(Ln(r.value,e,t,void 0,r.shallow,r.mock),r.dep.notify(),t):(n[e]=t,t)}}function Bn(n,e){if(o(n)&&h(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||zn(n)||w(n,e)&&(delete n[e],t&&t.dep.notify())}}function On(n){for(var e=void 0,t=0,r=n.length;t<r;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),o(e)&&On(e)}function Nn(n){return Mn(n,!0),X(n,"__v_isShallow",!0),n}function Mn(n,e){if(!zn(n)){Pn(n,e,an());0}}function zn(n){return!(!n||!n.__v_isReadonly)}function Dn(n){return!(!n||!0!==n.__v_isRef)}function qn(n,e,t){Object.defineProperty(n,t,{enumerable:!0,configurable:!0,get:function(){var n=e[t];if(Dn(n))return n.value;var r=n&&n.__ob__;return r&&r.dep.depend(),n},set:function(n){var r=e[t];Dn(r)&&!Dn(n)?r.value=n:e[t]=n}})}"".concat("watcher"," callback"),"".concat("watcher"," getter"),"".concat("watcher"," cleanup");var Jn;var Fn=function(){function n(n){void 0===n&&(n=!1),this.detached=n,this.active=!0,this.effects=[],this.cleanups=[],this.parent=Jn,!n&&Jn&&(this.index=(Jn.scopes||(Jn.scopes=[])).push(this)-1)}return n.prototype.run=function(n){if(this.active){var e=Jn;try{return Jn=this,n()}finally{Jn=e}}else 0},n.prototype.on=function(){Jn=this},n.prototype.off=function(){Jn=this.parent},n.prototype.stop=function(n){if(this.active){var e=void 0,t=void 0;for(e=0,t=this.effects.length;e<t;e++)this.effects[e].teardown();for(e=0,t=this.cleanups.length;e<t;e++)this.cleanups[e]();if(this.scopes)for(e=0,t=this.scopes.length;e<t;e++)this.scopes[e].stop(!0);if(!this.detached&&this.parent&&!n){var r=this.parent.scopes.pop();r&&r!==this&&(this.parent.scopes[this.index]=r,r.index=this.index)}this.parent=void 0,this.active=!1}},n}();function Un(n){var e=n._provided,t=n.$parent&&n.$parent._provided;return t===e?n._provided=Object.create(t):e}var Hn=S((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),r="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=r?n.slice(1):n,once:t,capture:r,passive:e}}));function Xn(n,e){function t(){var n=t.fns;if(!o(n))return Ce(n,null,arguments,e,"v-on handler");for(var r=n.slice(),a=0;a<r.length;a++)Ce(r[a],null,arguments,e,"v-on handler")}return t.fns=n,t}function $n(n,e,t,r,o,i){var s,c,d,u;for(s in n)c=n[s],d=e[s],u=Hn(s),a(c)||(a(d)?(a(c.fns)&&(c=n[s]=Xn(c,i)),l(u.once)&&(c=n[s]=o(u.name,c,u.capture)),t(u.name,c,u.capture,u.passive,u.params)):c!==d&&(d.fns=c,n[s]=d));for(s in e)a(n[s])&&r((u=Hn(s)).name,e[s],u.capture)}function Wn(n,e,t){var r;n instanceof gn&&(n=n.data.hook||(n.data.hook={}));var o=n[e];function s(){t.apply(this,arguments),y(r.fns,s)}a(o)?r=Xn([s]):i(o.fns)&&l(o.merged)?(r=o).fns.push(s):r=Xn([o,s]),r.merged=!0,n[e]=r}function Qn(n,e,t,r,o){if(i(e)){if(w(e,t))return n[t]=e[t],o||delete e[t],!0;if(w(e,r))return n[t]=e[r],o||delete e[r],!0}return!1}function Gn(n){return s(n)?[fn(n)]:o(n)?function n(e,t){var r,c,d,u,p=[];for(r=0;r<e.length;r++)a(c=e[r])||"boolean"==typeof c||(d=p.length-1,u=p[d],o(c)?c.length>0&&(Vn((c=n(c,"".concat(t||"","_").concat(r)))[0])&&Vn(u)&&(p[d]=fn(u.text+c[0].text),c.shift()),p.push.apply(p,c)):s(c)?Vn(u)?p[d]=fn(u.text+c):""!==c&&p.push(fn(c)):Vn(c)&&Vn(u)?p[d]=fn(u.text+c.text):(l(e._isVList)&&i(c.tag)&&a(c.key)&&i(t)&&(c.key="__vlist".concat(t,"_").concat(r,"__")),p.push(c)));return p}(n):void 0}function Vn(n){return i(n)&&i(n.text)&&!1===n.isComment}function Kn(n,e){var t,r,a,l,s=null;if(o(n)||"string"==typeof n)for(s=new Array(n.length),t=0,r=n.length;t<r;t++)s[t]=e(n[t],t);else if("number"==typeof n)for(s=new Array(n),t=0;t<n;t++)s[t]=e(t+1,t);else if(d(n))if(dn&&n[Symbol.iterator]){s=[];for(var c=n[Symbol.iterator](),u=c.next();!u.done;)s.push(e(u.value,s.length)),u=c.next()}else for(a=Object.keys(n),s=new Array(a.length),t=0,r=a.length;t<r;t++)l=a[t],s[t]=e(n[l],l,t);return i(s)||(s=[]),s._isVList=!0,s}function Zn(n,e,t,r){var o,a=this.$scopedSlots[n];a?(t=t||{},r&&(t=P(P({},r),t)),o=a(t)||(c(e)?e():e)):o=this.$slots[n]||(c(e)?e():e);var i=t&&t.slot;return i?this.$createElement("template",{slot:i},o):o}function Yn(n){return At(this.$options,"filters",n,!0)||O}function ne(n,e){return o(n)?-1===n.indexOf(e):n!==e}function ee(n,e,t,r,o){var a=F.keyCodes[e]||t;return o&&r&&!F.keyCodes[e]?ne(o,r):a?ne(a,n):r?E(r)!==e:void 0===n}function te(n,e,t,r,a){if(t)if(d(t)){o(t)&&(t=L(t));var i=void 0,l=function(o){if("class"===o||"style"===o||v(o))i=n;else{var l=n.attrs&&n.attrs.type;i=r||F.mustUseProp(e,l,o)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var s=T(o),c=E(o);s in i||c in i||(i[o]=t[o],a&&((n.on||(n.on={}))["update:".concat(o)]=function(n){t[o]=n}))};for(var s in t)l(s)}else;return n}function re(n,e){var t=this._staticTrees||(this._staticTrees=[]),r=t[n];return r&&!e||ae(r=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,this._c,this),"__static__".concat(n),!1),r}function oe(n,e,t){return ae(n,"__once__".concat(e).concat(t?"_".concat(t):""),!0),n}function ae(n,e,t){if(o(n))for(var r=0;r<n.length;r++)n[r]&&"string"!=typeof n[r]&&ie(n[r],"".concat(e,"_").concat(r),t);else ie(n,e,t)}function ie(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function le(n,e){if(e)if(p(e)){var t=n.on=n.on?P({},n.on):{};for(var r in e){var o=t[r],a=e[r];t[r]=o?[].concat(o,a):a}}else;return n}function se(n,e,t,r){e=e||{$stable:!t};for(var a=0;a<n.length;a++){var i=n[a];o(i)?se(i,e,t):i&&(i.proxy&&(i.fn.proxy=!0),e[i.key]=i.fn)}return r&&(e.$key=r),e}function ce(n,e){for(var t=0;t<e.length;t+=2){var r=e[t];"string"==typeof r&&r&&(n[e[t]]=e[t+1])}return n}function de(n,e){return"string"==typeof n?e+n:n}function ue(n){n._o=oe,n._n=b,n._s=m,n._l=Kn,n._t=Zn,n._q=N,n._i=M,n._m=re,n._f=Yn,n._k=ee,n._b=te,n._v=fn,n._e=hn,n._u=se,n._g=le,n._d=ce,n._p=de}function pe(n,e){if(!n||!n.length)return{};for(var t={},r=0,o=n.length;r<o;r++){var a=n[r],i=a.data;if(i&&i.attrs&&i.attrs.slot&&delete i.attrs.slot,a.context!==e&&a.fnContext!==e||!i||null==i.slot)(t.default||(t.default=[])).push(a);else{var l=i.slot,s=t[l]||(t[l]=[]);"template"===a.tag?s.push.apply(s,a.children||[]):s.push(a)}}for(var c in t)t[c].every(ge)&&delete t[c];return t}function ge(n){return n.isComment&&!n.asyncFactory||" "===n.text}function he(n){return n.isComment&&n.asyncFactory}function fe(n,e,t,o){var a,i=Object.keys(t).length>0,l=e?!!e.$stable:!i,s=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(l&&o&&o!==r&&s===o.$key&&!i&&!o.$hasNormal)return o;for(var c in a={},e)e[c]&&"$"!==c[0]&&(a[c]=me(n,t,c,e[c]))}else a={};for(var d in t)d in a||(a[d]=be(t,d));return e&&Object.isExtensible(e)&&(e._normalized=a),X(a,"$stable",l),X(a,"$key",s),X(a,"$hasNormal",i),a}function me(n,e,t,r){var a=function(){var e=un;pn(n);var t=arguments.length?r.apply(null,arguments):r({}),a=(t=t&&"object"==typeof t&&!o(t)?[t]:Gn(t))&&t[0];return pn(e),t&&(!a||1===t.length&&a.isComment&&!he(a))?void 0:t};return r.proxy&&Object.defineProperty(e,t,{get:a,enumerable:!0,configurable:!0}),a}function be(n,e){return function(){return n[e]}}function xe(n){return{get attrs(){if(!n._attrsProxy){var e=n._attrsProxy={};X(e,"_v_attr_proxy",!0),ve(e,n.$attrs,r,n,"$attrs")}return n._attrsProxy},get listeners(){n._listenersProxy||ve(n._listenersProxy={},n.$listeners,r,n,"$listeners");return n._listenersProxy},get slots(){return function(n){n._slotsProxy||ke(n._slotsProxy={},n.$scopedSlots);return n._slotsProxy}(n)},emit:I(n.$emit,n),expose:function(e){e&&Object.keys(e).forEach((function(t){return qn(n,e,t)}))}}}function ve(n,e,t,r,o){var a=!1;for(var i in e)i in n?e[i]!==t[i]&&(a=!0):(a=!0,ye(n,i,r,o));for(var i in n)i in e||(a=!0,delete n[i]);return a}function ye(n,e,t,r){Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){return t[r][e]}})}function ke(n,e){for(var t in e)n[t]=e[t];for(var t in n)t in e||delete n[t]}var we=null;function Se(n,e){return(n.__esModule||dn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),d(n)?e.extend(n):n}function je(n){if(o(n))for(var e=0;e<n.length;e++){var t=n[e];if(i(t)&&(i(t.componentOptions)||he(t)))return t}}function Te(n,e,t,r,u,p){return(o(t)||s(t))&&(u=r,r=t,t=void 0),l(p)&&(u=2),function(n,e,t,r,s){if(i(t)&&i(t.__ob__))return hn();i(t)&&i(t.is)&&(e=t.is);if(!e)return hn();0;o(r)&&c(r[0])&&((t=t||{}).scopedSlots={default:r[0]},r.length=0);2===s?r=Gn(r):1===s&&(r=function(n){for(var e=0;e<n.length;e++)if(o(n[e]))return Array.prototype.concat.apply([],n);return n}(r));var u,p;if("string"==typeof e){var g=void 0;p=n.$vnode&&n.$vnode.ns||F.getTagNamespace(e),u=F.isReservedTag(e)?new gn(F.parsePlatformTagName(e),t,r,void 0,void 0,n):t&&t.pre||!i(g=At(n.$options,"components",e))?new gn(e,t,r,void 0,void 0,n):yt(g,t,n,r,e)}else u=yt(e,t,n,r);return o(u)?u:i(u)?(i(p)&&function n(e,t,r){e.ns=t,"foreignObject"===e.tag&&(t=void 0,r=!0);if(i(e.children))for(var o=0,s=e.children.length;o<s;o++){var c=e.children[o];i(c.tag)&&(a(c.ns)||l(r)&&"svg"!==c.tag)&&n(c,t,r)}}(u,p),i(t)&&function(n){d(n.style)&&Fe(n.style);d(n.class)&&Fe(n.class)}(t),u):hn()}(n,e,t,r,u)}function _e(n,e,t){kn();try{if(e)for(var r=e;r=r.$parent;){var o=r.$options.errorCaptured;if(o)for(var a=0;a<o.length;a++)try{if(!1===o[a].call(r,n,e,t))return}catch(n){Ee(n,r,"errorCaptured hook")}}Ee(n,e,t)}finally{wn()}}function Ce(n,e,t,r,o){var a;try{(a=t?n.apply(e,t):n.call(e))&&!a._isVue&&f(a)&&!a._handled&&(a.catch((function(n){return _e(n,r,o+" (Promise/async)")})),a._handled=!0)}catch(n){_e(n,r,o)}return a}function Ee(n,e,t){if(F.errorHandler)try{return F.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Ie(e,null,"config.errorHandler")}Ie(n,e,t)}function Ie(n,e,t){if(!Q||"undefined"==typeof console)throw n;console.error(n)}var Ae,Pe=!1,Le=[],Re=!1;function Be(){Re=!1;var n=Le.slice(0);Le.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&sn(Promise)){var Oe=Promise.resolve();Ae=function(){Oe.then(Be),Y&&setTimeout(R)},Pe=!0}else if(V||"undefined"==typeof MutationObserver||!sn(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Ae="undefined"!=typeof setImmediate&&sn(setImmediate)?function(){setImmediate(Be)}:function(){setTimeout(Be,0)};else{var Ne=1,Me=new MutationObserver(Be),ze=document.createTextNode(String(Ne));Me.observe(ze,{characterData:!0}),Ae=function(){Ne=(Ne+1)%2,ze.data=String(Ne)},Pe=!0}function De(n,e){var t;if(Le.push((function(){if(n)try{n.call(e)}catch(n){_e(n,e,"nextTick")}else t&&t(e)})),Re||(Re=!0,Ae()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}function qe(n){return function(e,t){if(void 0===t&&(t=un),t)return function(n,e,t){var r=n.$options;r[e]=_t(r[e],t)}(t,n,e)}}qe("beforeMount"),qe("mounted"),qe("beforeUpdate"),qe("updated"),qe("beforeDestroy"),qe("destroyed"),qe("activated"),qe("deactivated"),qe("serverPrefetch"),qe("renderTracked"),qe("renderTriggered"),qe("errorCaptured");var Je=new cn;function Fe(n){return function n(e,t){var r,a,i=o(e);if(!i&&!d(e)||e.__v_skip||Object.isFrozen(e)||e instanceof gn)return;if(e.__ob__){var l=e.__ob__.dep.id;if(t.has(l))return;t.add(l)}if(i)for(r=e.length;r--;)n(e[r],t);else if(Dn(e))n(e.value,t);else for(a=Object.keys(e),r=a.length;r--;)n(e[a[r]],t)}(n,Je),Je.clear(),n}var Ue,He=0,Xe=function(){function n(n,e,t,r,o){var a,i;a=this,void 0===(i=Jn&&!Jn._vm?Jn:n?n._scope:void 0)&&(i=Jn),i&&i.active&&i.effects.push(a),(this.vm=n)&&o&&(n._watcher=this),r?(this.deep=!!r.deep,this.user=!!r.user,this.lazy=!!r.lazy,this.sync=!!r.sync,this.before=r.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++He,this.active=!0,this.post=!1,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new cn,this.newDepIds=new cn,this.expression="",c(e)?this.getter=e:(this.getter=function(n){if(!$.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=R)),this.value=this.lazy?void 0:this.get()}return n.prototype.get=function(){var n;kn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;_e(n,e,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&Fe(n),wn(),this.cleanupDeps()}return n},n.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},n.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},n.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():pt(this)},n.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||d(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'.concat(this.expression,'"');Ce(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},n.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},n.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},n.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&y(this.vm._scope.effects,this),this.active){for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},n}();function $e(n,e){Ue.$on(n,e)}function We(n,e){Ue.$off(n,e)}function Qe(n,e){var t=Ue;return function r(){var o=e.apply(null,arguments);null!==o&&t.$off(n,r)}}function Ge(n,e,t){Ue=n,$n(e,t||{},$e,We,Qe,n),Ue=void 0}var Ve=null;function Ke(n){var e=Ve;return Ve=n,function(){Ve=e}}function Ze(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function Ye(n,e){if(e){if(n._directInactive=!1,Ze(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)Ye(n.$children[t]);nt(n,"activated")}}function nt(n,e,t,r){void 0===r&&(r=!0),kn();var o=un;r&&pn(n);var a=n.$options[e],i="".concat(e," hook");if(a)for(var l=0,s=a.length;l<s;l++)Ce(a[l],n,t||null,n,i);n._hasHookEvent&&n.$emit("hook:"+e),r&&pn(o),wn()}var et=[],tt=[],rt={},ot=!1,at=!1,it=0;var lt=0,st=Date.now;if(Q&&!V){var ct=window.performance;ct&&"function"==typeof ct.now&&st()>document.createEvent("Event").timeStamp&&(st=function(){return ct.now()})}var dt=function(n,e){if(n.post){if(!e.post)return 1}else if(e.post)return-1;return n.id-e.id};function ut(){var n,e;for(lt=st(),at=!0,et.sort(dt),it=0;it<et.length;it++)(n=et[it]).before&&n.before(),e=n.id,rt[e]=null,n.run();var t=tt.slice(),r=et.slice();it=et.length=tt.length=0,rt={},ot=at=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,Ye(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],r=t.vm;r&&r._watcher===t&&r._isMounted&&!r._isDestroyed&&nt(r,"updated")}}(r),function(){for(var n=0;n<xn.length;n++){var e=xn[n];e.subs=e.subs.filter((function(n){return n})),e._pending=!1}xn.length=0}(),ln&&F.devtools&&ln.emit("flush")}function pt(n){var e=n.id;if(null==rt[e]&&(n!==vn.target||!n.noRecurse)){if(rt[e]=!0,at){for(var t=et.length-1;t>it&&et[t].id>n.id;)t--;et.splice(t+1,0,n)}else et.push(n);ot||(ot=!0,De(ut))}}function gt(n,e){if(n){for(var t=Object.create(null),r=dn?Reflect.ownKeys(n):Object.keys(n),o=0;o<r.length;o++){var a=r[o];if("__ob__"!==a){var i=n[a].from;if(i in e._provided)t[a]=e._provided[i];else if("default"in n[a]){var l=n[a].default;t[a]=c(l)?l.call(e):l}else 0}}return t}}function ht(n,e,t,a,i){var s,c=this,d=i.options;w(a,"_uid")?(s=Object.create(a))._original=a:(s=a,a=a._original);var u=l(d._compiled),p=!u;this.data=n,this.props=e,this.children=t,this.parent=a,this.listeners=n.on||r,this.injections=gt(d.inject,a),this.slots=function(){return c.$slots||fe(a,n.scopedSlots,c.$slots=pe(t,a)),c.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return fe(a,n.scopedSlots,this.slots())}}),u&&(this.$options=d,this.$slots=this.slots(),this.$scopedSlots=fe(a,n.scopedSlots,this.$slots)),d._scopeId?this._c=function(n,e,t,r){var i=Te(s,n,e,t,r,p);return i&&!o(i)&&(i.fnScopeId=d._scopeId,i.fnContext=a),i}:this._c=function(n,e,t,r){return Te(s,n,e,t,r,p)}}function ft(n,e,t,r,o){var a=mn(n);return a.fnContext=t,a.fnOptions=r,e.slot&&((a.data||(a.data={})).slot=e.slot),a}function mt(n,e){for(var t in e)n[T(t)]=e[t]}function bt(n){return n.name||n.__name||n._componentTag}ue(ht.prototype);var xt={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;xt.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},r=n.data.inlineTemplate;i(r)&&(t.render=r.render,t.staticRenderFns=r.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,Ve)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,o,a){var i=o.data.scopedSlots,l=n.$scopedSlots,s=!!(i&&!i.$stable||l!==r&&!l.$stable||i&&n.$scopedSlots.$key!==i.$key||!i&&n.$scopedSlots.$key),c=!!(a||n.$options._renderChildren||s),d=n.$vnode;n.$options._parentVnode=o,n.$vnode=o,n._vnode&&(n._vnode.parent=o),n.$options._renderChildren=a;var u=o.data.attrs||r;n._attrsProxy&&ve(n._attrsProxy,u,d.data&&d.data.attrs||r,n,"$attrs")&&(c=!0),n.$attrs=u,t=t||r;var p=n.$options._parentListeners;if(n._listenersProxy&&ve(n._listenersProxy,t,p||r,n,"$listeners"),n.$listeners=n.$options._parentListeners=t,Ge(n,t,p),e&&n.$options.props){En(!1);for(var g=n._props,h=n.$options._propKeys||[],f=0;f<h.length;f++){var m=h[f],b=n.$options.props;g[m]=Pt(m,b,e,n)}En(!0),n.$options.propsData=e}c&&(n.$slots=pe(a,o.context),n.$forceUpdate())}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,r=n.componentInstance;r._isMounted||(r._isMounted=!0,nt(r,"mounted")),n.data.keepAlive&&(t._isMounted?((e=r)._inactive=!1,tt.push(e)):Ye(r,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(!(t&&(e._directInactive=!0,Ze(e))||e._inactive)){e._inactive=!0;for(var r=0;r<e.$children.length;r++)n(e.$children[r]);nt(e,"deactivated")}}(e,!0):e.$destroy())}},vt=Object.keys(xt);function yt(n,e,t,s,c){if(!a(n)){var u=t.$options._base;if(d(n)&&(n=u.extend(n)),"function"==typeof n){var p;if(a(n.cid)&&void 0===(n=function(n,e){if(l(n.error)&&i(n.errorComp))return n.errorComp;if(i(n.resolved))return n.resolved;var t=we;if(t&&i(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t),l(n.loading)&&i(n.loadingComp))return n.loadingComp;if(t&&!i(n.owners)){var r=n.owners=[t],o=!0,s=null,c=null;t.$on("hook:destroyed",(function(){return y(r,t)}));var u=function(n){for(var e=0,t=r.length;e<t;e++)r[e].$forceUpdate();n&&(r.length=0,null!==s&&(clearTimeout(s),s=null),null!==c&&(clearTimeout(c),c=null))},p=z((function(t){n.resolved=Se(t,e),o?r.length=0:u(!0)})),g=z((function(e){i(n.errorComp)&&(n.error=!0,u(!0))})),h=n(p,g);return d(h)&&(f(h)?a(n.resolved)&&h.then(p,g):f(h.component)&&(h.component.then(p,g),i(h.error)&&(n.errorComp=Se(h.error,e)),i(h.loading)&&(n.loadingComp=Se(h.loading,e),0===h.delay?n.loading=!0:s=setTimeout((function(){s=null,a(n.resolved)&&a(n.error)&&(n.loading=!0,u(!1))}),h.delay||200)),i(h.timeout)&&(c=setTimeout((function(){c=null,a(n.resolved)&&g(null)}),h.timeout)))),o=!1,n.loading?n.loadingComp:n.resolved}}(p=n,u)))return function(n,e,t,r,o){var a=hn();return a.asyncFactory=n,a.asyncMeta={data:e,context:t,children:r,tag:o},a}(p,e,t,s,c);e=e||{},Xt(n),i(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",r=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var a=e.on||(e.on={}),l=a[r],s=e.model.callback;i(l)?(o(l)?-1===l.indexOf(s):l!==s)&&(a[r]=[s].concat(l)):a[r]=s}(n.options,e);var g=function(n,e,t){var r=e.options.props;if(!a(r)){var o={},l=n.attrs,s=n.props;if(i(l)||i(s))for(var c in r){var d=E(c);Qn(o,s,c,d,!0)||Qn(o,l,c,d,!1)}return o}}(e,n);if(l(n.options.functional))return function(n,e,t,a,l){var s=n.options,c={},d=s.props;if(i(d))for(var u in d)c[u]=Pt(u,d,e||r);else i(t.attrs)&&mt(c,t.attrs),i(t.props)&&mt(c,t.props);var p=new ht(t,c,l,a,n),g=s.render.call(null,p._c,p);if(g instanceof gn)return ft(g,t,p.parent,s,p);if(o(g)){for(var h=Gn(g)||[],f=new Array(h.length),m=0;m<h.length;m++)f[m]=ft(h[m],t,p.parent,s,p);return f}}(n,g,e,t,s);var h=e.on;if(e.on=e.nativeOn,l(n.options.abstract)){var m=e.slot;e={},m&&(e.slot=m)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<vt.length;t++){var r=vt[t],o=e[r],a=xt[r];o===a||o&&o._merged||(e[r]=o?kt(a,o):a)}}(e);var b=bt(n.options)||c;return new gn("vue-component-".concat(n.cid).concat(b?"-".concat(b):""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:g,listeners:h,tag:c,children:s},p)}}}function kt(n,e){var t=function(t,r){n(t,r),e(t,r)};return t._merged=!0,t}var wt=R,St=F.optionMergeStrategies;function jt(n,e,t){if(void 0===t&&(t=!0),!e)return n;for(var r,o,a,i=dn?Reflect.ownKeys(e):Object.keys(e),l=0;l<i.length;l++)"__ob__"!==(r=i[l])&&(o=n[r],a=e[r],t&&w(n,r)?o!==a&&p(o)&&p(a)&&jt(o,a):Rn(n,r,a));return n}function Tt(n,e,t){return t?function(){var r=c(e)?e.call(t,t):e,o=c(n)?n.call(t,t):n;return r?jt(r,o):o}:e?n?function(){return jt(c(e)?e.call(this,this):e,c(n)?n.call(this,this):n)}:e:n}function _t(n,e){var t=e?n?n.concat(e):o(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function Ct(n,e,t,r){var o=Object.create(n||null);return e?P(o,e):o}St.data=function(n,e,t){return t?Tt(n,e,t):e&&"function"!=typeof e?n:Tt(n,e)},J.forEach((function(n){St[n]=_t})),q.forEach((function(n){St[n+"s"]=Ct})),St.watch=function(n,e,t,r){if(n===tn&&(n=void 0),e===tn&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var a={};for(var i in P(a,n),e){var l=a[i],s=e[i];l&&!o(l)&&(l=[l]),a[i]=l?l.concat(s):o(s)?s:[s]}return a},St.props=St.methods=St.inject=St.computed=function(n,e,t,r){if(!n)return e;var o=Object.create(null);return P(o,n),e&&P(o,e),o},St.provide=function(n,e){return n?function(){var t=Object.create(null);return jt(t,c(n)?n.call(this):n),e&&jt(t,c(e)?e.call(this):e,!1),t}:e};var Et=function(n,e){return void 0===e?n:e};function It(n,e,t){if(c(e)&&(e=e.options),function(n,e){var t=n.props;if(t){var r,a,i={};if(o(t))for(r=t.length;r--;)"string"==typeof(a=t[r])&&(i[T(a)]={type:null});else if(p(t))for(var l in t)a=t[l],i[T(l)]=p(a)?a:{type:a};else 0;n.props=i}}(e),function(n,e){var t=n.inject;if(t){var r=n.inject={};if(o(t))for(var a=0;a<t.length;a++)r[t[a]]={from:t[a]};else if(p(t))for(var i in t){var l=t[i];r[i]=p(l)?P({from:i},l):{from:l}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var r=e[t];c(r)&&(e[t]={bind:r,update:r})}}(e),!e._base&&(e.extends&&(n=It(n,e.extends,t)),e.mixins))for(var r=0,a=e.mixins.length;r<a;r++)n=It(n,e.mixins[r],t);var i,l={};for(i in n)s(i);for(i in e)w(n,i)||s(i);function s(r){var o=St[r]||Et;l[r]=o(n[r],e[r],t,r)}return l}function At(n,e,t,r){if("string"==typeof t){var o=n[e];if(w(o,t))return o[t];var a=T(t);if(w(o,a))return o[a];var i=_(a);return w(o,i)?o[i]:o[t]||o[a]||o[i]}}function Pt(n,e,t,r){var o=e[n],a=!w(t,n),i=t[n],l=Ot(Boolean,o.type);if(l>-1)if(a&&!w(o,"default"))i=!1;else if(""===i||i===E(n)){var s=Ot(String,o.type);(s<0||l<s)&&(i=!0)}if(void 0===i){i=function(n,e,t){if(!w(e,"default"))return;var r=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return c(r)&&"Function"!==Rt(e.type)?r.call(n):r}(r,o,n);var d=Cn;En(!0),Pn(i),En(d)}return i}var Lt=/^\s*function (\w+)/;function Rt(n){var e=n&&n.toString().match(Lt);return e?e[1]:""}function Bt(n,e){return Rt(n)===Rt(e)}function Ot(n,e){if(!o(e))return Bt(e,n)?0:-1;for(var t=0,r=e.length;t<r;t++)if(Bt(e[t],n))return t;return-1}var Nt={enumerable:!0,configurable:!0,get:R,set:R};function Mt(n,e,t){Nt.get=function(){return this[e][t]},Nt.set=function(n){this[e][t]=n},Object.defineProperty(n,t,Nt)}function zt(n){var e=n.$options;if(e.props&&function(n,e){var t=n.$options.propsData||{},r=n._props=Nn({}),o=n.$options._propKeys=[];n.$parent&&En(!1);var a=function(a){o.push(a);var i=Pt(a,e,t,n);Ln(r,a,i),a in n||Mt(n,"_props",a)};for(var i in e)a(i);En(!0)}(n,e.props),function(n){var e=n.$options,t=e.setup;if(t){var r=n._setupContext=xe(n);pn(n),kn();var o=Ce(t,null,[n._props||Nn({}),r],n,"setup");if(wn(),pn(),c(o))e.render=o;else if(d(o))if(n._setupState=o,o.__sfc){var a=n._setupProxy={};for(var i in o)"__sfc"!==i&&qn(a,o,i)}else for(var i in o)H(i)||qn(n,o,i);else 0}}(n),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?R:I(e[t],n)}(n,e.methods),e.data)!function(n){var e=n.$options.data;p(e=n._data=c(e)?function(n,e){kn();try{return n.call(e,e)}catch(n){return _e(n,e,"data()"),{}}finally{wn()}}(e,n):e||{})||(e={});var t=Object.keys(e),r=n.$options.props,o=(n.$options.methods,t.length);for(;o--;){var a=t[o];0,r&&w(r,a)||H(a)||Mt(n,"_data",a)}var i=Pn(e);i&&i.vmCount++}(n);else{var t=Pn(n._data={});t&&t.vmCount++}e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),r=an();for(var o in e){var a=e[o],i=c(a)?a:a.get;0,r||(t[o]=new Xe(n,i||R,R,Dt)),o in n||qt(n,o,a)}}(n,e.computed),e.watch&&e.watch!==tn&&function(n,e){for(var t in e){var r=e[t];if(o(r))for(var a=0;a<r.length;a++)Ut(n,t,r[a]);else Ut(n,t,r)}}(n,e.watch)}var Dt={lazy:!0};function qt(n,e,t){var r=!an();c(t)?(Nt.get=r?Jt(e):Ft(t),Nt.set=R):(Nt.get=t.get?r&&!1!==t.cache?Jt(e):Ft(t.get):R,Nt.set=t.set||R),Object.defineProperty(n,e,Nt)}function Jt(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),vn.target&&e.depend(),e.value}}function Ft(n){return function(){return n.call(this,this)}}function Ut(n,e,t,r){return p(t)&&(r=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,r)}var Ht=0;function Xt(n){var e=n.options;if(n.super){var t=Xt(n.super);if(t!==n.superOptions){n.superOptions=t;var r=function(n){var e,t=n.options,r=n.sealedOptions;for(var o in t)t[o]!==r[o]&&(e||(e={}),e[o]=t[o]);return e}(n);r&&P(n.extendOptions,r),(e=n.options=It(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function $t(n){this._init(n)}function Wt(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,r=t.cid,o=n._Ctor||(n._Ctor={});if(o[r])return o[r];var a=bt(n)||bt(t.options);var i=function(n){this._init(n)};return(i.prototype=Object.create(t.prototype)).constructor=i,i.cid=e++,i.options=It(t.options,n),i.super=t,i.options.props&&function(n){var e=n.options.props;for(var t in e)Mt(n.prototype,"_props",t)}(i),i.options.computed&&function(n){var e=n.options.computed;for(var t in e)qt(n.prototype,t,e[t])}(i),i.extend=t.extend,i.mixin=t.mixin,i.use=t.use,q.forEach((function(n){i[n]=t[n]})),a&&(i.options.components[a]=i),i.superOptions=t.options,i.extendOptions=n,i.sealedOptions=P({},i.options),o[r]=i,i}}function Qt(n){return n&&(bt(n.Ctor.options)||n.tag)}function Gt(n,e){return o(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!g(n)&&n.test(e)}function Vt(n,e){var t=n.cache,r=n.keys,o=n._vnode;for(var a in t){var i=t[a];if(i){var l=i.name;l&&!e(l)&&Kt(t,a,r,o)}}}function Kt(n,e,t,r){var o=n[e];!o||r&&o.tag===r.tag||o.componentInstance.$destroy(),n[e]=null,y(t,e)}!function(n){n.prototype._init=function(n){var e=this;e._uid=Ht++,e._isVue=!0,e.__v_skip=!0,e._scope=new Fn(!0),e._scope._vm=!0,n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),r=e._parentVnode;t.parent=e.parent,t._parentVnode=r;var o=r.componentOptions;t.propsData=o.propsData,t._parentListeners=o.listeners,t._renderChildren=o.children,t._componentTag=o.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=It(Xt(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._provided=t?t._provided:Object.create(null),n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&Ge(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,o=t&&t.context;n.$slots=pe(e._renderChildren,o),n.$scopedSlots=t?fe(n.$parent,t.data.scopedSlots,n.$slots):r,n._c=function(e,t,r,o){return Te(n,e,t,r,o,!1)},n.$createElement=function(e,t,r,o){return Te(n,e,t,r,o,!0)};var a=t&&t.data;Ln(n,"$attrs",a&&a.attrs||r,null,!0),Ln(n,"$listeners",e._parentListeners||r,null,!0)}(e),nt(e,"beforeCreate",void 0,!1),function(n){var e=gt(n.$options.inject,n);e&&(En(!1),Object.keys(e).forEach((function(t){Ln(n,t,e[t])})),En(!0))}(e),zt(e),function(n){var e=n.$options.provide;if(e){var t=c(e)?e.call(n):e;if(!d(t))return;for(var r=Un(n),o=dn?Reflect.ownKeys(t):Object.keys(t),a=0;a<o.length;a++){var i=o[a];Object.defineProperty(r,i,Object.getOwnPropertyDescriptor(t,i))}}}(e),nt(e,"created"),e.$options.el&&e.$mount(e.$options.el)}}($t),function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=Rn,n.prototype.$delete=Bn,n.prototype.$watch=function(n,e,t){if(p(e))return Ut(this,n,e,t);(t=t||{}).user=!0;var r=new Xe(this,n,e,t);if(t.immediate){var o='callback for immediate watcher "'.concat(r.expression,'"');kn(),Ce(e,this,[r.value],this,o),wn()}return function(){r.teardown()}}}($t),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var r=this;if(o(n))for(var a=0,i=n.length;a<i;a++)r.$on(n[a],t);else(r._events[n]||(r._events[n]=[])).push(t),e.test(n)&&(r._hasHookEvent=!0);return r},n.prototype.$once=function(n,e){var t=this;function r(){t.$off(n,r),e.apply(t,arguments)}return r.fn=e,t.$on(n,r),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(o(n)){for(var r=0,a=n.length;r<a;r++)t.$off(n[r],e);return t}var i,l=t._events[n];if(!l)return t;if(!e)return t._events[n]=null,t;for(var s=l.length;s--;)if((i=l[s])===e||i.fn===e){l.splice(s,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?A(t):t;for(var r=A(arguments,1),o='event handler for "'.concat(n,'"'),a=0,i=t.length;a<i;a++)Ce(t[a],e,r,e,o)}return e}}($t),function(n){n.prototype._update=function(n,e){var t=this,r=t.$el,o=t._vnode,a=Ke(t);t._vnode=n,t.$el=o?t.__patch__(o,n):t.__patch__(t.$el,n,e,!1),a(),r&&(r.__vue__=null),t.$el&&(t.$el.__vue__=t);for(var i=t;i&&i.$vnode&&i.$parent&&i.$vnode===i.$parent._vnode;)i.$parent.$el=i.$el,i=i.$parent},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){nt(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||y(e.$children,n),n._scope.stop(),n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),nt(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}($t),function(n){ue(n.prototype),n.prototype.$nextTick=function(n){return De(n,this)},n.prototype._render=function(){var n,e=this,t=e.$options,r=t.render,a=t._parentVnode;a&&e._isMounted&&(e.$scopedSlots=fe(e.$parent,a.data.scopedSlots,e.$slots,e.$scopedSlots),e._slotsProxy&&ke(e._slotsProxy,e.$scopedSlots)),e.$vnode=a;try{pn(e),we=e,n=r.call(e._renderProxy,e.$createElement)}catch(t){_e(t,e,"render"),n=e._vnode}finally{we=null,pn()}return o(n)&&1===n.length&&(n=n[0]),n instanceof gn||(n=hn()),n.parent=a,n}}($t);var Zt=[String,RegExp,Array],Yt={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Zt,exclude:Zt,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,r=this.keyToCache;if(t){var o=t.tag,a=t.componentInstance,i=t.componentOptions;n[r]={name:Qt(i),tag:o,componentInstance:a},e.push(r),this.max&&e.length>parseInt(this.max)&&Kt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Kt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Vt(n,(function(n){return Gt(e,n)}))})),this.$watch("exclude",(function(e){Vt(n,(function(n){return!Gt(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=je(n),t=e&&e.componentOptions;if(t){var r=Qt(t),o=this.include,a=this.exclude;if(o&&(!r||!Gt(o,r))||a&&r&&Gt(a,r))return e;var i=this.cache,l=this.keys,s=null==e.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):e.key;i[s]?(e.componentInstance=i[s].componentInstance,y(l,s),l.push(s)):(this.vnodeToCache=e,this.keyToCache=s),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return F}};Object.defineProperty(n,"config",e),n.util={warn:wt,extend:P,mergeOptions:It,defineReactive:Ln},n.set=Rn,n.delete=Bn,n.nextTick=De,n.observable=function(n){return Pn(n),n},n.options=Object.create(null),q.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,P(n.options.components,Yt),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=A(arguments,1);return t.unshift(this),c(n.install)?n.install.apply(n,t):c(n)&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=It(this.options,n),this}}(n),Wt(n),function(n){q.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&p(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&c(t)&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}($t),Object.defineProperty($t.prototype,"$isServer",{get:an}),Object.defineProperty($t.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty($t,"FunctionalRenderContext",{value:ht}),$t.version="2.7.14";var nr=x("style,class"),er=x("input,textarea,option,select,progress"),tr=x("contenteditable,draggable,spellcheck"),rr=x("events,caret,typing,plaintext-only"),or=x("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),ar="http://www.w3.org/1999/xlink",ir=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},lr=function(n){return ir(n)?n.slice(6,n.length):""},sr=function(n){return null==n||!1===n};function cr(n){for(var e=n.data,t=n,r=n;i(r.componentInstance);)(r=r.componentInstance._vnode)&&r.data&&(e=dr(r.data,e));for(;i(t=t.parent);)t&&t.data&&(e=dr(e,t.data));return function(n,e){if(i(n)||i(e))return ur(n,pr(e));return""}(e.staticClass,e.class)}function dr(n,e){return{staticClass:ur(n.staticClass,e.staticClass),class:i(n.class)?[n.class,e.class]:e.class}}function ur(n,e){return n?e?n+" "+e:n:e||""}function pr(n){return Array.isArray(n)?function(n){for(var e,t="",r=0,o=n.length;r<o;r++)i(e=pr(n[r]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):d(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var gr={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},hr=x("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),fr=x("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),mr=function(n){return hr(n)||fr(n)};var br=Object.create(null);var xr=x("text,number,password,search,email,tel,url");var vr=Object.freeze({__proto__:null,createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(gr[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),yr={create:function(n,e){kr(e)},update:function(n,e){n.data.ref!==e.data.ref&&(kr(n,!0),kr(e))},destroy:function(n){kr(n,!0)}};function kr(n,e){var t=n.data.ref;if(i(t)){var r=n.context,a=n.componentInstance||n.elm,l=e?null:a,s=e?void 0:a;if(c(t))Ce(t,r,[l],r,"template ref function");else{var d=n.data.refInFor,u="string"==typeof t||"number"==typeof t,p=Dn(t),g=r.$refs;if(u||p)if(d){var h=u?g[t]:t.value;e?o(h)&&y(h,a):o(h)?h.includes(a)||h.push(a):u?(g[t]=[a],wr(r,t,g[t])):t.value=[a]}else if(u){if(e&&g[t]!==a)return;g[t]=s,wr(r,t,l)}else if(p){if(e&&t.value!==a)return;t.value=l}else 0}}}function wr(n,e,t){var r=n._setupState;r&&w(r,e)&&(Dn(r[e])?r[e].value=t:r[e]=t)}var Sr=new gn("",{},[]),jr=["create","activate","update","remove","destroy"];function Tr(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&i(n.data)===i(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,r=i(t=n.data)&&i(t=t.attrs)&&t.type,o=i(t=e.data)&&i(t=t.attrs)&&t.type;return r===o||xr(r)&&xr(o)}(n,e)||l(n.isAsyncPlaceholder)&&a(e.asyncFactory.error))}function _r(n,e,t){var r,o,a={};for(r=e;r<=t;++r)i(o=n[r].key)&&(a[o]=r);return a}var Cr={create:Er,update:Er,destroy:function(n){Er(n,Sr)}};function Er(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,r,o,a=n===Sr,i=e===Sr,l=Ar(n.data.directives,n.context),s=Ar(e.data.directives,e.context),c=[],d=[];for(t in s)r=l[t],o=s[t],r?(o.oldValue=r.value,o.oldArg=r.arg,Lr(o,"update",e,n),o.def&&o.def.componentUpdated&&d.push(o)):(Lr(o,"bind",e,n),o.def&&o.def.inserted&&c.push(o));if(c.length){var u=function(){for(var t=0;t<c.length;t++)Lr(c[t],"inserted",e,n)};a?Wn(e,"insert",u):u()}d.length&&Wn(e,"postpatch",(function(){for(var t=0;t<d.length;t++)Lr(d[t],"componentUpdated",e,n)}));if(!a)for(t in l)s[t]||Lr(l[t],"unbind",n,n,i)}(n,e)}var Ir=Object.create(null);function Ar(n,e){var t,r,o=Object.create(null);if(!n)return o;for(t=0;t<n.length;t++){if((r=n[t]).modifiers||(r.modifiers=Ir),o[Pr(r)]=r,e._setupState&&e._setupState.__sfc){var a=r.def||At(e,"_setupState","v-"+r.name);r.def="function"==typeof a?{bind:a,update:a}:a}r.def=r.def||At(e.$options,"directives",r.name)}return o}function Pr(n){return n.rawName||"".concat(n.name,".").concat(Object.keys(n.modifiers||{}).join("."))}function Lr(n,e,t,r,o){var a=n.def&&n.def[e];if(a)try{a(t.elm,n,t,r,o)}catch(r){_e(r,t.context,"directive ".concat(n.name," ").concat(e," hook"))}}var Rr=[yr,Cr];function Br(n,e){var t=e.componentOptions;if(!(i(t)&&!1===t.Ctor.options.inheritAttrs||a(n.data.attrs)&&a(e.data.attrs))){var r,o,s=e.elm,c=n.data.attrs||{},d=e.data.attrs||{};for(r in(i(d.__ob__)||l(d._v_attr_proxy))&&(d=e.data.attrs=P({},d)),d)o=d[r],c[r]!==o&&Or(s,r,o,e.data.pre);for(r in(V||Z)&&d.value!==c.value&&Or(s,"value",d.value),c)a(d[r])&&(ir(r)?s.removeAttributeNS(ar,lr(r)):tr(r)||s.removeAttribute(r))}}function Or(n,e,t,r){r||n.tagName.indexOf("-")>-1?Nr(n,e,t):or(e)?sr(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):tr(e)?n.setAttribute(e,function(n,e){return sr(e)||"false"===e?"false":"contenteditable"===n&&rr(e)?e:"true"}(e,t)):ir(e)?sr(t)?n.removeAttributeNS(ar,lr(e)):n.setAttributeNS(ar,e,t):Nr(n,e,t)}function Nr(n,e,t){if(sr(t))n.removeAttribute(e);else{if(V&&!K&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var r=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",r)};n.addEventListener("input",r),n.__ieph=!0}n.setAttribute(e,t)}}var Mr={create:Br,update:Br};function zr(n,e){var t=e.elm,r=e.data,o=n.data;if(!(a(r.staticClass)&&a(r.class)&&(a(o)||a(o.staticClass)&&a(o.class)))){var l=cr(e),s=t._transitionClasses;i(s)&&(l=ur(l,pr(s))),l!==t._prevClass&&(t.setAttribute("class",l),t._prevClass=l)}}var Dr,qr={create:zr,update:zr};function Jr(n,e,t){var r=Dr;return function o(){var a=e.apply(null,arguments);null!==a&&Hr(n,o,t,r)}}var Fr=Pe&&!(en&&Number(en[1])<=53);function Ur(n,e,t,r){if(Fr){var o=lt,a=e;e=a._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=o||n.timeStamp<=0||n.target.ownerDocument!==document)return a.apply(this,arguments)}}Dr.addEventListener(n,e,rn?{capture:t,passive:r}:t)}function Hr(n,e,t,r){(r||Dr).removeEventListener(n,e._wrapper||e,t)}function Xr(n,e){if(!a(n.data.on)||!a(e.data.on)){var t=e.data.on||{},r=n.data.on||{};Dr=e.elm||n.elm,function(n){if(i(n.__r)){var e=V?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}i(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),$n(t,r,Ur,Hr,Jr,e.context),Dr=void 0}}var $r,Wr={create:Xr,update:Xr,destroy:function(n){return Xr(n,Sr)}};function Qr(n,e){if(!a(n.data.domProps)||!a(e.data.domProps)){var t,r,o=e.elm,s=n.data.domProps||{},c=e.data.domProps||{};for(t in(i(c.__ob__)||l(c._v_attr_proxy))&&(c=e.data.domProps=P({},c)),s)t in c||(o[t]="");for(t in c){if(r=c[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),r===s[t])continue;1===o.childNodes.length&&o.removeChild(o.childNodes[0])}if("value"===t&&"PROGRESS"!==o.tagName){o._value=r;var d=a(r)?"":String(r);Gr(o,d)&&(o.value=d)}else if("innerHTML"===t&&fr(o.tagName)&&a(o.innerHTML)){($r=$r||document.createElement("div")).innerHTML="<svg>".concat(r,"</svg>");for(var u=$r.firstChild;o.firstChild;)o.removeChild(o.firstChild);for(;u.firstChild;)o.appendChild(u.firstChild)}else if(r!==s[t])try{o[t]=r}catch(n){}}}}function Gr(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,r=n._vModifiers;if(i(r)){if(r.number)return b(t)!==b(e);if(r.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Vr={create:Qr,update:Qr},Kr=S((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var r=n.split(t);r.length>1&&(e[r[0].trim()]=r[1].trim())}})),e}));function Zr(n){var e=Yr(n.style);return n.staticStyle?P(n.staticStyle,e):e}function Yr(n){return Array.isArray(n)?L(n):"string"==typeof n?Kr(n):n}var no,eo=/^--/,to=/\s*!important$/,ro=function(n,e,t){if(eo.test(e))n.style.setProperty(e,t);else if(to.test(t))n.style.setProperty(E(e),t.replace(to,""),"important");else{var r=ao(e);if(Array.isArray(t))for(var o=0,a=t.length;o<a;o++)n.style[r]=t[o];else n.style[r]=t}},oo=["Webkit","Moz","ms"],ao=S((function(n){if(no=no||document.createElement("div").style,"filter"!==(n=T(n))&&n in no)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<oo.length;t++){var r=oo[t]+e;if(r in no)return r}}));function io(n,e){var t=e.data,r=n.data;if(!(a(t.staticStyle)&&a(t.style)&&a(r.staticStyle)&&a(r.style))){var o,l,s=e.elm,c=r.staticStyle,d=r.normalizedStyle||r.style||{},u=c||d,p=Yr(e.data.style)||{};e.data.normalizedStyle=i(p.__ob__)?P({},p):p;var g=function(n,e){var t,r={};if(e)for(var o=n;o.componentInstance;)(o=o.componentInstance._vnode)&&o.data&&(t=Zr(o.data))&&P(r,t);(t=Zr(n.data))&&P(r,t);for(var a=n;a=a.parent;)a.data&&(t=Zr(a.data))&&P(r,t);return r}(e,!0);for(l in u)a(g[l])&&ro(s,l,"");for(l in g)(o=g[l])!==u[l]&&ro(s,l,null==o?"":o)}}var lo={create:io,update:io},so=/\s+/;function co(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(so).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" ".concat(n.getAttribute("class")||""," ");t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function uo(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(so).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" ".concat(n.getAttribute("class")||""," "),r=" "+e+" ";t.indexOf(r)>=0;)t=t.replace(r," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function po(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&P(e,go(n.name||"v")),P(e,n),e}return"string"==typeof n?go(n):void 0}}var go=S((function(n){return{enterClass:"".concat(n,"-enter"),enterToClass:"".concat(n,"-enter-to"),enterActiveClass:"".concat(n,"-enter-active"),leaveClass:"".concat(n,"-leave"),leaveToClass:"".concat(n,"-leave-to"),leaveActiveClass:"".concat(n,"-leave-active")}})),ho=Q&&!K,fo="transition",mo="transitionend",bo="animation",xo="animationend";ho&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(fo="WebkitTransition",mo="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(bo="WebkitAnimation",xo="webkitAnimationEnd"));var vo=Q?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function yo(n){vo((function(){vo(n)}))}function ko(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),co(n,e))}function wo(n,e){n._transitionClasses&&y(n._transitionClasses,e),uo(n,e)}function So(n,e,t){var r=To(n,e),o=r.type,a=r.timeout,i=r.propCount;if(!o)return t();var l="transition"===o?mo:xo,s=0,c=function(){n.removeEventListener(l,d),t()},d=function(e){e.target===n&&++s>=i&&c()};setTimeout((function(){s<i&&c()}),a+1),n.addEventListener(l,d)}var jo=/\b(transform|all)(,|$)/;function To(n,e){var t,r=window.getComputedStyle(n),o=(r[fo+"Delay"]||"").split(", "),a=(r[fo+"Duration"]||"").split(", "),i=_o(o,a),l=(r[bo+"Delay"]||"").split(", "),s=(r[bo+"Duration"]||"").split(", "),c=_o(l,s),d=0,u=0;return"transition"===e?i>0&&(t="transition",d=i,u=a.length):"animation"===e?c>0&&(t="animation",d=c,u=s.length):u=(t=(d=Math.max(i,c))>0?i>c?"transition":"animation":null)?"transition"===t?a.length:s.length:0,{type:t,timeout:d,propCount:u,hasTransform:"transition"===t&&jo.test(r[fo+"Property"])}}function _o(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return Co(e)+Co(n[t])})))}function Co(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function Eo(n,e){var t=n.elm;i(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var r=po(n.data.transition);if(!a(r)&&!i(t._enterCb)&&1===t.nodeType){for(var o=r.css,l=r.type,s=r.enterClass,u=r.enterToClass,p=r.enterActiveClass,g=r.appearClass,h=r.appearToClass,f=r.appearActiveClass,m=r.beforeEnter,x=r.enter,v=r.afterEnter,y=r.enterCancelled,k=r.beforeAppear,w=r.appear,S=r.afterAppear,j=r.appearCancelled,T=r.duration,_=Ve,C=Ve.$vnode;C&&C.parent;)_=C.context,C=C.parent;var E=!_._isMounted||!n.isRootInsert;if(!E||w||""===w){var I=E&&g?g:s,A=E&&f?f:p,P=E&&h?h:u,L=E&&k||m,R=E&&c(w)?w:x,B=E&&S||v,O=E&&j||y,N=b(d(T)?T.enter:T);0;var M=!1!==o&&!K,D=Po(R),q=t._enterCb=z((function(){M&&(wo(t,P),wo(t,A)),q.cancelled?(M&&wo(t,I),O&&O(t)):B&&B(t),t._enterCb=null}));n.data.show||Wn(n,"insert",(function(){var e=t.parentNode,r=e&&e._pending&&e._pending[n.key];r&&r.tag===n.tag&&r.elm._leaveCb&&r.elm._leaveCb(),R&&R(t,q)})),L&&L(t),M&&(ko(t,I),ko(t,A),yo((function(){wo(t,I),q.cancelled||(ko(t,P),D||(Ao(N)?setTimeout(q,N):So(t,l,q)))}))),n.data.show&&(e&&e(),R&&R(t,q)),M||D||q()}}}function Io(n,e){var t=n.elm;i(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var r=po(n.data.transition);if(a(r)||1!==t.nodeType)return e();if(!i(t._leaveCb)){var o=r.css,l=r.type,s=r.leaveClass,c=r.leaveToClass,u=r.leaveActiveClass,p=r.beforeLeave,g=r.leave,h=r.afterLeave,f=r.leaveCancelled,m=r.delayLeave,x=r.duration,v=!1!==o&&!K,y=Po(g),k=b(d(x)?x.leave:x);0;var w=t._leaveCb=z((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),v&&(wo(t,c),wo(t,u)),w.cancelled?(v&&wo(t,s),f&&f(t)):(e(),h&&h(t)),t._leaveCb=null}));m?m(S):S()}function S(){w.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),p&&p(t),v&&(ko(t,s),ko(t,u),yo((function(){wo(t,s),w.cancelled||(ko(t,c),y||(Ao(k)?setTimeout(w,k):So(t,l,w)))}))),g&&g(t,w),v||y||w())}}function Ao(n){return"number"==typeof n&&!isNaN(n)}function Po(n){if(a(n))return!1;var e=n.fns;return i(e)?Po(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function Lo(n,e){!0!==e.data.show&&Eo(e)}var Ro=function(n){var e,t,r={},c=n.modules,d=n.nodeOps;for(e=0;e<jr.length;++e)for(r[jr[e]]=[],t=0;t<c.length;++t)i(c[t][jr[e]])&&r[jr[e]].push(c[t][jr[e]]);function u(n){var e=d.parentNode(n);i(e)&&d.removeChild(e,n)}function p(n,e,t,o,a,s,c){if(i(n.elm)&&i(s)&&(n=s[c]=mn(n)),n.isRootInsert=!a,!function(n,e,t,o){var a=n.data;if(i(a)){var s=i(n.componentInstance)&&a.keepAlive;if(i(a=a.hook)&&i(a=a.init)&&a(n,!1),i(n.componentInstance))return g(n,e),h(t,n.elm,o),l(s)&&function(n,e,t,o){var a,l=n;for(;l.componentInstance;)if(l=l.componentInstance._vnode,i(a=l.data)&&i(a=a.transition)){for(a=0;a<r.activate.length;++a)r.activate[a](Sr,l);e.push(l);break}h(t,n.elm,o)}(n,e,t,o),!0}}(n,e,t,o)){var u=n.data,p=n.children,m=n.tag;i(m)?(n.elm=n.ns?d.createElementNS(n.ns,m):d.createElement(m,n),v(n),f(n,p,e),i(u)&&b(n,e),h(t,n.elm,o)):l(n.isComment)?(n.elm=d.createComment(n.text),h(t,n.elm,o)):(n.elm=d.createTextNode(n.text),h(t,n.elm,o))}}function g(n,e){i(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,m(n)?(b(n,e),v(n)):(kr(n),e.push(n))}function h(n,e,t){i(n)&&(i(t)?d.parentNode(t)===n&&d.insertBefore(n,e,t):d.appendChild(n,e))}function f(n,e,t){if(o(e)){0;for(var r=0;r<e.length;++r)p(e[r],t,n.elm,null,!0,e,r)}else s(n.text)&&d.appendChild(n.elm,d.createTextNode(String(n.text)))}function m(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return i(n.tag)}function b(n,t){for(var o=0;o<r.create.length;++o)r.create[o](Sr,n);i(e=n.data.hook)&&(i(e.create)&&e.create(Sr,n),i(e.insert)&&t.push(n))}function v(n){var e;if(i(e=n.fnScopeId))d.setStyleScope(n.elm,e);else for(var t=n;t;)i(e=t.context)&&i(e=e.$options._scopeId)&&d.setStyleScope(n.elm,e),t=t.parent;i(e=Ve)&&e!==n.context&&e!==n.fnContext&&i(e=e.$options._scopeId)&&d.setStyleScope(n.elm,e)}function y(n,e,t,r,o,a){for(;r<=o;++r)p(t[r],a,n,e,!1,t,r)}function k(n){var e,t,o=n.data;if(i(o))for(i(e=o.hook)&&i(e=e.destroy)&&e(n),e=0;e<r.destroy.length;++e)r.destroy[e](n);if(i(e=n.children))for(t=0;t<n.children.length;++t)k(n.children[t])}function w(n,e,t){for(;e<=t;++e){var r=n[e];i(r)&&(i(r.tag)?(S(r),k(r)):u(r.elm))}}function S(n,e){if(i(e)||i(n.data)){var t,o=r.remove.length+1;for(i(e)?e.listeners+=o:e=function(n,e){function t(){0==--t.listeners&&u(n)}return t.listeners=e,t}(n.elm,o),i(t=n.componentInstance)&&i(t=t._vnode)&&i(t.data)&&S(t,e),t=0;t<r.remove.length;++t)r.remove[t](n,e);i(t=n.data.hook)&&i(t=t.remove)?t(n,e):e()}else u(n.elm)}function j(n,e,t,r){for(var o=t;o<r;o++){var a=e[o];if(i(a)&&Tr(n,a))return o}}function T(n,e,t,o,s,c){if(n!==e){i(e.elm)&&i(o)&&(e=o[s]=mn(e));var u=e.elm=n.elm;if(l(n.isAsyncPlaceholder))i(e.asyncFactory.resolved)?E(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(l(e.isStatic)&&l(n.isStatic)&&e.key===n.key&&(l(e.isCloned)||l(e.isOnce)))e.componentInstance=n.componentInstance;else{var g,h=e.data;i(h)&&i(g=h.hook)&&i(g=g.prepatch)&&g(n,e);var f=n.children,b=e.children;if(i(h)&&m(e)){for(g=0;g<r.update.length;++g)r.update[g](n,e);i(g=h.hook)&&i(g=g.update)&&g(n,e)}a(e.text)?i(f)&&i(b)?f!==b&&function(n,e,t,r,o){var l,s,c,u=0,g=0,h=e.length-1,f=e[0],m=e[h],b=t.length-1,x=t[0],v=t[b],k=!o;for(0;u<=h&&g<=b;)a(f)?f=e[++u]:a(m)?m=e[--h]:Tr(f,x)?(T(f,x,r,t,g),f=e[++u],x=t[++g]):Tr(m,v)?(T(m,v,r,t,b),m=e[--h],v=t[--b]):Tr(f,v)?(T(f,v,r,t,b),k&&d.insertBefore(n,f.elm,d.nextSibling(m.elm)),f=e[++u],v=t[--b]):Tr(m,x)?(T(m,x,r,t,g),k&&d.insertBefore(n,m.elm,f.elm),m=e[--h],x=t[++g]):(a(l)&&(l=_r(e,u,h)),a(s=i(x.key)?l[x.key]:j(x,e,u,h))?p(x,r,n,f.elm,!1,t,g):Tr(c=e[s],x)?(T(c,x,r,t,g),e[s]=void 0,k&&d.insertBefore(n,c.elm,f.elm)):p(x,r,n,f.elm,!1,t,g),x=t[++g]);u>h?y(n,a(t[b+1])?null:t[b+1].elm,t,g,b,r):g>b&&w(e,u,h)}(u,f,b,t,c):i(b)?(i(n.text)&&d.setTextContent(u,""),y(u,null,b,0,b.length-1,t)):i(f)?w(f,0,f.length-1):i(n.text)&&d.setTextContent(u,""):n.text!==e.text&&d.setTextContent(u,e.text),i(h)&&i(g=h.hook)&&i(g=g.postpatch)&&g(n,e)}}}function _(n,e,t){if(l(t)&&i(n.parent))n.parent.data.pendingInsert=e;else for(var r=0;r<e.length;++r)e[r].data.hook.insert(e[r])}var C=x("attrs,class,staticClass,staticStyle,key");function E(n,e,t,r){var o,a=e.tag,s=e.data,c=e.children;if(r=r||s&&s.pre,e.elm=n,l(e.isComment)&&i(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(i(s)&&(i(o=s.hook)&&i(o=o.init)&&o(e,!0),i(o=e.componentInstance)))return g(e,t),!0;if(i(a)){if(i(c))if(n.hasChildNodes())if(i(o=s)&&i(o=o.domProps)&&i(o=o.innerHTML)){if(o!==n.innerHTML)return!1}else{for(var d=!0,u=n.firstChild,p=0;p<c.length;p++){if(!u||!E(u,c[p],t,r)){d=!1;break}u=u.nextSibling}if(!d||u)return!1}else f(e,c,t);if(i(s)){var h=!1;for(var m in s)if(!C(m)){h=!0,b(e,t);break}!h&&s.class&&Fe(s.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,o){if(!a(e)){var s,c=!1,u=[];if(a(n))c=!0,p(e,u);else{var g=i(n.nodeType);if(!g&&Tr(n,e))T(n,e,u,null,null,o);else{if(g){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),l(t)&&E(n,e,u))return _(e,u,!0),n;s=n,n=new gn(d.tagName(s).toLowerCase(),{},[],void 0,s)}var h=n.elm,f=d.parentNode(h);if(p(e,u,h._leaveCb?null:f,d.nextSibling(h)),i(e.parent))for(var b=e.parent,x=m(e);b;){for(var v=0;v<r.destroy.length;++v)r.destroy[v](b);if(b.elm=e.elm,x){for(var y=0;y<r.create.length;++y)r.create[y](Sr,b);var S=b.data.hook.insert;if(S.merged)for(var j=1;j<S.fns.length;j++)S.fns[j]()}else kr(b);b=b.parent}i(f)?w([n],0,0):i(n.tag)&&k(n)}}return _(e,u,c),e.elm}i(n)&&k(n)}}({nodeOps:vr,modules:[Mr,qr,Wr,Vr,lo,Q?{create:Lo,activate:Lo,remove:function(n,e){!0!==n.data.show?Io(n,e):e()}}:{}].concat(Rr)});K&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&Jo(n,"input")}));var Bo={inserted:function(n,e,t,r){"select"===t.tag?(r.elm&&!r.elm._vOptions?Wn(t,"postpatch",(function(){Bo.componentUpdated(n,e,t)})):Oo(n,e,t.context),n._vOptions=[].map.call(n.options,zo)):("textarea"===t.tag||xr(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",Do),n.addEventListener("compositionend",qo),n.addEventListener("change",qo),K&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){Oo(n,e,t.context);var r=n._vOptions,o=n._vOptions=[].map.call(n.options,zo);if(o.some((function(n,e){return!N(n,r[e])})))(n.multiple?e.value.some((function(n){return Mo(n,o)})):e.value!==e.oldValue&&Mo(e.value,o))&&Jo(n,"change")}}};function Oo(n,e,t){No(n,e,t),(V||Z)&&setTimeout((function(){No(n,e,t)}),0)}function No(n,e,t){var r=e.value,o=n.multiple;if(!o||Array.isArray(r)){for(var a,i,l=0,s=n.options.length;l<s;l++)if(i=n.options[l],o)a=M(r,zo(i))>-1,i.selected!==a&&(i.selected=a);else if(N(zo(i),r))return void(n.selectedIndex!==l&&(n.selectedIndex=l));o||(n.selectedIndex=-1)}}function Mo(n,e){return e.every((function(e){return!N(e,n)}))}function zo(n){return"_value"in n?n._value:n.value}function Do(n){n.target.composing=!0}function qo(n){n.target.composing&&(n.target.composing=!1,Jo(n.target,"input"))}function Jo(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function Fo(n){return!n.componentInstance||n.data&&n.data.transition?n:Fo(n.componentInstance._vnode)}var Uo={model:Bo,show:{bind:function(n,e,t){var r=e.value,o=(t=Fo(t)).data&&t.data.transition,a=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;r&&o?(t.data.show=!0,Eo(t,(function(){n.style.display=a}))):n.style.display=r?a:"none"},update:function(n,e,t){var r=e.value;!r!=!e.oldValue&&((t=Fo(t)).data&&t.data.transition?(t.data.show=!0,r?Eo(t,(function(){n.style.display=n.__vOriginalDisplay})):Io(t,(function(){n.style.display="none"}))):n.style.display=r?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,r,o){o||(n.style.display=n.__vOriginalDisplay)}}},Ho={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Xo(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?Xo(je(e.children)):n}function $o(n){var e={},t=n.$options;for(var r in t.propsData)e[r]=n[r];var o=t._parentListeners;for(var r in o)e[T(r)]=o[r];return e}function Wo(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Qo=function(n){return n.tag||he(n)},Go=function(n){return"show"===n.name},Vo={name:"transition",props:Ho,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Qo)).length){0;var r=this.mode;0;var o=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return o;var a=Xo(o);if(!a)return o;if(this._leaving)return Wo(n,o);var i="__transition-".concat(this._uid,"-");a.key=null==a.key?a.isComment?i+"comment":i+a.tag:s(a.key)?0===String(a.key).indexOf(i)?a.key:i+a.key:a.key;var l=(a.data||(a.data={})).transition=$o(this),c=this._vnode,d=Xo(c);if(a.data.directives&&a.data.directives.some(Go)&&(a.data.show=!0),d&&d.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(a,d)&&!he(d)&&(!d.componentInstance||!d.componentInstance._vnode.isComment)){var u=d.data.transition=P({},l);if("out-in"===r)return this._leaving=!0,Wn(u,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Wo(n,o);if("in-out"===r){if(he(a))return c;var p,g=function(){p()};Wn(l,"afterEnter",g),Wn(l,"enterCancelled",g),Wn(u,"delayLeave",(function(n){p=n}))}}return o}}},Ko=P({tag:String,moveClass:String},Ho);function Zo(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function Yo(n){n.data.newPos=n.elm.getBoundingClientRect()}function na(n){var e=n.data.pos,t=n.data.newPos,r=e.left-t.left,o=e.top-t.top;if(r||o){n.data.moved=!0;var a=n.elm.style;a.transform=a.WebkitTransform="translate(".concat(r,"px,").concat(o,"px)"),a.transitionDuration="0s"}}delete Ko.mode;var ea={Transition:Vo,TransitionGroup:{props:Ko,beforeMount:function(){var n=this,e=this._update;this._update=function(t,r){var o=Ke(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,o(),e.call(n,t,r)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),r=this.prevChildren=this.children,o=this.$slots.default||[],a=this.children=[],i=$o(this),l=0;l<o.length;l++){if((d=o[l]).tag)if(null!=d.key&&0!==String(d.key).indexOf("__vlist"))a.push(d),t[d.key]=d,(d.data||(d.data={})).transition=i;else;}if(r){var s=[],c=[];for(l=0;l<r.length;l++){var d;(d=r[l]).data.transition=i,d.data.pos=d.elm.getBoundingClientRect(),t[d.key]?s.push(d):c.push(d)}this.kept=n(e,null,s),this.removed=c}return n(e,null,a)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Zo),n.forEach(Yo),n.forEach(na),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,r=t.style;ko(t,e),r.transform=r.WebkitTransform=r.transitionDuration="",t.addEventListener(mo,t._moveCb=function n(r){r&&r.target!==t||r&&!/transform$/.test(r.propertyName)||(t.removeEventListener(mo,n),t._moveCb=null,wo(t,e))})}})))},methods:{hasMove:function(n,e){if(!ho)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){uo(t,n)})),co(t,e),t.style.display="none",this.$el.appendChild(t);var r=To(t);return this.$el.removeChild(t),this._hasMove=r.hasTransform}}}};function ta(n,e){for(var t in e)n[t]=e[t];return n}$t.config.mustUseProp=function(n,e,t){return"value"===t&&er(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},$t.config.isReservedTag=mr,$t.config.isReservedAttr=nr,$t.config.getTagNamespace=function(n){return fr(n)?"svg":"math"===n?"math":void 0},$t.config.isUnknownElement=function(n){if(!Q)return!0;if(mr(n))return!1;if(n=n.toLowerCase(),null!=br[n])return br[n];var e=document.createElement(n);return n.indexOf("-")>-1?br[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:br[n]=/HTMLUnknownElement/.test(e.toString())},P($t.options.directives,Uo),P($t.options.components,ea),$t.prototype.__patch__=Q?Ro:R,$t.prototype.$mount=function(n,e){return function(n,e,t){var r;n.$el=e,n.$options.render||(n.$options.render=hn),nt(n,"beforeMount"),r=function(){n._update(n._render(),t)},new Xe(n,r,R,{before:function(){n._isMounted&&!n._isDestroyed&&nt(n,"beforeUpdate")}},!0),t=!1;var o=n._preWatchers;if(o)for(var a=0;a<o.length;a++)o[a].run();return null==n.$vnode&&(n._isMounted=!0,nt(n,"mounted")),n}(this,n=n&&Q?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},Q&&setTimeout((function(){F.devtools&&ln&&ln.emit("init",$t)}),0);var ra=/[!'()*]/g,oa=function(n){return"%"+n.charCodeAt(0).toString(16)},aa=/%2C/g,ia=function(n){return encodeURIComponent(n).replace(ra,oa).replace(aa,",")};function la(n){try{return decodeURIComponent(n)}catch(n){0}return n}var sa=function(n){return null==n||"object"==typeof n?n:String(n)};function ca(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),r=la(t.shift()),o=t.length>0?la(t.join("=")):null;void 0===e[r]?e[r]=o:Array.isArray(e[r])?e[r].push(o):e[r]=[e[r],o]})),e):e}function da(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return ia(e);if(Array.isArray(t)){var r=[];return t.forEach((function(n){void 0!==n&&(null===n?r.push(ia(e)):r.push(ia(e)+"="+ia(n)))})),r.join("&")}return ia(e)+"="+ia(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var ua=/\/?$/;function pa(n,e,t,r){var o=r&&r.options.stringifyQuery,a=e.query||{};try{a=ga(a)}catch(n){}var i={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:a,params:e.params||{},fullPath:ma(e,o),matched:n?fa(n):[]};return t&&(i.redirectedFrom=ma(t,o)),Object.freeze(i)}function ga(n){if(Array.isArray(n))return n.map(ga);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=ga(n[t]);return e}return n}var ha=pa(null,{path:"/"});function fa(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function ma(n,e){var t=n.path,r=n.query;void 0===r&&(r={});var o=n.hash;return void 0===o&&(o=""),(t||"/")+(e||da)(r)+o}function ba(n,e,t){return e===ha?n===e:!!e&&(n.path&&e.path?n.path.replace(ua,"")===e.path.replace(ua,"")&&(t||n.hash===e.hash&&xa(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&xa(n.query,e.query)&&xa(n.params,e.params))))}function xa(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),r=Object.keys(e).sort();return t.length===r.length&&t.every((function(t,o){var a=n[t];if(r[o]!==t)return!1;var i=e[t];return null==a||null==i?a===i:"object"==typeof a&&"object"==typeof i?xa(a,i):String(a)===String(i)}))}function va(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var r in t.instances){var o=t.instances[r],a=t.enteredCbs[r];if(o&&a){delete t.enteredCbs[r];for(var i=0;i<a.length;i++)o._isBeingDestroyed||a[i](o)}}}}var ya={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,r=e.children,o=e.parent,a=e.data;a.routerView=!0;for(var i=o.$createElement,l=t.name,s=o.$route,c=o._routerViewCache||(o._routerViewCache={}),d=0,u=!1;o&&o._routerRoot!==o;){var p=o.$vnode?o.$vnode.data:{};p.routerView&&d++,p.keepAlive&&o._directInactive&&o._inactive&&(u=!0),o=o.$parent}if(a.routerViewDepth=d,u){var g=c[l],h=g&&g.component;return h?(g.configProps&&ka(h,a,g.route,g.configProps),i(h,a,r)):i()}var f=s.matched[d],m=f&&f.components[l];if(!f||!m)return c[l]=null,i();c[l]={component:m},a.registerRouteInstance=function(n,e){var t=f.instances[l];(e&&t!==n||!e&&t===n)&&(f.instances[l]=e)},(a.hook||(a.hook={})).prepatch=function(n,e){f.instances[l]=e.componentInstance},a.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==f.instances[l]&&(f.instances[l]=n.componentInstance),va(s)};var b=f.props&&f.props[l];return b&&(ta(c[l],{route:s,configProps:b}),ka(m,a,s,b)),i(m,a,r)}};function ka(n,e,t,r){var o=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,r);if(o){o=e.props=ta({},o);var a=e.attrs=e.attrs||{};for(var i in o)n.props&&i in n.props||(a[i]=o[i],delete o[i])}}function wa(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var o=e.split("/");t&&o[o.length-1]||o.pop();for(var a=n.replace(/^\//,"").split("/"),i=0;i<a.length;i++){var l=a[i];".."===l?o.pop():"."!==l&&o.push(l)}return""!==o[0]&&o.unshift(""),o.join("/")}function Sa(n){return n.replace(/\/(?:\s*\/)+/g,"/")}var ja=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},Ta=Da,_a=Pa,Ca=function(n,e){return Ra(Pa(n,e),e)},Ea=Ra,Ia=za,Aa=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function Pa(n,e){for(var t,r=[],o=0,a=0,i="",l=e&&e.delimiter||"/";null!=(t=Aa.exec(n));){var s=t[0],c=t[1],d=t.index;if(i+=n.slice(a,d),a=d+s.length,c)i+=c[1];else{var u=n[a],p=t[2],g=t[3],h=t[4],f=t[5],m=t[6],b=t[7];i&&(r.push(i),i="");var x=null!=p&&null!=u&&u!==p,v="+"===m||"*"===m,y="?"===m||"*"===m,k=t[2]||l,w=h||f;r.push({name:g||o++,prefix:p||"",delimiter:k,optional:y,repeat:v,partial:x,asterisk:!!b,pattern:w?Oa(w):b?".*":"[^"+Ba(k)+"]+?"})}}return a<n.length&&(i+=n.substr(a)),i&&r.push(i),r}function La(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function Ra(n,e){for(var t=new Array(n.length),r=0;r<n.length;r++)"object"==typeof n[r]&&(t[r]=new RegExp("^(?:"+n[r].pattern+")$",Ma(e)));return function(e,r){for(var o="",a=e||{},i=(r||{}).pretty?La:encodeURIComponent,l=0;l<n.length;l++){var s=n[l];if("string"!=typeof s){var c,d=a[s.name];if(null==d){if(s.optional){s.partial&&(o+=s.prefix);continue}throw new TypeError('Expected "'+s.name+'" to be defined')}if(ja(d)){if(!s.repeat)throw new TypeError('Expected "'+s.name+'" to not repeat, but received `'+JSON.stringify(d)+"`");if(0===d.length){if(s.optional)continue;throw new TypeError('Expected "'+s.name+'" to not be empty')}for(var u=0;u<d.length;u++){if(c=i(d[u]),!t[l].test(c))throw new TypeError('Expected all "'+s.name+'" to match "'+s.pattern+'", but received `'+JSON.stringify(c)+"`");o+=(0===u?s.prefix:s.delimiter)+c}}else{if(c=s.asterisk?encodeURI(d).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):i(d),!t[l].test(c))throw new TypeError('Expected "'+s.name+'" to match "'+s.pattern+'", but received "'+c+'"');o+=s.prefix+c}}else o+=s}return o}}function Ba(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function Oa(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function Na(n,e){return n.keys=e,n}function Ma(n){return n&&n.sensitive?"":"i"}function za(n,e,t){ja(e)||(t=e||t,e=[]);for(var r=(t=t||{}).strict,o=!1!==t.end,a="",i=0;i<n.length;i++){var l=n[i];if("string"==typeof l)a+=Ba(l);else{var s=Ba(l.prefix),c="(?:"+l.pattern+")";e.push(l),l.repeat&&(c+="(?:"+s+c+")*"),a+=c=l.optional?l.partial?s+"("+c+")?":"(?:"+s+"("+c+"))?":s+"("+c+")"}}var d=Ba(t.delimiter||"/"),u=a.slice(-d.length)===d;return r||(a=(u?a.slice(0,-d.length):a)+"(?:"+d+"(?=$))?"),a+=o?"$":r&&u?"":"(?="+d+"|$)",Na(new RegExp("^"+a,Ma(t)),e)}function Da(n,e,t){return ja(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var r=0;r<t.length;r++)e.push({name:r,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return Na(n,e)}(n,e):ja(n)?function(n,e,t){for(var r=[],o=0;o<n.length;o++)r.push(Da(n[o],e,t).source);return Na(new RegExp("(?:"+r.join("|")+")",Ma(t)),e)}(n,e,t):function(n,e,t){return za(Pa(n,t),e,t)}(n,e,t)}Ta.parse=_a,Ta.compile=Ca,Ta.tokensToFunction=Ea,Ta.tokensToRegExp=Ia;var qa=Object.create(null);function Ja(n,e,t){e=e||{};try{var r=qa[n]||(qa[n]=Ta.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),r(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function Fa(n,e,t,r){var o="string"==typeof n?{path:n}:n;if(o._normalized)return o;if(o.name){var a=(o=ta({},n)).params;return a&&"object"==typeof a&&(o.params=ta({},a)),o}if(!o.path&&o.params&&e){(o=ta({},o))._normalized=!0;var i=ta(ta({},e.params),o.params);if(e.name)o.name=e.name,o.params=i;else if(e.matched.length){var l=e.matched[e.matched.length-1].path;o.path=Ja(l,i,e.path)}else 0;return o}var s=function(n){var e="",t="",r=n.indexOf("#");r>=0&&(e=n.slice(r),n=n.slice(0,r));var o=n.indexOf("?");return o>=0&&(t=n.slice(o+1),n=n.slice(0,o)),{path:n,query:t,hash:e}}(o.path||""),c=e&&e.path||"/",d=s.path?wa(s.path,c,t||o.append):c,u=function(n,e,t){void 0===e&&(e={});var r,o=t||ca;try{r=o(n||"")}catch(n){r={}}for(var a in e){var i=e[a];r[a]=Array.isArray(i)?i.map(sa):sa(i)}return r}(s.query,o.query,r&&r.options.parseQuery),p=o.hash||s.hash;return p&&"#"!==p.charAt(0)&&(p="#"+p),{_normalized:!0,path:d,query:u,hash:p}}var Ua,Ha=function(){},Xa={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,r=this.$route,o=t.resolve(this.to,r,this.append),a=o.location,i=o.route,l=o.href,s={},c=t.options.linkActiveClass,d=t.options.linkExactActiveClass,u=null==c?"router-link-active":c,p=null==d?"router-link-exact-active":d,g=null==this.activeClass?u:this.activeClass,h=null==this.exactActiveClass?p:this.exactActiveClass,f=i.redirectedFrom?pa(null,Fa(i.redirectedFrom),null,t):i;s[h]=ba(r,f,this.exactPath),s[g]=this.exact||this.exactPath?s[h]:function(n,e){return 0===n.path.replace(ua,"/").indexOf(e.path.replace(ua,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(r,f);var m=s[h]?this.ariaCurrentValue:null,b=function(n){$a(n)&&(e.replace?t.replace(a,Ha):t.push(a,Ha))},x={click:$a};Array.isArray(this.event)?this.event.forEach((function(n){x[n]=b})):x[this.event]=b;var v={class:s},y=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:l,route:i,navigate:b,isActive:s[g],isExactActive:s[h]});if(y){if(1===y.length)return y[0];if(y.length>1||!y.length)return 0===y.length?n():n("span",{},y)}if("a"===this.tag)v.on=x,v.attrs={href:l,"aria-current":m};else{var k=function n(e){var t;if(e)for(var r=0;r<e.length;r++){if("a"===(t=e[r]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(k){k.isStatic=!1;var w=k.data=ta({},k.data);for(var S in w.on=w.on||{},w.on){var j=w.on[S];S in x&&(w.on[S]=Array.isArray(j)?j:[j])}for(var T in x)T in w.on?w.on[T].push(x[T]):w.on[T]=b;var _=k.data.attrs=ta({},k.data.attrs);_.href=l,_["aria-current"]=m}else v.on=x}return n(this.tag,v,this.$slots.default)}};function $a(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Wa="undefined"!=typeof window;function Qa(n,e,t,r,o){var a=e||[],i=t||Object.create(null),l=r||Object.create(null);n.forEach((function(n){!function n(e,t,r,o,a,i){var l=o.path,s=o.name;0;var c=o.pathToRegexpOptions||{},d=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return Sa(e.path+"/"+n)}(l,a,c.strict);"boolean"==typeof o.caseSensitive&&(c.sensitive=o.caseSensitive);var u={path:d,regex:Ga(d,c),components:o.components||{default:o.component},alias:o.alias?"string"==typeof o.alias?[o.alias]:o.alias:[],instances:{},enteredCbs:{},name:s,parent:a,matchAs:i,redirect:o.redirect,beforeEnter:o.beforeEnter,meta:o.meta||{},props:null==o.props?{}:o.components?o.props:{default:o.props}};o.children&&o.children.forEach((function(o){var a=i?Sa(i+"/"+o.path):void 0;n(e,t,r,o,u,a)}));t[u.path]||(e.push(u.path),t[u.path]=u);if(void 0!==o.alias)for(var p=Array.isArray(o.alias)?o.alias:[o.alias],g=0;g<p.length;++g){0;var h={path:p[g],children:o.children};n(e,t,r,h,a,u.path||"/")}s&&(r[s]||(r[s]=u))}(a,i,l,n,o)}));for(var s=0,c=a.length;s<c;s++)"*"===a[s]&&(a.push(a.splice(s,1)[0]),c--,s--);return{pathList:a,pathMap:i,nameMap:l}}function Ga(n,e){return Ta(n,[],e)}function Va(n,e){var t=Qa(n),r=t.pathList,o=t.pathMap,a=t.nameMap;function i(n,t,i){var l=Fa(n,t,!1,e),c=l.name;if(c){var d=a[c];if(!d)return s(null,l);var u=d.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof l.params&&(l.params={}),t&&"object"==typeof t.params)for(var p in t.params)!(p in l.params)&&u.indexOf(p)>-1&&(l.params[p]=t.params[p]);return l.path=Ja(d.path,l.params),s(d,l,i)}if(l.path){l.params={};for(var g=0;g<r.length;g++){var h=r[g],f=o[h];if(Ka(f.regex,l.path,l.params))return s(f,l,i)}}return s(null,l)}function l(n,t){var r=n.redirect,o="function"==typeof r?r(pa(n,t,null,e)):r;if("string"==typeof o&&(o={path:o}),!o||"object"!=typeof o)return s(null,t);var l=o,c=l.name,d=l.path,u=t.query,p=t.hash,g=t.params;if(u=l.hasOwnProperty("query")?l.query:u,p=l.hasOwnProperty("hash")?l.hash:p,g=l.hasOwnProperty("params")?l.params:g,c){a[c];return i({_normalized:!0,name:c,query:u,hash:p,params:g},void 0,t)}if(d){var h=function(n,e){return wa(n,e.parent?e.parent.path:"/",!0)}(d,n);return i({_normalized:!0,path:Ja(h,g),query:u,hash:p},void 0,t)}return s(null,t)}function s(n,t,r){return n&&n.redirect?l(n,r||t):n&&n.matchAs?function(n,e,t){var r=i({_normalized:!0,path:Ja(t,e.params)});if(r){var o=r.matched,a=o[o.length-1];return e.params=r.params,s(a,e)}return s(null,e)}(0,t,n.matchAs):pa(n,t,r,e)}return{match:i,addRoute:function(n,e){var t="object"!=typeof n?a[n]:void 0;Qa([e||n],r,o,a,t),t&&t.alias.length&&Qa(t.alias.map((function(n){return{path:n,children:[e]}})),r,o,a,t)},getRoutes:function(){return r.map((function(n){return o[n]}))},addRoutes:function(n){Qa(n,r,o,a)}}}function Ka(n,e,t){var r=e.match(n);if(!r)return!1;if(!t)return!0;for(var o=1,a=r.length;o<a;++o){var i=n.keys[o-1];i&&(t[i.name||"pathMatch"]="string"==typeof r[o]?la(r[o]):r[o])}return!0}var Za=Wa&&window.performance&&window.performance.now?window.performance:Date;function Ya(){return Za.now().toFixed(3)}var ni=Ya();function ei(){return ni}function ti(n){return ni=n}var ri=Object.create(null);function oi(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=ta({},window.history.state);return t.key=ei(),window.history.replaceState(t,"",e),window.addEventListener("popstate",li),function(){window.removeEventListener("popstate",li)}}function ai(n,e,t,r){if(n.app){var o=n.options.scrollBehavior;o&&n.app.$nextTick((function(){var a=function(){var n=ei();if(n)return ri[n]}(),i=o.call(n,e,t,r?a:null);i&&("function"==typeof i.then?i.then((function(n){pi(n,a)})).catch((function(n){0})):pi(i,a))}))}}function ii(){var n=ei();n&&(ri[n]={x:window.pageXOffset,y:window.pageYOffset})}function li(n){ii(),n.state&&n.state.key&&ti(n.state.key)}function si(n){return di(n.x)||di(n.y)}function ci(n){return{x:di(n.x)?n.x:window.pageXOffset,y:di(n.y)?n.y:window.pageYOffset}}function di(n){return"number"==typeof n}var ui=/^#\d/;function pi(n,e){var t,r="object"==typeof n;if(r&&"string"==typeof n.selector){var o=ui.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(o){var a=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),r=n.getBoundingClientRect();return{x:r.left-t.left-e.x,y:r.top-t.top-e.y}}(o,a={x:di((t=a).x)?t.x:0,y:di(t.y)?t.y:0})}else si(n)&&(e=ci(n))}else r&&si(n)&&(e=ci(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var gi,hi=Wa&&((-1===(gi=window.navigator.userAgent).indexOf("Android 2.")&&-1===gi.indexOf("Android 4.0")||-1===gi.indexOf("Mobile Safari")||-1!==gi.indexOf("Chrome")||-1!==gi.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function fi(n,e){ii();var t=window.history;try{if(e){var r=ta({},t.state);r.key=ei(),t.replaceState(r,"",n)}else t.pushState({key:ti(Ya())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function mi(n){fi(n,!0)}var bi={redirected:2,aborted:4,cancelled:8,duplicated:16};function xi(n,e){return yi(n,e,bi.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return ki.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function vi(n,e){return yi(n,e,bi.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function yi(n,e,t,r){var o=new Error(r);return o._isRouter=!0,o.from=n,o.to=e,o.type=t,o}var ki=["params","query","hash"];function wi(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function Si(n,e){return wi(n)&&n._isRouter&&(null==e||n.type===e)}function ji(n,e,t){var r=function(o){o>=n.length?t():n[o]?e(n[o],(function(){r(o+1)})):r(o+1)};r(0)}function Ti(n){return function(e,t,r){var o=!1,a=0,i=null;_i(n,(function(n,e,t,l){if("function"==typeof n&&void 0===n.cid){o=!0,a++;var s,c=Ii((function(e){var o;((o=e).__esModule||Ei&&"Module"===o[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:Ua.extend(e),t.components[l]=e,--a<=0&&r()})),d=Ii((function(n){var e="Failed to resolve async component "+l+": "+n;i||(i=wi(n)?n:new Error(e),r(i))}));try{s=n(c,d)}catch(n){d(n)}if(s)if("function"==typeof s.then)s.then(c,d);else{var u=s.component;u&&"function"==typeof u.then&&u.then(c,d)}}})),o||r()}}function _i(n,e){return Ci(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function Ci(n){return Array.prototype.concat.apply([],n)}var Ei="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Ii(n){var e=!1;return function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];if(!e)return e=!0,n.apply(this,t)}}var Ai=function(n,e){this.router=n,this.base=function(n){if(!n)if(Wa){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=ha,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Pi(n,e,t,r){var o=_i(n,(function(n,r,o,a){var i=function(n,e){"function"!=typeof n&&(n=Ua.extend(n));return n.options[e]}(n,e);if(i)return Array.isArray(i)?i.map((function(n){return t(n,r,o,a)})):t(i,r,o,a)}));return Ci(r?o.reverse():o)}function Li(n,e){if(e)return function(){return n.apply(e,arguments)}}Ai.prototype.listen=function(n){this.cb=n},Ai.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},Ai.prototype.onError=function(n){this.errorCbs.push(n)},Ai.prototype.transitionTo=function(n,e,t){var r,o=this;try{r=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var a=this.current;this.confirmTransition(r,(function(){o.updateRoute(r),e&&e(r),o.ensureURL(),o.router.afterHooks.forEach((function(n){n&&n(r,a)})),o.ready||(o.ready=!0,o.readyCbs.forEach((function(n){n(r)})))}),(function(n){t&&t(n),n&&!o.ready&&(Si(n,bi.redirected)&&a===ha||(o.ready=!0,o.readyErrorCbs.forEach((function(e){e(n)}))))}))},Ai.prototype.confirmTransition=function(n,e,t){var r=this,o=this.current;this.pending=n;var a,i,l=function(n){!Si(n)&&wi(n)&&(r.errorCbs.length?r.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},s=n.matched.length-1,c=o.matched.length-1;if(ba(n,o)&&s===c&&n.matched[s]===o.matched[c])return this.ensureURL(),n.hash&&ai(this.router,o,n,!1),l(((i=yi(a=o,n,bi.duplicated,'Avoided redundant navigation to current location: "'+a.fullPath+'".')).name="NavigationDuplicated",i));var d=function(n,e){var t,r=Math.max(n.length,e.length);for(t=0;t<r&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),u=d.updated,p=d.deactivated,g=d.activated,h=[].concat(function(n){return Pi(n,"beforeRouteLeave",Li,!0)}(p),this.router.beforeHooks,function(n){return Pi(n,"beforeRouteUpdate",Li)}(u),g.map((function(n){return n.beforeEnter})),Ti(g)),f=function(e,t){if(r.pending!==n)return l(vi(o,n));try{e(n,o,(function(e){!1===e?(r.ensureURL(!0),l(function(n,e){return yi(n,e,bi.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(o,n))):wi(e)?(r.ensureURL(!0),l(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(l(xi(o,n)),"object"==typeof e&&e.replace?r.replace(e):r.push(e)):t(e)}))}catch(n){l(n)}};ji(h,f,(function(){ji(function(n){return Pi(n,"beforeRouteEnter",(function(n,e,t,r){return function(n,e,t){return function(r,o,a){return n(r,o,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),a(n)}))}}(n,t,r)}))}(g).concat(r.router.resolveHooks),f,(function(){if(r.pending!==n)return l(vi(o,n));r.pending=null,e(n),r.router.app&&r.router.app.$nextTick((function(){va(n)}))}))}))},Ai.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},Ai.prototype.setupListeners=function(){},Ai.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=ha,this.pending=null};var Ri=function(n){function e(e,t){n.call(this,e,t),this._startLocation=Bi(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,r=hi&&t;r&&this.listeners.push(oi());var o=function(){var t=n.current,o=Bi(n.base);n.current===ha&&o===n._startLocation||n.transitionTo(o,(function(n){r&&ai(e,n,t,!0)}))};window.addEventListener("popstate",o),this.listeners.push((function(){window.removeEventListener("popstate",o)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){fi(Sa(r.base+n.fullPath)),ai(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){mi(Sa(r.base+n.fullPath)),ai(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(Bi(this.base)!==this.current.fullPath){var e=Sa(this.base+this.current.fullPath);n?fi(e):mi(e)}},e.prototype.getCurrentLocation=function(){return Bi(this.base)},e}(Ai);function Bi(n){var e=window.location.pathname,t=e.toLowerCase(),r=n.toLowerCase();return!n||t!==r&&0!==t.indexOf(Sa(r+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var Oi=function(n){function e(e,t,r){n.call(this,e,t),r&&function(n){var e=Bi(n);if(!/^\/#/.test(e))return window.location.replace(Sa(n+"/#"+e)),!0}(this.base)||Ni()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=hi&&e;t&&this.listeners.push(oi());var r=function(){var e=n.current;Ni()&&n.transitionTo(Mi(),(function(r){t&&ai(n.router,r,e,!0),hi||qi(r.fullPath)}))},o=hi?"popstate":"hashchange";window.addEventListener(o,r),this.listeners.push((function(){window.removeEventListener(o,r)}))}},e.prototype.push=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){Di(n.fullPath),ai(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){qi(n.fullPath),ai(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;Mi()!==e&&(n?Di(e):qi(e))},e.prototype.getCurrentLocation=function(){return Mi()},e}(Ai);function Ni(){var n=Mi();return"/"===n.charAt(0)||(qi("/"+n),!1)}function Mi(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function zi(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function Di(n){hi?fi(zi(n)):window.location.hash=n}function qi(n){hi?mi(zi(n)):window.location.replace(zi(n))}var Ji=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index+1).concat(n),r.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var r=this.stack[t];this.confirmTransition(r,(function(){var n=e.current;e.index=t,e.updateRoute(r),e.router.afterHooks.forEach((function(e){e&&e(r,n)}))}),(function(n){Si(n,bi.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(Ai),Fi=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Va(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!hi&&!1!==n.fallback,this.fallback&&(e="hash"),Wa||(e="abstract"),this.mode=e,e){case"history":this.history=new Ri(this,n.base);break;case"hash":this.history=new Oi(this,n.base,this.fallback);break;case"abstract":this.history=new Ji(this,n.base);break;default:0}},Ui={currentRoute:{configurable:!0}};Fi.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},Ui.currentRoute.get=function(){return this.history&&this.history.current},Fi.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof Ri||t instanceof Oi){var r=function(n){t.setupListeners(),function(n){var r=t.current,o=e.options.scrollBehavior;hi&&o&&"fullPath"in n&&ai(e,n,r,!1)}(n)};t.transitionTo(t.getCurrentLocation(),r,r)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},Fi.prototype.beforeEach=function(n){return Xi(this.beforeHooks,n)},Fi.prototype.beforeResolve=function(n){return Xi(this.resolveHooks,n)},Fi.prototype.afterEach=function(n){return Xi(this.afterHooks,n)},Fi.prototype.onReady=function(n,e){this.history.onReady(n,e)},Fi.prototype.onError=function(n){this.history.onError(n)},Fi.prototype.push=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.push(n,e,t)}));this.history.push(n,e,t)},Fi.prototype.replace=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.replace(n,e,t)}));this.history.replace(n,e,t)},Fi.prototype.go=function(n){this.history.go(n)},Fi.prototype.back=function(){this.go(-1)},Fi.prototype.forward=function(){this.go(1)},Fi.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},Fi.prototype.resolve=function(n,e,t){var r=Fa(n,e=e||this.history.current,t,this),o=this.match(r,e),a=o.redirectedFrom||o.fullPath;return{location:r,route:o,href:function(n,e,t){var r="hash"===t?"#"+e:e;return n?Sa(n+"/"+r):r}(this.history.base,a,this.mode),normalizedTo:r,resolved:o}},Fi.prototype.getRoutes=function(){return this.matcher.getRoutes()},Fi.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==ha&&this.history.transitionTo(this.history.getCurrentLocation())},Fi.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==ha&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(Fi.prototype,Ui);var Hi=Fi;function Xi(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}Fi.install=function n(e){if(!n.installed||Ua!==e){n.installed=!0,Ua=e;var t=function(n){return void 0!==n},r=function(n,e){var r=n.$options._parentVnode;t(r)&&t(r=r.data)&&t(r=r.registerRouteInstance)&&r(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,r(this,this)},destroyed:function(){r(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",ya),e.component("RouterLink",Xa);var o=e.config.optionMergeStrategies;o.beforeRouteEnter=o.beforeRouteLeave=o.beforeRouteUpdate=o.created}},Fi.version="3.6.5",Fi.isNavigationFailure=Si,Fi.NavigationFailureType=bi,Fi.START_LOCATION=ha,Wa&&window.Vue&&window.Vue.use(Fi);t(104);t(16),t(130);var $i={NotFound:()=>Promise.all([t.e(0),t.e(4)]).then(t.bind(null,330)),Layout:()=>Promise.all([t.e(0),t.e(2)]).then(t.bind(null,329))},Wi={"v-68ba2172":()=>t.e(5).then(t.bind(null,331)),"v-9f98b88c":()=>t.e(7).then(t.bind(null,332)),"v-eb6aaeb6":()=>t.e(6).then(t.bind(null,333)),"v-f0607dd8":()=>t.e(10).then(t.bind(null,334)),"v-062f8431":()=>t.e(11).then(t.bind(null,335)),"v-afa30cfc":()=>t.e(9).then(t.bind(null,336)),"v-e1c868da":()=>t.e(8).then(t.bind(null,337)),"v-2e7dd8a7":()=>t.e(13).then(t.bind(null,338)),"v-38cc1f4f":()=>t.e(14).then(t.bind(null,339)),"v-c8c76474":()=>t.e(17).then(t.bind(null,340)),"v-1dab0d7c":()=>t.e(15).then(t.bind(null,341)),"v-4a5e1071":()=>t.e(12).then(t.bind(null,342)),"v-6890b777":()=>t.e(19).then(t.bind(null,343)),"v-6db7c258":()=>t.e(16).then(t.bind(null,344)),"v-f8cd9c4a":()=>t.e(18).then(t.bind(null,345)),"v-1ca94746":()=>t.e(20).then(t.bind(null,346)),"v-87b51ada":()=>t.e(21).then(t.bind(null,347)),"v-0d72e0be":()=>t.e(22).then(t.bind(null,348)),"v-689aeb6e":()=>t.e(23).then(t.bind(null,349)),"v-30dbcc76":()=>t.e(24).then(t.bind(null,350)),"v-aebcce32":()=>t.e(26).then(t.bind(null,351)),"v-59982f2a":()=>t.e(27).then(t.bind(null,352)),"v-54af3d7f":()=>t.e(28).then(t.bind(null,353)),"v-5b394e2a":()=>t.e(25).then(t.bind(null,354)),"v-f080616e":()=>t.e(29).then(t.bind(null,355)),"v-e594d938":()=>t.e(30).then(t.bind(null,356)),"v-619d565d":()=>t.e(31).then(t.bind(null,357)),"v-c1afabda":()=>t.e(32).then(t.bind(null,358)),"v-62c5b9aa":()=>t.e(33).then(t.bind(null,359)),"v-04afedb8":()=>t.e(34).then(t.bind(null,360)),"v-4cfac2ae":()=>t.e(36).then(t.bind(null,361)),"v-366aefd3":()=>t.e(35).then(t.bind(null,362)),"v-11139ae4":()=>t.e(38).then(t.bind(null,363)),"v-98ff3c9c":()=>t.e(37).then(t.bind(null,364)),"v-d0b615f8":()=>t.e(39).then(t.bind(null,365)),"v-040c55f4":()=>t.e(41).then(t.bind(null,366)),"v-9062bd3c":()=>t.e(40).then(t.bind(null,367)),"v-230aad5c":()=>t.e(42).then(t.bind(null,368)),"v-b5de3650":()=>t.e(44).then(t.bind(null,369)),"v-ff4b2134":()=>t.e(43).then(t.bind(null,370)),"v-68f17928":()=>t.e(45).then(t.bind(null,371)),"v-20c514cb":()=>t.e(46).then(t.bind(null,372)),"v-ed0ea22a":()=>t.e(47).then(t.bind(null,373)),"v-218f759f":()=>t.e(48).then(t.bind(null,374)),"v-1a0380cd":()=>t.e(49).then(t.bind(null,375)),"v-2232d43f":()=>t.e(50).then(t.bind(null,376)),"v-75b72c80":()=>t.e(51).then(t.bind(null,377)),"v-64094560":()=>t.e(53).then(t.bind(null,378)),"v-49c73577":()=>t.e(52).then(t.bind(null,379)),"v-2a546378":()=>t.e(54).then(t.bind(null,380)),"v-849ebb74":()=>t.e(55).then(t.bind(null,381)),"v-18bfcd63":()=>t.e(57).then(t.bind(null,382)),"v-55669653":()=>t.e(58).then(t.bind(null,383)),"v-72a09f4a":()=>t.e(59).then(t.bind(null,384)),"v-0000769a":()=>t.e(60).then(t.bind(null,385)),"v-0112e9f6":()=>t.e(56).then(t.bind(null,386)),"v-40abcda6":()=>t.e(62).then(t.bind(null,387)),"v-7512a88a":()=>t.e(61).then(t.bind(null,388)),"v-fa2c9a0c":()=>t.e(63).then(t.bind(null,389)),"v-d47ce5a2":()=>t.e(64).then(t.bind(null,390)),"v-6f97f076":()=>t.e(65).then(t.bind(null,391)),"v-34b36bf8":()=>t.e(66).then(t.bind(null,392)),"v-c3e06076":()=>t.e(67).then(t.bind(null,393)),"v-391a0836":()=>t.e(68).then(t.bind(null,394)),"v-5f6c1111":()=>t.e(69).then(t.bind(null,395))};function Qi(n){const e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}const Gi=/-(\w)/g,Vi=Qi(n=>n.replace(Gi,(n,e)=>e?e.toUpperCase():"")),Ki=/\B([A-Z])/g,Zi=Qi(n=>n.replace(Ki,"-$1").toLowerCase()),Yi=Qi(n=>n.charAt(0).toUpperCase()+n.slice(1));function nl(n,e){if(!e)return;if(n(e))return n(e);return e.includes("-")?n(Yi(Vi(e))):n(Yi(e))||n(Zi(e))}const el=Object.assign({},$i,Wi),tl=n=>el[n],rl=n=>Wi[n],ol=n=>$i[n],al=n=>$t.component(n);function il(n){return nl(rl,n)}function ll(n){return nl(ol,n)}function sl(n){return nl(tl,n)}function cl(n){return nl(al,n)}function dl(...n){return Promise.all(n.filter(n=>n).map(async n=>{if(!cl(n)&&sl(n)){const e=await sl(n)();$t.component(n,e.default)}}))}function ul(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var pl=t(92),gl=t.n(pl),hl=t(93),fl=t.n(hl),ml={created(){if(this.siteMeta=this.$site.headTags.filter(([n])=>"meta"===n).map(([n,e])=>e),this.$ssrContext){const e=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(n=e)?n.map(n=>{let e="<meta";return Object.keys(n).forEach(t=>{e+=` ${t}="${fl()(n[t])}"`}),e+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=xl(this.$canonicalUrl)}var n},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const n=this.getMergedMetaTags();this.currentMetaTags=vl(n,this.currentMetaTags)},getMergedMetaTags(){const n=this.$page.frontmatter.meta||[];return gl()([{name:"description",content:this.$description}],n,this.siteMeta,yl)},updateCanonicalLink(){bl(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",xl(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){vl(null,this.currentMetaTags),bl()}};function bl(){const n=document.querySelector("link[rel='canonical']");n&&n.remove()}function xl(n=""){return n?`<link href="${n}" rel="canonical" />`:""}function vl(n,e){if(e&&[...e].filter(n=>n.parentNode===document.head).forEach(n=>document.head.removeChild(n)),n)return n.map(n=>{const e=document.createElement("meta");return Object.keys(n).forEach(t=>{e.setAttribute(t,n[t])}),document.head.appendChild(e),e})}function yl(n){for(const e of["name","property","itemprop"])if(n.hasOwnProperty(e))return n[e]+e;return JSON.stringify(n)}var kl=t(50),wl={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(kl)()((function(){this.setActiveHash()}),300),setActiveHash(){const n=[].slice.call(document.querySelectorAll(".sidebar-link")),e=[].slice.call(document.querySelectorAll(".header-anchor")).filter(e=>n.some(n=>n.hash===e.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),r=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),o=window.innerHeight+t;for(let n=0;n<e.length;n++){const a=e[n],i=e[n+1],l=0===n&&0===t||t>=a.parentElement.offsetTop+10&&(!i||t<i.parentElement.offsetTop-10),s=decodeURIComponent(this.$route.hash);if(l&&s!==decodeURIComponent(a.hash)){const t=a;if(o===r)for(let t=n+1;t<e.length;t++)if(s===decodeURIComponent(e[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},Sl=t(24),jl=t.n(Sl),Tl={mounted(){jl.a.configure({showSpinner:!1}),this.$router.beforeEach((n,e,t)=>{n.path===e.path||$t.component(n.name)||jl.a.start(),t()}),this.$router.afterEach(()=>{jl.a.done(),this.isSidebarOpen=!1})}};t(239),t(240);class _l{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:n="",duration:e=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${n}</div>\n    `,this.containerEl.appendChild(t),e>0&&setTimeout(()=>{this.close(t)},e)}close(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",()=>{n.remove()})}}var Cl={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(n=>{document.querySelectorAll(n).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(n){if(n.classList.contains("codecopy-enabled"))return;const e=document.createElement("i");e.className="code-copy",e.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',e.title="Copy to clipboard",e.addEventListener("click",()=>{this.copyToClipboard(n.innerText)}),n.appendChild(e),n.classList.add("codecopy-enabled")},copyToClipboard(n){const e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy");(new _l).show({text:"复制成功",duration:1e3}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};!function(n,e){void 0===e&&(e={});var t=e.insertAt;if(n&&"undefined"!=typeof document){var r=document.head||document.getElementsByTagName("head")[0],o=document.createElement("style");o.type="text/css","top"===t&&r.firstChild?r.insertBefore(o,r.firstChild):r.appendChild(o),o.styleSheet?o.styleSheet.cssText=n:o.appendChild(document.createTextNode(n))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var El={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},Il={},Al=function(n){return'<div id="app">\n'.concat(n,"\n</div>")},Pl=function(n){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[n]?window.$VUEPRESS_DEMO_BLOCK[n]:El[n]},Ll=function n(e,t,r){var o=document.createElement(e);return t&&Object.keys(t).forEach((function(n){if(n.indexOf("data"))o[n]=t[n];else{var e=n.replace("data","");o.dataset[e]=t[n]}})),r&&r.forEach((function(e){var t=e.tag,r=e.attrs,a=e.children;o.appendChild(n(t,r,a))})),o},Rl=function(n,e,t){var r,o=(r=n.querySelectorAll(".".concat(e)),Array.prototype.slice.call(r));return 1!==o.length||t?o:o[0]},Bl=function(n,e){var t,r,o=n.match(/<style>([\s\S]+)<\/style>/),a=n.match(/<template>([\s\S]+)<\/template>/),i=n.match(/<script>([\s\S]+)<\/script>/),l={css:o&&o[1].replace(/^\n|\n$/g,""),html:a&&a[1].replace(/^\n|\n$/g,""),js:i&&i[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};l.htmlTpl=Al(l.html),l.jsTpl=(t=l.js,r=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(r,"\n})")),l.script=function(n,e){var t=n.split(/export\s+default/),r="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),o=window.Babel?window.Babel.transform(r,{presets:["es2015"]}).code:r,a=[eval][0](o);return a.template=e,a}(l.js,l.html);var s=Pl("vue");return l.jsLib.unshift(s),l},Ol=function(n,e){var t,r=n.match(/<style>([\s\S]+)<\/style>/),o=n.match(/<html>([\s\S]+)<\/html>/),a=n.match(/<script>([\s\S]+)<\/script>/),i={css:r&&r[1].replace(/^\n|\n$/g,""),html:o&&o[1].replace(/^\n|\n$/g,""),js:a&&a[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};return i.htmlTpl=i.html,i.jsTpl=i.js,i.script=(t=i.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),i},Nl=function(n){return n=n.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),n+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function Ml(){var n=Rl(document,"vuepress-plugin-demo-block__wrapper",!0);n.length?n.forEach((function(n){if("true"!==n.dataset.created){n.style.display="block";var e=Rl(n,"vuepress-plugin-demo-block__code"),t=Rl(n,"vuepress-plugin-demo-block__display"),r=Rl(n,"vuepress-plugin-demo-block__footer"),o=Rl(t,"vuepress-plugin-demo-block__app"),a=decodeURIComponent(n.dataset.code),i=decodeURIComponent(n.dataset.config),l=decodeURIComponent(n.dataset.type);i=i?JSON.parse(i):{};var s=e.querySelector("div").clientHeight,c="react"===l?function(n,e){var t=(0,window.Babel.transform)(n,{presets:["es2015","react"]}).code,r="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),o=new Function("return ".concat(r))(),a={js:o,css:o.__style__||"",jsLib:e.jsLib||[],cssLib:e.cssLib||[],jsTpl:Nl(n),htmlTpl:Al("")},i=Pl("react"),l=Pl("reactDOM");return a.jsLib.unshift(i,l),a}(a,i):"vanilla"===l?Ol(a,i):Bl(a,i),d=Ll("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(r.appendChild(d),d.addEventListener("click",zl.bind(null,d,s,e,r)),Pl("jsfiddle")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,o=n.jsLib,a=n.cssLib,i=o.concat(a).concat(Pl("cssLib")).concat(Pl("jsLib")).join(",");return Ll("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:e}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:r}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:i}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(c)),Pl("codepen")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,o=n.jsLib,a=n.cssLib,i=JSON.stringify({css:e,html:t,js:r,js_external:o.concat(Pl("jsLib")).join(";"),css_external:a.concat(Pl("cssLib")).join(";"),layout:Pl("codepenLayout"),js_pre_processor:Pl("codepenJsProcessor"),editors:Pl("codepenEditors")});return Ll("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:i}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(c)),void 0!==i.horizontal?i.horizontal:Pl("horizontal")){n.classList.add("vuepress-plugin-demo-block__horizontal");var u=e.firstChild.cloneNode(!0);u.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(u)}if(c.css&&function(n){if(!Il[n]){var e=Ll("style",{innerHTML:n});document.body.appendChild(e),Il[n]=!0}}(c.css),"react"===l)ReactDOM.render(React.createElement(c.js),o);else if("vue"===l){var p=(new(Vue.extend(c.script))).$mount();o.appendChild(p.$el)}else"vanilla"===l&&(o.innerHTML=c.html,new Function("return (function(){".concat(c.script,"})()"))());n.dataset.created="true"}})):setTimeout((function(n){Ml()}),300)}function zl(n,e,t,r){var o="1"!==n.dataset.isExpand;t.style.height=o?"".concat(e,"px"):0,o?r.classList.add("vuepress-plugin-demo-block__show-link"):r.classList.remove("vuepress-plugin-demo-block__show-link"),n.dataset.isExpand=o?"1":"0"}var Dl={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},Ml()},updated:function(){Ml()}},ql="auto",Jl="zoom-in",Fl="zoom-out",Ul="grab",Hl="move";function Xl(n,e,t){var r=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],o={passive:!1};r?n.addEventListener(e,t,o):n.removeEventListener(e,t,o)}function $l(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function Wl(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function Ql(n,e,t){!function(n){var e=Gl,t=Vl;if(n.transition){var r=n.transition;delete n.transition,n[e]=r}if(n.transform){var o=n.transform;delete n.transform,n[t]=o}}(e);var r=n.style,o={};for(var a in e)t&&(o[a]=r[a]||""),r[a]=e[a];return o}var Gl="transition",Vl="transform",Kl="transform",Zl="transitionend";var Yl=function(){},ns={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:Yl,onClose:Yl,onGrab:Yl,onMove:Yl,onRelease:Yl,onBeforeOpen:Yl,onBeforeClose:Yl,onBeforeGrab:Yl,onBeforeRelease:Yl,onImageLoading:Yl,onImageLoaded:Yl},es={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),rs(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var r=this.lastScrollPosition.x-e,o=this.lastScrollPosition.y-t,a=this.options.scrollThreshold;(Math.abs(o)>=a||Math.abs(r)>=a)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(ts(n)&&!rs(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){ts(n)&&!rs(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,r=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,r)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,r=e.clientY;this.move(t,r)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function ts(n){return 0===n.button}function rs(n){return n.metaKey||n.ctrlKey}var os={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,Ql(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),Xl(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){Ql(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},as="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},is=function(){function n(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}return function(e,t,r){return t&&n(e.prototype,t),r&&n(e,r),e}}(),ls=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(n[r]=t[r])}return n},ss={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=Wl(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,r=n.transitionDuration,o=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?Ul:Fl,transition:Kl+"\n        "+r+"s\n        "+o,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Ql(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Ql(this.el,{transform:"none"})},grab:function(n,e,t){var r=cs(),o=r.x-n,a=r.y-e;Ql(this.el,{cursor:Hl,transform:"translate3d(\n        "+(this.translate.x+o)+"px, "+(this.translate.y+a)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var r=cs(),o=r.x-n,a=r.y-e;Ql(this.el,{transition:Kl,transform:"translate3d(\n        "+(this.translate.x+o)+"px, "+(this.translate.y+a)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Ql(this.el,this.styleClose)},restoreOpenStyle:function(){Ql(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=cs(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,r=this.instance.options,o=r.customSize,a=r.scaleBase;if(!o&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(o&&"object"===(void 0===o?"undefined":as(o)))return{x:o.width/this.rect.width,y:o.height/this.rect.height};var i=this.rect.width/2,l=this.rect.height/2,s=cs(),c={x:s.x-i,y:s.y-l},d=c.x/i,u=c.y/l,p=a+Math.min(d,u);if(o&&"string"==typeof o){var g=t||this.el.naturalWidth,h=e||this.el.naturalHeight,f=parseFloat(o)*g/(100*this.rect.width),m=parseFloat(o)*h/(100*this.rect.height);if(p>f||p>m)return{x:f,y:m}}return{x:p,y:p}}};function cs(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function ds(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(r){Xl(n,r,e[r],t)}))}var us=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(ss),this.overlay=Object.create(os),this.handler=Object.create(es),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=ls({},ns,e),this.overlay.init(this),this.handler.init(this)}return is(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=Jl,Xl(n,"click",this.handler.click),this.options.preloadImage&&$l(Wl(n)));return this}},{key:"config",value:function(n){return n?(ls(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var r="string"==typeof n?document.querySelector(n):n;if("IMG"===r.tagName){if(this.options.onBeforeOpen(r),this.target.init(r,this),!this.options.preloadImage){var o=this.target.srcOriginal;null!=o&&(this.options.onImageLoading(r),$l(o,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Xl(document,"scroll",this.handler.scroll),Xl(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Xl(window,"resize",this.handler.resizeWindow);var a=function n(){Xl(r,Zl,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&ds(document,e.handler,!0),t(r)};return Xl(r,Zl,a),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=ql,this.overlay.fadeOut(),this.target.zoomOut(),Xl(document,"scroll",this.handler.scroll,!1),Xl(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Xl(window,"resize",this.handler.resizeWindow,!1);var r=function r(){Xl(t,Zl,r,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&ds(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return Xl(t,Zl,r),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var o=this.target.el;this.options.onBeforeGrab(o),this.released=!1,this.target.grab(n,e,t);var a=function n(){Xl(o,Zl,n,!1),r(o)};return Xl(o,Zl,a),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=Hl,this.target.move(n,e,t);var o=this.target.el,a=function n(){Xl(o,Zl,n,!1),r(o)};return Xl(o,Zl,a),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=ql,this.target.restoreOpenStyle();var r=function r(){Xl(t,Zl,r,!1),n.lock=!1,n.released=!0,e(t)};return Xl(t,Zl,r),this}}}]),n}();const ps=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),gs=Number("500");class hs{constructor(){this.instance=new us(ps)}update(n=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(n)}updateDelay(n=".theme-vdoing-content img:not(.no-zoom)",e=gs){setTimeout(()=>this.update(n),e)}}var fs=[ml,wl,Tl,Cl,Dl,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new hs,this.$vuepress.zooming.updateDelay()}}],ms={name:"GlobalLayout",computed:{layout(){const n=this.getLayout();return ul("layout",n),$t.component(n)}},methods:{getLayout(){if(this.$page.path){const n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},bs=t(7),xs=Object(bs.a)(ms,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),n[e].push(...t);break;default:throw new Error("Unknown option name.")}}(xs,"mixins",fs);const vs=[{name:"v-68ba2172",path:"/pages/259a4b/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-68ba2172").then(t)}},{path:"/pages/259a4b/index.html",redirect:"/pages/259a4b/"},{path:"/02.文章/00.说明.html",redirect:"/pages/259a4b/"},{name:"v-9f98b88c",path:"/pages/a5b563/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-9f98b88c").then(t)}},{path:"/pages/a5b563/index.html",redirect:"/pages/a5b563/"},{path:"/02.文章/01.Java基础/1000.Java对于零拷贝的实现.html",redirect:"/pages/a5b563/"},{name:"v-eb6aaeb6",path:"/pages/5c396f/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-eb6aaeb6").then(t)}},{path:"/pages/5c396f/index.html",redirect:"/pages/5c396f/"},{path:"/02.文章/01.Java基础/100.Java NIO.html",redirect:"/pages/5c396f/"},{name:"v-f0607dd8",path:"/pages/493ffc/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-f0607dd8").then(t)}},{path:"/pages/493ffc/index.html",redirect:"/pages/493ffc/"},{path:"/02.文章/02.MySQL/01.InnoDB - 行格式.html",redirect:"/pages/493ffc/"},{name:"v-062f8431",path:"/pages/b3086d/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-062f8431").then(t)}},{path:"/pages/b3086d/index.html",redirect:"/pages/b3086d/"},{path:"/02.文章/02.MySQL/05.InnoDB - 页结构.html",redirect:"/pages/b3086d/"},{name:"v-afa30cfc",path:"/pages/d8c9ba/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-afa30cfc").then(t)}},{path:"/pages/d8c9ba/index.html",redirect:"/pages/d8c9ba/"},{path:"/02.文章/01.Java基础/300.单机定时任务的实现.html",redirect:"/pages/d8c9ba/"},{name:"v-e1c868da",path:"/pages/0c2518/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-e1c868da").then(t)}},{path:"/pages/0c2518/index.html",redirect:"/pages/0c2518/"},{path:"/02.文章/01.Java基础/150.Reactor模式.html",redirect:"/pages/0c2518/"},{name:"v-2e7dd8a7",path:"/pages/495592/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-2e7dd8a7").then(t)}},{path:"/pages/495592/index.html",redirect:"/pages/495592/"},{path:"/02.文章/02.MySQL/15.InnoDB - redo log 和 undo log.html",redirect:"/pages/495592/"},{name:"v-38cc1f4f",path:"/pages/31e077/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-38cc1f4f").then(t)}},{path:"/pages/31e077/index.html",redirect:"/pages/31e077/"},{path:"/02.文章/02.MySQL/17.InnoDB - Buffer Pool.html",redirect:"/pages/31e077/"},{name:"v-c8c76474",path:"/pages/4e0b96/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-c8c76474").then(t)}},{path:"/pages/4e0b96/index.html",redirect:"/pages/4e0b96/"},{path:"/02.文章/10.Redis/20.Redis 持久化机制.html",redirect:"/pages/4e0b96/"},{name:"v-1dab0d7c",path:"/pages/2e3013/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-1dab0d7c").then(t)}},{path:"/pages/2e3013/index.html",redirect:"/pages/2e3013/"},{path:"/02.文章/02.MySQL/20.InnoDB - 锁.html",redirect:"/pages/2e3013/"},{name:"v-4a5e1071",path:"/pages/26e2d2/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-4a5e1071").then(t)}},{path:"/pages/26e2d2/index.html",redirect:"/pages/26e2d2/"},{path:"/02.文章/02.MySQL/10.InnoDB - B+树索引.html",redirect:"/pages/26e2d2/"},{name:"v-6890b777",path:"/pages/db45e7/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-6890b777").then(t)}},{path:"/pages/db45e7/index.html",redirect:"/pages/db45e7/"},{path:"/02.文章/10.Redis/40.Redis主从集群原理.html",redirect:"/pages/db45e7/"},{name:"v-6db7c258",path:"/pages/77c4c7/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-6db7c258").then(t)}},{path:"/pages/77c4c7/index.html",redirect:"/pages/77c4c7/"},{path:"/02.文章/10.Redis/10.Redis数据结构与数据类型.html",redirect:"/pages/77c4c7/"},{name:"v-f8cd9c4a",path:"/pages/73749d/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-f8cd9c4a").then(t)}},{path:"/pages/73749d/index.html",redirect:"/pages/73749d/"},{path:"/02.文章/10.Redis/30.Redis内存回收.html",redirect:"/pages/73749d/"},{name:"v-1ca94746",path:"/pages/3743cc/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-1ca94746").then(t)}},{path:"/pages/3743cc/index.html",redirect:"/pages/3743cc/"},{path:"/02.文章/10.Redis/50.Redis哨兵集群.html",redirect:"/pages/3743cc/"},{name:"v-87b51ada",path:"/pages/70ea3d/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-87b51ada").then(t)}},{path:"/pages/70ea3d/index.html",redirect:"/pages/70ea3d/"},{path:"/02.文章/100.其他/100.常用工具类.html",redirect:"/pages/70ea3d/"},{name:"v-0d72e0be",path:"/pages/7ca562/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-0d72e0be").then(t)}},{path:"/pages/7ca562/index.html",redirect:"/pages/7ca562/"},{path:"/02.文章/100.其他/1000.Java学习路线.html",redirect:"/pages/7ca562/"},{name:"v-689aeb6e",path:"/pages/ad5a8e/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-689aeb6e").then(t)}},{path:"/pages/ad5a8e/index.html",redirect:"/pages/ad5a8e/"},{path:"/02.文章/100.其他/5.如何将IP地址存入MySQL.html",redirect:"/pages/ad5a8e/"},{name:"v-30dbcc76",path:"/pages/f63fe9/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-30dbcc76").then(t)}},{path:"/pages/f63fe9/index.html",redirect:"/pages/f63fe9/"},{path:"/02.文章/1000.实习小结/1.Git踩坑.html",redirect:"/pages/f63fe9/"},{name:"v-aebcce32",path:"/pages/65cd6f/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-aebcce32").then(t)}},{path:"/pages/65cd6f/index.html",redirect:"/pages/65cd6f/"},{path:"/02.文章/200.踩坑/10.xxl job Access token is wrong.html",redirect:"/pages/65cd6f/"},{name:"v-59982f2a",path:"/pages/3cac9b/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-59982f2a").then(t)}},{path:"/pages/3cac9b/index.html",redirect:"/pages/3cac9b/"},{path:"/02.文章/200.踩坑/20.国际化时需要返回给前端一段json，json工具不同结果报错.html",redirect:"/pages/3cac9b/"},{name:"v-54af3d7f",path:"/pages/0e629c/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-54af3d7f").then(t)}},{path:"/pages/0e629c/index.html",redirect:"/pages/0e629c/"},{path:"/02.文章/200.踩坑/30.mp使用@TableField注解未生效反而报错.html",redirect:"/pages/0e629c/"},{name:"v-5b394e2a",path:"/pages/99f624/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-5b394e2a").then(t)}},{path:"/pages/99f624/index.html",redirect:"/pages/99f624/"},{path:"/02.文章/1000.实习小结/150.开发规范.html",redirect:"/pages/99f624/"},{name:"v-f080616e",path:"/pages/e96a9e/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-f080616e").then(t)}},{path:"/pages/e96a9e/index.html",redirect:"/pages/e96a9e/"},{path:"/02.文章/200.踩坑/40.使用@Validated注解进行参数校验时报错：UnexpectedTypeException.html",redirect:"/pages/e96a9e/"},{name:"v-e594d938",path:"/pages/4e379b/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-e594d938").then(t)}},{path:"/pages/4e379b/index.html",redirect:"/pages/4e379b/"},{path:"/02.文章/200.踩坑/50.connection.setReadTimeout.html",redirect:"/pages/4e379b/"},{name:"v-619d565d",path:"/pages/c6965c/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-619d565d").then(t)}},{path:"/pages/c6965c/index.html",redirect:"/pages/c6965c/"},{path:"/02.文章/60.操作系统/10.用户态和内核态.html",redirect:"/pages/c6965c/"},{name:"v-c1afabda",path:"/pages/dbd03e/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-c1afabda").then(t)}},{path:"/pages/dbd03e/index.html",redirect:"/pages/dbd03e/"},{path:"/02.文章/60.操作系统/110.零拷贝.html",redirect:"/pages/dbd03e/"},{name:"v-62c5b9aa",path:"/pages/ee38bc/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-62c5b9aa").then(t)}},{path:"/pages/ee38bc/index.html",redirect:"/pages/ee38bc/"},{path:"/02.文章/60.操作系统/20.缓存一致性协议：MESI.html",redirect:"/pages/ee38bc/"},{name:"v-04afedb8",path:"/pages/424c75/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-04afedb8").then(t)}},{path:"/pages/424c75/index.html",redirect:"/pages/424c75/"},{path:"/02.文章/70.计算机网络/10.TCP、UDP协议.html",redirect:"/pages/424c75/"},{name:"v-4cfac2ae",path:"/pages/0776e3/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-4cfac2ae").then(t)}},{path:"/pages/0776e3/index.html",redirect:"/pages/0776e3/"},{path:"/02.文章/75.Java并发/100.原子类.html",redirect:"/pages/0776e3/"},{name:"v-366aefd3",path:"/pages/71bea1/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-366aefd3").then(t)}},{path:"/pages/71bea1/index.html",redirect:"/pages/71bea1/"},{path:"/02.文章/70.计算机网络/4.计算机网络五层网络模型.html",redirect:"/pages/71bea1/"},{name:"v-11139ae4",path:"/pages/c1826d/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-11139ae4").then(t)}},{path:"/pages/c1826d/index.html",redirect:"/pages/c1826d/"},{path:"/02.文章/75.Java并发/250.FutureTask中的适配器模式.html",redirect:"/pages/c1826d/"},{name:"v-98ff3c9c",path:"/pages/937dd3/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-98ff3c9c").then(t)}},{path:"/pages/937dd3/index.html",redirect:"/pages/937dd3/"},{path:"/02.文章/75.Java并发/200.FutureTask源码解析.html",redirect:"/pages/937dd3/"},{name:"v-d0b615f8",path:"/pages/671511/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-d0b615f8").then(t)}},{path:"/pages/671511/index.html",redirect:"/pages/671511/"},{path:"/02.文章/75.Java并发/300.线程池.html",redirect:"/pages/671511/"},{name:"v-040c55f4",path:"/pages/56d8fa/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-040c55f4").then(t)}},{path:"/pages/56d8fa/index.html",redirect:"/pages/56d8fa/"},{path:"/02.文章/75.Java并发/50.CAS.html",redirect:"/pages/56d8fa/"},{name:"v-9062bd3c",path:"/pages/79cb1d/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-9062bd3c").then(t)}},{path:"/pages/79cb1d/index.html",redirect:"/pages/79cb1d/"},{path:"/02.文章/75.Java并发/400.线程池源码解析.html",redirect:"/pages/79cb1d/"},{name:"v-230aad5c",path:"/pages/6c8c00/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-230aad5c").then(t)}},{path:"/pages/6c8c00/index.html",redirect:"/pages/6c8c00/"},{path:"/02.文章/75.Java并发/60.AQS源码解析.html",redirect:"/pages/6c8c00/"},{name:"v-b5de3650",path:"/pages/6cfda5/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-b5de3650").then(t)}},{path:"/pages/6cfda5/index.html",redirect:"/pages/6cfda5/"},{path:"/02.文章/75.Java并发/70.ReentrantReadWriteLock.html",redirect:"/pages/6cfda5/"},{name:"v-ff4b2134",path:"/pages/5031c2/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-ff4b2134").then(t)}},{path:"/pages/5031c2/index.html",redirect:"/pages/5031c2/"},{path:"/02.文章/75.Java并发/65.ReentrantLock.html",redirect:"/pages/5031c2/"},{name:"v-68f17928",path:"/pages/97a05f/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-68f17928").then(t)}},{path:"/pages/97a05f/index.html",redirect:"/pages/97a05f/"},{path:"/02.文章/85.算法/1.负载均衡算法.html",redirect:"/pages/97a05f/"},{name:"v-20c514cb",path:"/pages/5dba8e/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-20c514cb").then(t)}},{path:"/pages/5dba8e/index.html",redirect:"/pages/5dba8e/"},{path:"/02.文章/85.算法/20.限流算法.html",redirect:"/pages/5dba8e/"},{name:"v-ed0ea22a",path:"/pages/7e25cb/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-ed0ea22a").then(t)}},{path:"/pages/7e25cb/index.html",redirect:"/pages/7e25cb/"},{path:"/02.文章/85.算法/30.一致性哈希算法.html",redirect:"/pages/7e25cb/"},{name:"v-218f759f",path:"/pages/3fe609/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-218f759f").then(t)}},{path:"/pages/3fe609/index.html",redirect:"/pages/3fe609/"},{path:"/02.文章/85.算法/40.雪花算法.html",redirect:"/pages/3fe609/"},{name:"v-1a0380cd",path:"/pages/db9f45/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-1a0380cd").then(t)}},{path:"/pages/db9f45/index.html",redirect:"/pages/db9f45/"},{path:"/02.文章/91.框架/1.理论/10.CAP理论.html",redirect:"/pages/db9f45/"},{name:"v-2232d43f",path:"/pages/793cbb/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-2232d43f").then(t)}},{path:"/pages/793cbb/index.html",redirect:"/pages/793cbb/"},{path:"/02.文章/91.框架/1.理论/20.BASE理论.html",redirect:"/pages/793cbb/"},{name:"v-75b72c80",path:"/pages/208bb3/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-75b72c80").then(t)}},{path:"/pages/208bb3/index.html",redirect:"/pages/208bb3/"},{path:"/02.文章/91.框架/1.理论/30.Raft算法.html",redirect:"/pages/208bb3/"},{name:"v-64094560",path:"/pages/fcb98f/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-64094560").then(t)}},{path:"/pages/fcb98f/index.html",redirect:"/pages/fcb98f/"},{path:"/02.文章/91.框架/100.XXL-JOB/2.XXL-JOB的使用.html",redirect:"/pages/fcb98f/"},{name:"v-49c73577",path:"/pages/bb013b/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-49c73577").then(t)}},{path:"/pages/bb013b/index.html",redirect:"/pages/bb013b/"},{path:"/02.文章/91.框架/100.XXL-JOB/1.XXL-JOB的安装.html",redirect:"/pages/bb013b/"},{name:"v-2a546378",path:"/pages/75326c/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-2a546378").then(t)}},{path:"/pages/75326c/index.html",redirect:"/pages/75326c/"},{path:"/02.文章/91.框架/100.XXL-JOB/20.XXL-JOB负载均衡策略.html",redirect:"/pages/75326c/"},{name:"v-849ebb74",path:"/pages/ac1d9d/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-849ebb74").then(t)}},{path:"/pages/ac1d9d/index.html",redirect:"/pages/ac1d9d/"},{path:"/02.文章/91.框架/100.XXL-JOB/4.XXL-JOB数据库字段讲解.html",redirect:"/pages/ac1d9d/"},{name:"v-18bfcd63",path:"/pages/a25535/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-18bfcd63").then(t)}},{path:"/pages/a25535/index.html",redirect:"/pages/a25535/"},{path:"/02.文章/91.框架/100.XXL-JOB/6.执行器端的日志组件.html",redirect:"/pages/a25535/"},{name:"v-55669653",path:"/pages/243013/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-55669653").then(t)}},{path:"/pages/243013/index.html",redirect:"/pages/243013/"},{path:"/02.文章/91.框架/20.微服务中间件的使用/10.Nacos.html",redirect:"/pages/243013/"},{name:"v-72a09f4a",path:"/pages/afe80c/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-72a09f4a").then(t)}},{path:"/pages/afe80c/index.html",redirect:"/pages/afe80c/"},{path:"/02.文章/91.框架/20.微服务中间件的使用/20.Ribbon.html",redirect:"/pages/afe80c/"},{name:"v-0000769a",path:"/pages/e020ec/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-0000769a").then(t)}},{path:"/pages/e020ec/index.html",redirect:"/pages/e020ec/"},{path:"/02.文章/91.框架/20.微服务中间件的使用/30.OpenFeign.html",redirect:"/pages/e020ec/"},{name:"v-0112e9f6",path:"/pages/5531a6/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-0112e9f6").then(t)}},{path:"/pages/5531a6/index.html",redirect:"/pages/5531a6/"},{path:"/02.文章/91.框架/100.XXL-JOB/5.定时任务是如何执行的.html",redirect:"/pages/5531a6/"},{name:"v-40abcda6",path:"/pages/b4dd7e/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-40abcda6").then(t)}},{path:"/pages/b4dd7e/index.html",redirect:"/pages/b4dd7e/"},{path:"/02.文章/91.框架/5.Spring/100.Spring事务.html",redirect:"/pages/b4dd7e/"},{name:"v-7512a88a",path:"/pages/a7a70b/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-7512a88a").then(t)}},{path:"/pages/a7a70b/index.html",redirect:"/pages/a7a70b/"},{path:"/02.文章/91.框架/20.微服务中间件的使用/40.Sentinel.html",redirect:"/pages/a7a70b/"},{name:"v-fa2c9a0c",path:"/pages/3d8a71/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-fa2c9a0c").then(t)}},{path:"/pages/3d8a71/index.html",redirect:"/pages/3d8a71/"},{path:"/02.文章/91.框架/60.Sentinel/3. Sentinel中的一些概念.html",redirect:"/pages/3d8a71/"},{name:"v-d47ce5a2",path:"/pages/51db55/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-d47ce5a2").then(t)}},{path:"/pages/51db55/index.html",redirect:"/pages/51db55/"},{path:"/02.文章/91.框架/60.Sentinel/4. Sentinel 责任链流程.html",redirect:"/pages/51db55/"},{name:"v-6f97f076",path:"/pages/f4866d/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-6f97f076").then(t)}},{path:"/pages/f4866d/index.html",redirect:"/pages/f4866d/"},{path:"/02.文章/91.框架/60.Sentinel/5. Sentinel - NodeSelectorSlot.html",redirect:"/pages/f4866d/"},{name:"v-34b36bf8",path:"/pages/df7ccb/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-34b36bf8").then(t)}},{path:"/pages/df7ccb/index.html",redirect:"/pages/df7ccb/"},{path:"/02.文章/91.框架/60.Sentinel/6. Sentinel - ClusterBuilderSlot.html",redirect:"/pages/df7ccb/"},{name:"v-c3e06076",path:"/pages/1b12ed/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-c3e06076").then(t)}},{path:"/pages/1b12ed/index.html",redirect:"/pages/1b12ed/"},{path:"/06.联系我/01.联系我.html",redirect:"/pages/1b12ed/"},{name:"v-391a0836",path:"/blog/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-391a0836").then(t)}},{path:"/blog/index.html",redirect:"/blog/"},{path:"/@pages/archivesPage.html",redirect:"/blog/"},{name:"v-5f6c1111",path:"/",component:xs,beforeEnter:(n,e,t)=>{dl("Layout","v-5f6c1111").then(t)}},{path:"/index.html",redirect:"/"},{path:"*",component:xs}],ys={title:"",description:"一个基于VuePress的 知识管理&博客 主题",base:"/",headTags:[["link",{rel:"icon",href:"/img/favicon.ico"}],["meta",{name:"keywords",content:"vuepress,theme,blog,vdoing"}],["meta",{name:"theme-color",content:"#11a8cd"}]],pages:[{title:"说明",frontmatter:{title:"说明",date:"2023-06-08T21:45:52.000Z",permalink:"/pages/259a4b/"},regularPath:"/02.%E6%96%87%E7%AB%A0/00.%E8%AF%B4%E6%98%8E.html",relativePath:"02.文章/00.说明.md",key:"v-68ba2172",path:"/pages/259a4b/",headersStr:null,content:"这里是我平时学习记录的笔记。有些是看完一些视频/博客/笔记随便写写，有些是看书写的笔记。",normalizedContent:"这里是我平时学习记录的笔记。有些是看完一些视频/博客/笔记随便写写，有些是看书写的笔记。",charsets:{cjk:!0},lastUpdated:"2023/08/02, 01:36:29",lastUpdatedTimestamp:1690911389e3},{title:"Java对于零拷贝的实现",frontmatter:{title:"Java对于零拷贝的实现",date:"2023-11-02T16:33:02.000Z",permalink:"/pages/a5b563/"},regularPath:"/02.%E6%96%87%E7%AB%A0/01.Java%E5%9F%BA%E7%A1%80/1000.Java%E5%AF%B9%E4%BA%8E%E9%9B%B6%E6%8B%B7%E8%B4%9D%E7%9A%84%E5%AE%9E%E7%8E%B0.html",relativePath:"02.文章/01.Java基础/1000.Java对于零拷贝的实现.md",key:"v-9f98b88c",path:"/pages/a5b563/",headers:[{level:2,title:"1. MMAP",slug:"_1-mmap",normalizedTitle:"1. mmap",charIndex:221},{level:2,title:"2. 堆外内存",slug:"_2-堆外内存",normalizedTitle:"2. 堆外内存",charIndex:566},{level:2,title:"3. send file",slug:"_3-send-file",normalizedTitle:"3. send file",charIndex:1054},{level:3,title:"3.1 transferFrom 细节",slug:"_3-1-transferfrom-细节",normalizedTitle:"3.1 transferfrom 细节",charIndex:1247},{level:4,title:"3.1.1 MMAP",slug:"_3-1-1-mmap",normalizedTitle:"3.1.1 mmap",charIndex:1454},{level:4,title:"3.1.2 堆外内存",slug:"_3-1-2-堆外内存",normalizedTitle:"3.1.2 堆外内存",charIndex:2091},{level:4,title:"3.1.3 transferFrom 方法小结",slug:"_3-1-3-transferfrom-方法小结",normalizedTitle:"3.1.3 transferfrom 方法小结",charIndex:2195},{level:3,title:"3.2 transferTo 细节",slug:"_3-2-transferto-细节",normalizedTitle:"3.2 transferto 细节",charIndex:2486}],headersStr:"1. MMAP 2. 堆外内存 3. send file 3.1 transferFrom 细节 3.1.1 MMAP 3.1.2 堆外内存 3.1.3 transferFrom 方法小结 3.2 transferTo 细节",content:"关于 mmap、sendfile 的知识，参见 ：零拷贝。这篇文章介绍了零拷贝的知识，也讲解了 mmap、sendfile 对于数据传输的优化 以及 它俩的区别。\n\nJava sendfile 的 api 是 transferTo 和 transferFrom 方法。\n\n注意 ：send file 是一个从磁盘到网卡驱动的 IO 优化。反过来，网卡到磁盘，是没有这个优化的。也就是说 transferFrom 方法并没有这种福利。\n\n\n# 1. MMAP\n\nMMAP ：将用户缓冲区与内核缓冲区做映射，减少一次CPU拷贝。\n\n在 Java 中调用 MMAP 为 ：\n\nMappedByteBuffer mappedBuffer = \n    fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, fileChannel.size());\n\n\nfileChannel.map() 后即可获得映射后的 buffer，接着就可以使用 MMAP 方式进行文件拷贝。\n\n可以使用 mappedBuffer.put() 方法向缓冲区存放数据，再使用 mappedBuffer.force() 刷新到磁盘。\n\nmmap为何可以减少一次CPU拷贝，在零拷贝那一章已经介绍过了，不在介绍了。\n\n\n# 2. 堆外内存\n\nJava 中还有一种方式可以提高文件拷贝的效率 ：堆外内存。\n\n实际上这种方式并不是零拷贝，我们知道，Java中使用的内存大部分都在堆中，堆受Java堆内存管理的控制。\n\n而堆外内存是直接在堆的外面分配内存给你用，不再受 Java堆内存管理机制的约束，不存在频繁的移动或者清理。通常会与mmap结合在一起使用，所以Java 提供了一个类 ：DirectBuffer\n\npublic interface DirectBuffer {\n    long address();\n\n    Object attachment();\n\n    Cleaner cleaner();\n}\n\n\n这是一个接口，其中 address 是申请的堆外内存的地址。这个类拥有很多实现类，拿最典型的 DirectByteBuffer来说，它既实现了 DirectBuffer，拥有分配堆外内存的能力，又实现了MappedByteBuffer，拥有了内存映射的能力。\n\n堆外内存怎么分配呢？用学过的C语言来说，大概就是 malloc 一下，把申请的地址给 address变量。\n\n\n# 3. send file\n\n说 senfile 其实也不合适，Java对于send file 的实现中，按照不同的使用情况使用了不同的零拷贝方式，其中两个关键的 api ：transferTo、transferFrom。它俩在 FileChannel 中。\n\n其中只有 transferTo 用到了send file，而且想要触发 send file 是有条件的，具体往下看。\n\n\n# 3.1 transferFrom 细节\n\ntransferFrom的底层其实是两种实现方式 ：\n\n 1. MMAP\n 2. 堆外内存\n\n\n\n从代码可以看出来，使用transferFrom后，判断传入的 channel 类型，\n\n * 如果是普通的 FileChannel 实现类，那么使用mmap做映射。\n * 如果用的是 非FileChannel，即SocketChannel相关实现类，用堆外内存完成。\n\n# 3.1.1 MMAP\n\n\n\n方法的名字叫做 transferFromFileChannel\n\n简单来讲，在一个循环中，每次都是将源文件根据 position 映射为一个 mmap，最大8M，逐次的将数据写入目标文件中。\n\nprivatet long transferFromFileChannel(FileChannelImpl src, long position, long count) {\n    // 省略部分代码\n    // remaining: 需要拷贝的数据剩余的字节。\n    while (remaining > 0L) {\n        long size = Math.min(remaining, 8 * 1024 * 1024);\n        MappedByteBuffer bb = src.map(MapMode.READ_ONLY, p, size);\n        try {\n            // 写入n个字节，并将源文件和目标文件的下标更改\n            long n = write(bb, position); \n            position += n; \n            remaining -= n; \n        } finally {\n            // 取消映射\n            unmap(bb); \n        }\n    }\n}\n\n\n# 3.1.2 堆外内存\n\ntransferFrom堆外内存的细节：\n\n\n\n如果我们使用的是 SocketChannelImpl，就会走堆外内存，也是在一个循环中写入，每次最大8k。用完尽量回收重新利用。\n\n# 3.1.3 transferFrom 方法小结\n\n 1. 如果是源是 FileChannelImpl 类型， 就走 mmap ，循环映射 8MB 刷进磁盘。\n 2. 如果源是 SocketChannelImpl 类型，就走堆外内存。简单来说，就是循环放进堆外内存，每次 8kb 刷进磁盘。注意：关于这个堆外内存，是用到了缓存池子的（堆外内存池化是常用优化手段），这个池子是个数组，长度是 16，使用 ThreadLocal 提升性能，每次获取，只要目标数组比池子中的 ByteBuffer 的 capacity 小即可使用，用完就还，如果满了，就调用 unsafe 释放。\n\n\n# 3.2 transferTo 细节\n\ntransferTo 方法很有意思，先简单说下结论：\n\n 1. 如果 OS 支持 send file（windows 不支持），就执行 system call。\n 2. 如果 OS 不支持，就走 mmap。\n 3. 如果 mmap 失败，就走 堆外内存。\n\n\n\n> 看了 send file 的 Java 层面实现，这里总结一下，只有 transferTo 用到了 send file，而且还是有条件的，具体，本文第二部分已经给出。\n> \n> 而 transferFrom 方法则是很普通的使用 mmap 或者 堆外内存，似乎我们有可以自己实现，反而性能可能会更好，例如我们使用更大的缓存，而不必循环多次，我们可以使用更大的 mmap 映射，而不是 8Mb，每次都需要 clean 再重新 mapping。",normalizedContent:"关于 mmap、sendfile 的知识，参见 ：零拷贝。这篇文章介绍了零拷贝的知识，也讲解了 mmap、sendfile 对于数据传输的优化 以及 它俩的区别。\n\njava sendfile 的 api 是 transferto 和 transferfrom 方法。\n\n注意 ：send file 是一个从磁盘到网卡驱动的 io 优化。反过来，网卡到磁盘，是没有这个优化的。也就是说 transferfrom 方法并没有这种福利。\n\n\n# 1. mmap\n\nmmap ：将用户缓冲区与内核缓冲区做映射，减少一次cpu拷贝。\n\n在 java 中调用 mmap 为 ：\n\nmappedbytebuffer mappedbuffer = \n    filechannel.map(filechannel.mapmode.read_write, 0, filechannel.size());\n\n\nfilechannel.map() 后即可获得映射后的 buffer，接着就可以使用 mmap 方式进行文件拷贝。\n\n可以使用 mappedbuffer.put() 方法向缓冲区存放数据，再使用 mappedbuffer.force() 刷新到磁盘。\n\nmmap为何可以减少一次cpu拷贝，在零拷贝那一章已经介绍过了，不在介绍了。\n\n\n# 2. 堆外内存\n\njava 中还有一种方式可以提高文件拷贝的效率 ：堆外内存。\n\n实际上这种方式并不是零拷贝，我们知道，java中使用的内存大部分都在堆中，堆受java堆内存管理的控制。\n\n而堆外内存是直接在堆的外面分配内存给你用，不再受 java堆内存管理机制的约束，不存在频繁的移动或者清理。通常会与mmap结合在一起使用，所以java 提供了一个类 ：directbuffer\n\npublic interface directbuffer {\n    long address();\n\n    object attachment();\n\n    cleaner cleaner();\n}\n\n\n这是一个接口，其中 address 是申请的堆外内存的地址。这个类拥有很多实现类，拿最典型的 directbytebuffer来说，它既实现了 directbuffer，拥有分配堆外内存的能力，又实现了mappedbytebuffer，拥有了内存映射的能力。\n\n堆外内存怎么分配呢？用学过的c语言来说，大概就是 malloc 一下，把申请的地址给 address变量。\n\n\n# 3. send file\n\n说 senfile 其实也不合适，java对于send file 的实现中，按照不同的使用情况使用了不同的零拷贝方式，其中两个关键的 api ：transferto、transferfrom。它俩在 filechannel 中。\n\n其中只有 transferto 用到了send file，而且想要触发 send file 是有条件的，具体往下看。\n\n\n# 3.1 transferfrom 细节\n\ntransferfrom的底层其实是两种实现方式 ：\n\n 1. mmap\n 2. 堆外内存\n\n\n\n从代码可以看出来，使用transferfrom后，判断传入的 channel 类型，\n\n * 如果是普通的 filechannel 实现类，那么使用mmap做映射。\n * 如果用的是 非filechannel，即socketchannel相关实现类，用堆外内存完成。\n\n# 3.1.1 mmap\n\n\n\n方法的名字叫做 transferfromfilechannel\n\n简单来讲，在一个循环中，每次都是将源文件根据 position 映射为一个 mmap，最大8m，逐次的将数据写入目标文件中。\n\nprivatet long transferfromfilechannel(filechannelimpl src, long position, long count) {\n    // 省略部分代码\n    // remaining: 需要拷贝的数据剩余的字节。\n    while (remaining > 0l) {\n        long size = math.min(remaining, 8 * 1024 * 1024);\n        mappedbytebuffer bb = src.map(mapmode.read_only, p, size);\n        try {\n            // 写入n个字节，并将源文件和目标文件的下标更改\n            long n = write(bb, position); \n            position += n; \n            remaining -= n; \n        } finally {\n            // 取消映射\n            unmap(bb); \n        }\n    }\n}\n\n\n# 3.1.2 堆外内存\n\ntransferfrom堆外内存的细节：\n\n\n\n如果我们使用的是 socketchannelimpl，就会走堆外内存，也是在一个循环中写入，每次最大8k。用完尽量回收重新利用。\n\n# 3.1.3 transferfrom 方法小结\n\n 1. 如果是源是 filechannelimpl 类型， 就走 mmap ，循环映射 8mb 刷进磁盘。\n 2. 如果源是 socketchannelimpl 类型，就走堆外内存。简单来说，就是循环放进堆外内存，每次 8kb 刷进磁盘。注意：关于这个堆外内存，是用到了缓存池子的（堆外内存池化是常用优化手段），这个池子是个数组，长度是 16，使用 threadlocal 提升性能，每次获取，只要目标数组比池子中的 bytebuffer 的 capacity 小即可使用，用完就还，如果满了，就调用 unsafe 释放。\n\n\n# 3.2 transferto 细节\n\ntransferto 方法很有意思，先简单说下结论：\n\n 1. 如果 os 支持 send file（windows 不支持），就执行 system call。\n 2. 如果 os 不支持，就走 mmap。\n 3. 如果 mmap 失败，就走 堆外内存。\n\n\n\n> 看了 send file 的 java 层面实现，这里总结一下，只有 transferto 用到了 send file，而且还是有条件的，具体，本文第二部分已经给出。\n> \n> 而 transferfrom 方法则是很普通的使用 mmap 或者 堆外内存，似乎我们有可以自己实现，反而性能可能会更好，例如我们使用更大的缓存，而不必循环多次，我们可以使用更大的 mmap 映射，而不是 8mb，每次都需要 clean 再重新 mapping。",charsets:{cjk:!0},lastUpdated:"2023/11/08, 21:26:21",lastUpdatedTimestamp:1699449981e3},{title:"Java NIO",frontmatter:{title:"Java NIO",date:"2023-08-02T00:53:14.000Z",permalink:"/pages/5c396f/"},regularPath:"/02.%E6%96%87%E7%AB%A0/01.Java%E5%9F%BA%E7%A1%80/100.Java%20NIO.html",relativePath:"02.文章/01.Java基础/100.Java NIO.md",key:"v-eb6aaeb6",path:"/pages/5c396f/",headers:[{level:2,title:"1. IO概述",slug:"_1-io概述",normalizedTitle:"1. io概述",charIndex:2},{level:2,title:"2. Buffer",slug:"_2-buffer",normalizedTitle:"2. buffer",charIndex:1387},{level:3,title:"2.1 allocate()",slug:"_2-1-allocate",normalizedTitle:"2.1 allocate()",charIndex:2411},{level:3,title:"2.2 position() limit()",slug:"_2-2-position-limit",normalizedTitle:"2.2 position() limit()",charIndex:2903},{level:3,title:"2.3 flip()",slug:"_2-3-flip",normalizedTitle:"2.3 flip()",charIndex:4463},{level:3,title:"2.4 clear() rewind()",slug:"_2-4-clear-rewind",normalizedTitle:"2.4 clear() rewind()",charIndex:5311},{level:3,title:"2.5 compact()",slug:"_2-5-compact",normalizedTitle:"2.5 compact()",charIndex:5716},{level:3,title:"2.6 remaining()",slug:"_2-6-remaining",normalizedTitle:"2.6 remaining()",charIndex:6304},{level:2,title:"3. Channel",slug:"_3-channel",normalizedTitle:"3. channel",charIndex:7724},{level:3,title:"3.1 文件 IO 通道",slug:"_3-1-文件-io-通道",normalizedTitle:"3.1 文件 io 通道",charIndex:8025},{level:3,title:"3.2 网络 IO 通道",slug:"_3-2-网络-io-通道",normalizedTitle:"3.2 网络 io 通道",charIndex:9877},{level:4,title:"3.2.1 ServerSocketChannel",slug:"_3-2-1-serversocketchannel",normalizedTitle:"3.2.1 serversocketchannel",charIndex:10400},{level:4,title:"3.2.2 SocketChannel",slug:"_3-2-2-socketchannel",normalizedTitle:"3.2.2 socketchannel",charIndex:11896},{level:4,title:"3.2.3 DatagramChannel",slug:"_3-2-3-datagramchannel",normalizedTitle:"3.2.3 datagramchannel",charIndex:16782},{level:2,title:"4. Selector",slug:"_4-selector",normalizedTitle:"4. selector",charIndex:19449},{level:3,title:"4.1 SelectableChannel",slug:"_4-1-selectablechannel",normalizedTitle:"4.1 selectablechannel",charIndex:19810},{level:3,title:"4.2 SelectionKey",slug:"_4-2-selectionkey",normalizedTitle:"4.2 selectionkey",charIndex:20142},{level:3,title:"4.3 Selector",slug:"_4-3-selector",normalizedTitle:"4.3 selector",charIndex:21084},{level:2,title:"5. IO多路复用的几种模式",slug:"_5-io多路复用的几种模式",normalizedTitle:"5. io多路复用的几种模式",charIndex:23816},{level:2,title:"6. 总结",slug:"_6-总结",normalizedTitle:"6. 总结",charIndex:24698}],headersStr:"1. IO概述 2. Buffer 2.1 allocate() 2.2 position() limit() 2.3 flip() 2.4 clear() rewind() 2.5 compact() 2.6 remaining() 3. Channel 3.1 文件 IO 通道 3.2 网络 IO 通道 3.2.1 ServerSocketChannel 3.2.2 SocketChannel 3.2.3 DatagramChannel 4. Selector 4.1 SelectableChannel 4.2 SelectionKey 4.3 Selector 5. IO多路复用的几种模式 6. 总结",content:'# 1. IO概述\n\n在介绍Java NIO 之前，先来说一下什么是IO。\n\n什么是IO？\n\n简而言之，Input和OutPut，输入和输出就是IO。\n\n根据操作系统的知识 ：一个进程的地址空间划分为 用户空间、内核空间。我们平时运行的应用程序是在用户空间中的，只有当出现内存分配、文件操作等操作时 才会切换为内核空间，并且用户空间是无法访问这些资源的，用户进程想要访问系统资源就必须要 进行系统调用从用户空间切换到内核空间。\n\n一共为三个步骤 ：\n\n 1. 用户空间发起系统调用（例如进行读文件时执行的read方法），产生中断\n 2. 内核等待 I/O 设备准备好数据\n 3. 内核将数据从 内核空间 拷贝到用户空间。（更准确点是从内核空间的缓冲区拷贝到用户空间的缓冲区）\n\n那么在用户空间发起系统调用直到内核空间拿到值返回给你这个时间段，用户空间是 阻塞等待 还是 不断轮询，就产生了阻塞IO、非阻塞IO这些不同的IO方式。Linux中分为五种IO方式 ：\n\n 1. 同步阻塞 I/O ：应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间。\n 2. 同步非阻塞 I/O ：应用程序发起read后立刻返回并不断询问。\n 3. I/O 多路复用 ：线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间 -> 用户空间）还是阻塞的。\n 4. 信号驱动 I/O ：应用程序发起read调用后去做自己的事情，内核准备好数据后发出SIGIO信号通知应用程序已经准备好数据， 应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。\n 5. 异步 I/O ：应用程序发起read调用后去做自己的事情，内核将数据从内核空间拷贝到用户空间后发起signal信号通知应用程序已经准备好数据。\n\n乍一看信号驱动IO和异步IO不是一样吗？其实不然，\n\n * 信号驱动IO ：发起信号通知时，数据在内核态，应用程序需要把数据拷贝到用户态\n * 异步IO ：发起信号时数据已经在用户态了。\n\n在Java里面没有这么多IO模式，只有BIO、NIO、AIO。\n\n 1. BIO ：对应 同步阻塞I/O。\n 2. NIO ：对应 I/O多路复用。\n 3. AIO ：对应异步I/O。\n\nBIO是FileInputStream、OutputStream这种，NIO是 Buffer + Channel + Selector 这一套。\n\n本篇文章就是针对于 Java NIO 的 API 进行讲解。\n\n> 分割线\n\nJava 的 NIO 模型对应操作系统的 IO 多路复用模型，java.nio包下提供的类不仅可以实现阻塞IO、非阻塞IO，还可以实现IO多路复用。\n\n\n\n> Java的IO多路复用：可以使用一个线程处理多个客户端请求。客户端发送的请求会注册到多路复用器 Selector 上，由 Selector 轮询各个客户端的请求并进行处理。\n\nJava 的 NIO 提供了几个重要的组件：\n\n * Buffer ：缓冲区\n * Channel ：管道\n * Selector ：多路复用器（并不是所有的 io 都可以使用 Selector）\n\n\n# 2. Buffer\n\n在上一篇中我们提到：BIO 的操作都是基于流的，而 NIO 的操作都是基于缓存的。\n\n也就是说，在 NIO 中所有的操作都是用缓冲处理的，不管是读还是写，都使用 Buffer 完成。\n\n在 NIO 中，所有的缓冲区类型都继承于抽象类 Buffer，最常用的是 ByteBuffer，对于 Java 的基本数据类型，基本都有一个具体的 Buffer 实现类 与之对应。最常用的是 ByteBuffer。\n\n\n\n其实 Buffer 是使用数组实现的，也就是说我们读出来的或者写入的数据，都是先存进数组里面。\n\n举例：如下为 IntBuffer 里面存放数据的数组。\n\n\n\n现在回到 Buffer，Buffer 中有几个非常重要的变量：\n\n 1. capacity ：这个 Buffer 的容量，也就是一次最多放进去多少东西。这个变量在 Buffer 创建时指定，且无法改变。\n 2. position ：当前操作数据的下标。\n 3. limit ：当前操作最大操作到哪个下标，默认为 capacity。\n 4. mark ：标记\n\n也很好理解，由于数据放在数组中，我们必须使用几个变量记录一下现在操作到哪、最多操作到哪、数组最大容量。\n\nBuffer 常用的方法：\n\n方法                     作用\nxxxBuffer.allocate()   创建一个 Buffer 对象（如 ByteBuffer、IntBuffer...）\nget()                  获取 position 位置的数据，获取数据后 position++\nput()                  往 position 位置放置数据\nposition()             设置 position 的值\nlimit()                设置 limit 的值\nflip()                 切换为读模式\nclear()                切换为写模式（丢弃剩余数据）\ncompact()              切换为写模式（保留剩余数据）\nremaining()            return limit - position，一般用作查看 Buffer 中是否还有数据\nhasRemaining()         如果有残留数据，返回 true\n\n\n# 2.1 allocate()\n\n当想创建一个 Buffer 时，使用的是 对应 Buffer.allocate(int capacity)。\n\n例如想创建一个大小为 10 字节的 Buffer：（为了方便，本篇下面就使用 ByteBuffer 举例。）\n\npublic class TestNIO {\n    public static void main(String[] args) {\n        ByteBuffer byteBuffer = ByteBuffer.allocate(10);\n        IntBuffer intBuffer = IntBuffer.allocate(10);\n        CharBuffer charBuffer = CharBuffer.allocate(10);\n        LongBuffer longBuffer = LongBuffer.allocate(10);\n    }\n}\n\n\n刚才说的四个属性总是遵循以下规律：\n\nmark <= pasition <= limit <= capacity\n\n\n# 2.2 position() limit()\n\n同时，Buffer 提供了几个方法来改变这几个属性的值：\n\nbyteBuffer.position(int position);\nbyteBuffer.mark(int mark);\nbyteBuffer.limit(int limit);\n\n\n如下为新创建的 ByteBuffer：\n\n\n\n现在的可操作范围为：position - limit（0 - 10）\n\n使用 put 方法向数组中放入几个元素后：\n\npublic class TestNIO {\n    public static void main(String[] args) {\n        ByteBuffer byteBuffer = ByteBuffer.allocate(10);\n        // put方法的操作：将数据放到position位置，position++\n        byteBuffer.put((byte)5);\n        byteBuffer.put((byte)7);\n        byteBuffer.put((byte)2);\n        byteBuffer.put((byte)6);\n        byteBuffer.put((byte)4);\n    }\n}\n\n\n向内填充数据后，position 随之移动，可操作范围为 5 - 10。\n\n\n\n假如我现在不想存数据了，我想取数据怎么办？\n\n由于操作范围为 position - limit，我们想要数组下标为 0 到 4 的数据，那么首先要把操作范围改为 0-4.\n\n具体一点就是 limit = position，position = 0\n\npublic class TestNIO {\n    public static void main(String[] args) {\n        ByteBuffer byteBuffer = ByteBuffer.allocate(10);\n\n        byteBuffer.put((byte)5);\n        byteBuffer.put((byte)7);\n        byteBuffer.put((byte)2);\n        byteBuffer.put((byte)6);\n        byteBuffer.put((byte)4);\n\t// 获取此时limit和position的值\n        int limit = byteBuffer.limit();\n        int position = byteBuffer.position();\n\n        // 将limit = position\n        // 将position = 0\n        byteBuffer.limit(position);\n        byteBuffer.position(0);\n\t// get()操作：获取数组中position位置的元素，position++\n        System.out.println(byteBuffer.get());\n        System.out.println(byteBuffer.get());\n        System.out.println(byteBuffer.get());\n        System.out.println(byteBuffer.get());\n        System.out.println(byteBuffer.get());\n    }\n}\n\n\n打印之后：\n\n\n\n\n# 2.3 flip()\n\n但是这样会不会很麻烦？难道我每次想要读取数据的时候都需要 limit=position, position=0 ？\n\n肯定不啦，人家有现成的方法供我们调用：byteBuffer.flip()\n\npublic final Buffer flip() {\n    limit = position;\n    position = 0;\n    mark = -1;\n    return this;\n}\n\n\n这个方法帮我们把 position 和 limit 属性赋值，直接调用就可以读取数据，所以我们称它为读模式。\n\npublic class TestNIO {\n    public static void main(String[] args) {\n        ByteBuffer byteBuffer = ByteBuffer.allocate(10);\n        byteBuffer.put((byte)5);\n        byteBuffer.put((byte)7);\n        byteBuffer.put((byte)2);\n        byteBuffer.put((byte)6);\n        byteBuffer.put((byte)4);\n        // 进入读模式\n        byteBuffer.flip();\n\n        System.out.println(byteBuffer.get());\n        System.out.println(byteBuffer.get());\n        System.out.println(byteBuffer.get());\n        System.out.println(byteBuffer.get());\n        System.out.println(byteBuffer.get());\n    }\n}\n\n\n\n# 2.4 clear() rewind()\n\n既然有读模式，聪明的你肯定想到了写模式，没错，确实有：byteBuffer.clear()\n\npublic final Buffer clear() {\n    position = 0;\n    limit = capacity;\n    mark = -1;\n    return this;\n}\n\n\n写模式将 position 置为 0，limit 回到 capacity 处，就可以重新写入数据了。\n\n当然，还有一个 API 也可以实现类似写模式的作用：byteBuffer.rewind();\n\npublic final Buffer rewind() {\n    position = 0;\n    mark = -1;\n    return this;\n}\n\n\nclear 与 rewind 的区别是：rewind 不改变 limit 的值。\n\n\n# 2.5 compact()\n\n但是现在功能还不是很完善，如果数组中还有数据，但是我们依旧想向数组中写入数据该怎么办呢？使用 flip 方法和 clear 方法？\n\n\n\n如图所示，position 在下标为 3 的地方，调用 clear 方法后会将 position 置 0，再写入数据时就会发现：之前的 6 和 4 被覆盖了，我还没有用它呢怎么能让它丢弃呢？\n\nBuffer 也提供了方法保留这几个字节的数据：byteBuffer.compact()\n\npublic ByteBuffer compact() {\n    System.arraycopy(hb, ix(position()), hb, ix(0), remaining());\n    position(remaining());\n    limit(capacity());\n    discardMark();\n    return this;\n}\n\n\n简而言之：先把 position ~ limit 的数据拷贝到数组的首部，再将 position 放到剩余数据的后一个字节，最后 limit=capacity。\n\n在这个数组中，就是将 6 和 4 放到前两个字节，position = 3，limit = 10。\n\n\n\n然后再进行写操作，就会将 2、6、4 覆盖，实现了保留剩余数据的功能。\n\n\n# 2.6 remaining()\n\n如果我们不知道 ByteBuffer 中有多少数据，但是我们想一次全部获取该如何操作？说到底我们只是想获取 position ~ limit 之间的数据，只需要写一个循环 limit > position 就一直获取就行了\n\nwhile (byteBuffer.limit() > byteBuffer.position()) {\n\tSystem.out.println(byteBuffer.get());\n}\n\n\n但是这种操作也太繁琐了，Buffer 也为我们提供了相关的 API。\n\nremaining()：返回的结果是 limit - position。那我们在循环中只需要 remaining() > 0 就可以了。\n\npublic class TestBuffer {\n    public static void main(String[] args) {\n        ByteBuffer byteBuffer = ByteBuffer.allocate(10);\n\n\n        byteBuffer.put((byte)5);\n        byteBuffer.put((byte)7);\n        byteBuffer.put((byte)2);\n        byteBuffer.put((byte)6);\n        byteBuffer.put((byte)4);\n\n\n        // 将limit = position\n        // 将position = 0\n        byteBuffer.flip();\n\n\t// 如果limit-position不为0就一直打印\n        while (byteBuffer.remaining() > 0) {\n            System.out.println(byteBuffer.get());\n        }\n\n    }\n}\n\n\nhasRemaining也就是 return remaining() > 0\n\npublic class TestBuffer {\n    public static void main(String[] args) {\n        ByteBuffer byteBuffer = ByteBuffer.allocate(10);\n\n\n        byteBuffer.put((byte)5);\n        byteBuffer.put((byte)7);\n        byteBuffer.put((byte)2);\n        byteBuffer.put((byte)6);\n        byteBuffer.put((byte)4);\n\n\n        // 将limit = position\n        // 将position = 0\n        byteBuffer.flip();\n\t// 如果limit-position不为0就一直打印\n        while (byteBuffer.hasRemaining()) {\n            System.out.println(byteBuffer.get());\n        }\n    }\n}\n\n\n\n# 3. Channel\n\n刚才介绍了 Buffer，我们知道了 io 时的数据都是放在 Buffer 中的，那么数据从哪里来？NIO 的 io 是基于块的，那就肯定不能使用 stream 了，这里使用的是 Channel（通道）\n\nNIO 实现了四种通道：\n\n 1. FIleChannel ：文件通道，用于文件 io，无法使用 io 多路复用。\n 2. DatagramChannel ：UDP 通道，通过 UDP 读写网络中的数据。\n 3. SocketChannel ：TCP 通道，通过 TCP 读写网络中的数据。\n 4. ServerSocketChannel ：监听 TCP 通道。\n\n\n# 3.1 文件 IO 通道\n\nNIO 包下针对文件 IO 的 Channel 只有 FileChannel\n\njava.nio 包下的 FileChannel 提供了很多跟 java.io 包类似的功能，本质上都是读写文件，区别就是一个基于块，一个基于流。\n\n首先，FileChannel 是通过文件获取的，Channel 之所以叫做通道不是没有原因的，它不仅需要连接文件获取内容，还需要连接缓存，只有将数据给缓存，开发人员才能通过缓存来操作文件。那么使用 FileChannel 有两步：\n\n 1. 通过文件获取 FileChannel\n 2. 将通道（FileChannel）与缓存（ByteBuffer）连接。\n\nFileChannel fileChannel = new RandomAccessFile("NIO测试.txt", "rw").getChannel();\nByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n\n// 将文件中的内容读取到ByteBuffer中\nfileChannel.read(byteBuffer);\n\n// 将ByteBuffer中的内容写入到通道中\nfileChannel.write(byteBuffer);\n\n\n注意 ：在使用 Buffer 完成读写操作时，请注意读写模式的转换。\n\n以下代码为读取一个文件中的内容，将它们打印出来：\n\npublic class TestFileChannel {\n    public static void main(String[] args) throws Exception {\n        FileChannel fileChannel = new RandomAccessFile("NIO测试.txt", "rw").getChannel();\n        ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n\n\t// 将fileChannel中的内容读取到byteBuffer\n        while (fileChannel.read(byteBuffer) != -1) {\n\t    // 切换为读模式 \n            byteBuffer.flip();\n            while (byteBuffer.hasRemaining()) {\n                char b = (char) byteBuffer.get();\n                if (b == \' \') {\n                    continue;\n                }\n                System.out.print(b);\n            }\n\t    // 切换为写模式\n            byteBuffer.clear();\n        }\n\t// 操作数据后记得关闭哦.\n\tfileChannel.close();\n    }\n}\n\n\n注意：FileChannel 是没有多路复用这个功能的，为啥？\n\n首先看看多路复用是为了解决什么问题：多路复用使得一个线程可以监控多个连接，如果一个客户连接到服务端结果啥事也不干就干等，那么线程就不搭理它，如果有其他的连接发起了读事件或者写事件，线程就去处理有活的连接。可以看到多路复用是为了解决流氓客户端连接后不进行操作的问题，而文件 io 是完全开发人员操作的，你想什么时候读写就什么时候读写，主动权在你，不管别人的事，所以说文件 io 没有多路复用的功能。\n\nFileChannel 除了简单的 read 和 write 方法之外还有其他的方法：\n\n方法                       功能\nposition(int position)   指定位置读写，例如想在文件的第十个字节开始操作: fileChannel.position(10)\nsize()                   获取文件的大小\ntruncate(int size)       截取文件，truncate(100)，只获取文件的前 100 个字节\nforce()                  强制写入，将通道中未写入的数据强制写入文件。\n\n\n# 3.2 网络 IO 通道\n\nNIO 包下针对网络 IO 提供了三个通道：\n\n 1. ServerSocketChannel\n 2. SocketChannel\n 3. DatagramChannel\n\n它们都是同步非阻塞的 socket 操作，对于同步非阻塞 socket 操作实现的组件，它实际上是基于 socket 的（内部都有对应的 socket 对象，本质还是操作 socket），只是封装一下，多了同步非阻塞、双向数据传输这两个特点。一方面是因为通道所以拥有了数据双向传输的功能，同时它们都继承了 SelectableChannel，因此拥有了多路复用的功能。\n\nSelectableChannel 中提供了配置方法：configureBlocking(boolean block)，见名知意，这个配置方法是控制子类是否为阻塞 socket 的，configBloking(true)：阻塞，configBloking(false)：非阻塞。\n\n所以在编程时需要注意两个点：\n\n 1. 创建对应 Channel 后要获取内部的 Socket 再进行操作\n 2. 获取 Socket 后设置一下这个 Socket 阻塞还是非阻塞。\n\n# 3.2.1 ServerSocketChannel\n\nServerSocketChannel 提供了几个 API 用于网络 IO 操作：\n\n方法                         作用\nServerSocketChannel.open   创建 ServerSocketChannel\nconfigBloking              继承于 SelectableChannel，决定 socket 是否阻塞\nclose                      关闭 ServerSocketChannel\naccept                     接收连接，返回 SocketChannel 对象\nregister(Selector)         将 ServerSocketChannel 注册到 Selector 上\n\n// 创建ServerSocketChannel\nServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n// 获取内部的socket\nServerSocket socket = serverSocketChannel.socket();\n// 让socket监听8989端口\nsocket.bind(new InetSocketAddress(8989));\n// 设置serverSocketChannel为非阻塞\nserverSocketChannel.configureBlocking(false);\n// 处理连接\n\n// 关闭\n\n\n> 阻塞和非阻塞有什么区别呢？\n\n以下是阻塞代码：\n\nserverSocketChannel.configureBlocking(true);\nwhile (true) {\n    // 连接socketChannel\n    SocketChannel socketChannel = serverSocketChannel.accept();\n    if (socketChannel == null) {\n        continue;\n    }\n    System.out.println("有连接进来了");\n}\n\n\n因为是阻塞 socketChannel，那么代码执行到 accept 会卡着，直到有真正的 socket 连接。换句话说，socketChannel 永远不会为空。要么永远等待，要么就执行 有连接进来了\n\n但是非阻塞代码：\n\nserverSocketChannel.configureBlocking(false);\nwhile (true) {\n    // 连接socketChannel\n    SocketChannel socketChannel = serverSocketChannel.accept();\n    if (socketChannel == null) {\n\tSystem.out.println("socketChannel为空");\n        continue;\n    }\n    System.out.println("有连接进来了");\n}\n\n\n代码不会阻塞，只要执行到 accept，我管你有没有连接呢直接执行，没连接就返回 Null，继续执行下面的操作，所以代码里可能会打印很多 socketChannel为空。\n\n注意：这只是 NIO 包对于阻塞 IO 与非阻塞 IO 的实现，还不是 IO 多路复用。\n\n# 3.2.2 SocketChannel\n\nServerSocketChannel 是服务端，SocketChannel 是客户端。\n\n换言之，ServerSocketChannel 被动等待 SocketChannel 连接，SocketChannel 主动请求 ServerScoketChannel 的连接。\n\nSocketChannel 的特点：\n\n * 基于 TCP 的通道\n * 因为实现了 SelectableChannel，所以有 IO 多路复用的功能\n\nSocketChannel 提供的 API：\n\n方法                                  功能\nSocketChannel.open()                获取 SocketChannel\nSocketChannel.open(SocketAddress)   获取 SocketChannel 并连接到服务端\nconnect(SocketAddress)              将对应 socketChannel 连接到服务端\nregister(Selector)                  将 SocketChannel 注册到 Selector 上\n\n// 开启一个SocketChannel并把它连接到本机8989端口上。\nSocketChannel socketChannel = SocketChannel.open();\nsocketChannel.connect(new InetSocketAddress("localhost", 8989));\n\n\n方法                      功能\nisOpen()                测试 SocketChannel 是否为 open 状态\nisConnected()           测试 SocketChannel 是否已经连接上了\nisConnectionPending()   测试 SocketChannel 是否正在进行连接\nfinishConnect()         校验正在进行套接字连接的 SocketChannel 是否已经完成了连接。\n\nsocketChannel.isOpen(); // 测试 SocketChannel 是否为 open 状态\nsocketChannel.isConnected(); //测试 SocketChannel 是否已经被连接\nsocketChannel.isConnectionPending(); //测试 SocketChannel 是否正在进行\n连接\nsocketChannel.finishConnect(); //校验正在进行套接字连接的 SocketChannel是否已经完成连接\n\n\n方法                  功能\nread(ByteBuffer)    将 socket 中的数据读入缓存中\nwirte(ByteBuffer)   将缓存中的数据写入 socket\n\n如果在前面设置为阻塞模式，那么 read 方法和 wirte 方法也会是阻塞的，就是这个线程一直等待直到 socket 中有数据了才响应。如果是非阻塞，根本不带等的直接返回。\n\n这两个Channel说完就可以来一个小案例了：如下为NIO的具体例子：\n\n\n\nNIO是多路复用，也就是服务端通过 selector 来选择不同的客户端。想要selector选择客户端，肯定要客户端和selector绑定。从图上可以看到，绑定这件事并不是客户端做的，而是客户端连接后，服务端拿到客户端的socket之后，将其绑定在selector上。\n\n服务端代码 ：\n\npackage nio.ss;\n \nimport java.io.IOException;\nimport java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.*;\nimport java.util.Iterator;\n \npublic class Server {\n    public static void main(String[] args) {\n        try {\n            //1.获取管道\n            ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n            //2.设置非阻塞模式\n            serverSocketChannel.configureBlocking(false);\n            //3.绑定端口\n            serverSocketChannel.bind(new InetSocketAddress(8888));\n            //4.获取选择器\n            Selector selector = Selector.open();\n            //5.将通道注册到选择器上，并且开始指定监听的接收事件\n            serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n            //6.轮询已经就绪的事件\n            while (selector.select() > 0){\n                System.out.println("开启事件处理");\n                //7.获取选择器中所有注册的通道中已准备好的事件\n                Iterator<SelectionKey> it = selector.selectedKeys().iterator();\n                //8.开始遍历事件\n                while (it.hasNext()){\n                    SelectionKey selectionKey = it.next();\n                    System.out.println("---\x3e"+selectionKey);\n                    //9.判断这个事件具体是啥\n                    if (selectionKey.isAcceptable()){\n                        //10.获取当前接入事件的客户端通道\n                        SocketChannel socketChannel = serverSocketChannel.accept();\n                        //11.切换成非阻塞模式\n                        socketChannel.configureBlocking(false);\n                        //12.将本客户端注册到选择器\n                        socketChannel.register(selector,SelectionKey.OP_READ);\n                    }else if (selectionKey.isReadable()){\n                        //13.获取当前选择器上的读\n                        SocketChannel socketChannel = (SocketChannel) selectionKey.channel();\n                        //14.读取\n                        ByteBuffer buffer = ByteBuffer.allocate(1024);\n                        int len;\n                        while ((len = socketChannel.read(buffer)) > 0){\n                            buffer.flip();\n                            System.out.println(new String(buffer.array(),0,len));\n                            //清除之前的数据（覆盖写入）\n                            buffer.clear();\n                        }\n                    }\n                    //15.处理完毕后，移除当前事件\n                    it.remove();\n                }\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n\n客户端：\n\npackage nio.ss;\n \nimport java.io.IOException;\nimport java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.SocketChannel;\nimport java.util.Scanner;\n \npublic class Client {\n    public static void main(String[] args) {\n        try {\n            SocketChannel socketChannel = SocketChannel.open(new InetSocketAddress("127.0.0.1",8888));\n            socketChannel.configureBlocking(false);\n            ByteBuffer buffer = ByteBuffer.allocate(1024);\n            Scanner scanner = new Scanner(System.in);\n            while (true){\n                System.out.print("请输入:");\n                String msg = scanner.nextLine();\n                buffer.put(msg.getBytes());\n                buffer.flip();\n                socketChannel.write(buffer);\n                buffer.clear();\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n\n# 3.2.3 DatagramChannel\n\n每一个 SocketChannel 对应一个 Socket，每一个 SewrverSocketChannel 对应一个 ServerSocket\n\n每一个 DatagramChannel 也对应一个 DatagramSocket。\n\nDatagramChannel 是 NIO 提供的基于 UDP 的连接通道。\n\nAPI ：\n\n方法                                功能\nDatagramChannel.open()            创建一个 DatagramChannel\nsocket()                          返回 DatagramChannel 内部的 DatagramSocket\nconnect(SocketAddress)            连接，UDP 并没有 连接 这一说，这里只是声明一下往哪里发送数据\nreceive(ByteBuffer)               接收数据，将数据放到 ByteBuffer 中（注意是 ByteBuffer 不是 Buffer）\nsend(ByteBuffer, SocketAddress)   向 SocketAddress 对应的 IP&端口发送 ByteBuffer 中的数据\nregister(Selector)                将 DatagramChannel 注册到 Selector 上\n\n例子（使用尚硅谷的例子）：\n\npublic class TestDatagramChannel {\n    /**\n     * 发包的 datagram\n     *\n     * @throws IOException\n     * @throws InterruptedException\n     */\n    @Test\n    public void sendDatagram() throws IOException, InterruptedException {\n        DatagramChannel sendChannel= DatagramChannel.open();\n        InetSocketAddress sendAddress= new InetSocketAddress("127.0.0.1", 9999);\n        while (true) {\n            sendChannel.send(ByteBuffer.wrap("发包".getBytes("UTF-8")), sendAddress);\n            System.out.println("发包端发包");\n            Thread.sleep(1000);\n        }\n    }\n    /**\n     * 收包端\n     *\n     * @throws IOException\n     */\n    @Test\n    public void receive() throws IOException {\n        DatagramChannel receiveChannel= DatagramChannel.open();\n        InetSocketAddress receiveAddress= new InetSocketAddress(9999);\n        receiveChannel.bind(receiveAddress);\n        ByteBuffer receiveBuffer= ByteBuffer.allocate(512);\n        while (true) {\n            receiveBuffer.clear();\n            SocketAddress sendAddress= receiveChannel.receive(receiveBuffer);\n            receiveBuffer.flip();\n            System.out.print(sendAddress.toString() + " ");\n            System.out.println(Charset.forName("UTF-8").decode(receiveBuffer));\n        }\n    }\n    /**\n     * 只接收和发送 9999 的数据包\n     *\n     * @throws IOException\n     */\n    @Test\n    public void testConect1() throws IOException {\n        DatagramChannel connChannel= DatagramChannel.open();\n        connChannel.bind(new InetSocketAddress(9998));\n        connChannel.connect(new InetSocketAddress("127.0.0.1",9999));\n        connChannel.write(ByteBuffer.wrap("发包".getBytes("UTF-8")));\n        ByteBuffer readBuffer= ByteBuffer.allocate(512);\n        while (true) {\n            try {\n                readBuffer.clear();\n                connChannel.read(readBuffer);\n                readBuffer.flip();\n                System.out.println(Charset.forName("UTF-8").decode(readBuffer));\n            }catch(Exception e) {\n            }\n        }\n    }\n}\n\n\n\n# 4. Selector\n\n至此，java.nio 包下的两个重要组件已经介绍完毕，但是你会发现其实并没有介绍 IO 多路复用，只是浅浅提了一下阻塞与非阻塞。是因为 Java 的 NIO 的多路复用是基于 Selector 实现的。\n\nSelector 一般称为选择器，也可以翻译为多路复用器。它是 Java NIO 核心组件中的一个，用于检查多个 Channel 是否发生 读/写 操作，可以实现一个线程监听多个连接的功能，也就是 IO 多路复用。\n\n概述：假如现在服务端上有 5 个客户端连接，但是它们 5 个并不是一直都有事件需要处理的，很有可能一直空缺，如果每个连接都创建一个线程，那么实在太浪费了。就只使用一个线程监听它们就行了。没有读、写事件的连接我们不管它，某个连接有读写操作时就会通知线程让它处理。\n\n\n# 4.1 SelectableChannel\n\n前面说了，只有实现了 SelectableChannel 的 Channel 通道才有多路复用的功能，而多路复用的功能是 Selector 实现的，那么站在开发者的角度，说白了就是：FileChannel 没有绑定 Selector 的 register 方法。\n\npublic abstract class SelectableChannel {\n\t// 绑定\n\tpublic abstract SelectionKey register(Selector sel, int ops, Object att)\n        \t\t\t\t\tthrows ClosedChannelException;\n}\n\n\n\n\n\n# 4.2 SelectionKey\n\nChannel 注册到 Selector 上之后并不是发生任何事都会引起 Selector 的注意，这是 Channel 自己决定的，例如 可读、可写、可连接、可接受 这四种状态，当 Channel 选择以可读事件注册到 Selector 上时，只有当 Channel 发生读事件时才会通知 Selector 来处理。\n\n这四种状态都对应常量：\n\n状态           状态     常量       表示\nOP_READ      读操作    1 << 0   读就绪事件，表示通道中已经有了可读的数据，可以执行读操作了\nOP_WRITE     写操作    1 << 2   写就绪事件，表示已经可以向通道写数据了\nOP_CONNECT   连接操作   1 << 3   连接就绪事件，表示客户端与服务器的连接已经建立成功\nOP_ACCEPT    接收操作   1 << 4   接收连接继续事件，表示服务器监听到了客户连接，服务器可以接收这个连接了\n\n需要记吗？不需要，有一个类里面有这些常量：\n\npublic abstract class SelectionKey {\n\t// 读操作\n\tpublic static final int OP_READ = 1 << 0;\n\t// 写操作\n\tpublic static final int OP_WRITE = 1 << 2;\n\t// 连接操作\n\tpublic static final int OP_CONNECT = 1 << 3;\n\t// 接受操作\n\tpublic static final int OP_ACCEPT = 1 << 4;\n}\n\n\n所以只需要调用 channel.register(Selector, SelectionKey.OP_xxx)就可以将 Channel 绑定到 Selector 上。\n\nSelectionKey 这个类的专业名称叫做选择键，当Selector选择后，所有的就绪连接都会被封装为SelectionKey ，我们拿到SelectionKey之后可以判断什么事件准备好了，然后就可以获取SocketChannel进行处理。\n\n\n# 4.3 Selector\n\n介绍了前置知识后，终于迎来了Selector。在这里我会使用ServerSocketChannel和SocketChannel举例。\n\nSelector的工作原理前面已经介绍了很多遍了 ：使用一个线程对多个连接进行监听，有事件就处理，没事件就等待。\n\n\n\nSelector提供的API：\n\n方法                         作用\nSelector.open()            创建一个选择器\nint select()               选择准备好的连接，没有连接会阻塞\nint select(long timeout)   在timeout时间内选择准备好的连接\nint selectNow()            选择准备好的连接，没有连接不会阻塞\nSet selectedKey()          返回就绪的连接\n\n> select()方法返回的 int 值，表示有多少通道已经就绪，更准确的说，是上一次select与这一次select方法之间有多少新的连接进入就绪状态。\n\n一旦调用select方法并且返回值不为0（有就绪的连接）时，可以调用selectedKey()方法获得就绪连接。\n\n拿到连接的集合之后岂不是随心所欲为所欲为？你可以使用if else 来询问每一个连接对应的事件，“你的读就绪了吗？”“你的写就绪了吗？”“你的连接就绪了吗？”......\n\n所以，Java NIO的编程步骤：\n\npublic class TestSelector {\n    public static void main(String[] args) throws IOException {\n        // 获取连接\n        Selector selector = Selector.open();\n        // 获取服务端\n        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n        // 服务端监听8989端口\n        serverSocketChannel.bind(new InetSocketAddress("127.0.0.1", 8989));\n        // 与 Selector 一起使用时，Channel 必须处于非阻塞模式下\n        serverSocketChannel.configureBlocking(false);\n        // 将服务端绑定到选择器上，感兴趣的事件为 连接。\n        serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n        System.out.println("服务端就绪");\n        while (true) {\n            // 查看是否有就绪连接\n            int select = selector.select();\n\n            // 获取这1s内的所有就绪连接，遍历\n            Set<SelectionKey> selectionKeys = selector.selectedKeys();\n            Iterator<SelectionKey> iterator = selectionKeys.iterator();\n            \n            while (iterator.hasNext()) {\n                SelectionKey selectionKey = iterator.next();\n                // 如果选择键接收事件就绪\n                if (selectionKey.isAcceptable()) {\n                    SocketChannel socketChannel = serverSocketChannel.accept();\n                    // 处理socket逻辑\n\n                } else if (selectionKey.isConnectable()) {\n                    // 如果选择键连接事件就绪\n                    SocketChannel channel = (SocketChannel) selectionKey.channel();\n                    // 处理SocketChannel事件\n\n                } else if (selectionKey.isReadable()) {\n                    // 如果选择键读事件就绪\n                    SocketChannel channel = (SocketChannel) selectionKey.channel();\n                    ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n                    channel.read(byteBuffer);\n                    // 从buffer中读取数据\n                    // ......\n\n                } else if (selectionKey.isWritable()) {\n                    // 如果选择键写事件就绪\n\n                }\n                // 处理完这个连接后将它移除。\n                iterator.remove();\n            }\n        }\n\n    }\n}\n\n\n> 与 Selector 一起使用时，Channel 必须处于非阻塞模式下，为什么？\n> \n> 假如现在又5个就绪的连接被拿出来了，遍历第一个socketChannel时，调用accept突然阻塞了，你让其他的SocketChannel怎么执行？\n\n\n\n\n# 5. IO多路复用的几种模式\n\n你在读上面IO多路复用代码的时候是否会感觉阵阵无力？实际上我写的也很无力，为什么？遍历 + if/else，tmd太恶心了，为什么要把所有就绪的连接拿过来遍历呢？而且还是边遍历边if/else就更恶心了。\n\n这时候就引出了IO多路复用的几种模式：select、poll、epoll\n\n 1. select模式 ：当这些连接出现某种状态时（我们并不知道出现了什么状态），只能将所有就绪连接拿出来遍历询问：“你就绪了，你是什么状态啊？”，“你也就绪了，你是什么状态啊？”....因为需要遍历所有连接，所以时间复杂度为O(n)，同时存在最大连接数限制。\n 2. poll模式 ：同上，但是由于使用链表所以没有最大连接数限制。\n 3. epoll模式 ：采用事件通知方式，不是服务端去询问连接的状态，而是连接就绪后触发回调函数精准通知服务端：“我的读事件好了，你准备读吧”，“我的写事件好了，你准备写吧”。 这是因为在内核实现中epoll是根据每个文件描述符上面的callback函数实现的，只要就绪就会直接调用回调callback函数，实现精准通知，达到O(1)的时间复杂度。\n\n       SELECT （早期版本）         POLL （1.4）              EPOLL （1.5之后）\n操作方式   遍历                    遍历                      回调\n底层实现   数组                    链表                      哈希表\nIO效率   遍历数组中所有Channel，性能较差   遍历链表中所有的的Channel，性能较差   由操作系统将发生事件的Channel存到服务端的就绪事件列表中，Selector直接从就绪事件列表中获取感兴趣的事件，不需要遍历所有Channel，时间复杂度为O(1)\n最大连接   有上限                   无上限                     无上限\n\n\n# 6. 总结\n\n对于Java NIO的介绍到这里就结束了，至于java.nio包下的其他类就需要你自己去扩展了。总结一下本篇的内容：\n\n 1. Java NIO 的意思是New IO，意思是提供的新IO包，可以实现同步阻塞IO、同步非阻塞IO、IO多路复用。\n    \n    操作系统NIO的意思是Non bloking IO，只是同步非阻塞IO。\n\n 2. Java 的IO多路复用是使用 Selector实现的，一个Channel首先要注册到Selector才可以被发现。\n\n 3. Selector选择时是按照“感兴趣的事件”选择的，所以我们将服务端绑定到Selector上时大多数都会指定连接事件。',normalizedContent:'# 1. io概述\n\n在介绍java nio 之前，先来说一下什么是io。\n\n什么是io？\n\n简而言之，input和output，输入和输出就是io。\n\n根据操作系统的知识 ：一个进程的地址空间划分为 用户空间、内核空间。我们平时运行的应用程序是在用户空间中的，只有当出现内存分配、文件操作等操作时 才会切换为内核空间，并且用户空间是无法访问这些资源的，用户进程想要访问系统资源就必须要 进行系统调用从用户空间切换到内核空间。\n\n一共为三个步骤 ：\n\n 1. 用户空间发起系统调用（例如进行读文件时执行的read方法），产生中断\n 2. 内核等待 i/o 设备准备好数据\n 3. 内核将数据从 内核空间 拷贝到用户空间。（更准确点是从内核空间的缓冲区拷贝到用户空间的缓冲区）\n\n那么在用户空间发起系统调用直到内核空间拿到值返回给你这个时间段，用户空间是 阻塞等待 还是 不断轮询，就产生了阻塞io、非阻塞io这些不同的io方式。linux中分为五种io方式 ：\n\n 1. 同步阻塞 i/o ：应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间。\n 2. 同步非阻塞 i/o ：应用程序发起read后立刻返回并不断询问。\n 3. i/o 多路复用 ：线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间 -> 用户空间）还是阻塞的。\n 4. 信号驱动 i/o ：应用程序发起read调用后去做自己的事情，内核准备好数据后发出sigio信号通知应用程序已经准备好数据， 应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。\n 5. 异步 i/o ：应用程序发起read调用后去做自己的事情，内核将数据从内核空间拷贝到用户空间后发起signal信号通知应用程序已经准备好数据。\n\n乍一看信号驱动io和异步io不是一样吗？其实不然，\n\n * 信号驱动io ：发起信号通知时，数据在内核态，应用程序需要把数据拷贝到用户态\n * 异步io ：发起信号时数据已经在用户态了。\n\n在java里面没有这么多io模式，只有bio、nio、aio。\n\n 1. bio ：对应 同步阻塞i/o。\n 2. nio ：对应 i/o多路复用。\n 3. aio ：对应异步i/o。\n\nbio是fileinputstream、outputstream这种，nio是 buffer + channel + selector 这一套。\n\n本篇文章就是针对于 java nio 的 api 进行讲解。\n\n> 分割线\n\njava 的 nio 模型对应操作系统的 io 多路复用模型，java.nio包下提供的类不仅可以实现阻塞io、非阻塞io，还可以实现io多路复用。\n\n\n\n> java的io多路复用：可以使用一个线程处理多个客户端请求。客户端发送的请求会注册到多路复用器 selector 上，由 selector 轮询各个客户端的请求并进行处理。\n\njava 的 nio 提供了几个重要的组件：\n\n * buffer ：缓冲区\n * channel ：管道\n * selector ：多路复用器（并不是所有的 io 都可以使用 selector）\n\n\n# 2. buffer\n\n在上一篇中我们提到：bio 的操作都是基于流的，而 nio 的操作都是基于缓存的。\n\n也就是说，在 nio 中所有的操作都是用缓冲处理的，不管是读还是写，都使用 buffer 完成。\n\n在 nio 中，所有的缓冲区类型都继承于抽象类 buffer，最常用的是 bytebuffer，对于 java 的基本数据类型，基本都有一个具体的 buffer 实现类 与之对应。最常用的是 bytebuffer。\n\n\n\n其实 buffer 是使用数组实现的，也就是说我们读出来的或者写入的数据，都是先存进数组里面。\n\n举例：如下为 intbuffer 里面存放数据的数组。\n\n\n\n现在回到 buffer，buffer 中有几个非常重要的变量：\n\n 1. capacity ：这个 buffer 的容量，也就是一次最多放进去多少东西。这个变量在 buffer 创建时指定，且无法改变。\n 2. position ：当前操作数据的下标。\n 3. limit ：当前操作最大操作到哪个下标，默认为 capacity。\n 4. mark ：标记\n\n也很好理解，由于数据放在数组中，我们必须使用几个变量记录一下现在操作到哪、最多操作到哪、数组最大容量。\n\nbuffer 常用的方法：\n\n方法                     作用\nxxxbuffer.allocate()   创建一个 buffer 对象（如 bytebuffer、intbuffer...）\nget()                  获取 position 位置的数据，获取数据后 position++\nput()                  往 position 位置放置数据\nposition()             设置 position 的值\nlimit()                设置 limit 的值\nflip()                 切换为读模式\nclear()                切换为写模式（丢弃剩余数据）\ncompact()              切换为写模式（保留剩余数据）\nremaining()            return limit - position，一般用作查看 buffer 中是否还有数据\nhasremaining()         如果有残留数据，返回 true\n\n\n# 2.1 allocate()\n\n当想创建一个 buffer 时，使用的是 对应 buffer.allocate(int capacity)。\n\n例如想创建一个大小为 10 字节的 buffer：（为了方便，本篇下面就使用 bytebuffer 举例。）\n\npublic class testnio {\n    public static void main(string[] args) {\n        bytebuffer bytebuffer = bytebuffer.allocate(10);\n        intbuffer intbuffer = intbuffer.allocate(10);\n        charbuffer charbuffer = charbuffer.allocate(10);\n        longbuffer longbuffer = longbuffer.allocate(10);\n    }\n}\n\n\n刚才说的四个属性总是遵循以下规律：\n\nmark <= pasition <= limit <= capacity\n\n\n# 2.2 position() limit()\n\n同时，buffer 提供了几个方法来改变这几个属性的值：\n\nbytebuffer.position(int position);\nbytebuffer.mark(int mark);\nbytebuffer.limit(int limit);\n\n\n如下为新创建的 bytebuffer：\n\n\n\n现在的可操作范围为：position - limit（0 - 10）\n\n使用 put 方法向数组中放入几个元素后：\n\npublic class testnio {\n    public static void main(string[] args) {\n        bytebuffer bytebuffer = bytebuffer.allocate(10);\n        // put方法的操作：将数据放到position位置，position++\n        bytebuffer.put((byte)5);\n        bytebuffer.put((byte)7);\n        bytebuffer.put((byte)2);\n        bytebuffer.put((byte)6);\n        bytebuffer.put((byte)4);\n    }\n}\n\n\n向内填充数据后，position 随之移动，可操作范围为 5 - 10。\n\n\n\n假如我现在不想存数据了，我想取数据怎么办？\n\n由于操作范围为 position - limit，我们想要数组下标为 0 到 4 的数据，那么首先要把操作范围改为 0-4.\n\n具体一点就是 limit = position，position = 0\n\npublic class testnio {\n    public static void main(string[] args) {\n        bytebuffer bytebuffer = bytebuffer.allocate(10);\n\n        bytebuffer.put((byte)5);\n        bytebuffer.put((byte)7);\n        bytebuffer.put((byte)2);\n        bytebuffer.put((byte)6);\n        bytebuffer.put((byte)4);\n\t// 获取此时limit和position的值\n        int limit = bytebuffer.limit();\n        int position = bytebuffer.position();\n\n        // 将limit = position\n        // 将position = 0\n        bytebuffer.limit(position);\n        bytebuffer.position(0);\n\t// get()操作：获取数组中position位置的元素，position++\n        system.out.println(bytebuffer.get());\n        system.out.println(bytebuffer.get());\n        system.out.println(bytebuffer.get());\n        system.out.println(bytebuffer.get());\n        system.out.println(bytebuffer.get());\n    }\n}\n\n\n打印之后：\n\n\n\n\n# 2.3 flip()\n\n但是这样会不会很麻烦？难道我每次想要读取数据的时候都需要 limit=position, position=0 ？\n\n肯定不啦，人家有现成的方法供我们调用：bytebuffer.flip()\n\npublic final buffer flip() {\n    limit = position;\n    position = 0;\n    mark = -1;\n    return this;\n}\n\n\n这个方法帮我们把 position 和 limit 属性赋值，直接调用就可以读取数据，所以我们称它为读模式。\n\npublic class testnio {\n    public static void main(string[] args) {\n        bytebuffer bytebuffer = bytebuffer.allocate(10);\n        bytebuffer.put((byte)5);\n        bytebuffer.put((byte)7);\n        bytebuffer.put((byte)2);\n        bytebuffer.put((byte)6);\n        bytebuffer.put((byte)4);\n        // 进入读模式\n        bytebuffer.flip();\n\n        system.out.println(bytebuffer.get());\n        system.out.println(bytebuffer.get());\n        system.out.println(bytebuffer.get());\n        system.out.println(bytebuffer.get());\n        system.out.println(bytebuffer.get());\n    }\n}\n\n\n\n# 2.4 clear() rewind()\n\n既然有读模式，聪明的你肯定想到了写模式，没错，确实有：bytebuffer.clear()\n\npublic final buffer clear() {\n    position = 0;\n    limit = capacity;\n    mark = -1;\n    return this;\n}\n\n\n写模式将 position 置为 0，limit 回到 capacity 处，就可以重新写入数据了。\n\n当然，还有一个 api 也可以实现类似写模式的作用：bytebuffer.rewind();\n\npublic final buffer rewind() {\n    position = 0;\n    mark = -1;\n    return this;\n}\n\n\nclear 与 rewind 的区别是：rewind 不改变 limit 的值。\n\n\n# 2.5 compact()\n\n但是现在功能还不是很完善，如果数组中还有数据，但是我们依旧想向数组中写入数据该怎么办呢？使用 flip 方法和 clear 方法？\n\n\n\n如图所示，position 在下标为 3 的地方，调用 clear 方法后会将 position 置 0，再写入数据时就会发现：之前的 6 和 4 被覆盖了，我还没有用它呢怎么能让它丢弃呢？\n\nbuffer 也提供了方法保留这几个字节的数据：bytebuffer.compact()\n\npublic bytebuffer compact() {\n    system.arraycopy(hb, ix(position()), hb, ix(0), remaining());\n    position(remaining());\n    limit(capacity());\n    discardmark();\n    return this;\n}\n\n\n简而言之：先把 position ~ limit 的数据拷贝到数组的首部，再将 position 放到剩余数据的后一个字节，最后 limit=capacity。\n\n在这个数组中，就是将 6 和 4 放到前两个字节，position = 3，limit = 10。\n\n\n\n然后再进行写操作，就会将 2、6、4 覆盖，实现了保留剩余数据的功能。\n\n\n# 2.6 remaining()\n\n如果我们不知道 bytebuffer 中有多少数据，但是我们想一次全部获取该如何操作？说到底我们只是想获取 position ~ limit 之间的数据，只需要写一个循环 limit > position 就一直获取就行了\n\nwhile (bytebuffer.limit() > bytebuffer.position()) {\n\tsystem.out.println(bytebuffer.get());\n}\n\n\n但是这种操作也太繁琐了，buffer 也为我们提供了相关的 api。\n\nremaining()：返回的结果是 limit - position。那我们在循环中只需要 remaining() > 0 就可以了。\n\npublic class testbuffer {\n    public static void main(string[] args) {\n        bytebuffer bytebuffer = bytebuffer.allocate(10);\n\n\n        bytebuffer.put((byte)5);\n        bytebuffer.put((byte)7);\n        bytebuffer.put((byte)2);\n        bytebuffer.put((byte)6);\n        bytebuffer.put((byte)4);\n\n\n        // 将limit = position\n        // 将position = 0\n        bytebuffer.flip();\n\n\t// 如果limit-position不为0就一直打印\n        while (bytebuffer.remaining() > 0) {\n            system.out.println(bytebuffer.get());\n        }\n\n    }\n}\n\n\nhasremaining也就是 return remaining() > 0\n\npublic class testbuffer {\n    public static void main(string[] args) {\n        bytebuffer bytebuffer = bytebuffer.allocate(10);\n\n\n        bytebuffer.put((byte)5);\n        bytebuffer.put((byte)7);\n        bytebuffer.put((byte)2);\n        bytebuffer.put((byte)6);\n        bytebuffer.put((byte)4);\n\n\n        // 将limit = position\n        // 将position = 0\n        bytebuffer.flip();\n\t// 如果limit-position不为0就一直打印\n        while (bytebuffer.hasremaining()) {\n            system.out.println(bytebuffer.get());\n        }\n    }\n}\n\n\n\n# 3. channel\n\n刚才介绍了 buffer，我们知道了 io 时的数据都是放在 buffer 中的，那么数据从哪里来？nio 的 io 是基于块的，那就肯定不能使用 stream 了，这里使用的是 channel（通道）\n\nnio 实现了四种通道：\n\n 1. filechannel ：文件通道，用于文件 io，无法使用 io 多路复用。\n 2. datagramchannel ：udp 通道，通过 udp 读写网络中的数据。\n 3. socketchannel ：tcp 通道，通过 tcp 读写网络中的数据。\n 4. serversocketchannel ：监听 tcp 通道。\n\n\n# 3.1 文件 io 通道\n\nnio 包下针对文件 io 的 channel 只有 filechannel\n\njava.nio 包下的 filechannel 提供了很多跟 java.io 包类似的功能，本质上都是读写文件，区别就是一个基于块，一个基于流。\n\n首先，filechannel 是通过文件获取的，channel 之所以叫做通道不是没有原因的，它不仅需要连接文件获取内容，还需要连接缓存，只有将数据给缓存，开发人员才能通过缓存来操作文件。那么使用 filechannel 有两步：\n\n 1. 通过文件获取 filechannel\n 2. 将通道（filechannel）与缓存（bytebuffer）连接。\n\nfilechannel filechannel = new randomaccessfile("nio测试.txt", "rw").getchannel();\nbytebuffer bytebuffer = bytebuffer.allocate(1024);\n\n// 将文件中的内容读取到bytebuffer中\nfilechannel.read(bytebuffer);\n\n// 将bytebuffer中的内容写入到通道中\nfilechannel.write(bytebuffer);\n\n\n注意 ：在使用 buffer 完成读写操作时，请注意读写模式的转换。\n\n以下代码为读取一个文件中的内容，将它们打印出来：\n\npublic class testfilechannel {\n    public static void main(string[] args) throws exception {\n        filechannel filechannel = new randomaccessfile("nio测试.txt", "rw").getchannel();\n        bytebuffer bytebuffer = bytebuffer.allocate(1024);\n\n\t// 将filechannel中的内容读取到bytebuffer\n        while (filechannel.read(bytebuffer) != -1) {\n\t    // 切换为读模式 \n            bytebuffer.flip();\n            while (bytebuffer.hasremaining()) {\n                char b = (char) bytebuffer.get();\n                if (b == \' \') {\n                    continue;\n                }\n                system.out.print(b);\n            }\n\t    // 切换为写模式\n            bytebuffer.clear();\n        }\n\t// 操作数据后记得关闭哦.\n\tfilechannel.close();\n    }\n}\n\n\n注意：filechannel 是没有多路复用这个功能的，为啥？\n\n首先看看多路复用是为了解决什么问题：多路复用使得一个线程可以监控多个连接，如果一个客户连接到服务端结果啥事也不干就干等，那么线程就不搭理它，如果有其他的连接发起了读事件或者写事件，线程就去处理有活的连接。可以看到多路复用是为了解决流氓客户端连接后不进行操作的问题，而文件 io 是完全开发人员操作的，你想什么时候读写就什么时候读写，主动权在你，不管别人的事，所以说文件 io 没有多路复用的功能。\n\nfilechannel 除了简单的 read 和 write 方法之外还有其他的方法：\n\n方法                       功能\nposition(int position)   指定位置读写，例如想在文件的第十个字节开始操作: filechannel.position(10)\nsize()                   获取文件的大小\ntruncate(int size)       截取文件，truncate(100)，只获取文件的前 100 个字节\nforce()                  强制写入，将通道中未写入的数据强制写入文件。\n\n\n# 3.2 网络 io 通道\n\nnio 包下针对网络 io 提供了三个通道：\n\n 1. serversocketchannel\n 2. socketchannel\n 3. datagramchannel\n\n它们都是同步非阻塞的 socket 操作，对于同步非阻塞 socket 操作实现的组件，它实际上是基于 socket 的（内部都有对应的 socket 对象，本质还是操作 socket），只是封装一下，多了同步非阻塞、双向数据传输这两个特点。一方面是因为通道所以拥有了数据双向传输的功能，同时它们都继承了 selectablechannel，因此拥有了多路复用的功能。\n\nselectablechannel 中提供了配置方法：configureblocking(boolean block)，见名知意，这个配置方法是控制子类是否为阻塞 socket 的，configbloking(true)：阻塞，configbloking(false)：非阻塞。\n\n所以在编程时需要注意两个点：\n\n 1. 创建对应 channel 后要获取内部的 socket 再进行操作\n 2. 获取 socket 后设置一下这个 socket 阻塞还是非阻塞。\n\n# 3.2.1 serversocketchannel\n\nserversocketchannel 提供了几个 api 用于网络 io 操作：\n\n方法                         作用\nserversocketchannel.open   创建 serversocketchannel\nconfigbloking              继承于 selectablechannel，决定 socket 是否阻塞\nclose                      关闭 serversocketchannel\naccept                     接收连接，返回 socketchannel 对象\nregister(selector)         将 serversocketchannel 注册到 selector 上\n\n// 创建serversocketchannel\nserversocketchannel serversocketchannel = serversocketchannel.open();\n// 获取内部的socket\nserversocket socket = serversocketchannel.socket();\n// 让socket监听8989端口\nsocket.bind(new inetsocketaddress(8989));\n// 设置serversocketchannel为非阻塞\nserversocketchannel.configureblocking(false);\n// 处理连接\n\n// 关闭\n\n\n> 阻塞和非阻塞有什么区别呢？\n\n以下是阻塞代码：\n\nserversocketchannel.configureblocking(true);\nwhile (true) {\n    // 连接socketchannel\n    socketchannel socketchannel = serversocketchannel.accept();\n    if (socketchannel == null) {\n        continue;\n    }\n    system.out.println("有连接进来了");\n}\n\n\n因为是阻塞 socketchannel，那么代码执行到 accept 会卡着，直到有真正的 socket 连接。换句话说，socketchannel 永远不会为空。要么永远等待，要么就执行 有连接进来了\n\n但是非阻塞代码：\n\nserversocketchannel.configureblocking(false);\nwhile (true) {\n    // 连接socketchannel\n    socketchannel socketchannel = serversocketchannel.accept();\n    if (socketchannel == null) {\n\tsystem.out.println("socketchannel为空");\n        continue;\n    }\n    system.out.println("有连接进来了");\n}\n\n\n代码不会阻塞，只要执行到 accept，我管你有没有连接呢直接执行，没连接就返回 null，继续执行下面的操作，所以代码里可能会打印很多 socketchannel为空。\n\n注意：这只是 nio 包对于阻塞 io 与非阻塞 io 的实现，还不是 io 多路复用。\n\n# 3.2.2 socketchannel\n\nserversocketchannel 是服务端，socketchannel 是客户端。\n\n换言之，serversocketchannel 被动等待 socketchannel 连接，socketchannel 主动请求 serverscoketchannel 的连接。\n\nsocketchannel 的特点：\n\n * 基于 tcp 的通道\n * 因为实现了 selectablechannel，所以有 io 多路复用的功能\n\nsocketchannel 提供的 api：\n\n方法                                  功能\nsocketchannel.open()                获取 socketchannel\nsocketchannel.open(socketaddress)   获取 socketchannel 并连接到服务端\nconnect(socketaddress)              将对应 socketchannel 连接到服务端\nregister(selector)                  将 socketchannel 注册到 selector 上\n\n// 开启一个socketchannel并把它连接到本机8989端口上。\nsocketchannel socketchannel = socketchannel.open();\nsocketchannel.connect(new inetsocketaddress("localhost", 8989));\n\n\n方法                      功能\nisopen()                测试 socketchannel 是否为 open 状态\nisconnected()           测试 socketchannel 是否已经连接上了\nisconnectionpending()   测试 socketchannel 是否正在进行连接\nfinishconnect()         校验正在进行套接字连接的 socketchannel 是否已经完成了连接。\n\nsocketchannel.isopen(); // 测试 socketchannel 是否为 open 状态\nsocketchannel.isconnected(); //测试 socketchannel 是否已经被连接\nsocketchannel.isconnectionpending(); //测试 socketchannel 是否正在进行\n连接\nsocketchannel.finishconnect(); //校验正在进行套接字连接的 socketchannel是否已经完成连接\n\n\n方法                  功能\nread(bytebuffer)    将 socket 中的数据读入缓存中\nwirte(bytebuffer)   将缓存中的数据写入 socket\n\n如果在前面设置为阻塞模式，那么 read 方法和 wirte 方法也会是阻塞的，就是这个线程一直等待直到 socket 中有数据了才响应。如果是非阻塞，根本不带等的直接返回。\n\n这两个channel说完就可以来一个小案例了：如下为nio的具体例子：\n\n\n\nnio是多路复用，也就是服务端通过 selector 来选择不同的客户端。想要selector选择客户端，肯定要客户端和selector绑定。从图上可以看到，绑定这件事并不是客户端做的，而是客户端连接后，服务端拿到客户端的socket之后，将其绑定在selector上。\n\n服务端代码 ：\n\npackage nio.ss;\n \nimport java.io.ioexception;\nimport java.net.inetsocketaddress;\nimport java.nio.bytebuffer;\nimport java.nio.channels.*;\nimport java.util.iterator;\n \npublic class server {\n    public static void main(string[] args) {\n        try {\n            //1.获取管道\n            serversocketchannel serversocketchannel = serversocketchannel.open();\n            //2.设置非阻塞模式\n            serversocketchannel.configureblocking(false);\n            //3.绑定端口\n            serversocketchannel.bind(new inetsocketaddress(8888));\n            //4.获取选择器\n            selector selector = selector.open();\n            //5.将通道注册到选择器上，并且开始指定监听的接收事件\n            serversocketchannel.register(selector, selectionkey.op_accept);\n            //6.轮询已经就绪的事件\n            while (selector.select() > 0){\n                system.out.println("开启事件处理");\n                //7.获取选择器中所有注册的通道中已准备好的事件\n                iterator<selectionkey> it = selector.selectedkeys().iterator();\n                //8.开始遍历事件\n                while (it.hasnext()){\n                    selectionkey selectionkey = it.next();\n                    system.out.println("---\x3e"+selectionkey);\n                    //9.判断这个事件具体是啥\n                    if (selectionkey.isacceptable()){\n                        //10.获取当前接入事件的客户端通道\n                        socketchannel socketchannel = serversocketchannel.accept();\n                        //11.切换成非阻塞模式\n                        socketchannel.configureblocking(false);\n                        //12.将本客户端注册到选择器\n                        socketchannel.register(selector,selectionkey.op_read);\n                    }else if (selectionkey.isreadable()){\n                        //13.获取当前选择器上的读\n                        socketchannel socketchannel = (socketchannel) selectionkey.channel();\n                        //14.读取\n                        bytebuffer buffer = bytebuffer.allocate(1024);\n                        int len;\n                        while ((len = socketchannel.read(buffer)) > 0){\n                            buffer.flip();\n                            system.out.println(new string(buffer.array(),0,len));\n                            //清除之前的数据（覆盖写入）\n                            buffer.clear();\n                        }\n                    }\n                    //15.处理完毕后，移除当前事件\n                    it.remove();\n                }\n            }\n        } catch (ioexception e) {\n            e.printstacktrace();\n        }\n    }\n}\n\n\n客户端：\n\npackage nio.ss;\n \nimport java.io.ioexception;\nimport java.net.inetsocketaddress;\nimport java.nio.bytebuffer;\nimport java.nio.channels.socketchannel;\nimport java.util.scanner;\n \npublic class client {\n    public static void main(string[] args) {\n        try {\n            socketchannel socketchannel = socketchannel.open(new inetsocketaddress("127.0.0.1",8888));\n            socketchannel.configureblocking(false);\n            bytebuffer buffer = bytebuffer.allocate(1024);\n            scanner scanner = new scanner(system.in);\n            while (true){\n                system.out.print("请输入:");\n                string msg = scanner.nextline();\n                buffer.put(msg.getbytes());\n                buffer.flip();\n                socketchannel.write(buffer);\n                buffer.clear();\n            }\n        } catch (ioexception e) {\n            e.printstacktrace();\n        }\n    }\n}\n\n\n# 3.2.3 datagramchannel\n\n每一个 socketchannel 对应一个 socket，每一个 sewrversocketchannel 对应一个 serversocket\n\n每一个 datagramchannel 也对应一个 datagramsocket。\n\ndatagramchannel 是 nio 提供的基于 udp 的连接通道。\n\napi ：\n\n方法                                功能\ndatagramchannel.open()            创建一个 datagramchannel\nsocket()                          返回 datagramchannel 内部的 datagramsocket\nconnect(socketaddress)            连接，udp 并没有 连接 这一说，这里只是声明一下往哪里发送数据\nreceive(bytebuffer)               接收数据，将数据放到 bytebuffer 中（注意是 bytebuffer 不是 buffer）\nsend(bytebuffer, socketaddress)   向 socketaddress 对应的 ip&端口发送 bytebuffer 中的数据\nregister(selector)                将 datagramchannel 注册到 selector 上\n\n例子（使用尚硅谷的例子）：\n\npublic class testdatagramchannel {\n    /**\n     * 发包的 datagram\n     *\n     * @throws ioexception\n     * @throws interruptedexception\n     */\n    @test\n    public void senddatagram() throws ioexception, interruptedexception {\n        datagramchannel sendchannel= datagramchannel.open();\n        inetsocketaddress sendaddress= new inetsocketaddress("127.0.0.1", 9999);\n        while (true) {\n            sendchannel.send(bytebuffer.wrap("发包".getbytes("utf-8")), sendaddress);\n            system.out.println("发包端发包");\n            thread.sleep(1000);\n        }\n    }\n    /**\n     * 收包端\n     *\n     * @throws ioexception\n     */\n    @test\n    public void receive() throws ioexception {\n        datagramchannel receivechannel= datagramchannel.open();\n        inetsocketaddress receiveaddress= new inetsocketaddress(9999);\n        receivechannel.bind(receiveaddress);\n        bytebuffer receivebuffer= bytebuffer.allocate(512);\n        while (true) {\n            receivebuffer.clear();\n            socketaddress sendaddress= receivechannel.receive(receivebuffer);\n            receivebuffer.flip();\n            system.out.print(sendaddress.tostring() + " ");\n            system.out.println(charset.forname("utf-8").decode(receivebuffer));\n        }\n    }\n    /**\n     * 只接收和发送 9999 的数据包\n     *\n     * @throws ioexception\n     */\n    @test\n    public void testconect1() throws ioexception {\n        datagramchannel connchannel= datagramchannel.open();\n        connchannel.bind(new inetsocketaddress(9998));\n        connchannel.connect(new inetsocketaddress("127.0.0.1",9999));\n        connchannel.write(bytebuffer.wrap("发包".getbytes("utf-8")));\n        bytebuffer readbuffer= bytebuffer.allocate(512);\n        while (true) {\n            try {\n                readbuffer.clear();\n                connchannel.read(readbuffer);\n                readbuffer.flip();\n                system.out.println(charset.forname("utf-8").decode(readbuffer));\n            }catch(exception e) {\n            }\n        }\n    }\n}\n\n\n\n# 4. selector\n\n至此，java.nio 包下的两个重要组件已经介绍完毕，但是你会发现其实并没有介绍 io 多路复用，只是浅浅提了一下阻塞与非阻塞。是因为 java 的 nio 的多路复用是基于 selector 实现的。\n\nselector 一般称为选择器，也可以翻译为多路复用器。它是 java nio 核心组件中的一个，用于检查多个 channel 是否发生 读/写 操作，可以实现一个线程监听多个连接的功能，也就是 io 多路复用。\n\n概述：假如现在服务端上有 5 个客户端连接，但是它们 5 个并不是一直都有事件需要处理的，很有可能一直空缺，如果每个连接都创建一个线程，那么实在太浪费了。就只使用一个线程监听它们就行了。没有读、写事件的连接我们不管它，某个连接有读写操作时就会通知线程让它处理。\n\n\n# 4.1 selectablechannel\n\n前面说了，只有实现了 selectablechannel 的 channel 通道才有多路复用的功能，而多路复用的功能是 selector 实现的，那么站在开发者的角度，说白了就是：filechannel 没有绑定 selector 的 register 方法。\n\npublic abstract class selectablechannel {\n\t// 绑定\n\tpublic abstract selectionkey register(selector sel, int ops, object att)\n        \t\t\t\t\tthrows closedchannelexception;\n}\n\n\n\n\n\n# 4.2 selectionkey\n\nchannel 注册到 selector 上之后并不是发生任何事都会引起 selector 的注意，这是 channel 自己决定的，例如 可读、可写、可连接、可接受 这四种状态，当 channel 选择以可读事件注册到 selector 上时，只有当 channel 发生读事件时才会通知 selector 来处理。\n\n这四种状态都对应常量：\n\n状态           状态     常量       表示\nop_read      读操作    1 << 0   读就绪事件，表示通道中已经有了可读的数据，可以执行读操作了\nop_write     写操作    1 << 2   写就绪事件，表示已经可以向通道写数据了\nop_connect   连接操作   1 << 3   连接就绪事件，表示客户端与服务器的连接已经建立成功\nop_accept    接收操作   1 << 4   接收连接继续事件，表示服务器监听到了客户连接，服务器可以接收这个连接了\n\n需要记吗？不需要，有一个类里面有这些常量：\n\npublic abstract class selectionkey {\n\t// 读操作\n\tpublic static final int op_read = 1 << 0;\n\t// 写操作\n\tpublic static final int op_write = 1 << 2;\n\t// 连接操作\n\tpublic static final int op_connect = 1 << 3;\n\t// 接受操作\n\tpublic static final int op_accept = 1 << 4;\n}\n\n\n所以只需要调用 channel.register(selector, selectionkey.op_xxx)就可以将 channel 绑定到 selector 上。\n\nselectionkey 这个类的专业名称叫做选择键，当selector选择后，所有的就绪连接都会被封装为selectionkey ，我们拿到selectionkey之后可以判断什么事件准备好了，然后就可以获取socketchannel进行处理。\n\n\n# 4.3 selector\n\n介绍了前置知识后，终于迎来了selector。在这里我会使用serversocketchannel和socketchannel举例。\n\nselector的工作原理前面已经介绍了很多遍了 ：使用一个线程对多个连接进行监听，有事件就处理，没事件就等待。\n\n\n\nselector提供的api：\n\n方法                         作用\nselector.open()            创建一个选择器\nint select()               选择准备好的连接，没有连接会阻塞\nint select(long timeout)   在timeout时间内选择准备好的连接\nint selectnow()            选择准备好的连接，没有连接不会阻塞\nset selectedkey()          返回就绪的连接\n\n> select()方法返回的 int 值，表示有多少通道已经就绪，更准确的说，是上一次select与这一次select方法之间有多少新的连接进入就绪状态。\n\n一旦调用select方法并且返回值不为0（有就绪的连接）时，可以调用selectedkey()方法获得就绪连接。\n\n拿到连接的集合之后岂不是随心所欲为所欲为？你可以使用if else 来询问每一个连接对应的事件，“你的读就绪了吗？”“你的写就绪了吗？”“你的连接就绪了吗？”......\n\n所以，java nio的编程步骤：\n\npublic class testselector {\n    public static void main(string[] args) throws ioexception {\n        // 获取连接\n        selector selector = selector.open();\n        // 获取服务端\n        serversocketchannel serversocketchannel = serversocketchannel.open();\n        // 服务端监听8989端口\n        serversocketchannel.bind(new inetsocketaddress("127.0.0.1", 8989));\n        // 与 selector 一起使用时，channel 必须处于非阻塞模式下\n        serversocketchannel.configureblocking(false);\n        // 将服务端绑定到选择器上，感兴趣的事件为 连接。\n        serversocketchannel.register(selector, selectionkey.op_accept);\n        system.out.println("服务端就绪");\n        while (true) {\n            // 查看是否有就绪连接\n            int select = selector.select();\n\n            // 获取这1s内的所有就绪连接，遍历\n            set<selectionkey> selectionkeys = selector.selectedkeys();\n            iterator<selectionkey> iterator = selectionkeys.iterator();\n            \n            while (iterator.hasnext()) {\n                selectionkey selectionkey = iterator.next();\n                // 如果选择键接收事件就绪\n                if (selectionkey.isacceptable()) {\n                    socketchannel socketchannel = serversocketchannel.accept();\n                    // 处理socket逻辑\n\n                } else if (selectionkey.isconnectable()) {\n                    // 如果选择键连接事件就绪\n                    socketchannel channel = (socketchannel) selectionkey.channel();\n                    // 处理socketchannel事件\n\n                } else if (selectionkey.isreadable()) {\n                    // 如果选择键读事件就绪\n                    socketchannel channel = (socketchannel) selectionkey.channel();\n                    bytebuffer bytebuffer = bytebuffer.allocate(1024);\n                    channel.read(bytebuffer);\n                    // 从buffer中读取数据\n                    // ......\n\n                } else if (selectionkey.iswritable()) {\n                    // 如果选择键写事件就绪\n\n                }\n                // 处理完这个连接后将它移除。\n                iterator.remove();\n            }\n        }\n\n    }\n}\n\n\n> 与 selector 一起使用时，channel 必须处于非阻塞模式下，为什么？\n> \n> 假如现在又5个就绪的连接被拿出来了，遍历第一个socketchannel时，调用accept突然阻塞了，你让其他的socketchannel怎么执行？\n\n\n\n\n# 5. io多路复用的几种模式\n\n你在读上面io多路复用代码的时候是否会感觉阵阵无力？实际上我写的也很无力，为什么？遍历 + if/else，tmd太恶心了，为什么要把所有就绪的连接拿过来遍历呢？而且还是边遍历边if/else就更恶心了。\n\n这时候就引出了io多路复用的几种模式：select、poll、epoll\n\n 1. select模式 ：当这些连接出现某种状态时（我们并不知道出现了什么状态），只能将所有就绪连接拿出来遍历询问：“你就绪了，你是什么状态啊？”，“你也就绪了，你是什么状态啊？”....因为需要遍历所有连接，所以时间复杂度为o(n)，同时存在最大连接数限制。\n 2. poll模式 ：同上，但是由于使用链表所以没有最大连接数限制。\n 3. epoll模式 ：采用事件通知方式，不是服务端去询问连接的状态，而是连接就绪后触发回调函数精准通知服务端：“我的读事件好了，你准备读吧”，“我的写事件好了，你准备写吧”。 这是因为在内核实现中epoll是根据每个文件描述符上面的callback函数实现的，只要就绪就会直接调用回调callback函数，实现精准通知，达到o(1)的时间复杂度。\n\n       select （早期版本）         poll （1.4）              epoll （1.5之后）\n操作方式   遍历                    遍历                      回调\n底层实现   数组                    链表                      哈希表\nio效率   遍历数组中所有channel，性能较差   遍历链表中所有的的channel，性能较差   由操作系统将发生事件的channel存到服务端的就绪事件列表中，selector直接从就绪事件列表中获取感兴趣的事件，不需要遍历所有channel，时间复杂度为o(1)\n最大连接   有上限                   无上限                     无上限\n\n\n# 6. 总结\n\n对于java nio的介绍到这里就结束了，至于java.nio包下的其他类就需要你自己去扩展了。总结一下本篇的内容：\n\n 1. java nio 的意思是new io，意思是提供的新io包，可以实现同步阻塞io、同步非阻塞io、io多路复用。\n    \n    操作系统nio的意思是non bloking io，只是同步非阻塞io。\n\n 2. java 的io多路复用是使用 selector实现的，一个channel首先要注册到selector才可以被发现。\n\n 3. selector选择时是按照“感兴趣的事件”选择的，所以我们将服务端绑定到selector上时大多数都会指定连接事件。',charsets:{cjk:!0},lastUpdated:"2023/10/20, 13:14:55",lastUpdatedTimestamp:1697778895e3},{title:"InnoDB - 行格式",frontmatter:{title:"InnoDB - 行格式",date:"2023-06-08T21:47:16.000Z",permalink:"/pages/493ffc/"},regularPath:"/02.%E6%96%87%E7%AB%A0/02.MySQL/01.InnoDB%20-%20%E8%A1%8C%E6%A0%BC%E5%BC%8F.html",relativePath:"02.文章/02.MySQL/01.InnoDB - 行格式.md",key:"v-f0607dd8",path:"/pages/493ffc/",headers:[{level:2,title:"1. 什么是行格式",slug:"_1-什么是行格式",normalizedTitle:"1. 什么是行格式",charIndex:19},{level:2,title:"2. 四种行格式",slug:"_2-四种行格式",normalizedTitle:"2. 四种行格式",charIndex:325},{level:2,title:"3. Compact行格式",slug:"_3-compact行格式",normalizedTitle:"3. compact行格式",charIndex:537}],headersStr:"1. 什么是行格式 2. 四种行格式 3. Compact行格式",content:"# InnoDB - 行格式\n\n\n# 1. 什么是行格式\n\n我们平时是以行记录为单位向表中插入数据的，这些数据在磁盘上的存放方式被称为行格式或者记录格式。\n\nInnoDB引擎中支持四种行格式：Compact、Redundant、Dynamic、Compressed\n\n可以在创建表的时候指定行格式，或者直接使用alter命令更改表的行格式。\n\n 1. 创建表的时候指定行格式\n    \n    CREATE TABLE 表名 (    \n    \n    ) row_format = 行格式名称;\n    \n\n 2. 更改表的时候指定行格式\n    \n    ALTER TABLE 表名 ROW_FORMAT = 行格式名称;\n    \n\n\n# 2. 四种行格式\n\n如上所述：Compact、Redundant、Dynamic、Compressed\n\n行格式给我们的数据添加了很多额外的字段，这些字段记录了本条数据的一下信息，这些信息属于是MySQL服务器为了描述这条记录（行数据）而不得不额外添加的一些信息。\n\n这几种行格式大同小异，都是在你的表的基础上给你增加几个隐形的字段，目的是为了加快MySQL的运行效率。\n\n本篇文章只描述一下Compact行格式。\n\n\n# 3. Compact行格式\n\nCompact行格式给表增加了三个额外字段：变长字段长度列表、NULL值列表、记录头信息。\n\n * 变长字段长度列表：你的有些字段的值的长度是不确定的，例如varchar()、bolg、text这些类型，数据的长度不固定，但是MySQL解析的时候又不想猜你有几个字节，所以就使用这个列表记录所有会变化的字段的长度。\n * NULL值列表：有的字段的值是可以为空的，这些数据是不需要解析处理的，所以MySQL会将这些字段记录下来。（主键和not null 关键字修饰的字段不能为空，所以不会被记录）\n * 记录头信息：有很多字段组成，不同字段有不同的作用，主要有：标记该记录是否被删除、标记该记录是否是B+树叶子节点、该记录在记录堆中的位置信息...\n\n\n\n这三个字段是MySQL提供给自己使用的。现在详细看看它们。\n\n 1. 变长字段的长度列表\n    \n    如名字所示，你的表中有多少字段的值的长度是可变的，它就记录这些可变的数据的长度。\n    \n    我们知道MySQL中支持一些不定长的数据类型：varchar、blog、text、longtext.....我们可以将这些数据类型的列称为变长字段，变长字段中存储多长字节的数据是不固定的，所以MySQL将这些数据存储时顺便存上它们的长度，这样就可以更快的解析处理了。\n    \n    在compact行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头位置，从而形成一个长度列表，称为变长字段的长度列表，各个变长字段数据占用的字节数按照列的顺序逆序存放。强调一下，逆序存放。\n    \n    假如现在有三个字段：id、name、password，其中id是int类型，所以它不是变长字段，name和password都是varchar类型，它们是变长字段，所以长度列表中会记录他俩的长度。\n    \n    name: xiaoming \n    password: 123\n    \n    \n    如上，name的长度是8个字节，十六进制是0x08；password是3个字节，十六进制是0x03。\n    \n    存储在列表中就是：0308。\n    \n    放在整个行中就是：\n    \n    但是还有一个问题：如果某个字段存储的数据特别多，你只用一个字节可以存吗？或者说：你怎么知道03代表长度还是0308代表长度呢？\n    \n    放心 ，InnoDB 有它的一套规则。这里就不展开讲述了。\n    \n    另外需要注意的是：变长字段长度列表中只存储非NULL的列内容占用的长度，那肯定啊，为NULL的值你记录它干啥？\n    \n    同时，这个列表的中的字段不仅仅会被变长字段影响，还会被MySQL所使用字符集影响：\n    \n    对于 CHAR() 类型的列来说，当列采用的是定长字符集时，该列占用的字节数不会被加到变长字段长度列表，而如果采用变长字符集时，该列占用的字节数也会被加到变长字段长度列表。\n\n 2. NULL值列表\n    \n    某些表中的某些列可能存储NULL值，MySQL会将这些值为NULL的列统一管理起来，存储到NULl值列表中。\n    \n    首先，主键和被not null 修饰的字段不会被存储。其次，如果此行的数据没有NULL值，这个NULL值列表也就没有意义了。\n    \n    否则，每一个允许存储NULL值的字段对应一个二进制位，二进制位按照字段的顺序逆序排序，强调：逆序。\n    \n    二进制位的意义：\n    \n    * 二进制位的值为1：该字段的值为NULL。\n    * 二进制位的值为0：该字段的值不为NULL。\n    \n    如下：\n    \n    但是MySQL规定NULL值列表必须使用整数个字节的位表示，即：8、16、32...\n    \n    并且，对于这一行数据来说，值为NULL的字段是不被存储的。\n    \n    所以上面那张图完善一下其实是这样：\n    \n    \n\n 3. 记录头信息\n    \n    这个字段固定有5个字节，即40个二进制位，不同的位代表不同的意思，如下：\n    \n    \n\n名称             大小（BIT）   作用\n预留位            2         待使用\ndelete_mask    1         该记录是否被删除\nmin_rec_mask   1         B+树的每层非叶子节点中的最小记录都会添加该标记\nn_owned        4         表示当前记录拥有的记录数\nheap_no        13        表示当前记录在页中的位置\nrecord_type    3         表示当前记录的类型0：普通记录1：表示B+树非叶子节点记录2：表示最小记录3：表示最大记录\nnext_record    16        表示下一条记录的相对位置\n\n看到delete_mask大家可能会有些疑惑：这个标志不是“该条记录是否被删除”吗？我们删除一条数据之后MySQL原来并没有真正的删除它？对，MySQL执行的也是逻辑删除，至于具体是怎样做的，就在数据具体的存储方式：InnoDB - 页结构 中与其他头信息一起说吧~。\n\n 4. 隐藏字段\n    \n    背过MySQL面试题的大概都知道，在创建表的时候MySQL提供了几个隐藏字段（实现MVCC机制的三个隐藏字段）\n    \n    * row_id：行id，唯一标识\n    * transaction_id：操作此行数据的事务的id\n    * roll_pointer：回滚指针\n    \n    大家可能都背过，这里就不展开讲了。于是我们创建的表，加上所有隐藏字段之后其实是这样的：\n    \n    \n\n综上所述就是MySQL的Compact行格式。\n\n‍",normalizedContent:"# innodb - 行格式\n\n\n# 1. 什么是行格式\n\n我们平时是以行记录为单位向表中插入数据的，这些数据在磁盘上的存放方式被称为行格式或者记录格式。\n\ninnodb引擎中支持四种行格式：compact、redundant、dynamic、compressed\n\n可以在创建表的时候指定行格式，或者直接使用alter命令更改表的行格式。\n\n 1. 创建表的时候指定行格式\n    \n    create table 表名 (    \n    \n    ) row_format = 行格式名称;\n    \n\n 2. 更改表的时候指定行格式\n    \n    alter table 表名 row_format = 行格式名称;\n    \n\n\n# 2. 四种行格式\n\n如上所述：compact、redundant、dynamic、compressed\n\n行格式给我们的数据添加了很多额外的字段，这些字段记录了本条数据的一下信息，这些信息属于是mysql服务器为了描述这条记录（行数据）而不得不额外添加的一些信息。\n\n这几种行格式大同小异，都是在你的表的基础上给你增加几个隐形的字段，目的是为了加快mysql的运行效率。\n\n本篇文章只描述一下compact行格式。\n\n\n# 3. compact行格式\n\ncompact行格式给表增加了三个额外字段：变长字段长度列表、null值列表、记录头信息。\n\n * 变长字段长度列表：你的有些字段的值的长度是不确定的，例如varchar()、bolg、text这些类型，数据的长度不固定，但是mysql解析的时候又不想猜你有几个字节，所以就使用这个列表记录所有会变化的字段的长度。\n * null值列表：有的字段的值是可以为空的，这些数据是不需要解析处理的，所以mysql会将这些字段记录下来。（主键和not null 关键字修饰的字段不能为空，所以不会被记录）\n * 记录头信息：有很多字段组成，不同字段有不同的作用，主要有：标记该记录是否被删除、标记该记录是否是b+树叶子节点、该记录在记录堆中的位置信息...\n\n\n\n这三个字段是mysql提供给自己使用的。现在详细看看它们。\n\n 1. 变长字段的长度列表\n    \n    如名字所示，你的表中有多少字段的值的长度是可变的，它就记录这些可变的数据的长度。\n    \n    我们知道mysql中支持一些不定长的数据类型：varchar、blog、text、longtext.....我们可以将这些数据类型的列称为变长字段，变长字段中存储多长字节的数据是不固定的，所以mysql将这些数据存储时顺便存上它们的长度，这样就可以更快的解析处理了。\n    \n    在compact行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头位置，从而形成一个长度列表，称为变长字段的长度列表，各个变长字段数据占用的字节数按照列的顺序逆序存放。强调一下，逆序存放。\n    \n    假如现在有三个字段：id、name、password，其中id是int类型，所以它不是变长字段，name和password都是varchar类型，它们是变长字段，所以长度列表中会记录他俩的长度。\n    \n    name: xiaoming \n    password: 123\n    \n    \n    如上，name的长度是8个字节，十六进制是0x08；password是3个字节，十六进制是0x03。\n    \n    存储在列表中就是：0308。\n    \n    放在整个行中就是：\n    \n    但是还有一个问题：如果某个字段存储的数据特别多，你只用一个字节可以存吗？或者说：你怎么知道03代表长度还是0308代表长度呢？\n    \n    放心 ，innodb 有它的一套规则。这里就不展开讲述了。\n    \n    另外需要注意的是：变长字段长度列表中只存储非null的列内容占用的长度，那肯定啊，为null的值你记录它干啥？\n    \n    同时，这个列表的中的字段不仅仅会被变长字段影响，还会被mysql所使用字符集影响：\n    \n    对于 char() 类型的列来说，当列采用的是定长字符集时，该列占用的字节数不会被加到变长字段长度列表，而如果采用变长字符集时，该列占用的字节数也会被加到变长字段长度列表。\n\n 2. null值列表\n    \n    某些表中的某些列可能存储null值，mysql会将这些值为null的列统一管理起来，存储到null值列表中。\n    \n    首先，主键和被not null 修饰的字段不会被存储。其次，如果此行的数据没有null值，这个null值列表也就没有意义了。\n    \n    否则，每一个允许存储null值的字段对应一个二进制位，二进制位按照字段的顺序逆序排序，强调：逆序。\n    \n    二进制位的意义：\n    \n    * 二进制位的值为1：该字段的值为null。\n    * 二进制位的值为0：该字段的值不为null。\n    \n    如下：\n    \n    但是mysql规定null值列表必须使用整数个字节的位表示，即：8、16、32...\n    \n    并且，对于这一行数据来说，值为null的字段是不被存储的。\n    \n    所以上面那张图完善一下其实是这样：\n    \n    \n\n 3. 记录头信息\n    \n    这个字段固定有5个字节，即40个二进制位，不同的位代表不同的意思，如下：\n    \n    \n\n名称             大小（bit）   作用\n预留位            2         待使用\ndelete_mask    1         该记录是否被删除\nmin_rec_mask   1         b+树的每层非叶子节点中的最小记录都会添加该标记\nn_owned        4         表示当前记录拥有的记录数\nheap_no        13        表示当前记录在页中的位置\nrecord_type    3         表示当前记录的类型0：普通记录1：表示b+树非叶子节点记录2：表示最小记录3：表示最大记录\nnext_record    16        表示下一条记录的相对位置\n\n看到delete_mask大家可能会有些疑惑：这个标志不是“该条记录是否被删除”吗？我们删除一条数据之后mysql原来并没有真正的删除它？对，mysql执行的也是逻辑删除，至于具体是怎样做的，就在数据具体的存储方式：innodb - 页结构 中与其他头信息一起说吧~。\n\n 4. 隐藏字段\n    \n    背过mysql面试题的大概都知道，在创建表的时候mysql提供了几个隐藏字段（实现mvcc机制的三个隐藏字段）\n    \n    * row_id：行id，唯一标识\n    * transaction_id：操作此行数据的事务的id\n    * roll_pointer：回滚指针\n    \n    大家可能都背过，这里就不展开讲了。于是我们创建的表，加上所有隐藏字段之后其实是这样的：\n    \n    \n\n综上所述就是mysql的compact行格式。\n\n‍",charsets:{cjk:!0},lastUpdated:"2023/06/08, 21:54:53",lastUpdatedTimestamp:1686232493e3},{title:"InnoDB - 页结构",frontmatter:{title:"InnoDB - 页结构",date:"2023-06-08T21:47:16.000Z",permalink:"/pages/b3086d/"},regularPath:"/02.%E6%96%87%E7%AB%A0/02.MySQL/05.InnoDB%20-%20%E9%A1%B5%E7%BB%93%E6%9E%84.html",relativePath:"02.文章/02.MySQL/05.InnoDB - 页结构.md",key:"v-062f8431",path:"/pages/b3086d/",headers:[{level:2,title:"1. InnoDB页简介",slug:"_1-innodb页简介",normalizedTitle:"1. innodb页简介",charIndex:19},{level:2,title:"2. InnoDB页结构",slug:"_2-innodb页结构",normalizedTitle:"2. innodb页结构",charIndex:462},{level:3,title:"2.1 User Records（数据）",slug:"_2-1-user-records-数据",normalizedTitle:"2.1 user records（数据）",charIndex:1019},{level:3,title:"2.2 Page Directory（页目录）",slug:"_2-2-page-directory-页目录",normalizedTitle:"2.2 page directory（页目录）",charIndex:2464},{level:3,title:"2.3 Page Header（页头部信息）",slug:"_2-3-page-header-页头部信息",normalizedTitle:"2.3 page header（页头部信息）",charIndex:4146},{level:3,title:"2.4 File Header（文件头）",slug:"_2-4-file-header-文件头",normalizedTitle:"2.4 file header（文件头）",charIndex:4457},{level:3,title:"2.5 File Trailer（文件尾）",slug:"_2-5-file-trailer-文件尾",normalizedTitle:"2.5 file trailer（文件尾）",charIndex:4810},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:5222}],headersStr:"1. InnoDB页简介 2. InnoDB页结构 2.1 User Records（数据） 2.2 Page Directory（页目录） 2.3 Page Header（页头部信息） 2.4 File Header（文件头） 2.5 File Trailer（文件尾） 3. 总结",content:"# InnoDB - 页结构\n\n\n# 1. InnoDB页简介\n\nInnoDB是一个将表中的数据存储到磁盘上的存储引擎，所以即使关机后重启我们的数据还是存在的。而真正的对数据的处理过程是发生在内存中的。\n\n即：将磁盘中的数据读取到内存中进行操作。\n\n * 读请求：将磁盘中的内容读取到内存中。\n * 写请求：将内存中的被修改后的数据写回磁盘中。\n\n我们知道，读写磁盘的速度非常慢，与内存操作差了几个数量级，所以当我们想要从表中获取数据时，InnoDB会一条一条的把记录从磁盘中都出来吗？不是，InnoDB采取的方式是：将数据划分为若干页，以页为磁盘和内存之间交互的基本单位，InnoDB中页的大小一般为16k。\n\n在这种情况下，MySQL一次最少会从磁盘中加载16k的数据到内存中，说明白点：即使你只select了一条数据，与该条数据同一页的所有数据都会被加载（从磁盘加载到内存）。\n\n现在我们就可以梳理一下MySQL的InnoDB引擎中页的概念：InnoDB管理存储空间的基本单位、用于磁盘与内存交互的最小单位。\n\n\n# 2. InnoDB页结构\n\n16k的页被分为好多个部分，并不是16k全部存储数据的。以下为页的基本结构。\n\n\n\n共有7个部分，他们的大概功能如表格所示：\n\n你可以先看表格了解一下它们都是干啥的，下面会详细的描述它们的作用。\n\n名称                   中文名         作用\nFile Header          文件头部        页的一些通用信息\nPage Header          页面头部        数据页专用的一些信息\nInfimum + Supermum   最小记录和最大记录   两个虚拟的行记录\nUser Records         用户记录        实际存储的行数据内容，初始为空，随着记录的增加，从Free Space中挪用空间\nFree Space           空闲空间        页中未使用的空间，为User Records提供空间\nPage Directory       页面目录        页中的某些记录的相对位置\nFile Trailer         文件尾部        校验页是否完整\n\n我们接下来并不打算按照页中各个部分的出现顺序来依次介绍它们，因为各个部分中会出现很多大家目前不理解的概念.\n\n\n# 2.1 User Records（数据）\n\n\n\n在页的7个组成部分中，我们自己的数据（student、user）会存储在User Records中。但是在一开始生成页的时候不会为User Redords分配空间，每当我们插入一条数据，都会从Free Space分出部分空间到User Redords来存储这条数据，直到Free Space被User Records全部替代，说明这个页用光了，就会创建新的页。\n\n\n\n在上一篇InnoDB - 行格式中，我们介绍了InnoDB行格式，说到了每一行其实有6个隐藏字段，其中有一个隐藏字段叫做：记录头信息。\n\n\n\n记录头信息中又有很多字段，在这里会涉及到的有5个：（此图省略了其他隐藏字段）\n\n\n\ndelete_mask：该记录是否被删除。\n\nmin_rec_mask：是否为B+树的每层非叶子节点中的最小记录。\n\nn_owned：有几个记录属于这个记录。每个组的最后一条记录（也就是组内最大的那条记录）的头信息中的 n_owned 属性表示该记录拥有多少条记录。\n\n录，也就是该组内共有几条记录。\n\nheap_no：在页中的下标（第几条数据）。\n\nnext_record：表示下一条记录的相对位置。\n\n我们想这张表中插入3条数据：\n\ninsert into users values(1, 'aaaa'), \n                        (2, 'bbbb'),                       \n\t\t\t\t\t\t(3, 'cccc');\n\n\n于是这几条数据就如下图所示连接：\n\n\n\n由于还没有接触到，所以有几个字段在图中是不重要的，这里只需要注意两个字段：heap_no、next_record。\n\n很明显，next_record是指向下一条记录的指针。\n\nheap_no是此行数据在页中的下表，但是我们知道下标一般是从0或者1开始的，哪有从2开始的呢？怎么不见 heap_no 值为 0 和 1 的记录呢？\n\n其实MySQL的设计者在实现这部分的时候耍了花样：页结构中有这样一个字段：Infimum、supermum。它们的中文名分别是最小记录和最大记录。\n\n现在你应该猜到序号0和1都归谁了吧？就是最小记录和最大记录。\n\n\n\n那么刚才那张图完善一下就是：\n\n\n\n如图所示，MySQL隐藏的最小记录指向我们添加的主键最小的记录，形成一个链表，最后我们添加的主键最大的记录指向MySQL自带的最大记录。\n\n即：infimum -> User Records -> supermum。\n\n从中删除一条数据，整个链表的结构就会发生变化，假如从中删除id为1的数据，\n\n\n\n不论我们怎么对页中的记录做增删改操作，InnoDB始终会维护一条记录的单链表，链表中的各个节点是按照主键值由小到大的顺序连接起来的。\n\n当数据页中存在多条被删除掉的记录时，这些记录的next_record属性将会把这些被删除掉的记录组成一个垃圾链表，以备之后重用这部分存储空间。\n\n即：未删数据和删除数据都会组成链表。\n\n> 你会不会觉得next_record很奇怪？它竟然指向隐藏字段和真实数据之间的部分，而不是指向隐藏字段开头部分\n> \n> 因为这个位置刚刚好，向左读取就是记录头信息，向右读取就是真实数据。\n> \n> 我们知道，隐藏字段中信息的记录都是逆序的（参考InnoDB - 行格式），它从右向左读就可以读取到正序的信息了！\n\n\n# 2.2 Page Directory（页目录）\n\n\n\n刚才说了，数据之间会形成链表，方便查找，但是链表很明显效率很慢。MySQL的索引使用的是B+树，这里我们讲的是数据页，不是索引页，所以没有用到B+树，但是MySQL的设计者还是采用了一定的方式加快数据的查询。\n\n也就是查目录的方式。\n\n打一个比较形象的比喻：\n\n进了大学，班长记不住也不想记住所有同学的名称，于是他将全班同学按照学号排序、分组，每个组大概4-8人，组里学号最大的那个人当组长，班长建立一个组长群，将组长拉进去，有啥事就直接通知组长而不会通知组员，想要找某个人的时候就直接在组长群里说：xxx在哪一个组？组长叫他做一下青年大学习~\n\nMySQL采用了以下方式：\n\n 1. 将所有未删除的数据划分为不同的组\n 2. 每个组的最后一条记录的头信息中的 n_owned 属性表示该组内有多少条记录\n 3. 将每个组的最后一条记录的地址偏移量单独提取出来按照顺序存储到 Page Directory 中（也就是页目录），我们将这些地址偏移量称为 槽。\n\n这里不要被搞糊涂了：一个页中有很多条数据，这些数据会按照链表的格式存储，我们将这些数据分为很多组，每个组的最后一条记录\n\n的地址抽取出来记录在 Page Directory 中。\n\n这里的整个班就是一个页，各个组就是MySQL中的组，组长就是每个组的最后一条数据，组长群就是 Page Directory。进入组长群后的组长被称为“槽”。\n\n\n\n注意：\n\n * 槽0中的数字为91，代表最小记录的地址偏移量为91字节。\n * 槽1中的数字为122，代表最大记录的地址偏移量为122字节。\n * 槽0指向最小记录，代表最小记录单独一组，也就只有最小记录这一条数据，所以它的n_owned值为1。\n * 槽1指向最大记录，代表最大记录以及之前的数据为一组，所以它的n_owned为4\n\n那么为什么最小记录单独一组呢？因为规定，MySQL对于每个分组中的记录个数是有规定的：最小记录所在的分组只能由1条记录，最大记录所在的分组可以有1~8条记录，剩下的其他分组可以有4~8条记录。\n\n我们看一下数据多的时候：\n\n\n\n如图所示，当有15条数据时，总记录数为17，被分为5个组，共有5个槽位，槽位对应的数据条数分别为：1、4、4、4、3。\n\n但是！插入的时候是有讲究的！\n\n * 初始情况下是没有用户数据的，只有两个组：最小记录组与最大记录组。\n * 之后没插入一条记录，都会从页目录（槽位）中找到主键值比本记录大，并且差值最小的槽位，然后把该槽位指向的记录的 n_owned 值加一，表示本组内又添加了一条记录，直到该组中的记录数等于8个。\n * 当组中的记录数等于8个时，再次插入会将本组分为两个组，加入分为4组和5组，第四组有4条记录，第五组有5条记录。因为拆分了，所以页目录中会增加一个槽位。\n\n弄清了分组的情况，现在我们可以来查找了，假如想要查找到 id=8 的数据。从图中可以看到它在第三组。\n\n因为各个槽指向的记录的主键都是从小到大排列的，所以我们可以使用二分法。\n\n此时共有5组，编号为 0、1、2、3、4 ，记 low = 0，high = 4\n\n 1. （low + high）/ 2 = 2，第二个槽位对应的记录的id为9，太大了，high改为2\n 2. （low + high）/ 2 = 1，第一个槽位对应的记录的id为5，太小了，low改为1\n 3. 因为 high - low = 1，可以说明目标数据就在 第二组 中，我们只需要获取low槽位对应的数据(第一组的最后一个数据)，向下找一个数据就到达第二组的最小数据，此时high指向的槽位的记录数是第二组的最大记录，获得了最大与最小，id=8的数据还不是唾手可得？\n\n所以在一个数据页中查找指定主键值的记录的过程分为两步：\n\n * 通过二分法确定该记录所在的槽，并找到改槽中主键值最小的那条记录。\n * 通过记录的 next_record 属性遍历该槽，找到目标数据。\n\n\n# 2.3 Page Header（页头部信息）\n\n\n\n数据页头部信息，行数据字段记录本行的基本信息，那么页数据也会有专门的字段记录本页的信息，而Page Header就是用于记录一个数据页的状态信息，比如本页存储了多少个槽、多少个数据等等...\n\n具体有什么字段，来看表格：(由于字段太多了，这是精简过的字段)\n\n名称                 作用\nPage_N_Dir_Slots   该页的页目录中的槽的数量\nPage_N_Heap        本页中的记录的数量（删除&未删除）\nPage_Level         当前页在B+树所处的层级\nPage_Index_id      本页属于哪个索引\n\n\n# 2.4 File Header（文件头）\n\n\n\nFile Header是每种页都有的属性，其中重要的字段如：本页编号、上一页编号、下一页编号、校验和。\n\n上一个与下一个页的编号：可以将所有数据页组成一个双链表，遍历就很方便了。\n\nFile Header中有一个很重要的字段：校验和。\n\n什么是校验和？\n\n对于一个很长很长的字符串来说，我们会使用某种算法来计算一个比较短的字符串来代替它，比如我们通常用文件的md5编码来初步比较文件是否相等。\n\n我们想比较两个很长的字符串的时候，可以先比较他们的校验和，如果连校验和都不一样，那这两个字符串就肯定不一样。这样就省去了一个字符一个字符比较消耗的时间。\n\n同时，File Header的校验和还会和File Trailer的校验和配合工作，下面会介绍。\n\n\n# 2.5 File Trailer（文件尾）\n\n\n\nFile Trailer跟File Header一样，有一个校验和，那么这个校验和到底是什么作用呢？\n\n我们知道InnoDB存储引擎会将数据从磁盘中读到内存中，以页为单位。如果数据在内存中修改了，那么MySQL势必要把他们再写回磁盘中，写回的过程中万一出现了什么错怎么办？这不是尴尬了吗？为了检验一个页是否完整（也就是同步的时候是否出现同步了一半的情况），MySQL就在页的头部和尾部都加了校验和这个东西。\n\n每当一个页在内存中修改了，在同步之前就要把它的校验和算出来。File Header在页的最前面，所以校验和会被优先同步，如果完全写完，那么尾部的校验和也会写进去，这没问题。万一中断了，那么File Header的校验和是已经修改过的页，File Trailer的校验和是原先的页，二者不相同，说明同步过程中出现bug。\n\n（其实还有一个字段，现在先不管）\n\n\n# 3. 总结\n\n 1. InnoDB为了不同的目的而设计了不同的页类型，我们把存放数据的页称为数据页。\n\n 2. 数据页可以被分为7个部分：\n    \n    1. File Header：表示页的一些通用信息\n    2. Page Header：表示数据页专有的信息\n    3. Infimum + Supermum：两个虚拟的伪记录，分别表示页中的最小记录和最大记录\n    4. User Records：存放我们插入的数据\n    5. Free Space：页中可以被我们使用的数据\n    6. Page Directory：页中的某些记录的相对位置，其中存放很多槽位\n    7. File Trailer：页尾，与File Header一起提供校验和来检查同步状态\n\n 3. 每个数据页的File Header都有上一个与下一个页的编号，所以所有的数据页会组成一个双链表\n\n 4. User Records中的每一条记录有next_record，它将所有记录串联为一个链表（已删除的和未删除的，共两个链表）\n\n 5. 为保证内存到磁盘的同步的完整性，在数据页的首部和数据页的尾部都会存储页中数据的校验和\n\n‍",normalizedContent:"# innodb - 页结构\n\n\n# 1. innodb页简介\n\ninnodb是一个将表中的数据存储到磁盘上的存储引擎，所以即使关机后重启我们的数据还是存在的。而真正的对数据的处理过程是发生在内存中的。\n\n即：将磁盘中的数据读取到内存中进行操作。\n\n * 读请求：将磁盘中的内容读取到内存中。\n * 写请求：将内存中的被修改后的数据写回磁盘中。\n\n我们知道，读写磁盘的速度非常慢，与内存操作差了几个数量级，所以当我们想要从表中获取数据时，innodb会一条一条的把记录从磁盘中都出来吗？不是，innodb采取的方式是：将数据划分为若干页，以页为磁盘和内存之间交互的基本单位，innodb中页的大小一般为16k。\n\n在这种情况下，mysql一次最少会从磁盘中加载16k的数据到内存中，说明白点：即使你只select了一条数据，与该条数据同一页的所有数据都会被加载（从磁盘加载到内存）。\n\n现在我们就可以梳理一下mysql的innodb引擎中页的概念：innodb管理存储空间的基本单位、用于磁盘与内存交互的最小单位。\n\n\n# 2. innodb页结构\n\n16k的页被分为好多个部分，并不是16k全部存储数据的。以下为页的基本结构。\n\n\n\n共有7个部分，他们的大概功能如表格所示：\n\n你可以先看表格了解一下它们都是干啥的，下面会详细的描述它们的作用。\n\n名称                   中文名         作用\nfile header          文件头部        页的一些通用信息\npage header          页面头部        数据页专用的一些信息\ninfimum + supermum   最小记录和最大记录   两个虚拟的行记录\nuser records         用户记录        实际存储的行数据内容，初始为空，随着记录的增加，从free space中挪用空间\nfree space           空闲空间        页中未使用的空间，为user records提供空间\npage directory       页面目录        页中的某些记录的相对位置\nfile trailer         文件尾部        校验页是否完整\n\n我们接下来并不打算按照页中各个部分的出现顺序来依次介绍它们，因为各个部分中会出现很多大家目前不理解的概念.\n\n\n# 2.1 user records（数据）\n\n\n\n在页的7个组成部分中，我们自己的数据（student、user）会存储在user records中。但是在一开始生成页的时候不会为user redords分配空间，每当我们插入一条数据，都会从free space分出部分空间到user redords来存储这条数据，直到free space被user records全部替代，说明这个页用光了，就会创建新的页。\n\n\n\n在上一篇innodb - 行格式中，我们介绍了innodb行格式，说到了每一行其实有6个隐藏字段，其中有一个隐藏字段叫做：记录头信息。\n\n\n\n记录头信息中又有很多字段，在这里会涉及到的有5个：（此图省略了其他隐藏字段）\n\n\n\ndelete_mask：该记录是否被删除。\n\nmin_rec_mask：是否为b+树的每层非叶子节点中的最小记录。\n\nn_owned：有几个记录属于这个记录。每个组的最后一条记录（也就是组内最大的那条记录）的头信息中的 n_owned 属性表示该记录拥有多少条记录。\n\n录，也就是该组内共有几条记录。\n\nheap_no：在页中的下标（第几条数据）。\n\nnext_record：表示下一条记录的相对位置。\n\n我们想这张表中插入3条数据：\n\ninsert into users values(1, 'aaaa'), \n                        (2, 'bbbb'),                       \n\t\t\t\t\t\t(3, 'cccc');\n\n\n于是这几条数据就如下图所示连接：\n\n\n\n由于还没有接触到，所以有几个字段在图中是不重要的，这里只需要注意两个字段：heap_no、next_record。\n\n很明显，next_record是指向下一条记录的指针。\n\nheap_no是此行数据在页中的下表，但是我们知道下标一般是从0或者1开始的，哪有从2开始的呢？怎么不见 heap_no 值为 0 和 1 的记录呢？\n\n其实mysql的设计者在实现这部分的时候耍了花样：页结构中有这样一个字段：infimum、supermum。它们的中文名分别是最小记录和最大记录。\n\n现在你应该猜到序号0和1都归谁了吧？就是最小记录和最大记录。\n\n\n\n那么刚才那张图完善一下就是：\n\n\n\n如图所示，mysql隐藏的最小记录指向我们添加的主键最小的记录，形成一个链表，最后我们添加的主键最大的记录指向mysql自带的最大记录。\n\n即：infimum -> user records -> supermum。\n\n从中删除一条数据，整个链表的结构就会发生变化，假如从中删除id为1的数据，\n\n\n\n不论我们怎么对页中的记录做增删改操作，innodb始终会维护一条记录的单链表，链表中的各个节点是按照主键值由小到大的顺序连接起来的。\n\n当数据页中存在多条被删除掉的记录时，这些记录的next_record属性将会把这些被删除掉的记录组成一个垃圾链表，以备之后重用这部分存储空间。\n\n即：未删数据和删除数据都会组成链表。\n\n> 你会不会觉得next_record很奇怪？它竟然指向隐藏字段和真实数据之间的部分，而不是指向隐藏字段开头部分\n> \n> 因为这个位置刚刚好，向左读取就是记录头信息，向右读取就是真实数据。\n> \n> 我们知道，隐藏字段中信息的记录都是逆序的（参考innodb - 行格式），它从右向左读就可以读取到正序的信息了！\n\n\n# 2.2 page directory（页目录）\n\n\n\n刚才说了，数据之间会形成链表，方便查找，但是链表很明显效率很慢。mysql的索引使用的是b+树，这里我们讲的是数据页，不是索引页，所以没有用到b+树，但是mysql的设计者还是采用了一定的方式加快数据的查询。\n\n也就是查目录的方式。\n\n打一个比较形象的比喻：\n\n进了大学，班长记不住也不想记住所有同学的名称，于是他将全班同学按照学号排序、分组，每个组大概4-8人，组里学号最大的那个人当组长，班长建立一个组长群，将组长拉进去，有啥事就直接通知组长而不会通知组员，想要找某个人的时候就直接在组长群里说：xxx在哪一个组？组长叫他做一下青年大学习~\n\nmysql采用了以下方式：\n\n 1. 将所有未删除的数据划分为不同的组\n 2. 每个组的最后一条记录的头信息中的 n_owned 属性表示该组内有多少条记录\n 3. 将每个组的最后一条记录的地址偏移量单独提取出来按照顺序存储到 page directory 中（也就是页目录），我们将这些地址偏移量称为 槽。\n\n这里不要被搞糊涂了：一个页中有很多条数据，这些数据会按照链表的格式存储，我们将这些数据分为很多组，每个组的最后一条记录\n\n的地址抽取出来记录在 page directory 中。\n\n这里的整个班就是一个页，各个组就是mysql中的组，组长就是每个组的最后一条数据，组长群就是 page directory。进入组长群后的组长被称为“槽”。\n\n\n\n注意：\n\n * 槽0中的数字为91，代表最小记录的地址偏移量为91字节。\n * 槽1中的数字为122，代表最大记录的地址偏移量为122字节。\n * 槽0指向最小记录，代表最小记录单独一组，也就只有最小记录这一条数据，所以它的n_owned值为1。\n * 槽1指向最大记录，代表最大记录以及之前的数据为一组，所以它的n_owned为4\n\n那么为什么最小记录单独一组呢？因为规定，mysql对于每个分组中的记录个数是有规定的：最小记录所在的分组只能由1条记录，最大记录所在的分组可以有1~8条记录，剩下的其他分组可以有4~8条记录。\n\n我们看一下数据多的时候：\n\n\n\n如图所示，当有15条数据时，总记录数为17，被分为5个组，共有5个槽位，槽位对应的数据条数分别为：1、4、4、4、3。\n\n但是！插入的时候是有讲究的！\n\n * 初始情况下是没有用户数据的，只有两个组：最小记录组与最大记录组。\n * 之后没插入一条记录，都会从页目录（槽位）中找到主键值比本记录大，并且差值最小的槽位，然后把该槽位指向的记录的 n_owned 值加一，表示本组内又添加了一条记录，直到该组中的记录数等于8个。\n * 当组中的记录数等于8个时，再次插入会将本组分为两个组，加入分为4组和5组，第四组有4条记录，第五组有5条记录。因为拆分了，所以页目录中会增加一个槽位。\n\n弄清了分组的情况，现在我们可以来查找了，假如想要查找到 id=8 的数据。从图中可以看到它在第三组。\n\n因为各个槽指向的记录的主键都是从小到大排列的，所以我们可以使用二分法。\n\n此时共有5组，编号为 0、1、2、3、4 ，记 low = 0，high = 4\n\n 1. （low + high）/ 2 = 2，第二个槽位对应的记录的id为9，太大了，high改为2\n 2. （low + high）/ 2 = 1，第一个槽位对应的记录的id为5，太小了，low改为1\n 3. 因为 high - low = 1，可以说明目标数据就在 第二组 中，我们只需要获取low槽位对应的数据(第一组的最后一个数据)，向下找一个数据就到达第二组的最小数据，此时high指向的槽位的记录数是第二组的最大记录，获得了最大与最小，id=8的数据还不是唾手可得？\n\n所以在一个数据页中查找指定主键值的记录的过程分为两步：\n\n * 通过二分法确定该记录所在的槽，并找到改槽中主键值最小的那条记录。\n * 通过记录的 next_record 属性遍历该槽，找到目标数据。\n\n\n# 2.3 page header（页头部信息）\n\n\n\n数据页头部信息，行数据字段记录本行的基本信息，那么页数据也会有专门的字段记录本页的信息，而page header就是用于记录一个数据页的状态信息，比如本页存储了多少个槽、多少个数据等等...\n\n具体有什么字段，来看表格：(由于字段太多了，这是精简过的字段)\n\n名称                 作用\npage_n_dir_slots   该页的页目录中的槽的数量\npage_n_heap        本页中的记录的数量（删除&未删除）\npage_level         当前页在b+树所处的层级\npage_index_id      本页属于哪个索引\n\n\n# 2.4 file header（文件头）\n\n\n\nfile header是每种页都有的属性，其中重要的字段如：本页编号、上一页编号、下一页编号、校验和。\n\n上一个与下一个页的编号：可以将所有数据页组成一个双链表，遍历就很方便了。\n\nfile header中有一个很重要的字段：校验和。\n\n什么是校验和？\n\n对于一个很长很长的字符串来说，我们会使用某种算法来计算一个比较短的字符串来代替它，比如我们通常用文件的md5编码来初步比较文件是否相等。\n\n我们想比较两个很长的字符串的时候，可以先比较他们的校验和，如果连校验和都不一样，那这两个字符串就肯定不一样。这样就省去了一个字符一个字符比较消耗的时间。\n\n同时，file header的校验和还会和file trailer的校验和配合工作，下面会介绍。\n\n\n# 2.5 file trailer（文件尾）\n\n\n\nfile trailer跟file header一样，有一个校验和，那么这个校验和到底是什么作用呢？\n\n我们知道innodb存储引擎会将数据从磁盘中读到内存中，以页为单位。如果数据在内存中修改了，那么mysql势必要把他们再写回磁盘中，写回的过程中万一出现了什么错怎么办？这不是尴尬了吗？为了检验一个页是否完整（也就是同步的时候是否出现同步了一半的情况），mysql就在页的头部和尾部都加了校验和这个东西。\n\n每当一个页在内存中修改了，在同步之前就要把它的校验和算出来。file header在页的最前面，所以校验和会被优先同步，如果完全写完，那么尾部的校验和也会写进去，这没问题。万一中断了，那么file header的校验和是已经修改过的页，file trailer的校验和是原先的页，二者不相同，说明同步过程中出现bug。\n\n（其实还有一个字段，现在先不管）\n\n\n# 3. 总结\n\n 1. innodb为了不同的目的而设计了不同的页类型，我们把存放数据的页称为数据页。\n\n 2. 数据页可以被分为7个部分：\n    \n    1. file header：表示页的一些通用信息\n    2. page header：表示数据页专有的信息\n    3. infimum + supermum：两个虚拟的伪记录，分别表示页中的最小记录和最大记录\n    4. user records：存放我们插入的数据\n    5. free space：页中可以被我们使用的数据\n    6. page directory：页中的某些记录的相对位置，其中存放很多槽位\n    7. file trailer：页尾，与file header一起提供校验和来检查同步状态\n\n 3. 每个数据页的file header都有上一个与下一个页的编号，所以所有的数据页会组成一个双链表\n\n 4. user records中的每一条记录有next_record，它将所有记录串联为一个链表（已删除的和未删除的，共两个链表）\n\n 5. 为保证内存到磁盘的同步的完整性，在数据页的首部和数据页的尾部都会存储页中数据的校验和\n\n‍",charsets:{cjk:!0},lastUpdated:"2023/06/08, 21:54:53",lastUpdatedTimestamp:1686232493e3},{title:"单机定时任务的实现",frontmatter:{title:"单机定时任务的实现",date:"2024-06-11T23:06:35.000Z",permalink:"/pages/d8c9ba/"},regularPath:"/02.%E6%96%87%E7%AB%A0/01.Java%E5%9F%BA%E7%A1%80/300.%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%AE%9E%E7%8E%B0.html",relativePath:"02.文章/01.Java基础/300.单机定时任务的实现.md",key:"v-afa30cfc",path:"/pages/d8c9ba/",headers:[{level:2,title:"1. 简述",slug:"_1-简述",normalizedTitle:"1. 简述",charIndex:2},{level:2,title:"2. Timer",slug:"_2-timer",normalizedTitle:"2. timer",charIndex:350},{level:3,title:"2.1 TimerQueue",slug:"_2-1-timerqueue",normalizedTitle:"2.1 timerqueue",charIndex:511},{level:3,title:"2.2 TimerThread",slug:"_2-2-timerthread",normalizedTitle:"2.2 timerthread",charIndex:2441},{level:3,title:"2.3 总结",slug:"_2-3-总结",normalizedTitle:"2.3 总结",charIndex:6375},{level:2,title:"3. ScheduledThreadPoolExecutor",slug:"_3-scheduledthreadpoolexecutor",normalizedTitle:"3. scheduledthreadpoolexecutor",charIndex:6428},{level:2,title:"4. HashedWheelTimer",slug:"_4-hashedwheeltimer",normalizedTitle:"4. hashedwheeltimer",charIndex:6533}],headersStr:"1. 简述 2. Timer 2.1 TimerQueue 2.2 TimerThread 2.3 总结 3. ScheduledThreadPoolExecutor 4. HashedWheelTimer",content:"# 1. 简述\n\n本篇文章介绍的是单机定时任务的实现，不包括像 XXL-JOB、Power-JOB 这样的分布式定时任务。\n\n单机的定时任务用的比较多的实现有 JDK 提供的 Timer、ScheduledThreadPoolExecutor、Netty 和 Dubbo的 HashedWheelTimer。\n\n实现定时任务，都要使用特定的容器，因为这些任务需要在指定的时间执行，你怎么知道什么时候有哪些任务要执行呢？所以就要使用线程一直轮询这个容器。\n\n根据上面说的，实现定时任务有两个关键 ：\n\n 1. 存储任务的容器\n 2. 轮询容器的方式\n\n接下来就看看Timer、ScheduledThreadPoolExecutor、 HashedWheelTimer 它们对于定时任务的实现。\n\n\n# 2. Timer\n\nTimer 使用堆作为存储任务的容器，而且是小根堆，任务根据时间戳的大小在堆中排序。\n\n你想啊，任务是指定时间执行的，那么我将离现在最近的任务，也就是时间戳最小 的任务放在小根堆的最上面，线程每一次取，都可以将最早需要执行的任务取出来。线程的轮询方式也就成了：取任务、执行任务。单调，枯燥😜\n\n\n# 2.1 TimerQueue\n\n说到堆，你在第一次学习堆的使用使用什么方式实现的堆呢？我猜大多数都是用数组来实现。Timer也是如此，Timer 使用数组来实现堆，并将其封装为 TimerQueue。\n\n其实我完全可以将 TimerQueue 的全部代码展示给你，因为实在是太短了\n\nclass TaskQueue {\n    \n\t// 你可能不知道 TimerTask是啥，不重要，这只是一个存放任务的数组\n    private TimerTask[] queue = new TimerTask[128];\n\t// 数据个数\n    private int size = 0;\n\n    void add(TimerTask task) {\n        // 如果容量超了就扩容。\n        if (size + 1 == queue.length)\n            queue = Arrays.copyOf(queue, 2*queue.length);\n\t\t// 添加任务，然后根据这个任务的执行时间将其向上调整\n        queue[++size] = task;\n        fixUp(size);\n    }\n\n\t// 获取最近要执行的任务\n    TimerTask getMin() {\n        return queue[1];\n    }\n\n    /**\n     * 删除最近的任务\n     */\n    void removeMin() {\n        queue[1] = queue[size];\n        queue[size--] = null;  \n        fixDown(1);\n    }\n\n    private void fixUp(int k) {\n        while (k > 1) {\n            int j = k >> 1;\n            if (queue[j].nextExecutionTime <= queue[k].nextExecutionTime)\n                break;\n            TimerTask tmp = queue[j];  queue[j] = queue[k]; queue[k] = tmp;\n            k = j;\n        }\n    }\n\n    private void fixDown(int k) {\n        int j;\n        while ((j = k << 1) <= size && j > 0) {\n            if (j < size && queue[j].nextExecutionTime > queue[j+1].nextExecutionTime)\n                j++; \n            \n            if (queue[k].nextExecutionTime <= queue[j].nextExecutionTime)\n                break;\n            TimerTask tmp = queue[j];  queue[j] = queue[k]; queue[k] = tmp;\n            k = j;\n        }\n    }\n\n    void heapify() {\n        for (int i = size/2; i >= 1; i--)\n            fixDown(i);\n    }\n}\n\n\n\n实在是简单到爆炸！这不就是我们实现的堆吗？毫无阅读难度。堆无非就是两个操作 ：上调、下调。这里面 fixUp和 fixDown 就代表了这两个操作。\n\n其实我删减了部分方法，我来展示其中一个 ：\n\n    void rescheduleMin(long newTime) {\n        queue[1].nextExecutionTime = newTime;\n        fixDown(1);\n    }\n\n\nschedule 是定时，reschedule 是重新定时，min 是最小，这个方法的意思就是将最近的任务重新定时，用于何处？何时使用呢？\n\n当第一个任务执行完成后，这个任务是定时的，它一天执行一次，下一次执行就是一天后了，那么我们就要重新计算它的下一次执行时间，然后将其移到小根堆的下面某处。\n\n\n# 2.2 TimerThread\n\n整个代码也特别特别少，只有80行，但是我又不准备直接放代码了。先来看一下这个线程的工作方式：\n\n 1. 从小根堆堆顶取出任务，但是不能删除\n 2. 计算任务的执行时间与当前时间的差距，让此线程睡眠到任务的执行时间\n 3. 执行任务\n 4. 重新计算该任务的执行时间并调整小根堆。\n 5. 继续重复第一步\n\n由于是线程，所以要实现 run() 方法，主要逻辑在 run() 方法中 ：\n\n    public void run() {\n        try {\n            mainLoop();\n        } finally {\n            // 执行结束有两种情况:\n            // 正常运行结束: 小根堆中无数据\n            // 异常运行结束: 有其他线程将此任务终止，我们要清除小根堆中的任务。\n            synchronized(queue) {\n                newTasksMayBeScheduled = false;\n                queue.clear();   \n            }\n        }\n    }\n\n\n从上面可以看到，run() 调用了 mainLoop() ，看到 Loop 你就应该想到 循环、轮询 这些关键词。\n\nprivate void mainLoop() {\n        while (true) {\n            try {\n                TimerTask task;\n                boolean taskFired;\n                synchronized(queue) {\n                    // 当小根堆中无任务时，当前线程wait阻塞。\n                    // 此线程什么时候被唤醒呢？去 TimerQueue 中寻找 queue.notifyAll没有找到\n                    // 盲猜唤醒逻辑在 Timer 中。\n                    while (queue.isEmpty() && newTasksMayBeScheduled)\n                        queue.wait();\n                    if (queue.isEmpty())\n                        break; \n\n                    // 当前时间\n                    long currentTime; \n                    // 任务的执行时间\n                    long executionTime;\n                    // 得到最近要执行的任务\n                    task = queue.getMin();\n                    // 锁住该任务\n                    synchronized(task.lock) {\n                        // 如果任务已经取消，不用执行了，直接删了\n                        if (task.state == TimerTask.CANCELLED) {\n                            queue.removeMin();\n                            continue;  \n                        }\n                        // 获取当前时间和任务的执行时间\n                        currentTime = System.currentTimeMillis();\n                        executionTime = task.nextExecutionTime;\n                        // 如果任务的执行时间小于当前时间，那么任务就可以执行了\n                        if (taskFired = (executionTime<=currentTime)) {\n                            // 看看任务是周期性任务还是一次性任务\n                            // 如果是一次性任务就无需重新计算该任务的执行时间\n                            if (task.period == 0) { \n                                queue.removeMin();\n                                task.state = TimerTask.EXECUTED;\n                            } else { \n                                // 如果是周期性任务，查看是延时任务还是定时任务, 同时计算下次执行时间\n                                queue.rescheduleMin(\n                                  task.period<0 ? currentTime   - task.period\n                                                : executionTime + task.period);\n                            }\n                        }\n                    }\n                    // 如果任务的执行时间大于当前时间，此线程睡到任务该执行的时候。\n                    if (!taskFired) // Task hasn't yet fired; wait\n                        queue.wait(executionTime - currentTime);\n                }\n                // 执行任务\n                if (taskFired)  // Task fired; run it, holding no locks\n                    task.run();\n            } catch(InterruptedException e) {\n            }\n        }\n    }\n\n\n 1. 为什么要加锁 synchronized(queue) ？\n    \n    因为此线程取任务，其他线程可能向 queue 中放任务，所以要实现并发安全。\n    \n    同时可以看到它加 synchronized 的范围特别小，不包括任务的执行，只包括任务状态的修改、任务执行时间的修改。\n\n 2. 延时任务和定时任务的区别是什么？\n    \n    延时任务算上了任务的执行时间，定时任务不算。\n    \n    举例：一个任务 10s 执行一次，每次执行 5s\n    \n    如果该任务为定时任务 ：任务的执行时间为 10、20、30、40...\n    \n    如果该任务是延时任务 ：任务的执行时间为 10、25、40、55\n\nTimerThread 是如何区分定时任务和延时任务的呢？来看两个方法 ：\n\n    // 延时任务\n\tpublic void schedule(TimerTask task, Date firstTime, long period) {\n        sched(task, firstTime.getTime(), -period);\n    }\n\n\n    // 定时任务\n\tpublic void scheduleAtFixedRate(TimerTask task, Date firstTime, long period) {\n        sched(task, firstTime.getTime(), period);\n    }\n\n\n区别是什么？在调用 super(...) 时 period 的正负，现在再回去看 TimerThread 重新计算任务的执行时间那一段吧 ：\n\n// currentTime : 当前时间，换言之，任务执行的结束时间\n// executionTime : 任务开始执行的时间\n\tqueue.rescheduleMin(\n    \ttask.period < 0 ? \n        currentTime   - task.period : \n        executionTime + task.period\n    );\n\n\n\n# 2.3 总结\n\n没了，Timer就是如此简单。使用小根堆存放定时任务，使用线程扫描小根堆的堆顶。\n\n\n# 3. ScheduledThreadPoolExecutor\n\nScheduledThreadPoolExecutor 也使用堆作为存储任务的容器，唯一与 Timer 不同的是，扫描容器的线程变多了。\n\n\n# 4. HashedWheelTimer\n\nNetty 和 Dubbo 以及很多框架都有它的对应实现，核心思想都一样。它们都将任务放在数组中，使用线程扫描数组。\n\n（只提 Netty 和 Dubbo 是因为我只看过它俩的源码，其实 Kafka 的时间轮更吊，可以作为你的扩展学习内容）\n\n与堆不同的是，此数组模拟的是一个轮子，它的每一个刻度代表着一个时间段，比如大小为 60 的数组，数组中的每一个元素可以代表1s，那么这个数组就可以模拟一个钟表，线程模拟秒针，在循环遍历的时候只需要每 1s 执行那个时间段的所有任务，就可以实现“定时功能”。\n\n问一个问题，哪个线程将任务放在时间轮中？任务线程会取时间轮中的任务去执行，main 线程如果可以直接接触到时间轮的话，我们就需要保证时间轮的并发安全了。但是我不想让并发问题发生在时间轮上，如何实现？\n\n 1. main 线程将任务放到一个普通的数组中\n 2. 任务线程将任务从普通的数组中取出，计算任务的执行时间，然后将其放到对应的刻度上。\n\n不让 main 线程接触到时间轮数组，就可以将并发问题控制在普通数组中，时间轮只负责将任务按照时间维度存储即可。为什么要将并发问题控制在普通数组而不是时间轮数组？因为放在普通数组时，我们只需要放/取；而放在时间轮数组中，我们取后还要判断下次时间再放进去，涉及到很多状态的修改，于是并发情况就更多。\n\n还有一个问题 ：如果任务的执行时间离现在太远了，比如有一个任务在明天执行，我们需要创建一个 24 * 60 * 60 个元素的数组吗？肯定不能，我们可以使用圈数来代表任务距离现在的时间，明天执行的任务可以放在第1个刻度上，该任务的圈数为 24 * 60，每一次循环到它都将这个圈数减1，当圈数为 0 时即可执行。\n\n问题总结完了，来看一下 HashedWheelTimer 的工作流程：\n\n 1. main 线程负责将任务放到普通数组中\n 2. 任务线程每次循环都从普通数组中取任务，将其放到对应的刻度中，然后执行此时指向的刻度中的所有任务。",normalizedContent:"# 1. 简述\n\n本篇文章介绍的是单机定时任务的实现，不包括像 xxl-job、power-job 这样的分布式定时任务。\n\n单机的定时任务用的比较多的实现有 jdk 提供的 timer、scheduledthreadpoolexecutor、netty 和 dubbo的 hashedwheeltimer。\n\n实现定时任务，都要使用特定的容器，因为这些任务需要在指定的时间执行，你怎么知道什么时候有哪些任务要执行呢？所以就要使用线程一直轮询这个容器。\n\n根据上面说的，实现定时任务有两个关键 ：\n\n 1. 存储任务的容器\n 2. 轮询容器的方式\n\n接下来就看看timer、scheduledthreadpoolexecutor、 hashedwheeltimer 它们对于定时任务的实现。\n\n\n# 2. timer\n\ntimer 使用堆作为存储任务的容器，而且是小根堆，任务根据时间戳的大小在堆中排序。\n\n你想啊，任务是指定时间执行的，那么我将离现在最近的任务，也就是时间戳最小 的任务放在小根堆的最上面，线程每一次取，都可以将最早需要执行的任务取出来。线程的轮询方式也就成了：取任务、执行任务。单调，枯燥😜\n\n\n# 2.1 timerqueue\n\n说到堆，你在第一次学习堆的使用使用什么方式实现的堆呢？我猜大多数都是用数组来实现。timer也是如此，timer 使用数组来实现堆，并将其封装为 timerqueue。\n\n其实我完全可以将 timerqueue 的全部代码展示给你，因为实在是太短了\n\nclass taskqueue {\n    \n\t// 你可能不知道 timertask是啥，不重要，这只是一个存放任务的数组\n    private timertask[] queue = new timertask[128];\n\t// 数据个数\n    private int size = 0;\n\n    void add(timertask task) {\n        // 如果容量超了就扩容。\n        if (size + 1 == queue.length)\n            queue = arrays.copyof(queue, 2*queue.length);\n\t\t// 添加任务，然后根据这个任务的执行时间将其向上调整\n        queue[++size] = task;\n        fixup(size);\n    }\n\n\t// 获取最近要执行的任务\n    timertask getmin() {\n        return queue[1];\n    }\n\n    /**\n     * 删除最近的任务\n     */\n    void removemin() {\n        queue[1] = queue[size];\n        queue[size--] = null;  \n        fixdown(1);\n    }\n\n    private void fixup(int k) {\n        while (k > 1) {\n            int j = k >> 1;\n            if (queue[j].nextexecutiontime <= queue[k].nextexecutiontime)\n                break;\n            timertask tmp = queue[j];  queue[j] = queue[k]; queue[k] = tmp;\n            k = j;\n        }\n    }\n\n    private void fixdown(int k) {\n        int j;\n        while ((j = k << 1) <= size && j > 0) {\n            if (j < size && queue[j].nextexecutiontime > queue[j+1].nextexecutiontime)\n                j++; \n            \n            if (queue[k].nextexecutiontime <= queue[j].nextexecutiontime)\n                break;\n            timertask tmp = queue[j];  queue[j] = queue[k]; queue[k] = tmp;\n            k = j;\n        }\n    }\n\n    void heapify() {\n        for (int i = size/2; i >= 1; i--)\n            fixdown(i);\n    }\n}\n\n\n\n实在是简单到爆炸！这不就是我们实现的堆吗？毫无阅读难度。堆无非就是两个操作 ：上调、下调。这里面 fixup和 fixdown 就代表了这两个操作。\n\n其实我删减了部分方法，我来展示其中一个 ：\n\n    void reschedulemin(long newtime) {\n        queue[1].nextexecutiontime = newtime;\n        fixdown(1);\n    }\n\n\nschedule 是定时，reschedule 是重新定时，min 是最小，这个方法的意思就是将最近的任务重新定时，用于何处？何时使用呢？\n\n当第一个任务执行完成后，这个任务是定时的，它一天执行一次，下一次执行就是一天后了，那么我们就要重新计算它的下一次执行时间，然后将其移到小根堆的下面某处。\n\n\n# 2.2 timerthread\n\n整个代码也特别特别少，只有80行，但是我又不准备直接放代码了。先来看一下这个线程的工作方式：\n\n 1. 从小根堆堆顶取出任务，但是不能删除\n 2. 计算任务的执行时间与当前时间的差距，让此线程睡眠到任务的执行时间\n 3. 执行任务\n 4. 重新计算该任务的执行时间并调整小根堆。\n 5. 继续重复第一步\n\n由于是线程，所以要实现 run() 方法，主要逻辑在 run() 方法中 ：\n\n    public void run() {\n        try {\n            mainloop();\n        } finally {\n            // 执行结束有两种情况:\n            // 正常运行结束: 小根堆中无数据\n            // 异常运行结束: 有其他线程将此任务终止，我们要清除小根堆中的任务。\n            synchronized(queue) {\n                newtasksmaybescheduled = false;\n                queue.clear();   \n            }\n        }\n    }\n\n\n从上面可以看到，run() 调用了 mainloop() ，看到 loop 你就应该想到 循环、轮询 这些关键词。\n\nprivate void mainloop() {\n        while (true) {\n            try {\n                timertask task;\n                boolean taskfired;\n                synchronized(queue) {\n                    // 当小根堆中无任务时，当前线程wait阻塞。\n                    // 此线程什么时候被唤醒呢？去 timerqueue 中寻找 queue.notifyall没有找到\n                    // 盲猜唤醒逻辑在 timer 中。\n                    while (queue.isempty() && newtasksmaybescheduled)\n                        queue.wait();\n                    if (queue.isempty())\n                        break; \n\n                    // 当前时间\n                    long currenttime; \n                    // 任务的执行时间\n                    long executiontime;\n                    // 得到最近要执行的任务\n                    task = queue.getmin();\n                    // 锁住该任务\n                    synchronized(task.lock) {\n                        // 如果任务已经取消，不用执行了，直接删了\n                        if (task.state == timertask.cancelled) {\n                            queue.removemin();\n                            continue;  \n                        }\n                        // 获取当前时间和任务的执行时间\n                        currenttime = system.currenttimemillis();\n                        executiontime = task.nextexecutiontime;\n                        // 如果任务的执行时间小于当前时间，那么任务就可以执行了\n                        if (taskfired = (executiontime<=currenttime)) {\n                            // 看看任务是周期性任务还是一次性任务\n                            // 如果是一次性任务就无需重新计算该任务的执行时间\n                            if (task.period == 0) { \n                                queue.removemin();\n                                task.state = timertask.executed;\n                            } else { \n                                // 如果是周期性任务，查看是延时任务还是定时任务, 同时计算下次执行时间\n                                queue.reschedulemin(\n                                  task.period<0 ? currenttime   - task.period\n                                                : executiontime + task.period);\n                            }\n                        }\n                    }\n                    // 如果任务的执行时间大于当前时间，此线程睡到任务该执行的时候。\n                    if (!taskfired) // task hasn't yet fired; wait\n                        queue.wait(executiontime - currenttime);\n                }\n                // 执行任务\n                if (taskfired)  // task fired; run it, holding no locks\n                    task.run();\n            } catch(interruptedexception e) {\n            }\n        }\n    }\n\n\n 1. 为什么要加锁 synchronized(queue) ？\n    \n    因为此线程取任务，其他线程可能向 queue 中放任务，所以要实现并发安全。\n    \n    同时可以看到它加 synchronized 的范围特别小，不包括任务的执行，只包括任务状态的修改、任务执行时间的修改。\n\n 2. 延时任务和定时任务的区别是什么？\n    \n    延时任务算上了任务的执行时间，定时任务不算。\n    \n    举例：一个任务 10s 执行一次，每次执行 5s\n    \n    如果该任务为定时任务 ：任务的执行时间为 10、20、30、40...\n    \n    如果该任务是延时任务 ：任务的执行时间为 10、25、40、55\n\ntimerthread 是如何区分定时任务和延时任务的呢？来看两个方法 ：\n\n    // 延时任务\n\tpublic void schedule(timertask task, date firsttime, long period) {\n        sched(task, firsttime.gettime(), -period);\n    }\n\n\n    // 定时任务\n\tpublic void scheduleatfixedrate(timertask task, date firsttime, long period) {\n        sched(task, firsttime.gettime(), period);\n    }\n\n\n区别是什么？在调用 super(...) 时 period 的正负，现在再回去看 timerthread 重新计算任务的执行时间那一段吧 ：\n\n// currenttime : 当前时间，换言之，任务执行的结束时间\n// executiontime : 任务开始执行的时间\n\tqueue.reschedulemin(\n    \ttask.period < 0 ? \n        currenttime   - task.period : \n        executiontime + task.period\n    );\n\n\n\n# 2.3 总结\n\n没了，timer就是如此简单。使用小根堆存放定时任务，使用线程扫描小根堆的堆顶。\n\n\n# 3. scheduledthreadpoolexecutor\n\nscheduledthreadpoolexecutor 也使用堆作为存储任务的容器，唯一与 timer 不同的是，扫描容器的线程变多了。\n\n\n# 4. hashedwheeltimer\n\nnetty 和 dubbo 以及很多框架都有它的对应实现，核心思想都一样。它们都将任务放在数组中，使用线程扫描数组。\n\n（只提 netty 和 dubbo 是因为我只看过它俩的源码，其实 kafka 的时间轮更吊，可以作为你的扩展学习内容）\n\n与堆不同的是，此数组模拟的是一个轮子，它的每一个刻度代表着一个时间段，比如大小为 60 的数组，数组中的每一个元素可以代表1s，那么这个数组就可以模拟一个钟表，线程模拟秒针，在循环遍历的时候只需要每 1s 执行那个时间段的所有任务，就可以实现“定时功能”。\n\n问一个问题，哪个线程将任务放在时间轮中？任务线程会取时间轮中的任务去执行，main 线程如果可以直接接触到时间轮的话，我们就需要保证时间轮的并发安全了。但是我不想让并发问题发生在时间轮上，如何实现？\n\n 1. main 线程将任务放到一个普通的数组中\n 2. 任务线程将任务从普通的数组中取出，计算任务的执行时间，然后将其放到对应的刻度上。\n\n不让 main 线程接触到时间轮数组，就可以将并发问题控制在普通数组中，时间轮只负责将任务按照时间维度存储即可。为什么要将并发问题控制在普通数组而不是时间轮数组？因为放在普通数组时，我们只需要放/取；而放在时间轮数组中，我们取后还要判断下次时间再放进去，涉及到很多状态的修改，于是并发情况就更多。\n\n还有一个问题 ：如果任务的执行时间离现在太远了，比如有一个任务在明天执行，我们需要创建一个 24 * 60 * 60 个元素的数组吗？肯定不能，我们可以使用圈数来代表任务距离现在的时间，明天执行的任务可以放在第1个刻度上，该任务的圈数为 24 * 60，每一次循环到它都将这个圈数减1，当圈数为 0 时即可执行。\n\n问题总结完了，来看一下 hashedwheeltimer 的工作流程：\n\n 1. main 线程负责将任务放到普通数组中\n 2. 任务线程每次循环都从普通数组中取任务，将其放到对应的刻度中，然后执行此时指向的刻度中的所有任务。",charsets:{cjk:!0},lastUpdated:"2024/06/11, 23:06:50",lastUpdatedTimestamp:171811841e4},{title:"Reator模式",frontmatter:{title:"Reator模式",date:"2024-01-22T00:32:48.000Z",permalink:"/pages/0c2518/"},regularPath:"/02.%E6%96%87%E7%AB%A0/01.Java%E5%9F%BA%E7%A1%80/150.Reactor%E6%A8%A1%E5%BC%8F.html",relativePath:"02.文章/01.Java基础/150.Reactor模式.md",key:"v-e1c868da",path:"/pages/0c2518/",headers:[{level:2,title:"Reator",slug:"reator",normalizedTitle:"reator",charIndex:11},{level:3,title:"1. 单Reactor单线程模型",slug:"_1-单reactor单线程模型",normalizedTitle:"1. 单reactor单线程模型",charIndex:159},{level:3,title:"2. 单Reactor多线程模型",slug:"_2-单reactor多线程模型",normalizedTitle:"2. 单reactor多线程模型",charIndex:178},{level:3,title:"3. 主从Reactor多线程模型",slug:"_3-主从reactor多线程模型",normalizedTitle:"3. 主从reactor多线程模型",charIndex:197},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:13992}],headersStr:"Reator 1. 单Reactor单线程模型 2. 单Reactor多线程模型 3. 主从Reactor多线程模型 总结",content:"本文摘自 ：一文搞懂 Reator\n\n在网络IO设计中，有两种高性能模型：Reactor模型和Proactor模型。Reactor基于同步IO模式，Proactor基于异步IO模式。\n\nNetty网络框架，Redis等中间件中都有使用到Reactor模型。本文将对Reactor模型的如下三种分类进行学习和实现。\n\n 1. 单Reactor单线程模型；\n 2. 单Reactor多线程模型；\n 3. 主从Reactor多线程模型。\n\n如果不具备网络IO的相关知识，建议先阅读Java网络IO模型分析与实现。\n\n\n# Reator\n\n\n# 1. 单Reactor单线程模型\n\n单Reactor单线程模型中，只有一个Reactor在监听事件和分发事件，并且监听事件，分发事件和处理事件都在一个线程中完成。示意图如下所示。\n\n\n\n上述示意图中，一次完整的处理流程可以概括如下。\n\n 1. Reactor监听到ACCEPT事件发生，表示此时有客户端建立连接；\n 2. Reactor将ACCEPT事件分发给Acceptor处理；\n 3. Acceptor会在服务端创建与客户端通信的client-socket管道，然后注册到IO多路复用器selector上，并监听READ事件；\n 4. Reactor监听到READ事件发生，表示此时客户端数据可读；\n 5. Reactor将READ事件分发给Handler处理，Handler处理READ事件就会基于client-socket管道完成客户端数据的读取。\n\n下面将基于Java语言，实现一个简单的单Reactor单线程模型的服务端，整体代码实现完全符合上述示意图，大家可以进行参照阅读。\n\n首先实现Reactor，如下所示。\n\npublic class Reactor implements Runnable {\n\n    private final Selector selector;\n\n    public Reactor(int port) throws IOException {\n        // 开启多路复用\n        selector = Selector.open();\n        // 服务端创建listen-socket管道\n        ServerSocketChannel listenSocketChannel = ServerSocketChannel.open();\n        // 绑定端口\n        listenSocketChannel.socket().bind(new InetSocketAddress(port));\n        // 设置为非阻塞模式\n        listenSocketChannel.configureBlocking(false);\n        // ACCEPT事件的附加器是Acceptor\n        listenSocketChannel.register(selector, SelectionKey.OP_ACCEPT,\n                new Acceptor(selector, listenSocketChannel));\n    }\n\n    @Override\n    public void run() {\n        while (!Thread.interrupted()) {\n            try {\n                // 获取发生的事件\n                selector.select();\n                Set<SelectionKey> selectionKeys = selector.selectedKeys();\n                Iterator<SelectionKey> iterable = selectionKeys.iterator();\n                while (iterable.hasNext()) {\n                    // 对事件进行分发\n                    dispatch(iterable.next());\n                    iterable.remove();\n                }\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n            LockSupport.parkNanos(1000 * 1000 * 1000);\n        }\n    }\n\n    private void dispatch(SelectionKey selectionKey) {\n        // 获取事件的附加器\n        // ACCEPT事件的附加器是Acceptor，故由Acceptor来处理ACCEPT事件\n        // READ事件的附加器是Handler，故由Handler来处理READ事件\n        Runnable attachment = (Runnable) selectionKey.attachment();\n        if (attachment != null) {\n            attachment.run();\n        }\n    }\n\n}\n\n\n已知Reactor会监听客户端连接的ACCEPT事件，还已知ACCEPT事件由Acceptor处理，所以在向多路复用器注册服务端用于监听客户端连接的listen-socket管道时，添加了一个Acceptor作为附加器，那么当发生ACCEPT事件时，就能够获取到作为ACCEPT事件附加器的Acceptor来处理ACCEPT事件。\n\n下面看一下Acceptor的实现，如下所示。\n\npublic class Acceptor implements Runnable {\n\n    private final Selector selector;\n    private final ServerSocketChannel listenSocketChannel;\n\n    public Acceptor(Selector selector, ServerSocketChannel listenSocketChannel) {\n        this.selector = selector;\n        this.listenSocketChannel = listenSocketChannel;\n    }\n\n    @Override\n    public void run() {\n        try {\n            // 为连接的客户端创建client-socket管道\n            SocketChannel clientSocketChannel = listenSocketChannel.accept();\n            // 设置为非阻塞\n            clientSocketChannel.configureBlocking(false);\n            // READ事件的附加器是Handler\n            clientSocketChannel.register(selector, SelectionKey.OP_READ,\n                    new Handler(clientSocketChannel));\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n}\n\n\n在Acceptor中就是在服务端创建与客户端通信的client-socket管道，然后注册到多路复用器上并指定监听READ事件，同时又因为READ事件由Handler处理，所以还添加了一个Handler作为附加器，当READ事件发生时可以获取到作为READ事件附加器的Handler来处理READ事件。\n\n下面看一下Handler的实现，如下所示。\n\npublic class Handler implements Runnable {\n\n    private final SocketChannel clientSocketChannel;\n\n    public Handler(SocketChannel clientSocketChannel) {\n        this.clientSocketChannel = clientSocketChannel;\n    }\n\n    @Override\n    public void run() {\n        ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n        try {\n            // 读取数据\n            int read = clientSocketChannel.read(byteBuffer);\n            if (read <= 0) {\n                clientSocketChannel.close();\n            } else {\n                System.out.println(new String(byteBuffer.array()));\n            }\n        } catch (IOException e1) {\n            try {\n                clientSocketChannel.close();\n            } catch (IOException e2) {\n                e2.printStackTrace();\n            }\n            e1.printStackTrace();\n        }\n    }\n\n}\n\n\n在Handler中就是简单的读取数据并打印，当读取数据为空或者发生异常时，需要及时将管道关闭。\n\n最后编写一个主程序将Reactor运行起来，如下所示。\n\npublic class MainServer {\n\n    public static void main(String[] args) throws IOException {\n        Thread reactorThread = new Thread(new Reactor(8080));\n        reactorThread.start();\n    }\n\n}\n\n\n现在来思考一下，单Reactor单线程模型有什么优点和缺点。优点其实就是模型简单，实现方便。缺点有两点，如下所示。\n\n 1. 一个Reactor同时负责监听ACCEPT事件和READ事件；\n 2. 只有一个线程在工作，处理效率低，无法利用多核CPU的优势。\n\n但是尽管单Reactor单线程模型有上述的缺点，但是著名的缓存中间件Redis的服务端，就是使用的单Reactor单线程模型，示意图如下。\n\n\n\n那为什么以性能著称的Redis会采取单Reactor单线程模型呢，其实就是因为Redis的操作都在内存中，读写都非常快速，所以单Reactor单线程模型也能运行得很流畅，同时还避免了多线程下的各种并发问题。\n\n\n# 2. 单Reactor多线程模型\n\n在理解了单Reactor单线程模型后，那么肯定就能想到，假如在Handler中处理READ事件的这个事情能够使用一个线程池来完成，从而就可以实现READ事件的处理不会阻塞主线程。而这样的一个模型，其实就是单Reactor多线程模型，示意图如下所示。\n\n和单Reactor单线程模型唯一的不同，就是在Handler中多了一个线程池。\n\n单Reactor多线程模型的代码实现，除了Handler以外，其余和单Reactor单线程模型一摸一样，所以下面就看一下单Reactor多线程模型中的Handler实现，如下所示。\n\npublic class Handler implements Runnable {\n\n    private static final ThreadPoolExecutor threadPool = new ThreadPoolExecutor(16, 32,\n            60, TimeUnit.SECONDS, new LinkedBlockingQueue<>(200));\n\n    private final SocketChannel clientSocketChannel;\n\n    public Handler(SocketChannel clientSocketChannel) {\n        this.clientSocketChannel = clientSocketChannel;\n    }\n\n    @Override\n    public void run() {\n        threadPool.execute(() -> {\n            ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n            try {\n                // 读取数据\n                int read = clientSocketChannel.read(byteBuffer);\n                if (read <= 0) {\n                    clientSocketChannel.close();\n                } else {\n                    System.out.println(new String(byteBuffer.array()));\n                }\n                // 睡眠10S，演示任务执行耗时长也不会阻塞处理其它客户端请求\n                LockSupport.parkNanos(1000 * 1000 * 1000 * 10L);\n            } catch (IOException e1) {\n                try {\n                    clientSocketChannel.close();\n                } catch (IOException e2) {\n                    e2.printStackTrace();\n                }\n                e1.printStackTrace();\n            }\n        });\n    }\n\n}\n\n\n其实就是每一个READ事件的处理会作为一个任务被扔到线程池中去处理。\n\n单Reactor多线程模型虽然解决了只有一个线程的问题，但是可以发现，仍旧是只有一个Reactor在同时监听ACCEPT事件和READ事件。\n\n那么现在思考一下，为什么一个Reactor同时监听ACCEPT事件和READ事件是不好的。其实就是因为通常客户端连接的建立是不频繁的，但是连接建立后数据的收发是频繁的，所以如果能够将监听READ事件这个动作拆分出来，让多个子Reactor来监听READ事件，而原来的主Reactor只监听ACCEPT事件，那么整体的效率，会进一步提升，而这，就是主从Reactor多线程模型。\n\n\n# 3. 主从Reactor多线程模型\n\n主从Reactor模型中，有一个主Reactor，专门监听ACCEPT事件，然后有多个从Reactor，专门监听READ事件，示意图如下所示。\n\n\n\n上述示意图中，一次完整的处理流程可以概括如下。\n\n 1. 主Reactor监听到ACCEPT事件发生，表示此时有客户端建立连接；\n 2. 主Reactor将ACCEPT事件分发给Acceptor处理；\n 3. Acceptor会在服务端创建与客户端通信的client-socket管道，然后注册到从Reactor的IO多路复用器selector上，并监听READ事件；\n 4. 从Reactor监听到READ事件发生，表示此时客户端数据可读；\n 5. 从Reactor将ACCEPT事件分发给Handler处理，Handler处理READ事件就会基于client-socket管道完成客户端数据的读取。\n\n下面将基于Java语言，实现一个简单的主从Reactor多线程模型的服务端，整体代码实现完全符合上述示意图，大家可以进行参照阅读。\n\n首先是主Reactor的实现，如下所示。\n\npublic class MainReactor implements Runnable {\n\n    private final Selector selector;\n\n    public MainReactor(int port) throws IOException {\n        // 开多路复用器\n        selector = Selector.open();\n        // 服务端创建listen-socket管道\n        ServerSocketChannel listenSocketChannel = ServerSocketChannel.open();\n        // 设置为非阻塞\n        listenSocketChannel.configureBlocking(false);\n        // 绑定监听端口\n        listenSocketChannel.socket().bind(new InetSocketAddress(port));\n        // 将listen-socket管道绑定到主Reactor的多路复用器上\n        // 并且主Reactor上只会注册listen-socket管道，用于监听ACCEPT事件\n        listenSocketChannel.register(selector, SelectionKey.OP_ACCEPT,\n                new Acceptor(listenSocketChannel));\n    }\n\n    @Override\n    public void run() {\n        while (!Thread.interrupted()) {\n            try {\n                selector.select();\n                Set<SelectionKey> selectionKeys = selector.selectedKeys();\n                Iterator<SelectionKey> iterable = selectionKeys.iterator();\n                while (iterable.hasNext()) {\n                    // 对事件进行分发\n                    dispatch(iterable.next());\n                    iterable.remove();\n                }\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n            LockSupport.parkNanos(1000 * 1000 * 1000);\n        }\n    }\n\n    private void dispatch(SelectionKey selectionKey) {\n        // 获取事件附加器，只会是Acceptor\n        Runnable attachment = (Runnable) selectionKey.attachment();\n        if (attachment != null) {\n            attachment.run();\n        }\n    }\n\n}\n\n\n主Reactor的实现中，还是先创建服务端监听客户端连接的listen-socket管道，然后注册到主Reactor的IO多路复用器上，并监听ACCEPT事件，同时我们现在知道，主Reactor的IO多路复用器上只会注册listen-socket管道且只会监听ACCEPT事件。同样，也添加了一个Acceptor作为附加器，那么当发生ACCEPT事件时，就能够获取到作为ACCEPT事件附加器的Acceptor来处理ACCEPT事件。\n\n下面是Acceptor的实现，如下所示。\n\npublic class Acceptor implements Runnable {\n\n    // 指定从Reactor一共有16个\n    private static final int TOTAL_SUBREACTOR_NUM = 16;\n\n    // 服务端的listen-socket管道\n    private final ServerSocketChannel listenSocketChannel;\n\n    // 用于运行从Reactor\n    private final ThreadPoolExecutor threadPool = new ThreadPoolExecutor(\n            TOTAL_SUBREACTOR_NUM, TOTAL_SUBREACTOR_NUM * 2,\n            60, TimeUnit.SECONDS, new LinkedBlockingQueue<>(200));\n\n    // 从Reactor集合\n    private final List<SubReactor> subReactors = new ArrayList<>(TOTAL_SUBREACTOR_NUM);\n\n    public Acceptor(ServerSocketChannel listenSocketChannel) throws IOException {\n        this.listenSocketChannel = listenSocketChannel;\n        // 将从Reactor初始化出来并运行\n        for (int i = 0; i < TOTAL_SUBREACTOR_NUM; i++) {\n            SubReactor subReactor = new SubReactor(Selector.open());\n            subReactors.add(subReactor);\n            threadPool.execute(subReactor);\n        }\n    }\n\n    @Override\n    public void run() {\n        try {\n            // 为连接的客户端创建client-socket管道\n            SocketChannel clientSocketChannel = listenSocketChannel.accept();\n            // 设置为非阻塞\n            clientSocketChannel.configureBlocking(false);\n            // 任意选择一个从Reactor，让其监听连接的客户端的READ事件\n            Optional<SubReactor> anySubReactor = subReactors.stream().findAny();\n            if (anySubReactor.isPresent()) {\n                SubReactor subReactor = anySubReactor.get();\n                // 从Reactor的多路复用器会阻塞在select()方法上\n                // 这里需要先唤醒多路复用器，立即从select()方法返回\n                subReactor.getSelector().wakeup();\n                // 让从Reactor负责处理客户端的READ事件\n                clientSocketChannel.register(subReactor.getSelector(), SelectionKey.OP_READ,\n                        new Handler(clientSocketChannel));\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n}\n\n\n首先在Acceptor的构造函数中，会将所有从Reactor初始化出来，并且每一个从Reactor都会持有一个IO多路复用器。当一个从Reactor创建出来后就会立即运行，此时从Reactor的IO多路复用器就会开始监听，即阻塞在select() 方法上。\n\n然后在Acceptor的主体逻辑中，会为连接的客户端创建client-socket管道，然后从所有从Reactor中基于某种策略（随机）选择一个从Reactor，并将client-socket管道注册在选择的从Reactor的IO多路复用器上，有一点需要注意，此时从Reactor的IO多路复用器可能会阻塞在select() 方法上，所以注册前需要先通过wakeup() 方法进行唤醒。\n\n接下来继续看从Reactor的实现，如下所示。\n\npublic class SubReactor implements Runnable {\n\n    private final Selector selector;\n\n    public SubReactor(Selector selector) {\n        this.selector = selector;\n    }\n\n    @Override\n    public void run() {\n        while (!Thread.interrupted()) {\n            try {\n                selector.select();\n                Set<SelectionKey> selectionKeys = selector.selectedKeys();\n                Iterator<SelectionKey> iterator = selectionKeys.iterator();\n                while (iterator.hasNext()) {\n                    // 对事件进行分发\n                    dispatch(iterator.next());\n                    iterator.remove();\n                }\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n            LockSupport.parkNanos(1000 * 1000 * 1000);\n        }\n    }\n\n    private void dispatch(SelectionKey selectionKey) {\n        // 获取事件附加器，只会是Handler\n        Runnable runnable = (Runnable) selectionKey.attachment();\n        if (runnable != null) {\n            runnable.run();\n        }\n    }\n\n    public Selector getSelector() {\n        return selector;\n    }\n\n}\n\n\n从Reactor的实现中，会监听服务端为连接的客户端创建的client-socket管道上的READ事件，一旦有READ事件发生，就会使用作为附加器的Handler来处理READ事件。同样，从Reactor的IO多路复用器上只会注册client-socket管道且只会监听READ事件。\n\n然后是Handler，因为是多线程模型，所以其实现和第三节中的Handler完全一样，下面再贴一下代码。\n\npublic class Handler implements Runnable {\n\n    private static final ThreadPoolExecutor threadPool = new ThreadPoolExecutor(16, 32,\n            60, TimeUnit.SECONDS, new LinkedBlockingQueue<>(200));\n\n    private final SocketChannel clientSocketChannel;\n\n    public Handler(SocketChannel clientSocketChannel) {\n        this.clientSocketChannel = clientSocketChannel;\n    }\n\n    @Override\n    public void run() {\n        threadPool.execute(() -> {\n            ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n            try {\n                // 读取数据\n                int read = clientSocketChannel.read(byteBuffer);\n                if (read <= 0) {\n                    clientSocketChannel.close();\n                } else {\n                    System.out.println(new String(byteBuffer.array()));\n                }\n                // 睡眠10S，演示任务执行耗时长也不会阻塞处理其它客户端请求\n                LockSupport.parkNanos(1000 * 1000 * 1000 * 10L);\n            } catch (IOException e1) {\n                try {\n                    clientSocketChannel.close();\n                } catch (IOException e2) {\n                    e2.printStackTrace();\n                }\n                e1.printStackTrace();\n            }\n        });\n    }\n\n}\n\n\n最后编写一个主程序将主Reactor运行起来，如下所示。\n\npublic class MainServer {\n\n    public static void main(String[] args) throws IOException {\n        Thread mainReactorThread = new Thread(new MainReactor(8080));\n        mainReactorThread.start();\n    }\n\n}\n\n\n\n# 总结\n\nReactor模型主要就是监听事件，分发事件和处理事件。其中Reactor角色会负责监听事件 和分发事件，Handler角色和Acceptor角色会负责处理事件。\n\nReactor模型虽然分为：单Reactor单线程模型，单Reactor多线程模型和主从Reactor多线程模型，但是其本质就是NIO的实现，是不过套了Reactor设计模式的外壳。\n\n在网络通信框架Netty中，三种Reactor模型都有使用到，所以想要学习Netty的精髓，理解Reactor模型是必不可少的。\n\n作者：半夏之沫 链接：https://juejin.cn/post/7210375522512666679 来源：稀土掘金",normalizedContent:"本文摘自 ：一文搞懂 reator\n\n在网络io设计中，有两种高性能模型：reactor模型和proactor模型。reactor基于同步io模式，proactor基于异步io模式。\n\nnetty网络框架，redis等中间件中都有使用到reactor模型。本文将对reactor模型的如下三种分类进行学习和实现。\n\n 1. 单reactor单线程模型；\n 2. 单reactor多线程模型；\n 3. 主从reactor多线程模型。\n\n如果不具备网络io的相关知识，建议先阅读java网络io模型分析与实现。\n\n\n# reator\n\n\n# 1. 单reactor单线程模型\n\n单reactor单线程模型中，只有一个reactor在监听事件和分发事件，并且监听事件，分发事件和处理事件都在一个线程中完成。示意图如下所示。\n\n\n\n上述示意图中，一次完整的处理流程可以概括如下。\n\n 1. reactor监听到accept事件发生，表示此时有客户端建立连接；\n 2. reactor将accept事件分发给acceptor处理；\n 3. acceptor会在服务端创建与客户端通信的client-socket管道，然后注册到io多路复用器selector上，并监听read事件；\n 4. reactor监听到read事件发生，表示此时客户端数据可读；\n 5. reactor将read事件分发给handler处理，handler处理read事件就会基于client-socket管道完成客户端数据的读取。\n\n下面将基于java语言，实现一个简单的单reactor单线程模型的服务端，整体代码实现完全符合上述示意图，大家可以进行参照阅读。\n\n首先实现reactor，如下所示。\n\npublic class reactor implements runnable {\n\n    private final selector selector;\n\n    public reactor(int port) throws ioexception {\n        // 开启多路复用\n        selector = selector.open();\n        // 服务端创建listen-socket管道\n        serversocketchannel listensocketchannel = serversocketchannel.open();\n        // 绑定端口\n        listensocketchannel.socket().bind(new inetsocketaddress(port));\n        // 设置为非阻塞模式\n        listensocketchannel.configureblocking(false);\n        // accept事件的附加器是acceptor\n        listensocketchannel.register(selector, selectionkey.op_accept,\n                new acceptor(selector, listensocketchannel));\n    }\n\n    @override\n    public void run() {\n        while (!thread.interrupted()) {\n            try {\n                // 获取发生的事件\n                selector.select();\n                set<selectionkey> selectionkeys = selector.selectedkeys();\n                iterator<selectionkey> iterable = selectionkeys.iterator();\n                while (iterable.hasnext()) {\n                    // 对事件进行分发\n                    dispatch(iterable.next());\n                    iterable.remove();\n                }\n            } catch (ioexception e) {\n                e.printstacktrace();\n            }\n            locksupport.parknanos(1000 * 1000 * 1000);\n        }\n    }\n\n    private void dispatch(selectionkey selectionkey) {\n        // 获取事件的附加器\n        // accept事件的附加器是acceptor，故由acceptor来处理accept事件\n        // read事件的附加器是handler，故由handler来处理read事件\n        runnable attachment = (runnable) selectionkey.attachment();\n        if (attachment != null) {\n            attachment.run();\n        }\n    }\n\n}\n\n\n已知reactor会监听客户端连接的accept事件，还已知accept事件由acceptor处理，所以在向多路复用器注册服务端用于监听客户端连接的listen-socket管道时，添加了一个acceptor作为附加器，那么当发生accept事件时，就能够获取到作为accept事件附加器的acceptor来处理accept事件。\n\n下面看一下acceptor的实现，如下所示。\n\npublic class acceptor implements runnable {\n\n    private final selector selector;\n    private final serversocketchannel listensocketchannel;\n\n    public acceptor(selector selector, serversocketchannel listensocketchannel) {\n        this.selector = selector;\n        this.listensocketchannel = listensocketchannel;\n    }\n\n    @override\n    public void run() {\n        try {\n            // 为连接的客户端创建client-socket管道\n            socketchannel clientsocketchannel = listensocketchannel.accept();\n            // 设置为非阻塞\n            clientsocketchannel.configureblocking(false);\n            // read事件的附加器是handler\n            clientsocketchannel.register(selector, selectionkey.op_read,\n                    new handler(clientsocketchannel));\n        } catch (ioexception e) {\n            e.printstacktrace();\n        }\n    }\n\n}\n\n\n在acceptor中就是在服务端创建与客户端通信的client-socket管道，然后注册到多路复用器上并指定监听read事件，同时又因为read事件由handler处理，所以还添加了一个handler作为附加器，当read事件发生时可以获取到作为read事件附加器的handler来处理read事件。\n\n下面看一下handler的实现，如下所示。\n\npublic class handler implements runnable {\n\n    private final socketchannel clientsocketchannel;\n\n    public handler(socketchannel clientsocketchannel) {\n        this.clientsocketchannel = clientsocketchannel;\n    }\n\n    @override\n    public void run() {\n        bytebuffer bytebuffer = bytebuffer.allocate(1024);\n        try {\n            // 读取数据\n            int read = clientsocketchannel.read(bytebuffer);\n            if (read <= 0) {\n                clientsocketchannel.close();\n            } else {\n                system.out.println(new string(bytebuffer.array()));\n            }\n        } catch (ioexception e1) {\n            try {\n                clientsocketchannel.close();\n            } catch (ioexception e2) {\n                e2.printstacktrace();\n            }\n            e1.printstacktrace();\n        }\n    }\n\n}\n\n\n在handler中就是简单的读取数据并打印，当读取数据为空或者发生异常时，需要及时将管道关闭。\n\n最后编写一个主程序将reactor运行起来，如下所示。\n\npublic class mainserver {\n\n    public static void main(string[] args) throws ioexception {\n        thread reactorthread = new thread(new reactor(8080));\n        reactorthread.start();\n    }\n\n}\n\n\n现在来思考一下，单reactor单线程模型有什么优点和缺点。优点其实就是模型简单，实现方便。缺点有两点，如下所示。\n\n 1. 一个reactor同时负责监听accept事件和read事件；\n 2. 只有一个线程在工作，处理效率低，无法利用多核cpu的优势。\n\n但是尽管单reactor单线程模型有上述的缺点，但是著名的缓存中间件redis的服务端，就是使用的单reactor单线程模型，示意图如下。\n\n\n\n那为什么以性能著称的redis会采取单reactor单线程模型呢，其实就是因为redis的操作都在内存中，读写都非常快速，所以单reactor单线程模型也能运行得很流畅，同时还避免了多线程下的各种并发问题。\n\n\n# 2. 单reactor多线程模型\n\n在理解了单reactor单线程模型后，那么肯定就能想到，假如在handler中处理read事件的这个事情能够使用一个线程池来完成，从而就可以实现read事件的处理不会阻塞主线程。而这样的一个模型，其实就是单reactor多线程模型，示意图如下所示。\n\n和单reactor单线程模型唯一的不同，就是在handler中多了一个线程池。\n\n单reactor多线程模型的代码实现，除了handler以外，其余和单reactor单线程模型一摸一样，所以下面就看一下单reactor多线程模型中的handler实现，如下所示。\n\npublic class handler implements runnable {\n\n    private static final threadpoolexecutor threadpool = new threadpoolexecutor(16, 32,\n            60, timeunit.seconds, new linkedblockingqueue<>(200));\n\n    private final socketchannel clientsocketchannel;\n\n    public handler(socketchannel clientsocketchannel) {\n        this.clientsocketchannel = clientsocketchannel;\n    }\n\n    @override\n    public void run() {\n        threadpool.execute(() -> {\n            bytebuffer bytebuffer = bytebuffer.allocate(1024);\n            try {\n                // 读取数据\n                int read = clientsocketchannel.read(bytebuffer);\n                if (read <= 0) {\n                    clientsocketchannel.close();\n                } else {\n                    system.out.println(new string(bytebuffer.array()));\n                }\n                // 睡眠10s，演示任务执行耗时长也不会阻塞处理其它客户端请求\n                locksupport.parknanos(1000 * 1000 * 1000 * 10l);\n            } catch (ioexception e1) {\n                try {\n                    clientsocketchannel.close();\n                } catch (ioexception e2) {\n                    e2.printstacktrace();\n                }\n                e1.printstacktrace();\n            }\n        });\n    }\n\n}\n\n\n其实就是每一个read事件的处理会作为一个任务被扔到线程池中去处理。\n\n单reactor多线程模型虽然解决了只有一个线程的问题，但是可以发现，仍旧是只有一个reactor在同时监听accept事件和read事件。\n\n那么现在思考一下，为什么一个reactor同时监听accept事件和read事件是不好的。其实就是因为通常客户端连接的建立是不频繁的，但是连接建立后数据的收发是频繁的，所以如果能够将监听read事件这个动作拆分出来，让多个子reactor来监听read事件，而原来的主reactor只监听accept事件，那么整体的效率，会进一步提升，而这，就是主从reactor多线程模型。\n\n\n# 3. 主从reactor多线程模型\n\n主从reactor模型中，有一个主reactor，专门监听accept事件，然后有多个从reactor，专门监听read事件，示意图如下所示。\n\n\n\n上述示意图中，一次完整的处理流程可以概括如下。\n\n 1. 主reactor监听到accept事件发生，表示此时有客户端建立连接；\n 2. 主reactor将accept事件分发给acceptor处理；\n 3. acceptor会在服务端创建与客户端通信的client-socket管道，然后注册到从reactor的io多路复用器selector上，并监听read事件；\n 4. 从reactor监听到read事件发生，表示此时客户端数据可读；\n 5. 从reactor将accept事件分发给handler处理，handler处理read事件就会基于client-socket管道完成客户端数据的读取。\n\n下面将基于java语言，实现一个简单的主从reactor多线程模型的服务端，整体代码实现完全符合上述示意图，大家可以进行参照阅读。\n\n首先是主reactor的实现，如下所示。\n\npublic class mainreactor implements runnable {\n\n    private final selector selector;\n\n    public mainreactor(int port) throws ioexception {\n        // 开多路复用器\n        selector = selector.open();\n        // 服务端创建listen-socket管道\n        serversocketchannel listensocketchannel = serversocketchannel.open();\n        // 设置为非阻塞\n        listensocketchannel.configureblocking(false);\n        // 绑定监听端口\n        listensocketchannel.socket().bind(new inetsocketaddress(port));\n        // 将listen-socket管道绑定到主reactor的多路复用器上\n        // 并且主reactor上只会注册listen-socket管道，用于监听accept事件\n        listensocketchannel.register(selector, selectionkey.op_accept,\n                new acceptor(listensocketchannel));\n    }\n\n    @override\n    public void run() {\n        while (!thread.interrupted()) {\n            try {\n                selector.select();\n                set<selectionkey> selectionkeys = selector.selectedkeys();\n                iterator<selectionkey> iterable = selectionkeys.iterator();\n                while (iterable.hasnext()) {\n                    // 对事件进行分发\n                    dispatch(iterable.next());\n                    iterable.remove();\n                }\n            } catch (ioexception e) {\n                e.printstacktrace();\n            }\n            locksupport.parknanos(1000 * 1000 * 1000);\n        }\n    }\n\n    private void dispatch(selectionkey selectionkey) {\n        // 获取事件附加器，只会是acceptor\n        runnable attachment = (runnable) selectionkey.attachment();\n        if (attachment != null) {\n            attachment.run();\n        }\n    }\n\n}\n\n\n主reactor的实现中，还是先创建服务端监听客户端连接的listen-socket管道，然后注册到主reactor的io多路复用器上，并监听accept事件，同时我们现在知道，主reactor的io多路复用器上只会注册listen-socket管道且只会监听accept事件。同样，也添加了一个acceptor作为附加器，那么当发生accept事件时，就能够获取到作为accept事件附加器的acceptor来处理accept事件。\n\n下面是acceptor的实现，如下所示。\n\npublic class acceptor implements runnable {\n\n    // 指定从reactor一共有16个\n    private static final int total_subreactor_num = 16;\n\n    // 服务端的listen-socket管道\n    private final serversocketchannel listensocketchannel;\n\n    // 用于运行从reactor\n    private final threadpoolexecutor threadpool = new threadpoolexecutor(\n            total_subreactor_num, total_subreactor_num * 2,\n            60, timeunit.seconds, new linkedblockingqueue<>(200));\n\n    // 从reactor集合\n    private final list<subreactor> subreactors = new arraylist<>(total_subreactor_num);\n\n    public acceptor(serversocketchannel listensocketchannel) throws ioexception {\n        this.listensocketchannel = listensocketchannel;\n        // 将从reactor初始化出来并运行\n        for (int i = 0; i < total_subreactor_num; i++) {\n            subreactor subreactor = new subreactor(selector.open());\n            subreactors.add(subreactor);\n            threadpool.execute(subreactor);\n        }\n    }\n\n    @override\n    public void run() {\n        try {\n            // 为连接的客户端创建client-socket管道\n            socketchannel clientsocketchannel = listensocketchannel.accept();\n            // 设置为非阻塞\n            clientsocketchannel.configureblocking(false);\n            // 任意选择一个从reactor，让其监听连接的客户端的read事件\n            optional<subreactor> anysubreactor = subreactors.stream().findany();\n            if (anysubreactor.ispresent()) {\n                subreactor subreactor = anysubreactor.get();\n                // 从reactor的多路复用器会阻塞在select()方法上\n                // 这里需要先唤醒多路复用器，立即从select()方法返回\n                subreactor.getselector().wakeup();\n                // 让从reactor负责处理客户端的read事件\n                clientsocketchannel.register(subreactor.getselector(), selectionkey.op_read,\n                        new handler(clientsocketchannel));\n            }\n        } catch (ioexception e) {\n            e.printstacktrace();\n        }\n    }\n\n}\n\n\n首先在acceptor的构造函数中，会将所有从reactor初始化出来，并且每一个从reactor都会持有一个io多路复用器。当一个从reactor创建出来后就会立即运行，此时从reactor的io多路复用器就会开始监听，即阻塞在select() 方法上。\n\n然后在acceptor的主体逻辑中，会为连接的客户端创建client-socket管道，然后从所有从reactor中基于某种策略（随机）选择一个从reactor，并将client-socket管道注册在选择的从reactor的io多路复用器上，有一点需要注意，此时从reactor的io多路复用器可能会阻塞在select() 方法上，所以注册前需要先通过wakeup() 方法进行唤醒。\n\n接下来继续看从reactor的实现，如下所示。\n\npublic class subreactor implements runnable {\n\n    private final selector selector;\n\n    public subreactor(selector selector) {\n        this.selector = selector;\n    }\n\n    @override\n    public void run() {\n        while (!thread.interrupted()) {\n            try {\n                selector.select();\n                set<selectionkey> selectionkeys = selector.selectedkeys();\n                iterator<selectionkey> iterator = selectionkeys.iterator();\n                while (iterator.hasnext()) {\n                    // 对事件进行分发\n                    dispatch(iterator.next());\n                    iterator.remove();\n                }\n            } catch (ioexception e) {\n                e.printstacktrace();\n            }\n            locksupport.parknanos(1000 * 1000 * 1000);\n        }\n    }\n\n    private void dispatch(selectionkey selectionkey) {\n        // 获取事件附加器，只会是handler\n        runnable runnable = (runnable) selectionkey.attachment();\n        if (runnable != null) {\n            runnable.run();\n        }\n    }\n\n    public selector getselector() {\n        return selector;\n    }\n\n}\n\n\n从reactor的实现中，会监听服务端为连接的客户端创建的client-socket管道上的read事件，一旦有read事件发生，就会使用作为附加器的handler来处理read事件。同样，从reactor的io多路复用器上只会注册client-socket管道且只会监听read事件。\n\n然后是handler，因为是多线程模型，所以其实现和第三节中的handler完全一样，下面再贴一下代码。\n\npublic class handler implements runnable {\n\n    private static final threadpoolexecutor threadpool = new threadpoolexecutor(16, 32,\n            60, timeunit.seconds, new linkedblockingqueue<>(200));\n\n    private final socketchannel clientsocketchannel;\n\n    public handler(socketchannel clientsocketchannel) {\n        this.clientsocketchannel = clientsocketchannel;\n    }\n\n    @override\n    public void run() {\n        threadpool.execute(() -> {\n            bytebuffer bytebuffer = bytebuffer.allocate(1024);\n            try {\n                // 读取数据\n                int read = clientsocketchannel.read(bytebuffer);\n                if (read <= 0) {\n                    clientsocketchannel.close();\n                } else {\n                    system.out.println(new string(bytebuffer.array()));\n                }\n                // 睡眠10s，演示任务执行耗时长也不会阻塞处理其它客户端请求\n                locksupport.parknanos(1000 * 1000 * 1000 * 10l);\n            } catch (ioexception e1) {\n                try {\n                    clientsocketchannel.close();\n                } catch (ioexception e2) {\n                    e2.printstacktrace();\n                }\n                e1.printstacktrace();\n            }\n        });\n    }\n\n}\n\n\n最后编写一个主程序将主reactor运行起来，如下所示。\n\npublic class mainserver {\n\n    public static void main(string[] args) throws ioexception {\n        thread mainreactorthread = new thread(new mainreactor(8080));\n        mainreactorthread.start();\n    }\n\n}\n\n\n\n# 总结\n\nreactor模型主要就是监听事件，分发事件和处理事件。其中reactor角色会负责监听事件 和分发事件，handler角色和acceptor角色会负责处理事件。\n\nreactor模型虽然分为：单reactor单线程模型，单reactor多线程模型和主从reactor多线程模型，但是其本质就是nio的实现，是不过套了reactor设计模式的外壳。\n\n在网络通信框架netty中，三种reactor模型都有使用到，所以想要学习netty的精髓，理解reactor模型是必不可少的。\n\n作者：半夏之沫 链接：https://juejin.cn/post/7210375522512666679 来源：稀土掘金",charsets:{cjk:!0},lastUpdated:"2024/01/22, 14:42:01",lastUpdatedTimestamp:1705905721e3},{title:"InnoDB - redo log 和 undo log",frontmatter:{title:"InnoDB - redo log 和 undo log",date:"2023-06-08T21:47:16.000Z",permalink:"/pages/495592/"},regularPath:"/02.%E6%96%87%E7%AB%A0/02.MySQL/15.InnoDB%20-%20redo%20log%20%E5%92%8C%20undo%20log.html",relativePath:"02.文章/02.MySQL/15.InnoDB - redo log 和 undo log.md",key:"v-2e7dd8a7",path:"/pages/495592/",headers:[{level:2,title:"1. redo log",slug:"_1-redo-log",normalizedTitle:"1. redo log",charIndex:35},{level:2,title:"2. undo log",slug:"_2-undo-log",normalizedTitle:"2. undo log",charIndex:895},{level:3,title:"2.1 事务id",slug:"_2-1-事务id",normalizedTitle:"2.1 事务id",charIndex:911},{level:3,title:"2.2 undo日志",slug:"_2-2-undo日志",normalizedTitle:"2.2 undo日志",charIndex:1146},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:1538}],headersStr:"1. redo log 2. undo log 2.1 事务id 2.2 undo日志 3. 总结",content:"# InnoDB - redo log 和 undo log\n\n\n# 1. redo log\n\n我们知道 InnoDB 存储引擎是以页为单位来管理存储空间的，我们进行的增删改查操作其实本质上是在内存中对页的访问。也就是在缓冲中对页的修改。\n\n但是我们又知道：InnoDB引擎支持的事务是有 持久性 这个特性的，持久性是什么呢？\n\n持久性：事务提交后对于MySQL的影响一定会到达数据库并且对数据进行修改。\n\n想一下这个场景：我们执行了一个 delete 操作，在内存中的缓冲池里将对应页数据修改了，但是在持久化到磁盘中之 **前**，MySQL宕机了，磁盘中的数据没修改，但是宕机之后内存中的数据没了。。。这不就违反了持久性吗？\n\n那么如何保证持久性呢？一个很简单的做法：在事务提交之前把该事务所修改的所有页都刷新到磁盘。但是这种做法有问题：\n\n * 刷新一个完整的数据页太浪费了，我们可能仅仅修改了页的某一个字节，现在就要把整个页都刷进磁盘？？？\n\n所以现在需要一个机制，保证不能频繁刷内存到磁盘，也要解决突然宕机的危害。\n\n我们只是想让已经提交了的事务对于数据库中数据所做的修改永久生效，即使后来系统崩溃，再重启后也能把这种修改回复出来。所以我们没有必要每次都把事务修染指过的页都刷新到磁盘中，只需要把修改了哪些东西记录一下就好，比方说某个事务把系统表空间中的第100页中偏移量为1000处的那个字节的值从1改为2，那么我们只需要记录一下：\n\n将0号表空间的100号页面的偏移量为1000出的值更新为2.\n\n这样，即使在 事务提交之后&amp;&amp;内存刷到磁盘之前 系统崩溃了，我们也可以使用redo log恢复更改的数据。\n\n通过上述的描述我们知道**redo log的作用 ：记录了事务对记录的修改。**\n\nredo log的格式如下：\n\n字段            描述\ntype          这个redo log日志的类型\nspace id      表空间id\npage number   页号\ndata          该条redo log具体的内容\n\n\n# 2. undo log\n\n\n# 2.1 事务id\n\n在学习undo log 之前，有必要了解了解一下事务id ：transaction_id。\n\n在行记录中，MySQL自动为我们添加了几个字段：变长字段的长度列表、NULL值列表、记录头信息、row_id、transaction_id、roll_pointer。\n\n\n\n挺好理解的，哪个事务对此条记录做了修改，这个transaction_id就是哪个事务的id。\n\n并不是所有事务都有事务id，进行增删改操作的事务有id，只读的事务没有id。\n\n\n# 2.2 undo日志\n\nundo log又称为回滚日志，就是事务出现问题的时候执行回滚操作。\n\n事务需要保证原子性：一个事务的语句要么全部执行成功，要么全部执行失败。执行成功的情况就不说了，万一执行失败呢？事务中的语句已经对内存中的数据修改了，怎么执行回滚操作呢？\n\n我们可以参考 redo log，把进行的操作记录下来，需要回滚的时候就可以按照记录的操作反方向执行，但是反方向执行又太麻烦了，我们索性记录反方向执行的操作。\n\n * 用户增加 id = 1的记录，我们记录 删除id = 1的语句，回滚的时候直接执行这条语句。\n * 用户删除 id = 1的记录，我们记录id=1的语句的全部字段值，回滚的时候直接执行这条语句。\n * 用户修改 id = 1的记录，我们记录id=1的记录原来的数据，回滚的时候直接执行这条语句。\n\n这样就可以做到事务出现问题后执行回滚操作。\n\n\n# 3. 总结\n\nredo log日志保证持久性\n\nundo log日志保证原子性\n\n可能有小伙伴会说，MySQL不是有三种日志吗？redo log、undo log、bin log\n\n但是标题写的是InnoDB哦，本文主要还是针对InnoDB引擎的日志。binlog是MySQL的 Server 层的，所有引擎都有的~\n\n简而言之，redo log和undo log是InnoDB引擎的，bin log是MySQL Server的。\n\n还是在这里简述一下bin log吧：\n\n> MySQL 在完成一条更新操作后，Server 层会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。\n> \n> bin log 在我们手里常用于数据的同步，例如MySQL的主从、MySQL与Redis数据同步、MySQL与ES数据同步~\n\n‍",normalizedContent:"# innodb - redo log 和 undo log\n\n\n# 1. redo log\n\n我们知道 innodb 存储引擎是以页为单位来管理存储空间的，我们进行的增删改查操作其实本质上是在内存中对页的访问。也就是在缓冲中对页的修改。\n\n但是我们又知道：innodb引擎支持的事务是有 持久性 这个特性的，持久性是什么呢？\n\n持久性：事务提交后对于mysql的影响一定会到达数据库并且对数据进行修改。\n\n想一下这个场景：我们执行了一个 delete 操作，在内存中的缓冲池里将对应页数据修改了，但是在持久化到磁盘中之 **前**，mysql宕机了，磁盘中的数据没修改，但是宕机之后内存中的数据没了。。。这不就违反了持久性吗？\n\n那么如何保证持久性呢？一个很简单的做法：在事务提交之前把该事务所修改的所有页都刷新到磁盘。但是这种做法有问题：\n\n * 刷新一个完整的数据页太浪费了，我们可能仅仅修改了页的某一个字节，现在就要把整个页都刷进磁盘？？？\n\n所以现在需要一个机制，保证不能频繁刷内存到磁盘，也要解决突然宕机的危害。\n\n我们只是想让已经提交了的事务对于数据库中数据所做的修改永久生效，即使后来系统崩溃，再重启后也能把这种修改回复出来。所以我们没有必要每次都把事务修染指过的页都刷新到磁盘中，只需要把修改了哪些东西记录一下就好，比方说某个事务把系统表空间中的第100页中偏移量为1000处的那个字节的值从1改为2，那么我们只需要记录一下：\n\n将0号表空间的100号页面的偏移量为1000出的值更新为2.\n\n这样，即使在 事务提交之后&amp;&amp;内存刷到磁盘之前 系统崩溃了，我们也可以使用redo log恢复更改的数据。\n\n通过上述的描述我们知道**redo log的作用 ：记录了事务对记录的修改。**\n\nredo log的格式如下：\n\n字段            描述\ntype          这个redo log日志的类型\nspace id      表空间id\npage number   页号\ndata          该条redo log具体的内容\n\n\n# 2. undo log\n\n\n# 2.1 事务id\n\n在学习undo log 之前，有必要了解了解一下事务id ：transaction_id。\n\n在行记录中，mysql自动为我们添加了几个字段：变长字段的长度列表、null值列表、记录头信息、row_id、transaction_id、roll_pointer。\n\n\n\n挺好理解的，哪个事务对此条记录做了修改，这个transaction_id就是哪个事务的id。\n\n并不是所有事务都有事务id，进行增删改操作的事务有id，只读的事务没有id。\n\n\n# 2.2 undo日志\n\nundo log又称为回滚日志，就是事务出现问题的时候执行回滚操作。\n\n事务需要保证原子性：一个事务的语句要么全部执行成功，要么全部执行失败。执行成功的情况就不说了，万一执行失败呢？事务中的语句已经对内存中的数据修改了，怎么执行回滚操作呢？\n\n我们可以参考 redo log，把进行的操作记录下来，需要回滚的时候就可以按照记录的操作反方向执行，但是反方向执行又太麻烦了，我们索性记录反方向执行的操作。\n\n * 用户增加 id = 1的记录，我们记录 删除id = 1的语句，回滚的时候直接执行这条语句。\n * 用户删除 id = 1的记录，我们记录id=1的语句的全部字段值，回滚的时候直接执行这条语句。\n * 用户修改 id = 1的记录，我们记录id=1的记录原来的数据，回滚的时候直接执行这条语句。\n\n这样就可以做到事务出现问题后执行回滚操作。\n\n\n# 3. 总结\n\nredo log日志保证持久性\n\nundo log日志保证原子性\n\n可能有小伙伴会说，mysql不是有三种日志吗？redo log、undo log、bin log\n\n但是标题写的是innodb哦，本文主要还是针对innodb引擎的日志。binlog是mysql的 server 层的，所有引擎都有的~\n\n简而言之，redo log和undo log是innodb引擎的，bin log是mysql server的。\n\n还是在这里简述一下bin log吧：\n\n> mysql 在完成一条更新操作后，server 层会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。\n> \n> bin log 在我们手里常用于数据的同步，例如mysql的主从、mysql与redis数据同步、mysql与es数据同步~\n\n‍",charsets:{cjk:!0},lastUpdated:"2023/06/08, 21:54:53",lastUpdatedTimestamp:1686232493e3},{title:"InnoDB - Buffer Pool",frontmatter:{title:"InnoDB - Buffer Pool",date:"2023-06-17T20:35:21.000Z",permalink:"/pages/31e077/"},regularPath:"/02.%E6%96%87%E7%AB%A0/02.MySQL/17.InnoDB%20-%20Buffer%20Pool.html",relativePath:"02.文章/02.MySQL/17.InnoDB - Buffer Pool.md",key:"v-38cc1f4f",path:"/pages/31e077/",headers:[{level:2,title:"1. 什么是Buffer Pool",slug:"_1-什么是buffer-pool",normalizedTitle:"1. 什么是buffer pool",charIndex:2},{level:2,title:"2. Buffer Pool的组成",slug:"_2-buffer-pool的组成",normalizedTitle:"2. buffer pool的组成",charIndex:242},{level:2,title:"3. free链表",slug:"_3-free链表",normalizedTitle:"3. free链表",charIndex:678},{level:2,title:"4. flush链表",slug:"_4-flush链表",normalizedTitle:"4. flush链表",charIndex:1117},{level:2,title:"5. LRU链表",slug:"_5-lru链表",normalizedTitle:"5. lru链表",charIndex:1507},{level:2,title:"6. 总结",slug:"_6-总结",normalizedTitle:"6. 总结",charIndex:3567}],headersStr:"1. 什么是Buffer Pool 2. Buffer Pool的组成 3. free链表 4. flush链表 5. LRU链表 6. 总结",content:"# 1. 什么是Buffer Pool\n\n通过前几篇文章的学习我们大致了解到：对于InnoDB引擎来说，所有的数据都是存在磁盘中，用的时候以页为单位加载到内存中的。 这样就减小了select一条数据还要来回进行磁盘IO的性能损耗。但是加载到内存中后并不是用完就丢了，而是放在缓存中，下次用直接拿就好了。\n\n为了缓存这些页数据，MySQL服务器启动的时候就申请了一片连续的内存，叫做Buffer Pool。它的大小通常是128M，这个值可以设置，如果小于5M会自动设置为5M。\n\n\n# 2. Buffer Pool的组成\n\nBuffer Pool需要缓存从磁盘加载出来的页，磁盘中的页是16k，BufferPool里面页的和磁盘中的页一样大。为了表示区分，接下来将称Buffer Pool中的页为缓存页。\n\n一般来说，为了更好的管理数据，都会给数据添加一些“元数据”、“头信息”之类的描述数据的数据， 例如对象Object的对象头、MySQL的隐藏字段、消息队列中消息的元数据.... 在这里也不意外，InnoDB引擎也对Buffer Pool缓存的页增加了描述信息：控制块。每一个缓存页都有它对应的控制块， 每一个控制块中的信息包括 该页的页号、该页所属的表号、该页在Buffer Pool中的位置、链表节点信息.... 所有控制块的内存大小是相同的（大概是页的8%），控制块和缓存页是一一对应的，他们都存放在Buffer Pool中， 其中控制块被放在缓存页前面，所以在Buffer Pool中，控制块和缓存页对应的空间看起来就跟这样式的：\n\n\n\n\n# 3. free链表\n\n最初启动MySQL时，需要完成Buffer Pool的初始化过程，就是向操作系统申请Buffer Pool的空间，然后将它划分为若干对控制块和缓存页， 但是此时并没有页被缓存到Buffer中（因为还没有select语句），后面随着程序的运行才会不断的有页被放入Buffer中。 但是问题来了：页应该放在Buffer Pool的哪一个位置呢？或者说，怎么知道哪些缓存页是没有用过的？ 难道要挨个遍历缓存页查看它是否为空吗？\n\n这个是很好解决的，我们把所有空闲的缓存页对应的控制块组成一个链表，我们称之为free链表。\n\n当从磁盘加载出一个页并且确定需要缓存它时，在free链表中拿一个控制块，将该页的基本信息记录在控制块中并把控制块从free链表中删除。\n\n那么刚才的图改一下就成了这个样子：\n\n\n\n当我们使用select语句时就会从磁盘中读取页出来，当读取出一页时，会将free链表的第一个控制块填上这个页的信息，然后将它从free链表删除：\n\n\n\n\n# 4. flush链表\n\n缓存虽好，但问题也挺多，例如：脏数据。什么是脏数据？就是你把数据从磁盘中读到内存操作，内存中的数据被修改了但是并没有写入磁盘，造成了同一个数据在内存中和磁盘中不一样。这就是脏数据。\n\n上面说过，MySQL在Buffer中维护了很多个控制块-缓存页，操作一段时间后肯定会出现脏数据，也肯定要往磁盘中同步数据，那么我们怎么知道哪些页是脏数据呢？一个一个遍历？MySQL的设计者肯定不会这么傻。\n\n他们增加了一个链表：flush链表，用来记录脏数据页。所有被写过的页对应的控制块都会被加入这个链表中，等数据同步的时候直接遍历flush链表，通过控制块找到缓存页，将缓存页刷到磁盘中。\n\n那么刚才的图继续完善：\n\n（缓存块1和缓存块6都没有被使用，缓存块13和缓存块45都产生了脏数据）\n\n\n\nfree链表和flush都有一个头节点不存储任何控制块。\n\n\n\n\n# 5. LRU链表\n\n你看到LRU这个词可能会懵逼，但是你大概率学过LRU：Redis的淘汰策略之一，LRU策略。\n\nLRU ：Least Recently Used，最近最少使用。LRU是典型的内存管理算法，它的思想用通俗的话来说就是最近被频繁访问的数据会具备更高的留存，淘汰那些不常被访问的数据。\n\n每当使用到一个数据时，将它放在最前面，删除最后面的数据。设想一个队列，规定它只能从队头进入队尾删除，差不多就是LRU的思想了。\n\n为什么MySQL要使用LRU算法呢？Buffer Pool大小毕竟是有限的，我们要把那些旧的数据从Buffer Pool中移除。\n\n> 那么问题来了，为什么一定要移除旧的呢？不是应该移除最少使用过的吗？\n> \n> 其实可以看一下时间局部性和空间局部性。\n\n先来看一下简单的LRU链表的实现吧：\n\n * 如果该页不在Buffer Pool中，当把该页从磁盘中加载到Buffer Pool的缓存页中时，就把该缓存页对应的控制块放到LRU链表头部。\n * 如果该页已经在Buffer Pool中，就把该页对应的缓存块移动到LRU链表头部。\n\n也就是说，只要用到某个缓存页，就把这个缓存页对应的控制块移动到LRU链表头部，那么尾部就是最近最少使用到的缓存页了。\n\n但是MySQL并没有直接使用上述LRU链表。\n\n因为有两个情况对于这种简单的LRU链表来说特别尴尬：\n\n 1. InnoDB的预读。\n    \n    预读 ：InnoDB认为执行当前的请求可能之后会读取某些页，就提前把这些页加载到Buffer Pool中。根据触发的方式不同，预读又可以分为两类：\n    \n    * 线性预读：\n      \n      如果顺序访问了某个区(extent)的页面数量超过了特定值，就会触发一次异步读取下一个区中全部的页到Buffer Pool中。异步就意味着从磁盘加载这些被预读的页面并不会影响当前工作线程的正常执行。\n    \n    * 随机预读：\n      \n      如果Buffer Pool中已经缓存了某个区的13个连续的页面，不论这些页是顺序读取还是随机读取，都会触发一次随机预读，异步读取本区中所有其他的页加载到缓存。\n    \n    预读本来是好事，如果预读的页被访问到，就可以大大提升效率。可是如果用不到呢？这些预读的页会被放到Buffer Pool的LRU链表的头部，将原来的页挤掉很多，万一预读的页不经常用到，就会出现劣币驱逐良币的现象，大大减小命中率。\n\n 2. 扫描全表\n    \n    有时候我们的SQL语句需要对全表进行扫描，这意味着要将这个表对应的所有页都加载到Buffer Pool中，同样也要放入LRU链表的头部，同样会出现劣币驱逐良币的现象。\n\n总结一下这两种特殊情况吧：有时候会一次扫描到很多使用不到页，会出现劣币驱除良币的现象。\n\n因为有这两种特殊情况的存在，MySQL将LRU链表分为两个部分：\n\n * young区域 ：存储使用频率很高的缓存页\n * old区域 ：存储使用频率不高的缓存页\n\n（有没有很像JVM的新生代和老年代？）\n\n如图所示，缓存页2、45、1处在young区域，为经常使用到的缓存页。\n\n缓存页13、6处在old区域，为使用频率不高的缓存页。\n\n\n\n需要注意的是，MySQL按照比例给young区域和old区域分配大小，一般来说是 63 ：37，随着程序的运行，一个控制块可能从young区域跳到old区域，也可能从old区域跳到young区域。\n\n有了这个划分为young和old区域的LRU链表后，MySQL就可以解决我们刚才的问题了：\n\n 1. 针对预读：\n    \n    预读的主要危害：预读出来的缓存页可能后续就不访问。\n    \n    优化：当磁盘上的某个页面在首次加载到Buffer Pool中时，优先将缓存页对应的控制块加入到old区域的头部，这样针对预读到Buffer Pool却不进行后续访问的缓存页就会逐渐从old区域逐出，而不会影响young区域中比较经常使用道到的缓存页\n\n 2. 针对全表扫描：\n    \n    全表扫描的危害：在进行全表扫描时，虽然首次被加载到Buffer Pool的页被放在了old区域的头部，但是后续会被马上访问到，每次进行访问的时候又会将其放到young区域的头部，这样仍会影响原本就经常访问到的缓存页。\n    \n    优化：全表扫描的执行频率非常低，（毕竟谁也不会没事就在那写select * from user），所以MySQL规定，在对某个处在old区域的缓存页第一访问时就在它对应的控制块中记录下来这个访问时间，如果后续的访问时间与第一次的访问时间隔的时间很短，大概率就是全表扫描，就不把它移动到young区域的头部。否则就把它移动到young区域。\n\n当然，MySQL的LRU比上述描述的还要复杂得多，不过在复杂了我也不会了~~~~\n\n\n# 6. 总结\n\n 1. 内存与磁盘之间进行交互，有必要设置一个缓存。\n\n 2. Buffer Pool本质上是内存中的一块连续空间\n\n 3. Buffer Pool的组成 ：控制块、缓存页。\n\n 4. InnoDB引擎使用了很多链表来管理Buffer Pool：\n    \n    * free链表 ：记录所有未使用的缓存页\n    * flush链表 ：记录所有脏缓存页\n    * LRU链表 ：用于淘汰缓存页，分为old和young两个区域。",normalizedContent:"# 1. 什么是buffer pool\n\n通过前几篇文章的学习我们大致了解到：对于innodb引擎来说，所有的数据都是存在磁盘中，用的时候以页为单位加载到内存中的。 这样就减小了select一条数据还要来回进行磁盘io的性能损耗。但是加载到内存中后并不是用完就丢了，而是放在缓存中，下次用直接拿就好了。\n\n为了缓存这些页数据，mysql服务器启动的时候就申请了一片连续的内存，叫做buffer pool。它的大小通常是128m，这个值可以设置，如果小于5m会自动设置为5m。\n\n\n# 2. buffer pool的组成\n\nbuffer pool需要缓存从磁盘加载出来的页，磁盘中的页是16k，bufferpool里面页的和磁盘中的页一样大。为了表示区分，接下来将称buffer pool中的页为缓存页。\n\n一般来说，为了更好的管理数据，都会给数据添加一些“元数据”、“头信息”之类的描述数据的数据， 例如对象object的对象头、mysql的隐藏字段、消息队列中消息的元数据.... 在这里也不意外，innodb引擎也对buffer pool缓存的页增加了描述信息：控制块。每一个缓存页都有它对应的控制块， 每一个控制块中的信息包括 该页的页号、该页所属的表号、该页在buffer pool中的位置、链表节点信息.... 所有控制块的内存大小是相同的（大概是页的8%），控制块和缓存页是一一对应的，他们都存放在buffer pool中， 其中控制块被放在缓存页前面，所以在buffer pool中，控制块和缓存页对应的空间看起来就跟这样式的：\n\n\n\n\n# 3. free链表\n\n最初启动mysql时，需要完成buffer pool的初始化过程，就是向操作系统申请buffer pool的空间，然后将它划分为若干对控制块和缓存页， 但是此时并没有页被缓存到buffer中（因为还没有select语句），后面随着程序的运行才会不断的有页被放入buffer中。 但是问题来了：页应该放在buffer pool的哪一个位置呢？或者说，怎么知道哪些缓存页是没有用过的？ 难道要挨个遍历缓存页查看它是否为空吗？\n\n这个是很好解决的，我们把所有空闲的缓存页对应的控制块组成一个链表，我们称之为free链表。\n\n当从磁盘加载出一个页并且确定需要缓存它时，在free链表中拿一个控制块，将该页的基本信息记录在控制块中并把控制块从free链表中删除。\n\n那么刚才的图改一下就成了这个样子：\n\n\n\n当我们使用select语句时就会从磁盘中读取页出来，当读取出一页时，会将free链表的第一个控制块填上这个页的信息，然后将它从free链表删除：\n\n\n\n\n# 4. flush链表\n\n缓存虽好，但问题也挺多，例如：脏数据。什么是脏数据？就是你把数据从磁盘中读到内存操作，内存中的数据被修改了但是并没有写入磁盘，造成了同一个数据在内存中和磁盘中不一样。这就是脏数据。\n\n上面说过，mysql在buffer中维护了很多个控制块-缓存页，操作一段时间后肯定会出现脏数据，也肯定要往磁盘中同步数据，那么我们怎么知道哪些页是脏数据呢？一个一个遍历？mysql的设计者肯定不会这么傻。\n\n他们增加了一个链表：flush链表，用来记录脏数据页。所有被写过的页对应的控制块都会被加入这个链表中，等数据同步的时候直接遍历flush链表，通过控制块找到缓存页，将缓存页刷到磁盘中。\n\n那么刚才的图继续完善：\n\n（缓存块1和缓存块6都没有被使用，缓存块13和缓存块45都产生了脏数据）\n\n\n\nfree链表和flush都有一个头节点不存储任何控制块。\n\n\n\n\n# 5. lru链表\n\n你看到lru这个词可能会懵逼，但是你大概率学过lru：redis的淘汰策略之一，lru策略。\n\nlru ：least recently used，最近最少使用。lru是典型的内存管理算法，它的思想用通俗的话来说就是最近被频繁访问的数据会具备更高的留存，淘汰那些不常被访问的数据。\n\n每当使用到一个数据时，将它放在最前面，删除最后面的数据。设想一个队列，规定它只能从队头进入队尾删除，差不多就是lru的思想了。\n\n为什么mysql要使用lru算法呢？buffer pool大小毕竟是有限的，我们要把那些旧的数据从buffer pool中移除。\n\n> 那么问题来了，为什么一定要移除旧的呢？不是应该移除最少使用过的吗？\n> \n> 其实可以看一下时间局部性和空间局部性。\n\n先来看一下简单的lru链表的实现吧：\n\n * 如果该页不在buffer pool中，当把该页从磁盘中加载到buffer pool的缓存页中时，就把该缓存页对应的控制块放到lru链表头部。\n * 如果该页已经在buffer pool中，就把该页对应的缓存块移动到lru链表头部。\n\n也就是说，只要用到某个缓存页，就把这个缓存页对应的控制块移动到lru链表头部，那么尾部就是最近最少使用到的缓存页了。\n\n但是mysql并没有直接使用上述lru链表。\n\n因为有两个情况对于这种简单的lru链表来说特别尴尬：\n\n 1. innodb的预读。\n    \n    预读 ：innodb认为执行当前的请求可能之后会读取某些页，就提前把这些页加载到buffer pool中。根据触发的方式不同，预读又可以分为两类：\n    \n    * 线性预读：\n      \n      如果顺序访问了某个区(extent)的页面数量超过了特定值，就会触发一次异步读取下一个区中全部的页到buffer pool中。异步就意味着从磁盘加载这些被预读的页面并不会影响当前工作线程的正常执行。\n    \n    * 随机预读：\n      \n      如果buffer pool中已经缓存了某个区的13个连续的页面，不论这些页是顺序读取还是随机读取，都会触发一次随机预读，异步读取本区中所有其他的页加载到缓存。\n    \n    预读本来是好事，如果预读的页被访问到，就可以大大提升效率。可是如果用不到呢？这些预读的页会被放到buffer pool的lru链表的头部，将原来的页挤掉很多，万一预读的页不经常用到，就会出现劣币驱逐良币的现象，大大减小命中率。\n\n 2. 扫描全表\n    \n    有时候我们的sql语句需要对全表进行扫描，这意味着要将这个表对应的所有页都加载到buffer pool中，同样也要放入lru链表的头部，同样会出现劣币驱逐良币的现象。\n\n总结一下这两种特殊情况吧：有时候会一次扫描到很多使用不到页，会出现劣币驱除良币的现象。\n\n因为有这两种特殊情况的存在，mysql将lru链表分为两个部分：\n\n * young区域 ：存储使用频率很高的缓存页\n * old区域 ：存储使用频率不高的缓存页\n\n（有没有很像jvm的新生代和老年代？）\n\n如图所示，缓存页2、45、1处在young区域，为经常使用到的缓存页。\n\n缓存页13、6处在old区域，为使用频率不高的缓存页。\n\n\n\n需要注意的是，mysql按照比例给young区域和old区域分配大小，一般来说是 63 ：37，随着程序的运行，一个控制块可能从young区域跳到old区域，也可能从old区域跳到young区域。\n\n有了这个划分为young和old区域的lru链表后，mysql就可以解决我们刚才的问题了：\n\n 1. 针对预读：\n    \n    预读的主要危害：预读出来的缓存页可能后续就不访问。\n    \n    优化：当磁盘上的某个页面在首次加载到buffer pool中时，优先将缓存页对应的控制块加入到old区域的头部，这样针对预读到buffer pool却不进行后续访问的缓存页就会逐渐从old区域逐出，而不会影响young区域中比较经常使用道到的缓存页\n\n 2. 针对全表扫描：\n    \n    全表扫描的危害：在进行全表扫描时，虽然首次被加载到buffer pool的页被放在了old区域的头部，但是后续会被马上访问到，每次进行访问的时候又会将其放到young区域的头部，这样仍会影响原本就经常访问到的缓存页。\n    \n    优化：全表扫描的执行频率非常低，（毕竟谁也不会没事就在那写select * from user），所以mysql规定，在对某个处在old区域的缓存页第一访问时就在它对应的控制块中记录下来这个访问时间，如果后续的访问时间与第一次的访问时间隔的时间很短，大概率就是全表扫描，就不把它移动到young区域的头部。否则就把它移动到young区域。\n\n当然，mysql的lru比上述描述的还要复杂得多，不过在复杂了我也不会了~~~~\n\n\n# 6. 总结\n\n 1. 内存与磁盘之间进行交互，有必要设置一个缓存。\n\n 2. buffer pool本质上是内存中的一块连续空间\n\n 3. buffer pool的组成 ：控制块、缓存页。\n\n 4. innodb引擎使用了很多链表来管理buffer pool：\n    \n    * free链表 ：记录所有未使用的缓存页\n    * flush链表 ：记录所有脏缓存页\n    * lru链表 ：用于淘汰缓存页，分为old和young两个区域。",charsets:{cjk:!0},lastUpdated:"2023/08/02, 23:56:18",lastUpdatedTimestamp:1690991778e3},{title:"Redis 持久化机制",frontmatter:{title:"Redis 持久化机制",date:"2023-06-11T12:25:09.000Z",permalink:"/pages/4e0b96/"},regularPath:"/02.%E6%96%87%E7%AB%A0/10.Redis/20.Redis%20%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6.html",relativePath:"02.文章/10.Redis/20.Redis 持久化机制.md",key:"v-c8c76474",path:"/pages/4e0b96/",headers:[{level:2,title:"1. 概述",slug:"_1-概述",normalizedTitle:"1. 概述",charIndex:18},{level:2,title:"2. RDB",slug:"_2-rdb",normalizedTitle:"2. rdb",charIndex:554},{level:3,title:"2.1 手动快照",slug:"_2-1-手动快照",normalizedTitle:"2.1 手动快照",charIndex:750},{level:3,title:"2.2 自动快照",slug:"_2-2-自动快照",normalizedTitle:"2.2 自动快照",charIndex:1011},{level:2,title:"3. AOF",slug:"_3-aof",normalizedTitle:"3. aof",charIndex:1510},{level:3,title:"3.1 AOF 机制",slug:"_3-1-aof-机制",normalizedTitle:"3.1 aof 机制",charIndex:1636},{level:3,title:"3.2 AOF 文件的重写",slug:"_3-2-aof-文件的重写",normalizedTitle:"3.2 aof 文件的重写",charIndex:2347},{level:2,title:"4. 混合型持久化",slug:"_4-混合型持久化",normalizedTitle:"4. 混合型持久化",charIndex:3418},{level:2,title:"5. 总结",slug:"_5-总结",normalizedTitle:"5. 总结",charIndex:3900}],headersStr:"1. 概述 2. RDB 2.1 手动快照 2.2 自动快照 3. AOF 3.1 AOF 机制 3.2 AOF 文件的重写 4. 混合型持久化 5. 总结",content:"# Redis 持久化机制\n\n\n# 1. 概述\n\nRedis 为了保证性能，会将所有数据放在内存中，那么万一 Redis 宕机，数据岂不是全部丢失了？\n\n不要怕，Redis 自然想到了这一点，它提供了三种持久化机制将内存中的数据持久化到磁盘中。\n\n 1. RDB\n    \n    快照方式持久化（snapshot），快照在 Linux 就已经学过，保存所有数据的状态，下次开机直接按照这个状态恢复。\n    \n    因为保存的快照是以.rdb 结尾的文件，故称此方式为 RDB 持久化方式。\n\n 2. AOF\n    \n    （append only file）只追加日志文件，记录 Redis 所有写命令，下次开机将这些命令全部执行，即可恢复数据。\n\n 3. 混合型持久化\n    \n    RDB 虽然快，但是数据丢失问题较为严重；AOF 虽然能保证数据安全，但是执行所有命令需要很长时间。\n    \n    所以 Redis4.x 以后，将两种方式结合，RDB 文件的内容放在 AOF 文件中，以.aof 文件的形式存储。在恢复数据时，先加载 rdb 的内容，再执行 aof 的内容。缺点是两种格式混合在一起难以阅读。\n\n==需要注意的是，不论是哪种方式，都无法保证数据的绝对安全。==\n\n\n# 2. RDB\n\nsnapshot 想必大家已经不陌生了，Linux 已经接触过这个机制：==保存现在的状态，随时准备恢复。==\n\n拍摄的快照以**.rdb** 的形式保存在磁盘中。\n\n假如在 Redis 宕机之前拍摄的快照为：\n\n\n\n那么下次开机就可以即将这两个数据恢复。\n\nRedis 提供了两种拍摄快照的方式 ：自动、手动。其中手动拍摄快照有两个命令：save、bgsave\n\n\n\n\n# 2.1 手动快照\n\n 1. save\n    \n    由主进程完成快照的拍摄，持久化过程中其他命令阻塞。\n    \n    \n\n 2. bgsave\n    \n    background save，主线程 fork 出一个子进程，由这个子进程完成持久化。\n    \n    \n\n> fork ：\n> \n> 当一个进程创建子进程时，底层的操作系统会创建该进程的副本，在类 unix 系统中创建子进程的操作会进行优化：在刚开始的时候，父子进程共享相同内存，直到父进程/子进程对内存进行写操作后结束共享，各用各的。\n\n\n# 2.2 自动快照\n\n在 redis.conf 配置文件中存在，参数如下:（版本不同，默认参数不同）\n\n#   * After 3600 seconds (an hour) if at least 1 key changed\n#   * After 300 seconds (5 minutes) if at least 100 keys changed\n#   * After 60 seconds if at least 10000 keys changed\n\n# save 3600 1\n# save 300 100\n# save 60 10000\n\n\n解释 ：\n\n1h 内有一个键被改变会触发快照拍摄。\n\n5mins 内有 100 个键被改变会触发快照拍摄。\n\n1min 内有 10000 个键被改变会触发快照拍摄。\n\n这些快照的拍摄方式都是 bgsave。\n\n优点 ：\n\n * rdb 文件的加载速度特别快，远超 aof。\n\n * 使用单独子进程来进行持久化，主进程不会进行任何 IO 操作。\n\n缺点 ：\n\n * 容易造成数据丢失。\n\n * 每次拍快照都要创建子进程，浪费资源.。\n\n\n# 3. AOF\n\n这种机制可以将所有客户端执行的写命令记录到日志文件中，AOF 持久化会将被执行的写命令写到 AOF 文件末尾，以此来记录数据发生变化的全过程，因此只要 Redis 从头到尾执行一遍 AOF 文件中的命令，就可以恢复之前的数据。\n\n\n# 3.1 AOF 机制\n\nRDB 是间隔一段时间进行持久化，如果持久化之间的时间内发生故障，会出现数据丢失。而 AOF 持久化方式能很好的解决 RDB 持久化方式造成的数据丢失，AOF 持久化到硬盘中的并不是内存中的数据快照，而是将所有写命令记录到日志中。\n\nAOF 能做到最多丢失 1s 内的数据，甚至不丢失数据。\n\nRedis 提供了三种 AOF 策略 ：\n\n * appendfsync always\n   \n   每执行一次写命令，都对 aof 文件续写。\n\n * appendfsync everysec\n   \n   每一秒进行一次 aof 文件续写，这一秒的写命令都会记录。\n\n * appendfsync no\n   \n   并不是不开启，而是将 aof 续写的时机交给操作系统管理，操作系统开心了就续写，不开心就不续写。\n\n这三种策略其实也就是控制aof缓存写入日志的时机罢了，什么？aof缓存是什么呢？往下看\n\nAOF文件记录的具体过程 ：先将命令写入内存，再将命令写入日志。\n\n 1. 命令追加 ：将新执行的命令追加到 aof缓存 中\n 2. 文件写入 ：将 aof缓存 中的数据写到aof文件中 这一步需要进行系统调用，看过操作系统的都知道，系统调用需要触发函数，比如read、write，redis用的是 fsync(), 这个命令怎么触发？ 就是上面配置的AOF策略，always、everysec、no。\n\n所以说，AOF的三种策略其实就是控制执行 fsync命令 的时机。\n\n优点 ：\n\n * 保证数据丢失风险降到最低\n\n缺点 ：\n\n * aof 文件的体积会很大，同时加载速度很慢\n\n\n# 3.2 AOF 文件的重写\n\n随着 Redis 在线上运行的时间越来越久，客户端执行的命令越来越多，AOF 的文件也会越来越大。\n\n当我们执行 100 次 set name 张三 ，其中 99 次都是多余的，因为想要恢复只要执行一次 set name 张三 就行了。为了压缩 AOF 文件的体积，Redis 提供了 AOF文件重写机制 。\n\n有两种方式触发 AOF 的重写机制：\n\n * 手动：执行 bgrewrite ，background rewrite，不会阻塞 Redis\n\n * 自动：在配置文件中进行配置\n   \n   auto-aof-rewrite-percentage 100\n   auto-aof-rewrite-min-size 64mb\n   \n   \n   当 AOF 文件体积大于 64MB，或者比上一次重写之后体积大了 100%，会自动触发。\n   \n   如果重写过于频繁，可以考虑将 auto-aof-rewrite-percentage 设置为更大。\n\n‍\n\n> AOF 重写机制并没有根据现有的AOF文件重写，而是是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。\n\n为什么不使用原有的 AOF 文件呢?\n\n如果在原有的AOF文件基础上重新，但凡AOF文件重写过程中宕机或者失败，原有的AOF文件就被污染了，可能无法用于数据恢复。所以保留原有的AOF文件是保底策略。\n\n重写的具体过程\n\n重写使用到了写时复制\n\n写时复制 ：父进程 fork 出一个子进程，两个进程共用同一块内存区域（二者的虚拟内存虽然不相同，但是虚拟内存对应的物理内存是一样的），主进程是可以正常处理读请求的，但是如果出现写请求，且操作的数据是已经存在的，⭐操作系统就会将这个数据在父进程的物理内存复制一份交给子进程。注意，这里复制的物理内存是 修改了哪个数据就只复制这个数据的物理内存，而不是将父进程的所有物理内存都复制一份。\n\nRedis 设置了一个 AOF 重写缓冲区。 在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」。\n\n当子进程完成AOF的重写后，会通知父进程，父进程操作AOF 重写缓冲区，将追加的数据写入AOF文件（这个步骤是父进程进行的）\n\n需要注意的是 ：RDB快照和AOF重写的过程都用到了写时复制。\n\n\n# 4. 混合型持久化\n\n因为 RDB 虽然加载快但是存在数据丢失，AOF 数据安全但是加载缓慢，Redis 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 RDB 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量 的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。Redis 重启的时候，可以先加载 RDB 的内容，然后再重放增量 AOF 日志，就可以完全替代之前的 AOF 全量文件重放，恢复效率因此大幅得到提升（混合型持久化最终生成的文件后缀是 .aof ，可以通过 redis.conf 文件中 aof-use-rdb-preamble yes 配置开启）。\n\n * 优点：\n   \n   结合了 RDB 和 AOF 的优点，使得数据恢复的效率大幅提升\n\n * 缺点：\n   \n   兼容性不好，Redis-4.x 新增，虽然最终的文件也是 .aof 格式的文件，但在 4.0 之前版本都不识别该 aof 文件，同时由于前部分是 RDB 格式，阅读性较差。\n\n\n# 5. 总结\n\n",normalizedContent:"# redis 持久化机制\n\n\n# 1. 概述\n\nredis 为了保证性能，会将所有数据放在内存中，那么万一 redis 宕机，数据岂不是全部丢失了？\n\n不要怕，redis 自然想到了这一点，它提供了三种持久化机制将内存中的数据持久化到磁盘中。\n\n 1. rdb\n    \n    快照方式持久化（snapshot），快照在 linux 就已经学过，保存所有数据的状态，下次开机直接按照这个状态恢复。\n    \n    因为保存的快照是以.rdb 结尾的文件，故称此方式为 rdb 持久化方式。\n\n 2. aof\n    \n    （append only file）只追加日志文件，记录 redis 所有写命令，下次开机将这些命令全部执行，即可恢复数据。\n\n 3. 混合型持久化\n    \n    rdb 虽然快，但是数据丢失问题较为严重；aof 虽然能保证数据安全，但是执行所有命令需要很长时间。\n    \n    所以 redis4.x 以后，将两种方式结合，rdb 文件的内容放在 aof 文件中，以.aof 文件的形式存储。在恢复数据时，先加载 rdb 的内容，再执行 aof 的内容。缺点是两种格式混合在一起难以阅读。\n\n==需要注意的是，不论是哪种方式，都无法保证数据的绝对安全。==\n\n\n# 2. rdb\n\nsnapshot 想必大家已经不陌生了，linux 已经接触过这个机制：==保存现在的状态，随时准备恢复。==\n\n拍摄的快照以**.rdb** 的形式保存在磁盘中。\n\n假如在 redis 宕机之前拍摄的快照为：\n\n\n\n那么下次开机就可以即将这两个数据恢复。\n\nredis 提供了两种拍摄快照的方式 ：自动、手动。其中手动拍摄快照有两个命令：save、bgsave\n\n\n\n\n# 2.1 手动快照\n\n 1. save\n    \n    由主进程完成快照的拍摄，持久化过程中其他命令阻塞。\n    \n    \n\n 2. bgsave\n    \n    background save，主线程 fork 出一个子进程，由这个子进程完成持久化。\n    \n    \n\n> fork ：\n> \n> 当一个进程创建子进程时，底层的操作系统会创建该进程的副本，在类 unix 系统中创建子进程的操作会进行优化：在刚开始的时候，父子进程共享相同内存，直到父进程/子进程对内存进行写操作后结束共享，各用各的。\n\n\n# 2.2 自动快照\n\n在 redis.conf 配置文件中存在，参数如下:（版本不同，默认参数不同）\n\n#   * after 3600 seconds (an hour) if at least 1 key changed\n#   * after 300 seconds (5 minutes) if at least 100 keys changed\n#   * after 60 seconds if at least 10000 keys changed\n\n# save 3600 1\n# save 300 100\n# save 60 10000\n\n\n解释 ：\n\n1h 内有一个键被改变会触发快照拍摄。\n\n5mins 内有 100 个键被改变会触发快照拍摄。\n\n1min 内有 10000 个键被改变会触发快照拍摄。\n\n这些快照的拍摄方式都是 bgsave。\n\n优点 ：\n\n * rdb 文件的加载速度特别快，远超 aof。\n\n * 使用单独子进程来进行持久化，主进程不会进行任何 io 操作。\n\n缺点 ：\n\n * 容易造成数据丢失。\n\n * 每次拍快照都要创建子进程，浪费资源.。\n\n\n# 3. aof\n\n这种机制可以将所有客户端执行的写命令记录到日志文件中，aof 持久化会将被执行的写命令写到 aof 文件末尾，以此来记录数据发生变化的全过程，因此只要 redis 从头到尾执行一遍 aof 文件中的命令，就可以恢复之前的数据。\n\n\n# 3.1 aof 机制\n\nrdb 是间隔一段时间进行持久化，如果持久化之间的时间内发生故障，会出现数据丢失。而 aof 持久化方式能很好的解决 rdb 持久化方式造成的数据丢失，aof 持久化到硬盘中的并不是内存中的数据快照，而是将所有写命令记录到日志中。\n\naof 能做到最多丢失 1s 内的数据，甚至不丢失数据。\n\nredis 提供了三种 aof 策略 ：\n\n * appendfsync always\n   \n   每执行一次写命令，都对 aof 文件续写。\n\n * appendfsync everysec\n   \n   每一秒进行一次 aof 文件续写，这一秒的写命令都会记录。\n\n * appendfsync no\n   \n   并不是不开启，而是将 aof 续写的时机交给操作系统管理，操作系统开心了就续写，不开心就不续写。\n\n这三种策略其实也就是控制aof缓存写入日志的时机罢了，什么？aof缓存是什么呢？往下看\n\naof文件记录的具体过程 ：先将命令写入内存，再将命令写入日志。\n\n 1. 命令追加 ：将新执行的命令追加到 aof缓存 中\n 2. 文件写入 ：将 aof缓存 中的数据写到aof文件中 这一步需要进行系统调用，看过操作系统的都知道，系统调用需要触发函数，比如read、write，redis用的是 fsync(), 这个命令怎么触发？ 就是上面配置的aof策略，always、everysec、no。\n\n所以说，aof的三种策略其实就是控制执行 fsync命令 的时机。\n\n优点 ：\n\n * 保证数据丢失风险降到最低\n\n缺点 ：\n\n * aof 文件的体积会很大，同时加载速度很慢\n\n\n# 3.2 aof 文件的重写\n\n随着 redis 在线上运行的时间越来越久，客户端执行的命令越来越多，aof 的文件也会越来越大。\n\n当我们执行 100 次 set name 张三 ，其中 99 次都是多余的，因为想要恢复只要执行一次 set name 张三 就行了。为了压缩 aof 文件的体积，redis 提供了 aof文件重写机制 。\n\n有两种方式触发 aof 的重写机制：\n\n * 手动：执行 bgrewrite ，background rewrite，不会阻塞 redis\n\n * 自动：在配置文件中进行配置\n   \n   auto-aof-rewrite-percentage 100\n   auto-aof-rewrite-min-size 64mb\n   \n   \n   当 aof 文件体积大于 64mb，或者比上一次重写之后体积大了 100%，会自动触发。\n   \n   如果重写过于频繁，可以考虑将 auto-aof-rewrite-percentage 设置为更大。\n\n‍\n\n> aof 重写机制并没有根据现有的aof文件重写，而是是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 aof 文件」，等到全部记录完后，就将新的 aof 文件替换掉现有的 aof 文件。\n\n为什么不使用原有的 aof 文件呢?\n\n如果在原有的aof文件基础上重新，但凡aof文件重写过程中宕机或者失败，原有的aof文件就被污染了，可能无法用于数据恢复。所以保留原有的aof文件是保底策略。\n\n重写的具体过程\n\n重写使用到了写时复制\n\n写时复制 ：父进程 fork 出一个子进程，两个进程共用同一块内存区域（二者的虚拟内存虽然不相同，但是虚拟内存对应的物理内存是一样的），主进程是可以正常处理读请求的，但是如果出现写请求，且操作的数据是已经存在的，⭐操作系统就会将这个数据在父进程的物理内存复制一份交给子进程。注意，这里复制的物理内存是 修改了哪个数据就只复制这个数据的物理内存，而不是将父进程的所有物理内存都复制一份。\n\nredis 设置了一个 aof 重写缓冲区。 在重写 aof 期间，当 redis 执行完一个写命令之后，它会同时将这个写命令写入到 「aof 缓冲区」和 「aof 重写缓冲区」。\n\n当子进程完成aof的重写后，会通知父进程，父进程操作aof 重写缓冲区，将追加的数据写入aof文件（这个步骤是父进程进行的）\n\n需要注意的是 ：rdb快照和aof重写的过程都用到了写时复制。\n\n\n# 4. 混合型持久化\n\n因为 rdb 虽然加载快但是存在数据丢失，aof 数据安全但是加载缓慢，redis 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 rdb 文件的内容和增量的 aof 日志文件存在一起。这里的 aof 日志不再是全量 的日志，而是自持久化开始到持久化结束的这段时间发生的增量 aof 日志，通常这部分 aof 日志很小。redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 aof 日志，就可以完全替代之前的 aof 全量文件重放，恢复效率因此大幅得到提升（混合型持久化最终生成的文件后缀是 .aof ，可以通过 redis.conf 文件中 aof-use-rdb-preamble yes 配置开启）。\n\n * 优点：\n   \n   结合了 rdb 和 aof 的优点，使得数据恢复的效率大幅提升\n\n * 缺点：\n   \n   兼容性不好，redis-4.x 新增，虽然最终的文件也是 .aof 格式的文件，但在 4.0 之前版本都不识别该 aof 文件，同时由于前部分是 rdb 格式，阅读性较差。\n\n\n# 5. 总结\n\n",charsets:{cjk:!0},lastUpdated:"2023/10/31, 23:05:02",lastUpdatedTimestamp:1698764702e3},{title:"InnoDB - 锁",frontmatter:{title:"InnoDB - 锁",date:"2023-06-08T21:47:16.000Z",permalink:"/pages/2e3013/"},regularPath:"/02.%E6%96%87%E7%AB%A0/02.MySQL/20.InnoDB%20-%20%E9%94%81.html",relativePath:"02.文章/02.MySQL/20.InnoDB - 锁.md",key:"v-1dab0d7c",path:"/pages/2e3013/",headers:[{level:2,title:"1. 锁的概念",slug:"_1-锁的概念",normalizedTitle:"1. 锁的概念",charIndex:12},{level:2,title:"2. 锁的分类",slug:"_2-锁的分类",normalizedTitle:"2. 锁的分类",charIndex:73},{level:3,title:"2.1 共享锁",slug:"_2-1-共享锁",normalizedTitle:"2.1 共享锁",charIndex:149},{level:3,title:"2.2 排他锁",slug:"_2-2-排他锁",normalizedTitle:"2.2 排他锁",charIndex:355},{level:3,title:"2.3 全局锁",slug:"_2-3-全局锁",normalizedTitle:"2.3 全局锁",charIndex:587},{level:3,title:"2.4 表级锁",slug:"_2-4-表级锁",normalizedTitle:"2.4 表级锁",charIndex:710},{level:3,title:"2.5 行级锁",slug:"_2-5-行级锁",normalizedTitle:"2.5 行级锁",charIndex:1108},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:1415}],headersStr:"1. 锁的概念 2. 锁的分类 2.1 共享锁 2.2 排他锁 2.3 全局锁 2.4 表级锁 2.5 行级锁 3. 总结",content:"# 12. 锁\n\n\n# 1. 锁的概念\n\n锁机制是==数据库为了保证数据的一致性，在使用共享资源时并发访问变得有序所设计的一种规则。==\n\n\n# 2. 锁的分类\n\n在MySQL中可以按照功能与范围分类 ，\n\n按照功能分类 ：共享锁、排他锁。\n\n按照范围分类 ：全局锁、表级锁、行级锁。\n\n\n\n\n# 2.1 共享锁\n\n共享锁又称读锁 (shared lock)，即共享读。\n\n读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。当如果事务对读锁进行修改操作，很可能会造成死锁。\n\n> 如果事务A给数据加了共享读锁 ：\n> \n> 事务A能读，不能写。\n> \n> 事务B能读，不能写。\n> \n> 即 ：共享数据的读权限，关闭数据的写权限。\n\n\n# 2.2 排他锁\n\n排他锁又称写锁（exclusive lock），即独占写。\n若某个事物对某一行加上了排他锁，只能这个事务对其进行读写，在此事务结束之前，其他事务不能对其进行加任何锁，其他进程可以读取,不能进行写操作，需等待其释放。 排它锁是悲观锁的一种实现，在上面悲观锁也介绍过。\n\n> 如果事务A给数据加了排他锁 ：\n> \n> 事务A可以读，可以写。\n> \n> 事务B不能读，不能写。\n> \n> 即 ：独占数据读写操作的权限。排斥其他事务的读写操作。\n\n\n# 2.3 全局锁\n\n全局锁就是对整个数据库实例加锁，加锁后整个实例处于只读状态，后续的增删改、修改表这些操作的事务提交都会被阻塞。\n\n-- 全局锁，整个数据库的所有表都加上锁。\nflush tables with read locks;\n\n\n\n# 2.4 表级锁\n\n表级锁就是锁住某张表。分为 表锁、元数据锁、意向锁。\n\n 1. 表锁\n    \n    表锁分为读锁和写锁，遵循上述 共享读，独占写。\n\n 2. 元数据锁\n    \n    维护表结构的数据一致性。在访问一张表时会自动加元数据锁，如果某一张表存在未提交的事务，那么就不能修改表的结构。\n\n 3. 意向锁\n    \n    如果某张表的某一行加了行锁，这个表是不能加表锁的，但是如何判断呢？遍历整张表查看是否有行锁？太麻烦。\n    \n    意向锁存在于表中，在加表锁之前查看这张表是否有意向锁，如果有意向锁，代表这张表某些字段加了行锁，就不能加表锁了。\n    \n    > 意向共享锁 与 表共享锁 兼容，与表排他锁互斥。\n    > \n    > 意向排他锁 与 表共享、表排他都互斥。\n    > \n    > 即 ：共享锁与共享锁兼容，排他锁与任何锁都互斥。\n\n\n# 2.5 行级锁\n\n锁住对应的行。应用在Innodb引擎中，MyISAM不支持。（InnoDB与MyISAM的三大区别之一）。\n\nInnoDB的数据是基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加锁。行锁锁的是索引项。\n\n主要分为 ：行锁、间隙锁、临键锁\n\n 1. 行锁\n    \n    锁定单行记录，防止其他事务对此进行update、delete操作。\n\n 2. 间隙锁\n    \n    锁定索引记录间隙（不包含该记录），确保索引记录间隙不变，防止其他事务在间隙中插入数据。\n\n 3. 临键锁\n    \n    临键锁是行锁和间隙锁的组合，同时锁住索引记录以及记录前面的间隙。\n\n\n# 3. 总结\n\n在本篇中就对MySQL 的锁机制有了大概认知，从锁的概念、分类，到共享锁、排他锁、全局锁、表级锁、行级锁的介绍，相信本章看下来，足够让你对MySQL 锁机制有一个系统化的认知，那么我们下篇再见。",normalizedContent:"# 12. 锁\n\n\n# 1. 锁的概念\n\n锁机制是==数据库为了保证数据的一致性，在使用共享资源时并发访问变得有序所设计的一种规则。==\n\n\n# 2. 锁的分类\n\n在mysql中可以按照功能与范围分类 ，\n\n按照功能分类 ：共享锁、排他锁。\n\n按照范围分类 ：全局锁、表级锁、行级锁。\n\n\n\n\n# 2.1 共享锁\n\n共享锁又称读锁 (shared lock)，即共享读。\n\n读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。当如果事务对读锁进行修改操作，很可能会造成死锁。\n\n> 如果事务a给数据加了共享读锁 ：\n> \n> 事务a能读，不能写。\n> \n> 事务b能读，不能写。\n> \n> 即 ：共享数据的读权限，关闭数据的写权限。\n\n\n# 2.2 排他锁\n\n排他锁又称写锁（exclusive lock），即独占写。\n若某个事物对某一行加上了排他锁，只能这个事务对其进行读写，在此事务结束之前，其他事务不能对其进行加任何锁，其他进程可以读取,不能进行写操作，需等待其释放。 排它锁是悲观锁的一种实现，在上面悲观锁也介绍过。\n\n> 如果事务a给数据加了排他锁 ：\n> \n> 事务a可以读，可以写。\n> \n> 事务b不能读，不能写。\n> \n> 即 ：独占数据读写操作的权限。排斥其他事务的读写操作。\n\n\n# 2.3 全局锁\n\n全局锁就是对整个数据库实例加锁，加锁后整个实例处于只读状态，后续的增删改、修改表这些操作的事务提交都会被阻塞。\n\n-- 全局锁，整个数据库的所有表都加上锁。\nflush tables with read locks;\n\n\n\n# 2.4 表级锁\n\n表级锁就是锁住某张表。分为 表锁、元数据锁、意向锁。\n\n 1. 表锁\n    \n    表锁分为读锁和写锁，遵循上述 共享读，独占写。\n\n 2. 元数据锁\n    \n    维护表结构的数据一致性。在访问一张表时会自动加元数据锁，如果某一张表存在未提交的事务，那么就不能修改表的结构。\n\n 3. 意向锁\n    \n    如果某张表的某一行加了行锁，这个表是不能加表锁的，但是如何判断呢？遍历整张表查看是否有行锁？太麻烦。\n    \n    意向锁存在于表中，在加表锁之前查看这张表是否有意向锁，如果有意向锁，代表这张表某些字段加了行锁，就不能加表锁了。\n    \n    > 意向共享锁 与 表共享锁 兼容，与表排他锁互斥。\n    > \n    > 意向排他锁 与 表共享、表排他都互斥。\n    > \n    > 即 ：共享锁与共享锁兼容，排他锁与任何锁都互斥。\n\n\n# 2.5 行级锁\n\n锁住对应的行。应用在innodb引擎中，myisam不支持。（innodb与myisam的三大区别之一）。\n\ninnodb的数据是基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加锁。行锁锁的是索引项。\n\n主要分为 ：行锁、间隙锁、临键锁\n\n 1. 行锁\n    \n    锁定单行记录，防止其他事务对此进行update、delete操作。\n\n 2. 间隙锁\n    \n    锁定索引记录间隙（不包含该记录），确保索引记录间隙不变，防止其他事务在间隙中插入数据。\n\n 3. 临键锁\n    \n    临键锁是行锁和间隙锁的组合，同时锁住索引记录以及记录前面的间隙。\n\n\n# 3. 总结\n\n在本篇中就对mysql 的锁机制有了大概认知，从锁的概念、分类，到共享锁、排他锁、全局锁、表级锁、行级锁的介绍，相信本章看下来，足够让你对mysql 锁机制有一个系统化的认知，那么我们下篇再见。",charsets:{cjk:!0},lastUpdated:"2023/06/08, 21:54:53",lastUpdatedTimestamp:1686232493e3},{title:"InnoDB - B+树索引",frontmatter:{title:"InnoDB - B+树索引",date:"2023-06-08T21:47:16.000Z",permalink:"/pages/26e2d2/"},regularPath:"/02.%E6%96%87%E7%AB%A0/02.MySQL/10.InnoDB%20-%20B+%E6%A0%91%E7%B4%A2%E5%BC%95.html",relativePath:"02.文章/02.MySQL/10.InnoDB - B+树索引.md",key:"v-4a5e1071",path:"/pages/26e2d2/",headers:[{level:2,title:"1. 没有索引的查找",slug:"_1-没有索引的查找",normalizedTitle:"1. 没有索引的查找",charIndex:58},{level:3,title:"1.1 在一页中查找",slug:"_1-1-在一页中查找",normalizedTitle:"1.1 在一页中查找",charIndex:73},{level:3,title:"1.2 在很多页中查找",slug:"_1-2-在很多页中查找",normalizedTitle:"1.2 在很多页中查找",charIndex:345},{level:2,title:"2. 索引",slug:"_2-索引",normalizedTitle:"2. 索引",charIndex:545},{level:3,title:"2.1 一个简单的索引方案",slug:"_2-1-一个简单的索引方案",normalizedTitle:"2.1 一个简单的索引方案",charIndex:936},{level:3,title:"2.2 InnoDB的索引方案",slug:"_2-2-innodb的索引方案",normalizedTitle:"2.2 innodb的索引方案",charIndex:2035},{level:3,title:"2.3 聚簇索引",slug:"_2-3-聚簇索引",normalizedTitle:"2.3 聚簇索引",charIndex:3305},{level:3,title:"2.4 二级索引",slug:"_2-4-二级索引",normalizedTitle:"2.4 二级索引",charIndex:3447},{level:2,title:"3. 回表",slug:"_3-回表",normalizedTitle:"3. 回表",charIndex:3752},{level:3,title:"3.1 回表的代价",slug:"_3-1-回表的代价",normalizedTitle:"3.1 回表的代价",charIndex:3762},{level:3,title:"3.2 覆盖索引",slug:"_3-2-覆盖索引",normalizedTitle:"3.2 覆盖索引",charIndex:4649},{level:2,title:"4. B+树索引的使用",slug:"_4-b-树索引的使用",normalizedTitle:"4. b+树索引的使用",charIndex:4824},{level:3,title:"4.1 索引的代价",slug:"_4-1-索引的代价",normalizedTitle:"4.1 索引的代价",charIndex:4969},{level:3,title:"4.2 索引失效的场景",slug:"_4-2-索引失效的场景",normalizedTitle:"4.2 索引失效的场景",charIndex:5256},{level:4,title:"4.2.1 最左前缀匹配",slug:"_4-2-1-最左前缀匹配",normalizedTitle:"4.2.1 最左前缀匹配",charIndex:5896},{level:4,title:"4.2.2 模糊查询",slug:"_4-2-2-模糊查询",normalizedTitle:"4.2.2 模糊查询",charIndex:6901},{level:4,title:"4.2.4 运算与函数",slug:"_4-2-4-运算与函数",normalizedTitle:"4.2.4 运算与函数",charIndex:7423},{level:4,title:"4.2.5 or",slug:"_4-2-5-or",normalizedTitle:"4.2.5 or",charIndex:7552},{level:2,title:"5. 如何挑选索引",slug:"_5-如何挑选索引",normalizedTitle:"5. 如何挑选索引",charIndex:7644},{level:3,title:"5.1 常用于搜索、排序、分组的列",slug:"_5-1-常用于搜索、排序、分组的列",normalizedTitle:"5.1 常用于搜索、排序、分组的列",charIndex:7658},{level:3,title:"5.2 考虑列的基数",slug:"_5-2-考虑列的基数",normalizedTitle:"5.2 考虑列的基数",charIndex:7861},{level:3,title:"5.3 主键插入顺序",slug:"_5-3-主键插入顺序",normalizedTitle:"5.3 主键插入顺序",charIndex:8025}],headersStr:"1. 没有索引的查找 1.1 在一页中查找 1.2 在很多页中查找 2. 索引 2.1 一个简单的索引方案 2.2 InnoDB的索引方案 2.3 聚簇索引 2.4 二级索引 3. 回表 3.1 回表的代价 3.2 覆盖索引 4. B+树索引的使用 4.1 索引的代价 4.2 索引失效的场景 4.2.1 最左前缀匹配 4.2.2 模糊查询 4.2.4 运算与函数 4.2.5 or 5. 如何挑选索引 5.1 常用于搜索、排序、分组的列 5.2 考虑列的基数 5.3 主键插入顺序",content:"# InnoDB - B+树索引\n\n在阅读前你需要了解的前置知识： InnoDB行格式 InnoDB页结构\n\n\n# 1. 没有索引的查找\n\n\n# 1.1 在一页中查找\n\n本篇的主题是索引，在正式介绍索引之前，我们需要了解一下没有索引的查找（下面只针对精确查找，并且现在一页中讨论）\n\n如果一条SQL是这样的：\n\nselect * from user where 列名 = 'xxx';\n\n\n对于精确查找，又分为两种情况：主键查找和非主键查找。\n\n * 主键查找：在页目录的槽位中进行二分法查找，找到差值最小的槽后去User Record区域寻找对应的组，在组中就可以查找到相应数据。\n * 非主键查找：由于槽位中并不会记录非主键的信息，只能从最小记录挨个遍历寻找符合条件的行数据。\n\n\n# 1.2 在很多页中查找\n\n上述情况只是针对只有一页数据的情况，大部分情况下我们的数据是很多的，往往有很多页来存储数据，那么查询的步骤就变成这样：\n\n * 遍历所有页\n * 在每一页中使用二分法查找数据。\n\n在没有索引的情况下，不论是根据主键或者其他字段进行查找，我们无法快速定位到数据所在的页，所以只能沿着页组成的双向链表挨个遍历，遍历所有页的效率是非常低的，这时候索引的优势就体现出来了。\n\n\n# 2. 索引\n\n为了故事的顺利发展，我们先创建一个表：\n\ncreate table indx_demo (   \n\tc1 int ,   \n\tc2 int ,   \n\tc3 char(1),   \n\tprimary key(c1) \n) row_format = compact;\n\n\n这个新建的 index_demo 表中有2个 int 类型的列，1个char类型的列，c1为主键，而且规定了这个表使用Compact行格式来存储数据。\n\n为了方便理解，我们简化行格式，只保留本篇文章用到的：\n\n * record_type ：此条记录的类型\n   \n   * 0：普通记录\n   * 1：B+树非叶子节点记录\n   * 2：最小记录\n   * 3：最大记录\n\n * next_record：此条记录的下一条记录\n\n于是我们向 index_demo 表中插入几条数据后：\n\n\n\n\n# 2.1 一个简单的索引方案\n\n先说哈，MySQL用的不是这个小标题中的索引方案，只是我们在尝试使用自己的想法来设计一个索引方案。\n\n我们在根据某个搜索条件查询时为什么要遍历所有的数据页呢？因为各个页的数据没有规律，或者说我们并不知道我们的搜索条件匹配哪些页中的记录，所以不得不遍历所有的数据页。\n\n如果我们想要快速定位到需要查找的记录在哪个数据页该怎么办？还记得我们为了根据主键值快速定位一条记录在页中的位置而设立的目录吗？我们也可以借鉴这个思想：目录\n\n这个目录必须做到以下功能：\n\n 1. 下一个数据页中的第一条数据的主键值必须大于上一个数据页中最后一条数据的主键值，这样才能用二分法。\n 2. 给页建立目录，这样才能获得快速到达页\n\n（假设一页只能存储3条用户记录）\n\n我们向其中插入三条数据：\n\n\n\n这一页共有三条数据，id分别为1、2、5.\n\n当我们继续向表中插入一条id = 4的数据，这个页已经满了，所以MySQL会创建新的页来存储数据。\n\n\n\n为什么新分配的页的编号是24而不是11呢？其实MySQL并没有规定页码必须按照顺序，只要两个页之间有指针相连组成一个双向链表就行了。\n\n页10中最大用户记录的id为5，页24中最小记录的id为4，这就不符合下一个数据页中用户记录的主键值大于该页中用户记录的主键值的要求。\n\n我们想要页24的最小主键值大于页10的最大主键值，这时就需要将5移动到24，将4移动到10。\n\n这个过程表明了在对页的记录进行增删改的时候，MySQL会通过一些操作，例如记录移动、页的增加/删除来维持：下一个数据页中的主键值永远比上一个数据页中的主键值大。这个过程可以称为：页分裂。\n\n页分裂是非常消耗资源的，所以MySQL建议我们给一个表创建一个无意义且自增的主键。避免老是发生页分裂。\n\n第一条我们已经满足了：下一个数据页中的主键值必须大于上一个数据页中的主键值，这样才能用二分法。\n\n下面来看第二个：给页建立目录\n\n站在页的内部，我们将数据进行分组，给各个组建立了目录，加快对于数据的查询。\n\n现在我们将站在页的外部，（也就是表的角度）给页建立目录，加快找到目标页的速度。\n\n先向这张表中多插入几条数据：\n\n\n\n现在共有4个页，每个页有3条用户记录。\n\n因为这些16KB的页在物理存储上很可能并不挨着，所以如果想从这么多页中根据主键值快速定位某些记录所在的页，我们可以根据 主键值-页码 生成一个目录，这样就可以根据主键值定位页码了。每一个页对应一个目录项，每个目录项包含：页码、页码对应的页中数据的最小主键值。\n\n于是，一个索引雏形就出现了：\n\n\n\n\n# 2.2 InnoDB的索引方案\n\n上面小节的标题是”一个简单的索引方案“，是因为它只是一个雏形，还具有很多不完备的地方。它具有以下几个缺点：\n\n 1. InnoDB是使用页作为管理存储空间的基本单位，也就是最多能保证16KB的连续存储空间，而随着表中记录的增多，需要非常大的连续的存储空间，这显然是不现实的。\n 2. 我们经常会对数据进行增删改，假设我们把24页中的数据全都删除了，那么24页也就没有了存在的必要，那么对应的目录项也就没有了存在的必要，这牵扯到页、目录项的移动，牵一发而动全身\n\n所以如何灵活的管理目录项是个问题，MySQL设计者当然想出了解决这个问题的方案：目录项同样使用页进行存储。\n\n他们复用了存储用户数据的页来存储目录项（也就是索引）。我们可以区别的称呼其为：用户记录、索引记录（目录项记录）。\n\n那么如何区分一条记录是用户记录还是索引记录呢？record_type属性。record_type各个取值代表的意思：\n\n * 0 ：用户记录\n * 1 ：目录项记录（索引记录）\n * 2 ：最小记录\n * 3 ：最大记录\n\n我们将上述图完善一下就是：\n\n\n\n这张图你有没有感觉像什么数据结构？B+树！\n\n从图中我们可以看出：\n\n * 叶子节点存储主键以及数据，数据的record_type为0\n * 非叶子节点只存储主键+页目录，数据的record_type为1\n * 每一层的节点（每一个节点即一页）使用双向链表连接。\n\n于是当我们查询一条记录时可以分为两步：\n\n 1. 确定 目录项记录 页：根据主键，使用二分法确定这个记录大概处在哪个页\n 2. 确定 记录在哪个组：根据页目录，使用二分法的槽位确定这个记录在哪个组，进而从组中找到该数据。\n\n从头到尾都是二分法。\n\n需要注意的是：我们一般用一个顶点来存储目录项记录的页。于是上面那张图的最终版为：\n\n\n\n更像B+树了~\n\n假如一个页可以有1000个子页（也就是一页中有1000条记录），一层是一个页，第二层就可以有1000页，第三层就可以有1000 * 1000 页，每一页有1000条数据，那么第三层可以有 1000 * 1000 * 1000 条数据，所以我们的数据绝大多数只有两~三层B+树。\n\n想起之前背的面试题：\n\n相比于二叉树，B+树的层级更低...(阿巴阿巴阿巴)\n\n现在知道到底为什么了吧。\n\n但是现在还有一个问题：\n\n如果我们为 age 创建了一个二级索引，那么在B+树的非叶子节点中的记录就是：age对应页码。但是age是很容易重复的，13这个age有可能对应很多个页码，进而出现了这种情况：age=13对应了 54、32、15这三页，再插入一条age=13的数据，这条数据该往哪个页中插入呢？\n\n为了让新插入记录能找到自己在那个页里，我们需要在记录中再添加一个唯一字段，什么字段适合做这个唯一索引呢？主键啊。\n\n所以对于二级索引的内节点的目录项记录的内容实际上是由三个部分构成的\n\n * 字段值\n * 字段对应的主键值\n * 页码\n\n\n# 2.3 聚簇索引\n\nInnoDB的B+树索引也可以大致分为这两类：聚簇索引和二级索引。\n\n（只有主键会建立一颗聚簇索引B+树，不管是唯一索引还是联合索引巴拉巴拉这些其他的索引都是二级索引）\n\n上述图片描述的是聚簇索引，叶子节点中存储的是 主键->数据 。（学过的大概都知道）\n\n\n# 2.4 二级索引\n\n二级索引的叶子节点中存储的是 字段值 -> 主键。\n\n如果查询二级索引，拿到主键后还需要去聚簇索引的B+树中通过主键拿到全部数据。这也被称为回表查询。\n\n联合索引：\n\n联合索引就是很多个字段一起共用同一颗B+树。\n\n假如为 id、name、age建立联合索引 idx_id_name_age，那么它们三个字段就会使用同一颗B+树。\n\n通过刚才的学习，我们知道B+树是按照一定顺序存储数据的，也就是有序的，聚簇索引按照主键排序，那么联合索引呢？\n\n对于 idx_id_name_age 这个联合索引来说，顺序：按照id排序，id相同再按照name排序，name相同再按照age排序。\n\n\n# 3. 回表\n\n\n# 3.1 回表的代价\n\n之前对于回表这个词都是一带而过，下面详细说一下。\n\n假如对于 name、birthday、phone_num建立了一个联合索引：idx_name_birthday_phone_number。\n\n对于以下SQL语句：\n\nselect * from person_info where name > 'xiaoming' and name < 'zengyi';\n\n\n在使用联合索引 idx_name_birthday_phone_number时可以分为这两步：\n\n * 从索引 idx_name_birthday_phone_number 中的B+树取出值在 xiaoming ~ zengyi 的数据。\n * 由于索引只有 name birthday phone_number 这三个字段，而查询列表中想要的是 *，所以会拿着主键id去聚簇索引中拿全部记录。\n\n由于索引 idx_name_birthday 对应的B+树的记录会首先按照name列的值进行排序，所以值在 xiaoming ~ zengyi 之间的记录在磁盘中的存储时是相连的，有可能就集中分布在同一页中，我们可以直接沿着链表将数据读取出来，这个过程称为顺序IO。但是根据name拿到的id并不相连，虽然聚簇索引中的id是顺序的，但是我们根据 name 拿到的id不相连，所以只能去不同的页去拿数据，这种读取方式被称为随机IO。一般情况下，顺序IO比随机IO快得多，所以这个SQL语句的两步其实是这样的：\n\n * 会用到两个索引：联合(二级)索引和聚簇索引\n * 访问二级索引时使用顺序IO，访问聚簇索引时使用随机IO。\n\n需要回表的记录越多，使用二级索引的性能就越低。甚至某些查询宁愿用全表扫描也不用二级索引。\n\n例如刚才那个SQL查出的记录占到表中总记录的９０％时，真的不如直接全表扫描。\n\n那么什么时候使用索引，什么时候全表扫描呢？这是查询优化器需要做的事。\n\n查询优化器会根据一条ＳＱＬ走了哪些索引占用了多少性能来计算分数，最后使用分数最低的那个SQL或者直接全表扫描。\n\n\n# 3.2 覆盖索引\n\n为了减少回表带来的性能损耗，MySQL更建议：查询列表尽量只包含索引列。\n\nselect　name, birthday, phone_number  \nfrom person_info \nwhere name > 'xiaoming' and name < 'zengyi';\n\n\n只要不让它回表，就不会有回表的坏处啦~\n\n\n# 4. B+树索引的使用\n\n前面两节详细描述了B+树的结构，温故：\n\n * 每一个索引都对应一个B+树，B+树的节点是页。非叶子节点存储的是目录，叶子节点存储的是数据（聚簇索引和二级索引不同）\n * B+树的叶子节点（页）按照双向链表连接，页的内部，即数据，按照单链表顺序连接。\n\n\n\n\n# 4.1 索引的代价\n\n在介绍更好的使用索引前肯定要知道 为什么要更好的使用索引？因为索引也有缺点啊~\n\n * 空间上的代价 ：这个是显而易见的，每建立一个索引，空间中就多一颗B+树，B+树的每一个节点都是一页，一页16K，当然很占空间喽。\n * 时间上的代价 ：索引优化了查询操作，毕竟使用了二分查找。但是在增删改操作时，不仅需要修改数据页，还需要修改索引页。（不仅要修改叶子节点，又要修改非叶子节点）。时不时还会伴随着页分裂、页回收、记录移动的操作，这些都是对时间的消耗。\n\n所以，一张表上索引建立的越多，就会占用越多的存储空间，在对数据增删改时的性能就会更差。\n\n\n# 4.2 索引失效的场景\n\n这个知识点想必大家面试题都背烂了，那么你知道\n\n * 为什么不符合最左前缀匹配原则，索引就会失效吗？\n * 为什么使用 '%xxx'，索引就会失效吗\n\n下面来看一下为什么。\n\n我们建立一张表，以便后续用到：\n\nCREATE TABLE person_info(     \n    id INT NOT NULL auto_increment,     \n    name VARCHAR(100) NOT NULL,     \n    birthday DATE NOT NULL,     \n    phone_number CHAR(11) NOT NULL,     \n    country varchar(100) NOT NULL,     \n    PRIMARY KEY (id),     \n    KEY idx_name_birthday_phone_number (name, birthday, phone_number) \n);\n\n\n这张表中共有5个字段，其中id字段自动生成一颗聚簇索引的B+树，name、birthday、number这三个字段共用一颗B+树。\n\n等等，在继续向下看之前，你需要回顾一下：\n\n对于联合索引 idx_name_birthday_phone_number，排序的规则为：先按照 name 排序，name 相同再按照 birthday 排序，birthday相同再按照number 排序。\n\n# 4.2.1 最左前缀匹配\n\n最左前缀匹配相比大家都知道，对于一个联合索引，如果有一个字段没有走索引，那么它后面的所有字段都不会走索引。\n\n出现这种情况的原因就是联合索引的排序规则，刚才说过，排序规则是按照左边的列排序，左边的列相同再按照右边的列排序。\n\n现在来看一下这几种情况：\n\n 1. select * from person_info where name = 'xiaoming' and birthday = '2000-01-01';\n    \n    这个会走索引吗？会，MySQL会在联合索引的B+树中找到 xiaoming 所在的页，再找它所在的组，最后确定第一个name为xiaoming的地方，再根据已经排好序的 birthday 进行顺序查找，直至找到目标。（拿到该目标的主键后去聚簇索引中回表查询）\n\n 2. select * from person_info where birthday = '2000-01-01';\n    \n    这个会走索引吗？不会，因为birthday所在的索引首先按照name进行排序，再按照birthday排序。都不按birthday排序了，怎么走索引？\n\n 3. select * from person_info where name < 'xiaoming' and name > 'xiaohong' and birthday = '2002-01-01';\n    \n    这个会走几个索引？一个name的索引，为什么呢？我们根据name走了索引之后获得了一个范围值，那么这个范围之可能如下所示：\n    \n    xiaohong 1998-03-12\n    \n    xiaohong 2002-01-01\n    \n    xiaohong 2005-08-09\n    \n    xiaoming 2001-10-02\n    \n    xiaoming 2002-09-13\n    \n    可以看到，虽然按照name排好序了，但是birthday并没有顺序可言，也就无法走索引，只能先拿到主键id，去聚簇索引中拿到对应数据后再判断一下这些数据的birthday是否为 2002-01-01。\n    \n    不仅仅是等值匹配、范围匹配会使用最左前缀匹配，分组操作也会使用最左前缀匹配原则，所以分组时也要注意哦。\n\n# 4.2.2 模糊查询\n\n在进行模糊查询时，'xx%'和'x%x' 都不会失效，而'%xxx'就会导致索引失效。\n\n为啥？前两个最起码第一个为x，MySQL可以在索引中找到第一个字符为x的数据，这样即使不能最终确定有哪些数据也能筛选掉不少的数据了。\n\n但是给我个 '%xx' 是什么意思？第一个 '%' 你想让我怎么匹配怎么排序？肯定走不了索引啊~\n\n4.2.3 排序\n\n排序会出现什么问题呢？\n\nMySQL规定：对于使用联合索引的场景，要求各个排序列的排序顺序是一致的，也就是要各个列要么全部降序，要么全部升序。\n\n为什么呢？\n\n假如有一下SQL语句：\n\nselect * from person_info  order by name asc, birthday desc limit 10;\n\n\n这句sql的作用：\n\n * 先从索引的最左边确定 name 列最小的值，然后从name列的最右边那条记录从右向左找10条(因为要求是birthday降序)\n * 如果此name列不足10条，那么就要去下一个name列中重复上述操作。\n\n这样非常麻烦，而且不能高效利用索引，所以MySQL就规定 使用联合索引的各个排序顺序都必须是一致的。\n\n# 4.2.4 运算与函数\n\n要想使用索引进行排序操作，必须保证索引列是以单独列的形式出现，而不是修饰过的形式。\n\n因为where 条件字段类型与实际表中字段类型不匹配时，MySQL会进行隐式的类型转换，而类型转换会用到内置函数，导致在查询时没有走索引。\n\n# 4.2.5 or\n\n我们有时候会用到or，select * from user where age = 18 or age = 20;\n\nor左右的字段必须都加索引才会生效。\n\n\n# 5. 如何挑选索引\n\n\n# 5.1 常用于搜索、排序、分组的列\n\n为常用于搜索、排序、分组的列创建索引，也就是说，只为出现在 where 子句中的列创建索引，出现在查询列表中的就没必要了（因为回表后自然能查出来）。\n\n下面这一句，我们为name创建索引，而不为birthday和country创建索引。\n\nselect birthday, country from person_info where name='xxx';\n\n\n# 5.2 考虑列的基数\n\n什么是基数？一张表有10000条数据，它的每一列的基数一样吗？\n\n不是，如果是id字段，10000条数据可能id都不一样。如果是age呢？如果是分数呢？\n\n所以基数是指不相同的个数，我们应该尽量挑选基数大的列建立索引。\n\n（像那些性别、状态就不要创建索引，但是如果经常用于分组的话也可以考虑）。\n\n\n# 5.3 主键插入顺序\n\n主键插入顺序尽量递增，并且尽量不要让主键变更。所以主键尽量设置为无意义且自增的。防止页分裂、记录重排序....造成的性能损耗。\n\n‍",normalizedContent:"# innodb - b+树索引\n\n在阅读前你需要了解的前置知识： innodb行格式 innodb页结构\n\n\n# 1. 没有索引的查找\n\n\n# 1.1 在一页中查找\n\n本篇的主题是索引，在正式介绍索引之前，我们需要了解一下没有索引的查找（下面只针对精确查找，并且现在一页中讨论）\n\n如果一条sql是这样的：\n\nselect * from user where 列名 = 'xxx';\n\n\n对于精确查找，又分为两种情况：主键查找和非主键查找。\n\n * 主键查找：在页目录的槽位中进行二分法查找，找到差值最小的槽后去user record区域寻找对应的组，在组中就可以查找到相应数据。\n * 非主键查找：由于槽位中并不会记录非主键的信息，只能从最小记录挨个遍历寻找符合条件的行数据。\n\n\n# 1.2 在很多页中查找\n\n上述情况只是针对只有一页数据的情况，大部分情况下我们的数据是很多的，往往有很多页来存储数据，那么查询的步骤就变成这样：\n\n * 遍历所有页\n * 在每一页中使用二分法查找数据。\n\n在没有索引的情况下，不论是根据主键或者其他字段进行查找，我们无法快速定位到数据所在的页，所以只能沿着页组成的双向链表挨个遍历，遍历所有页的效率是非常低的，这时候索引的优势就体现出来了。\n\n\n# 2. 索引\n\n为了故事的顺利发展，我们先创建一个表：\n\ncreate table indx_demo (   \n\tc1 int ,   \n\tc2 int ,   \n\tc3 char(1),   \n\tprimary key(c1) \n) row_format = compact;\n\n\n这个新建的 index_demo 表中有2个 int 类型的列，1个char类型的列，c1为主键，而且规定了这个表使用compact行格式来存储数据。\n\n为了方便理解，我们简化行格式，只保留本篇文章用到的：\n\n * record_type ：此条记录的类型\n   \n   * 0：普通记录\n   * 1：b+树非叶子节点记录\n   * 2：最小记录\n   * 3：最大记录\n\n * next_record：此条记录的下一条记录\n\n于是我们向 index_demo 表中插入几条数据后：\n\n\n\n\n# 2.1 一个简单的索引方案\n\n先说哈，mysql用的不是这个小标题中的索引方案，只是我们在尝试使用自己的想法来设计一个索引方案。\n\n我们在根据某个搜索条件查询时为什么要遍历所有的数据页呢？因为各个页的数据没有规律，或者说我们并不知道我们的搜索条件匹配哪些页中的记录，所以不得不遍历所有的数据页。\n\n如果我们想要快速定位到需要查找的记录在哪个数据页该怎么办？还记得我们为了根据主键值快速定位一条记录在页中的位置而设立的目录吗？我们也可以借鉴这个思想：目录\n\n这个目录必须做到以下功能：\n\n 1. 下一个数据页中的第一条数据的主键值必须大于上一个数据页中最后一条数据的主键值，这样才能用二分法。\n 2. 给页建立目录，这样才能获得快速到达页\n\n（假设一页只能存储3条用户记录）\n\n我们向其中插入三条数据：\n\n\n\n这一页共有三条数据，id分别为1、2、5.\n\n当我们继续向表中插入一条id = 4的数据，这个页已经满了，所以mysql会创建新的页来存储数据。\n\n\n\n为什么新分配的页的编号是24而不是11呢？其实mysql并没有规定页码必须按照顺序，只要两个页之间有指针相连组成一个双向链表就行了。\n\n页10中最大用户记录的id为5，页24中最小记录的id为4，这就不符合下一个数据页中用户记录的主键值大于该页中用户记录的主键值的要求。\n\n我们想要页24的最小主键值大于页10的最大主键值，这时就需要将5移动到24，将4移动到10。\n\n这个过程表明了在对页的记录进行增删改的时候，mysql会通过一些操作，例如记录移动、页的增加/删除来维持：下一个数据页中的主键值永远比上一个数据页中的主键值大。这个过程可以称为：页分裂。\n\n页分裂是非常消耗资源的，所以mysql建议我们给一个表创建一个无意义且自增的主键。避免老是发生页分裂。\n\n第一条我们已经满足了：下一个数据页中的主键值必须大于上一个数据页中的主键值，这样才能用二分法。\n\n下面来看第二个：给页建立目录\n\n站在页的内部，我们将数据进行分组，给各个组建立了目录，加快对于数据的查询。\n\n现在我们将站在页的外部，（也就是表的角度）给页建立目录，加快找到目标页的速度。\n\n先向这张表中多插入几条数据：\n\n\n\n现在共有4个页，每个页有3条用户记录。\n\n因为这些16kb的页在物理存储上很可能并不挨着，所以如果想从这么多页中根据主键值快速定位某些记录所在的页，我们可以根据 主键值-页码 生成一个目录，这样就可以根据主键值定位页码了。每一个页对应一个目录项，每个目录项包含：页码、页码对应的页中数据的最小主键值。\n\n于是，一个索引雏形就出现了：\n\n\n\n\n# 2.2 innodb的索引方案\n\n上面小节的标题是”一个简单的索引方案“，是因为它只是一个雏形，还具有很多不完备的地方。它具有以下几个缺点：\n\n 1. innodb是使用页作为管理存储空间的基本单位，也就是最多能保证16kb的连续存储空间，而随着表中记录的增多，需要非常大的连续的存储空间，这显然是不现实的。\n 2. 我们经常会对数据进行增删改，假设我们把24页中的数据全都删除了，那么24页也就没有了存在的必要，那么对应的目录项也就没有了存在的必要，这牵扯到页、目录项的移动，牵一发而动全身\n\n所以如何灵活的管理目录项是个问题，mysql设计者当然想出了解决这个问题的方案：目录项同样使用页进行存储。\n\n他们复用了存储用户数据的页来存储目录项（也就是索引）。我们可以区别的称呼其为：用户记录、索引记录（目录项记录）。\n\n那么如何区分一条记录是用户记录还是索引记录呢？record_type属性。record_type各个取值代表的意思：\n\n * 0 ：用户记录\n * 1 ：目录项记录（索引记录）\n * 2 ：最小记录\n * 3 ：最大记录\n\n我们将上述图完善一下就是：\n\n\n\n这张图你有没有感觉像什么数据结构？b+树！\n\n从图中我们可以看出：\n\n * 叶子节点存储主键以及数据，数据的record_type为0\n * 非叶子节点只存储主键+页目录，数据的record_type为1\n * 每一层的节点（每一个节点即一页）使用双向链表连接。\n\n于是当我们查询一条记录时可以分为两步：\n\n 1. 确定 目录项记录 页：根据主键，使用二分法确定这个记录大概处在哪个页\n 2. 确定 记录在哪个组：根据页目录，使用二分法的槽位确定这个记录在哪个组，进而从组中找到该数据。\n\n从头到尾都是二分法。\n\n需要注意的是：我们一般用一个顶点来存储目录项记录的页。于是上面那张图的最终版为：\n\n\n\n更像b+树了~\n\n假如一个页可以有1000个子页（也就是一页中有1000条记录），一层是一个页，第二层就可以有1000页，第三层就可以有1000 * 1000 页，每一页有1000条数据，那么第三层可以有 1000 * 1000 * 1000 条数据，所以我们的数据绝大多数只有两~三层b+树。\n\n想起之前背的面试题：\n\n相比于二叉树，b+树的层级更低...(阿巴阿巴阿巴)\n\n现在知道到底为什么了吧。\n\n但是现在还有一个问题：\n\n如果我们为 age 创建了一个二级索引，那么在b+树的非叶子节点中的记录就是：age对应页码。但是age是很容易重复的，13这个age有可能对应很多个页码，进而出现了这种情况：age=13对应了 54、32、15这三页，再插入一条age=13的数据，这条数据该往哪个页中插入呢？\n\n为了让新插入记录能找到自己在那个页里，我们需要在记录中再添加一个唯一字段，什么字段适合做这个唯一索引呢？主键啊。\n\n所以对于二级索引的内节点的目录项记录的内容实际上是由三个部分构成的\n\n * 字段值\n * 字段对应的主键值\n * 页码\n\n\n# 2.3 聚簇索引\n\ninnodb的b+树索引也可以大致分为这两类：聚簇索引和二级索引。\n\n（只有主键会建立一颗聚簇索引b+树，不管是唯一索引还是联合索引巴拉巴拉这些其他的索引都是二级索引）\n\n上述图片描述的是聚簇索引，叶子节点中存储的是 主键->数据 。（学过的大概都知道）\n\n\n# 2.4 二级索引\n\n二级索引的叶子节点中存储的是 字段值 -> 主键。\n\n如果查询二级索引，拿到主键后还需要去聚簇索引的b+树中通过主键拿到全部数据。这也被称为回表查询。\n\n联合索引：\n\n联合索引就是很多个字段一起共用同一颗b+树。\n\n假如为 id、name、age建立联合索引 idx_id_name_age，那么它们三个字段就会使用同一颗b+树。\n\n通过刚才的学习，我们知道b+树是按照一定顺序存储数据的，也就是有序的，聚簇索引按照主键排序，那么联合索引呢？\n\n对于 idx_id_name_age 这个联合索引来说，顺序：按照id排序，id相同再按照name排序，name相同再按照age排序。\n\n\n# 3. 回表\n\n\n# 3.1 回表的代价\n\n之前对于回表这个词都是一带而过，下面详细说一下。\n\n假如对于 name、birthday、phone_num建立了一个联合索引：idx_name_birthday_phone_number。\n\n对于以下sql语句：\n\nselect * from person_info where name > 'xiaoming' and name < 'zengyi';\n\n\n在使用联合索引 idx_name_birthday_phone_number时可以分为这两步：\n\n * 从索引 idx_name_birthday_phone_number 中的b+树取出值在 xiaoming ~ zengyi 的数据。\n * 由于索引只有 name birthday phone_number 这三个字段，而查询列表中想要的是 *，所以会拿着主键id去聚簇索引中拿全部记录。\n\n由于索引 idx_name_birthday 对应的b+树的记录会首先按照name列的值进行排序，所以值在 xiaoming ~ zengyi 之间的记录在磁盘中的存储时是相连的，有可能就集中分布在同一页中，我们可以直接沿着链表将数据读取出来，这个过程称为顺序io。但是根据name拿到的id并不相连，虽然聚簇索引中的id是顺序的，但是我们根据 name 拿到的id不相连，所以只能去不同的页去拿数据，这种读取方式被称为随机io。一般情况下，顺序io比随机io快得多，所以这个sql语句的两步其实是这样的：\n\n * 会用到两个索引：联合(二级)索引和聚簇索引\n * 访问二级索引时使用顺序io，访问聚簇索引时使用随机io。\n\n需要回表的记录越多，使用二级索引的性能就越低。甚至某些查询宁愿用全表扫描也不用二级索引。\n\n例如刚才那个sql查出的记录占到表中总记录的９０％时，真的不如直接全表扫描。\n\n那么什么时候使用索引，什么时候全表扫描呢？这是查询优化器需要做的事。\n\n查询优化器会根据一条ｓｑｌ走了哪些索引占用了多少性能来计算分数，最后使用分数最低的那个sql或者直接全表扫描。\n\n\n# 3.2 覆盖索引\n\n为了减少回表带来的性能损耗，mysql更建议：查询列表尽量只包含索引列。\n\nselect　name, birthday, phone_number  \nfrom person_info \nwhere name > 'xiaoming' and name < 'zengyi';\n\n\n只要不让它回表，就不会有回表的坏处啦~\n\n\n# 4. b+树索引的使用\n\n前面两节详细描述了b+树的结构，温故：\n\n * 每一个索引都对应一个b+树，b+树的节点是页。非叶子节点存储的是目录，叶子节点存储的是数据（聚簇索引和二级索引不同）\n * b+树的叶子节点（页）按照双向链表连接，页的内部，即数据，按照单链表顺序连接。\n\n\n\n\n# 4.1 索引的代价\n\n在介绍更好的使用索引前肯定要知道 为什么要更好的使用索引？因为索引也有缺点啊~\n\n * 空间上的代价 ：这个是显而易见的，每建立一个索引，空间中就多一颗b+树，b+树的每一个节点都是一页，一页16k，当然很占空间喽。\n * 时间上的代价 ：索引优化了查询操作，毕竟使用了二分查找。但是在增删改操作时，不仅需要修改数据页，还需要修改索引页。（不仅要修改叶子节点，又要修改非叶子节点）。时不时还会伴随着页分裂、页回收、记录移动的操作，这些都是对时间的消耗。\n\n所以，一张表上索引建立的越多，就会占用越多的存储空间，在对数据增删改时的性能就会更差。\n\n\n# 4.2 索引失效的场景\n\n这个知识点想必大家面试题都背烂了，那么你知道\n\n * 为什么不符合最左前缀匹配原则，索引就会失效吗？\n * 为什么使用 '%xxx'，索引就会失效吗\n\n下面来看一下为什么。\n\n我们建立一张表，以便后续用到：\n\ncreate table person_info(     \n    id int not null auto_increment,     \n    name varchar(100) not null,     \n    birthday date not null,     \n    phone_number char(11) not null,     \n    country varchar(100) not null,     \n    primary key (id),     \n    key idx_name_birthday_phone_number (name, birthday, phone_number) \n);\n\n\n这张表中共有5个字段，其中id字段自动生成一颗聚簇索引的b+树，name、birthday、number这三个字段共用一颗b+树。\n\n等等，在继续向下看之前，你需要回顾一下：\n\n对于联合索引 idx_name_birthday_phone_number，排序的规则为：先按照 name 排序，name 相同再按照 birthday 排序，birthday相同再按照number 排序。\n\n# 4.2.1 最左前缀匹配\n\n最左前缀匹配相比大家都知道，对于一个联合索引，如果有一个字段没有走索引，那么它后面的所有字段都不会走索引。\n\n出现这种情况的原因就是联合索引的排序规则，刚才说过，排序规则是按照左边的列排序，左边的列相同再按照右边的列排序。\n\n现在来看一下这几种情况：\n\n 1. select * from person_info where name = 'xiaoming' and birthday = '2000-01-01';\n    \n    这个会走索引吗？会，mysql会在联合索引的b+树中找到 xiaoming 所在的页，再找它所在的组，最后确定第一个name为xiaoming的地方，再根据已经排好序的 birthday 进行顺序查找，直至找到目标。（拿到该目标的主键后去聚簇索引中回表查询）\n\n 2. select * from person_info where birthday = '2000-01-01';\n    \n    这个会走索引吗？不会，因为birthday所在的索引首先按照name进行排序，再按照birthday排序。都不按birthday排序了，怎么走索引？\n\n 3. select * from person_info where name < 'xiaoming' and name > 'xiaohong' and birthday = '2002-01-01';\n    \n    这个会走几个索引？一个name的索引，为什么呢？我们根据name走了索引之后获得了一个范围值，那么这个范围之可能如下所示：\n    \n    xiaohong 1998-03-12\n    \n    xiaohong 2002-01-01\n    \n    xiaohong 2005-08-09\n    \n    xiaoming 2001-10-02\n    \n    xiaoming 2002-09-13\n    \n    可以看到，虽然按照name排好序了，但是birthday并没有顺序可言，也就无法走索引，只能先拿到主键id，去聚簇索引中拿到对应数据后再判断一下这些数据的birthday是否为 2002-01-01。\n    \n    不仅仅是等值匹配、范围匹配会使用最左前缀匹配，分组操作也会使用最左前缀匹配原则，所以分组时也要注意哦。\n\n# 4.2.2 模糊查询\n\n在进行模糊查询时，'xx%'和'x%x' 都不会失效，而'%xxx'就会导致索引失效。\n\n为啥？前两个最起码第一个为x，mysql可以在索引中找到第一个字符为x的数据，这样即使不能最终确定有哪些数据也能筛选掉不少的数据了。\n\n但是给我个 '%xx' 是什么意思？第一个 '%' 你想让我怎么匹配怎么排序？肯定走不了索引啊~\n\n4.2.3 排序\n\n排序会出现什么问题呢？\n\nmysql规定：对于使用联合索引的场景，要求各个排序列的排序顺序是一致的，也就是要各个列要么全部降序，要么全部升序。\n\n为什么呢？\n\n假如有一下sql语句：\n\nselect * from person_info  order by name asc, birthday desc limit 10;\n\n\n这句sql的作用：\n\n * 先从索引的最左边确定 name 列最小的值，然后从name列的最右边那条记录从右向左找10条(因为要求是birthday降序)\n * 如果此name列不足10条，那么就要去下一个name列中重复上述操作。\n\n这样非常麻烦，而且不能高效利用索引，所以mysql就规定 使用联合索引的各个排序顺序都必须是一致的。\n\n# 4.2.4 运算与函数\n\n要想使用索引进行排序操作，必须保证索引列是以单独列的形式出现，而不是修饰过的形式。\n\n因为where 条件字段类型与实际表中字段类型不匹配时，mysql会进行隐式的类型转换，而类型转换会用到内置函数，导致在查询时没有走索引。\n\n# 4.2.5 or\n\n我们有时候会用到or，select * from user where age = 18 or age = 20;\n\nor左右的字段必须都加索引才会生效。\n\n\n# 5. 如何挑选索引\n\n\n# 5.1 常用于搜索、排序、分组的列\n\n为常用于搜索、排序、分组的列创建索引，也就是说，只为出现在 where 子句中的列创建索引，出现在查询列表中的就没必要了（因为回表后自然能查出来）。\n\n下面这一句，我们为name创建索引，而不为birthday和country创建索引。\n\nselect birthday, country from person_info where name='xxx';\n\n\n# 5.2 考虑列的基数\n\n什么是基数？一张表有10000条数据，它的每一列的基数一样吗？\n\n不是，如果是id字段，10000条数据可能id都不一样。如果是age呢？如果是分数呢？\n\n所以基数是指不相同的个数，我们应该尽量挑选基数大的列建立索引。\n\n（像那些性别、状态就不要创建索引，但是如果经常用于分组的话也可以考虑）。\n\n\n# 5.3 主键插入顺序\n\n主键插入顺序尽量递增，并且尽量不要让主键变更。所以主键尽量设置为无意义且自增的。防止页分裂、记录重排序....造成的性能损耗。\n\n‍",charsets:{cjk:!0},lastUpdated:"2023/06/14, 19:46:55",lastUpdatedTimestamp:1686743215e3},{title:"Redis主从集群原理",frontmatter:{title:"Redis主从集群原理",date:"2023-07-01T14:55:03.000Z",permalink:"/pages/db45e7/"},regularPath:"/02.%E6%96%87%E7%AB%A0/10.Redis/40.Redis%E4%B8%BB%E4%BB%8E%E9%9B%86%E7%BE%A4%E5%8E%9F%E7%90%86.html",relativePath:"02.文章/10.Redis/40.Redis主从集群原理.md",key:"v-6890b777",path:"/pages/db45e7/",headers:[{level:2,title:"1. Redis主从概念",slug:"_1-redis主从概念",normalizedTitle:"1. redis主从概念",charIndex:2},{level:2,title:"2. 全量同步",slug:"_2-全量同步",normalizedTitle:"2. 全量同步",charIndex:706},{level:2,title:"3. 增量同步",slug:"_3-增量同步",normalizedTitle:"3. 增量同步",charIndex:1543},{level:2,title:"4. 无磁盘复制",slug:"_4-无磁盘复制",normalizedTitle:"4. 无磁盘复制",charIndex:2148},{level:2,title:"5. 主从同步注意事项",slug:"_5-主从同步注意事项",normalizedTitle:"5. 主从同步注意事项",charIndex:2276}],headersStr:"1. Redis主从概念 2. 全量同步 3. 增量同步 4. 无磁盘复制 5. 主从同步注意事项",content:"# 1. Redis主从概念\n\n单机的Redis能够承载的QPS大概是几万左右。对于缓存来说，一般都是用来支持读高并发的，因此架构做成主从(master-slave)结构，一主多从，主节点负责写，从节点负责读，主节点写之后将数据同步到从节点。所有的读请求全部走从节点，这样也可以很轻松实现水平扩展，支撑读高并发。\n\n并且在面试中经常会出现 “你是否了解Redis高可用” 这类面试题，Redis高可用回答包括两个方面，一个就是数据不能丢失，或者说尽量减少丢失；另一个就是保证Redis服务不中断。\n\n * 对于尽量减少丢失，可以通过AOF和RDB数据持久化保证。\n * 对于保证服务不中断，Redis就不能单点部署，这时候就需要使用Redis主从。\n\n> 怎么进行数据同步？\n> \n> 想要做数据同步，首先要有全部数据，那么哪个地方记载了Redis的全部数据呢？你是否还记得Redis的RDB持久化方式？它会将所有数据记录在rdb文件中，我们可以利用这个日志来进行数据的同步，当主节点想要进行数据同步时，直接将RDB文件甩给从从节点就行了~\n> \n> （当然“全部甩过去”只是一个构想，Redis才不会使用这种愚蠢的方式）\n\nRedis毕竟是个数据库，想要实现写主读从的模式就需要进行数据同步：将写到主节点的数据同步到从节点。数据同步的过程是我们主要想解决的问题，Redis将数据的同步方式分为两种：全量同步、增量同步。\n\n * 全量同步 ：大部分用于从节点第一次连接到主节点时需要拿到主节点的全部数据。\n * 增量同步 ：全量同步后还会有后续的数据写入主节点，这些后续增加的数据的同步就叫做增量同步。\n\n\n# 2. 全量同步\n\n全量同步刚才解释过了，就是Redis主节点把全部的数据都丢给从节点，也就是RDB文件的全部内容。\n\n什么时候会发生全量同步呢？肯定是从节点第一次连接到到主节点的时候啦，但是只有这一个场景吗？不，有两种情况会触发全量同步：\n\n 1. 从节点第一次连接主节点。\n 2. 从节点宕机时间太久，无法进行增量同步。\n\n先来学习一下全量同步吧，全量同步分为三个阶段：\n\n 1. 主从之间建立连接。\n 2. 主节点把数据同步到从节点。\n 3. 主节点把新写的命令发送到从节点。\n\n第一个阶段：主从之间建立连接\n\n根据经验，主从之间建立连接的过程肯定不仅仅是建立连接这么简单，它俩肯定要交换一些信息。\n\n * 从节点发送psync命令，告诉主节点自己想要成为它的从节点，这个命令中包含自己的runID，主节点发现这个runID与自己的runID不一致，它就意识到这个家伙是第一次同步，需要进行全量同步。\n * 于是主节点响应fullresync命令告诉从节点让它进行全量同步，这个命令中包含主节点的runID与目前RDB的复制进度offset，发送runID是为了让从节点也使用这个runID，下一次来的时候就知道它是不是第一次连接了，发送offset是为了告诉从节点你第一次就复制RDB文件的这个地方数据。\n\n\n\n第二个阶段：主节点把数据同步到从节点\n\n * 首先主节点会使用bgsave命令生成RDB文件，将RDB文件发送给从节点\n * 从节点收到RDB文件后会先清空当前的全部数据，毕竟你要跟主节点的数据一致，那么你原来的数据你就要删除，之后就按照offset加载RDB文件\n * 主节点把RDB文件发送给从节点进行同步的过程是异步的，主节点还有可能接收到新的数据写入，于是它把这些数据记录在日志文件repl_baklog中\n\n\n\n第三个阶段：主节点把新写的命令发送到从节点。\n\n * 主节点将repl_baklog发送给从节点，从节点继续将内容写入。\n\n\n\n\n# 3. 增量同步\n\n全量同步完运行了一段时间后，主从产生了不一致总不能再进行一次全量同步吧，这时就需要使用增量同步。\n\n从Redis2.8开始支持增量同步，而且是断点续传的增量复制，也就是说如果出现网络延迟或者从节点宕机导致复制中断的情况，在系统恢复后仍然可以从上次同步的地方开始同步。\n\n它的原理是主从都维护一个offset（复制偏移量），master_offset、slave_offset，主节点每一次都将从 slave_offset 到 master_offset的数据传输给从节点，什么？没收到？那就重新从slave_offset传。\n\noffset记录的主从节点在repl_baklog日志中的偏移量，repl_baklog实际上就是主与从之间数据差异的缓冲区，它是一个大小固定的文件，假如它是1024k，现在offset到了第1024k的位置，下一次它会覆盖前面的数据。\n\n这样是有危险的，如图：\n\n正常情况下，slave与master之间的差距并不多，是可以使用增量同步保证数据一致性。\n\n\n\n但是万一slave宕机，master中的数据比slave数据整整多了一个”环“，那么就无法进行增量同步了。\n\n\n\n这时就需要重新进行全量复制（也就是第二种进行全量同步的情况），而全量复制非常损耗性能，所以我们要 提高repl_baklog的大小并且当从节点宕机时尽快恢复，减少全量同步的出现。\n\n\n# 4. 无磁盘复制\n\n全量同步和增量同步都是基于RDB文件的，需要进行磁盘IO，但是我们可以开启无磁盘同步，这就不会生成RDB文件，而是把RDB文件中的内容不保存在磁盘中，直接在内存中发送给从节点。\n\nrepl-diskless-sync yes\n\n\n\n# 5. 主从同步注意事项\n\n主从模式解决了数据备份和性能的问题，但是还是存在一些问题：\n\n 1. 第一次建立连接时一定是全量同步，同步的耗时比较久，此时应该避开Redis提供服务的高峰期。\n 2. 如果有多个从节点需要建立连接，可以考虑将几个从节点错开时间段，避免主节点内存占用过多。此外如果从节点太多，也可以调整主从复制的结构，使其变为树状结构。\n 3. 在一主一从或者一主多从的情况下，如果主服务器挂了，对外提供的服务就不可用了，单点问题没有解决。所以会出现后面的哨兵集群模式。",normalizedContent:"# 1. redis主从概念\n\n单机的redis能够承载的qps大概是几万左右。对于缓存来说，一般都是用来支持读高并发的，因此架构做成主从(master-slave)结构，一主多从，主节点负责写，从节点负责读，主节点写之后将数据同步到从节点。所有的读请求全部走从节点，这样也可以很轻松实现水平扩展，支撑读高并发。\n\n并且在面试中经常会出现 “你是否了解redis高可用” 这类面试题，redis高可用回答包括两个方面，一个就是数据不能丢失，或者说尽量减少丢失；另一个就是保证redis服务不中断。\n\n * 对于尽量减少丢失，可以通过aof和rdb数据持久化保证。\n * 对于保证服务不中断，redis就不能单点部署，这时候就需要使用redis主从。\n\n> 怎么进行数据同步？\n> \n> 想要做数据同步，首先要有全部数据，那么哪个地方记载了redis的全部数据呢？你是否还记得redis的rdb持久化方式？它会将所有数据记录在rdb文件中，我们可以利用这个日志来进行数据的同步，当主节点想要进行数据同步时，直接将rdb文件甩给从从节点就行了~\n> \n> （当然“全部甩过去”只是一个构想，redis才不会使用这种愚蠢的方式）\n\nredis毕竟是个数据库，想要实现写主读从的模式就需要进行数据同步：将写到主节点的数据同步到从节点。数据同步的过程是我们主要想解决的问题，redis将数据的同步方式分为两种：全量同步、增量同步。\n\n * 全量同步 ：大部分用于从节点第一次连接到主节点时需要拿到主节点的全部数据。\n * 增量同步 ：全量同步后还会有后续的数据写入主节点，这些后续增加的数据的同步就叫做增量同步。\n\n\n# 2. 全量同步\n\n全量同步刚才解释过了，就是redis主节点把全部的数据都丢给从节点，也就是rdb文件的全部内容。\n\n什么时候会发生全量同步呢？肯定是从节点第一次连接到到主节点的时候啦，但是只有这一个场景吗？不，有两种情况会触发全量同步：\n\n 1. 从节点第一次连接主节点。\n 2. 从节点宕机时间太久，无法进行增量同步。\n\n先来学习一下全量同步吧，全量同步分为三个阶段：\n\n 1. 主从之间建立连接。\n 2. 主节点把数据同步到从节点。\n 3. 主节点把新写的命令发送到从节点。\n\n第一个阶段：主从之间建立连接\n\n根据经验，主从之间建立连接的过程肯定不仅仅是建立连接这么简单，它俩肯定要交换一些信息。\n\n * 从节点发送psync命令，告诉主节点自己想要成为它的从节点，这个命令中包含自己的runid，主节点发现这个runid与自己的runid不一致，它就意识到这个家伙是第一次同步，需要进行全量同步。\n * 于是主节点响应fullresync命令告诉从节点让它进行全量同步，这个命令中包含主节点的runid与目前rdb的复制进度offset，发送runid是为了让从节点也使用这个runid，下一次来的时候就知道它是不是第一次连接了，发送offset是为了告诉从节点你第一次就复制rdb文件的这个地方数据。\n\n\n\n第二个阶段：主节点把数据同步到从节点\n\n * 首先主节点会使用bgsave命令生成rdb文件，将rdb文件发送给从节点\n * 从节点收到rdb文件后会先清空当前的全部数据，毕竟你要跟主节点的数据一致，那么你原来的数据你就要删除，之后就按照offset加载rdb文件\n * 主节点把rdb文件发送给从节点进行同步的过程是异步的，主节点还有可能接收到新的数据写入，于是它把这些数据记录在日志文件repl_baklog中\n\n\n\n第三个阶段：主节点把新写的命令发送到从节点。\n\n * 主节点将repl_baklog发送给从节点，从节点继续将内容写入。\n\n\n\n\n# 3. 增量同步\n\n全量同步完运行了一段时间后，主从产生了不一致总不能再进行一次全量同步吧，这时就需要使用增量同步。\n\n从redis2.8开始支持增量同步，而且是断点续传的增量复制，也就是说如果出现网络延迟或者从节点宕机导致复制中断的情况，在系统恢复后仍然可以从上次同步的地方开始同步。\n\n它的原理是主从都维护一个offset（复制偏移量），master_offset、slave_offset，主节点每一次都将从 slave_offset 到 master_offset的数据传输给从节点，什么？没收到？那就重新从slave_offset传。\n\noffset记录的主从节点在repl_baklog日志中的偏移量，repl_baklog实际上就是主与从之间数据差异的缓冲区，它是一个大小固定的文件，假如它是1024k，现在offset到了第1024k的位置，下一次它会覆盖前面的数据。\n\n这样是有危险的，如图：\n\n正常情况下，slave与master之间的差距并不多，是可以使用增量同步保证数据一致性。\n\n\n\n但是万一slave宕机，master中的数据比slave数据整整多了一个”环“，那么就无法进行增量同步了。\n\n\n\n这时就需要重新进行全量复制（也就是第二种进行全量同步的情况），而全量复制非常损耗性能，所以我们要 提高repl_baklog的大小并且当从节点宕机时尽快恢复，减少全量同步的出现。\n\n\n# 4. 无磁盘复制\n\n全量同步和增量同步都是基于rdb文件的，需要进行磁盘io，但是我们可以开启无磁盘同步，这就不会生成rdb文件，而是把rdb文件中的内容不保存在磁盘中，直接在内存中发送给从节点。\n\nrepl-diskless-sync yes\n\n\n\n# 5. 主从同步注意事项\n\n主从模式解决了数据备份和性能的问题，但是还是存在一些问题：\n\n 1. 第一次建立连接时一定是全量同步，同步的耗时比较久，此时应该避开redis提供服务的高峰期。\n 2. 如果有多个从节点需要建立连接，可以考虑将几个从节点错开时间段，避免主节点内存占用过多。此外如果从节点太多，也可以调整主从复制的结构，使其变为树状结构。\n 3. 在一主一从或者一主多从的情况下，如果主服务器挂了，对外提供的服务就不可用了，单点问题没有解决。所以会出现后面的哨兵集群模式。",charsets:{cjk:!0},lastUpdated:"2023/07/01, 15:08:05",lastUpdatedTimestamp:1688195285e3},{title:"Redis数据结构与数据类型",frontmatter:{title:"Redis数据结构与数据类型",date:"2023-06-11T12:25:09.000Z",permalink:"/pages/77c4c7/"},regularPath:"/02.%E6%96%87%E7%AB%A0/10.Redis/10.Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html",relativePath:"02.文章/10.Redis/10.Redis数据结构与数据类型.md",key:"v-6db7c258",path:"/pages/77c4c7/",headers:[{level:2,title:"1. 简述",slug:"_1-简述",normalizedTitle:"1. 简述",charIndex:16},{level:2,title:"2. 数据类型",slug:"_2-数据类型",normalizedTitle:"2. 数据类型",charIndex:463},{level:3,title:"2.1 SDS动态字符串",slug:"_2-1-sds动态字符串",normalizedTitle:"2.1 sds动态字符串",charIndex:571},{level:3,title:"2.2 Intset",slug:"_2-2-intset",normalizedTitle:"2.2 intset",charIndex:1539},{level:3,title:"2.3 Dict",slug:"_2-3-dict",normalizedTitle:"2.3 dict",charIndex:2153},{level:3,title:"2.4 ZipList",slug:"_2-4-ziplist",normalizedTitle:"2.4 ziplist",charIndex:3550},{level:3,title:"2.5 QuickList",slug:"_2-5-quicklist",normalizedTitle:"2.5 quicklist",charIndex:4332},{level:3,title:"2.6 SkipList",slug:"_2-6-skiplist",normalizedTitle:"2.6 skiplist",charIndex:5462},{level:2,title:"3. RedisObject",slug:"_3-redisobject",normalizedTitle:"3. redisobject",charIndex:6632},{level:2,title:"4. 数据结构",slug:"_4-数据结构",normalizedTitle:"4. 数据结构",charIndex:7729},{level:3,title:"4.1 string",slug:"_4-1-string",normalizedTitle:"4.1 string",charIndex:7741},{level:3,title:"4.2 list",slug:"_4-2-list",normalizedTitle:"4.2 list",charIndex:8406},{level:3,title:"4.3 set",slug:"_4-3-set",normalizedTitle:"4.3 set",charIndex:8538},{level:3,title:"4.4 zset",slug:"_4-4-zset",normalizedTitle:"4.4 zset",charIndex:8653},{level:3,title:"4.5 hash",slug:"_4-5-hash",normalizedTitle:"4.5 hash",charIndex:9122},{level:3,title:"4.6 总结",slug:"_4-6-总结",normalizedTitle:"4.6 总结",charIndex:9381},{level:2,title:"5. 应用场景",slug:"_5-应用场景",normalizedTitle:"5. 应用场景",charIndex:9392},{level:3,title:"5.1 string",slug:"_5-1-string",normalizedTitle:"5.1 string",charIndex:9404},{level:3,title:"5.2 list",slug:"_5-2-list",normalizedTitle:"5.2 list",charIndex:9689},{level:3,title:"5.3 set",slug:"_5-3-set",normalizedTitle:"5.3 set",charIndex:9757},{level:3,title:"5.4 zset",slug:"_5-4-zset",normalizedTitle:"5.4 zset",charIndex:9857},{level:3,title:"5.5 hash",slug:"_5-5-hash",normalizedTitle:"5.5 hash",charIndex:9903}],headersStr:"1. 简述 2. 数据类型 2.1 SDS动态字符串 2.2 Intset 2.3 Dict 2.4 ZipList 2.5 QuickList 2.6 SkipList 3. RedisObject 4. 数据结构 4.1 string 4.2 list 4.3 set 4.4 zset 4.5 hash 4.6 总结 5. 应用场景 5.1 string 5.2 list 5.3 set 5.4 zset 5.5 hash",content:'# Redis数据结构\n\n\n# 1. 简述\n\n想必大家已经了解了Redis的几大数据结构，那么数据类型是什么？\n\n😜其实是我自己编的，为了让自己理解这些东西造出来的~~\n\n> 数据结构 ：像string、set、list、zset，我们可以直接使用的这些Redis具体的类型。\n> \n> 数据类型 ：上述数据结构底层的实现。\n\n该如何理解这两个词呢？\n\n学习各种语言都是先学各种数据类型，例如int、float、char...\n\n再学各种数据结构，例如栈、队列、树...\n\n数据结构由数据类型组成，就像栈、队列这些结构的底层可以由数组实现。\n\n本篇将会讲述以下内容 ：\n\n * 数据类型 ：SDS、Intset、Dit、ZipList、QuickList、SkipList\n * 用于确认数据结构使用哪种数据结构的RedisObject\n * 数据类型 ：string、list、set、zset、Hash以及它们的应用场景。\n\n再说一句！本文的数据类型、数据结构都是本人杜撰！便于自己理解，实际上它们都是数据类型\n\n\n# 2. 数据类型\n\n看了一些面试题，出现Redis数据类型这一块知识的，对于SDS和SkipList较多，Dict也有，Intset、ZipList、QuickList就比较少了。\n\n主要还是它们的应用场景。\n\n\n# 2.1 SDS动态字符串\n\nRedis构建了一种结构体来完成存储字符串的功能：简单动态字符串（Simple Dynamic String），简称SDS。\n\nstruct __attribute__ ((__packed__)) sdshdr8{\n    char buf[];\n\n    uint8_t alloc;\n \n    uint8_t len;\n\n    unsigned char flags;\n};\n\n\n * char buf[] ：字节数组，用于存储string/int/float。\n * uint8_t alloc ：记录buf数组申请的总字节数,类型为8位无符号整型。不包括结束标志\'\\0\'。\n * uint8_t len ：记录buf数组中已经使用的字节的数量,类型为:8位无符号整型。不包括结束标志。\n * unsigned char flags ：记录SDS的最大空间，即决定alloc的最大值。因为存储空间不同，SDS类型也不同，有很多不同类型的SDS，例如16位、32位...\n\n之所以被称为动态字符串，因为这个字符串有动态扩容机制：\n\n * 扩容后的空间小于1M ：扩容后的空间大小乘以 2＋1\n * 扩容后的空间大于1M ：空间直接 +1M+1\n\n# 扩容方案:\nni -> nihao\n# 原空间: \n    len=2\n    alloc=2\n# 扩容后:\n    len=5\n    alloc=10\n# 为什么没有加一？不应该是5*2 + 1 = 11吗?\n    因为字符串后面有 \'\\0\', 而这len和alloc两个字段都不计算结束标志。\n    空间确实有了，但是alloc没有计算进去。\n\n\n但是alloc的类型是8位无符号整型，只能存储2^8个数字，太有限，所以Redis提供了不同类型的SDS，它们的其他特性都相同，只有alloc、len的类型不同，有5位、8位、16位、32位。\n\n如何区分？使用 flag 这个字段。flag有不同的值，分别代表字节大小，5、8、16、32.\n\n总结 ：flag规定alloc的最大值，需要扩容时需要改变alloc甚至flag。alloc规定字符串可以存储多少元素，一旦超过，需要扩容。len是当前元素个数。buf[]存储当前元素。\n\n\n# 2.2 Intset\n\nIntset是Redis中set集合的一种实现方式，基于整数数组来实现，具有长度可变、唯一、有序等特点。\n\ntypedef struct intset {\n    uint32_t encoding;\n    \n    uint32_t length;\n    \n    int8_t contents[];\n} intset;\n\n\n * uint32_t encoding ：数据编码方式，支持存放16位、32位、64位的数据。\n * uint32_t length ：元素个数。\n * int8_t contents[] ：整数数组，保存集合数据。数据范围由encoding确认。\n\n> 那么Intset如何维持有序、唯一的特点？\n\n在插入时 ：\n\n 1. 检查插入数据是否太大或太小，是否需要改变encoding编码。\n    \n    如果重置编码，假如重置编码后原来的16位变成32位，需要重新拷贝数组的原有数据到升级后的内存而且需要倒序拷贝防止数据丢失。\n\n 2. 查看数组中是否已经存在该数据，若已存在就不插入，若不存在，二分法获得该数据的插入位置。\n    \n    二分法保证数据有序，数据有序可以使用二分法。\n\n 3. 数组原地扩容，将待插入元素插入\n\n通过第二点就可以保证Intset的唯一性和有序性。\n\n上述具体步骤可以打开Redis源码阅读。将Redi安装包打开即可。\n\n\n# 2.3 Dict\n\nRedis是典型的键值型（key-value）数据库，它就是靠Dict来保持键与值的映射关系的。\n\nJava中的Map是基于Hash的字典结构，Redis中的字典Dict也是。\n\nDict由三部分组成 ：哈希节点（DictEntry）、哈希表（DictHashTable）、字典（Dict）。\n\n从小往大说，先说哈希节点与哈希表，一个哈希表可以包含多个哈希节点，哈希节点是键-值型的。\n\n哈希节点：\n\ntypedef struct dictEntry {\n    void *key;\n    \n    union {\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n        double d;\n    } value;\n    \n    struct dictEntry *next;\n} dictEntry;\n\n\n * key：哈希节点的键。\n * value ：哈希节点的值，为联合体类型。\n * *next ：为了方便寻址，每个哈希节点都有指向下一个哈希节点的指针。\n\n哈希表 ：\n\ntypedef struct dictht {\n    dictEntry **table;\n    unsigned long size;\n    unsigned long sizemask;\n    unsigned long used;\n} dictht;   \n\n\n * table ：指向键值对数组的指针。数组是指针，table是指向数组的指针，所以table是二级指针。\n * size ：哈希表大小。总等于 2^n （n为整数）。\n * sizemark ：哈希表大小的掩码，总等于size - 1 。\n * used ：哈希节点个数。\n\n为什么有了size表示哈希节点个数，还要使用used多此一举呢？\n\nHash运算会产生Hash冲突，会在数组的基础上多一些链表，size表示数组元素个数，used表示数组+链表的元素个数。\n\n当我们向Dict添加键值对时，Redis首先根据key计算出hash值，然后通过hash & sizemark计算该数据应该放到数组中哪个位置。\n\n\n\n除了哈希节点与哈希表之外，Dict最后一个组成：字典 DictHashTable.\n\ntypedef struct dict {\n\tdictType *type;\n    void *privdata;\n    dictht ht[2];\n    long rehashidx;\n    int16_t pauserehash;\n} ;\n\n\n * *type：本字典的类型，不同类型使用不同Hash函数。\n * *privdata ：私有数据，在做特殊hash运算时使用。\n * ht[2] ：一个字典拥有两个哈希表，一个放哈希节点，一个为rehash时使用。\n * rehashidx ：rehash的进度，-1代表未开始。\n * pauserehash ：rehash是否暂停，1则暂停，0则继续。\n\n总结 ：Dict底层是基于数组、链表的Hash表，数组中保存的是一个个entry键值对，键值对的类型大多是指针，指向SDS对象。数组中的entry键值对由next指针连接，便于寻址。\n\n\n# 2.4 ZipList\n\n压缩链表，为了节省内存而设计的链表，由一系列特殊编码的连续空间组成，可以在任意一端进行压入/弹出操作，并且该操作的时间复杂度为 O(1)。\n\n但是成也连续，败也连续，ZipList的诞生是为了解决Dict指针过多且内存不连续的问题，不过产生了新问题 ：一旦数据量太大，上哪去找这么多连续的空间？所以很多Redis的数据类型只在数据量小的时候用ZipList。\n\ntypedef struct ziplist {\n    uint32_t albytes;\n    uint32_t zltail;\n    uint16_t zllen;\n    entry *entry;\n    uint8_t zlend;\n} ziplist;\n\n\n * zlbytes ：总字节数\n * zltail ：尾节点与起始地址之间的字节数\n * zllen ：entry节点的个数\n * zlend ：结束标志，0xff\n * entry ：ZipList中所有节点，个数、字节大小不定。\n\n\n\nentry字节大小不确定，那遍历的时候该如何遍历呢？数组中的元素字节大小固定，可以知道每次读取几个字节的空间，链表直接使用指针指向下一个元素，那么entry该如何遍历？\n\n只要在entry这个结构内部记录一下使用的空间就行了。\n\n但是Entry记录的是上一个entry占用的字节数。（Redis7改为此entry字节数）\n\n每一个entry有三个字段 ：\n\n * previous_entry_length ：前一节点的长度，1-5个字节。\n * encoding ：本节点属性，记录content的数据类型（整数/字符串）以及长度。\n * contents ：保存节点数据，可以是字符串或整数。\n\n只要知道前一个节点/本节点的字节数，就可以遍历。\n\n\n# 2.5 QuickList\n\n为了解决ZipList的问题，QuickList诞生了。\n\nZipList的问题是空间连续，但是找不到太大的连续空间。\n\n为了解决这个问题，QuickList采用两种方法 ：\n\n * 限制entry的个数及大小。\n * 使用多个ZipList。\n\n一个5M的数据，使用一个ZipList可能找不到连续的5M空间，但如果可以找到5个连续的1M空间，就可以将这个数据分为5份，使用5个ZipList存储。\n\nRedis3.2之后引入的QuickList是一个双端链表，只不过每一个节点都是一个ZipList。\n\n除了控制ZipList的大小，QuickList还对节点的ZipList进行压缩\n\nQuickListNode（节点）源码：\n\ntypedef struct quicklistNode {\n    // 指向前一个结点的指针\n    struct quicklistNode *pre;\n    // 指向后一个节点的指针\n    struct quicklistNode *next;\n    // 当前节点的ziplist指针\n    unsigned char *zl;\n    // 当前节点的ziplist的字节数\n    unsigned int sz;\n    // 当前节点所属的ziplist的entry个数\n    unsigned int count;\n    // 编码方式 1.ZipList  2.lzf压缩模式\n    unsigned int encoding;\n    // 是否被解压缩 1说明被解压了，以后要重新压缩\n    unsigned int recompress;\n}\n\n\nQuickList源码：\n\ntypedef struct quicklist {\n    // 头节点指针\n    quicklistNode *head;\n    // 尾节点指针\n    quicklistNode *tail;\n    // 所有ziplist中的entry个数\n    unsigned long count;\n    // ziplist个数\n    unsigned long len;\n    // ziplist的entry数量上限\n    int fill; // 默认为2\n}\n\n\n\n（源码删了一点没用的）\n\n当存储一定数据时，QuickList的模样 ：\n\n\n\n总结 QuickList特点：\n\n 1. 节点为ziplist的双端链表。\n 2. 控制ziplist中entry的个数以及每个entry的大小。\n 3. 中间节点可以压缩，进一步节省内存。\n\n\n# 2.6 SkipList\n\nSkipList，面试中经常问的跳表，被称为跳表是因为它遍历的时候可以“跳”着遍历。\n\n对于一个有序数组，可以使用二分法快速查找，但是链表怎么快速呢？\n\n正常的链表只有指向前后节点的指针，但是跳表不一样，它有随机个随机指针。对于1-10这几个数组成的跳表，可能1这个元素中有指向5、6、9、10的指针，2有指向3、4、8、10的，10可能有指向1、4、7的指针。这样就可以通过不断的跳跃、比较，快速得到想要的值。此结构正因为这个特点被称为跳表。\n\n当然了，跳表的指针是随机生成的，随机性太大，可能一次就找到值，可能需要一个一个遍历。\n\nSkipList（跳表）首先是链表，但与传统链表有几点差异 ：\n\n * 元素升序排列，不过不是按照元素进行排序，而是根据元素生成的score排序。\n * 节点可能包含多个指针，指针跨度随机。\n\n正因为这两个特点，跳表可以边跳跃边比较，大大提高查询效率。\n\n跳表节点\n\ntypedef struct zskiplistNode {\n    sds ele;\n    double score;\n    zskiplistNode *backward;\n    struct zskiplistLevel {\n        zskiplistNode *forward;\n        unsigned long span;\n    } level[];\n}zskiplistNode;\n\n\n * ele ：节点存储的值。\n * score ：节点的分数，用于排序。\n * backward ：前一个节点的指针。\n * level ：多级索引数组，所有后继节点\n * forward ：一个节点可能有多个level，forward指向这个level代表的节点。\n * span ：索引跨度，第一个节点指向第十个节点，跨度为9\n\n跳表\n\ntypedef struct zskiplist {\n    struct zskiplistNode *header, *tail;\n    unsigned long length;\n    int level;\n}\n\n\n * header tail ：头节点、尾节点。\n * length ：节点数量。\n * level ：最大索引层级，默认为1，最大为32，即一个节点的后继指针可以有1-32个。\n\n\n\nSkipList特点：\n\n 1. 双向链表，每个节点包含score和ele值\n 2. 节点按照score排序，score值一样则按照ele排序\n 3. 每个节点都可以包含多层指针，层数是1-32的随机值\n 4. 不同指针到下一个节点的跨度不同，层级越高，跨度越大。\n 5. 增删改查效率与红黑树基本一致，实现却更简单。\n\n\n# 3. RedisObject\n\n学习了以上几种数据类型，有什么用呢？对，组成Redis中可以使用的数据结构，那么各个数据结构用什么样的底层实现呢？在哪里可以看到呢？在哪里记录下来呢？\n\nRedisObject\n\nRedis中的任何数据类型都会被封装为一个RedisObject，也叫做Redis对象。\n\ntypedef struct redisObject {\n    unsigned type:4;\n    unsigned encoding:4;\n    unsigned lru:24; \n    int refcount;\n    void *ptr;\n}\n\n\n * type ：此对象的类型，分别为string、list、set、zset、hash\n\n * encoding ：此对象的底层实现，上述SDS、Intset、Dict、SkipList...有11个值。\n\n * lru ：记录当前Redis对象最近一次访问时间，以便将长时间未使用的对象回收。\n\n * refcount ：对象引用计数器，计数器为0则说明对象无人使用，可以被回收。\n\n * *ptr ：指向具体存放数据的空间。\n\ntype和encoding字段是本篇文章关注的地方。\n\n先来看看encoding字段的11个值 ：\n\n编号   编码方式                      说明\n0    OBJ_ENCODING_INT          long类型的整数字符串\n1    OBJ_ENCODING_RAW          raw编码的动态字符串\n2    OBJ_ENCODING_EMBSTR       embstr编码的动态字符串\n3    OBJ_ENCODING_INTSET       整数集合\n4    OBJ_ENCODING_ZIPLIST      压缩列表\n5    OBJ_ENCODING_QUICKLIST    快速列表\n6    OBJ_ENCODING_SKIPLIST     跳表\n7    OBJ_ENCODING_LINKEDLIST   双端链表\n8    OBJ_ENCODING_HT           字典\n9    OBJ_ENCODING_ZIPMAP       已废弃\n10   OBJ_ENCODING_STREAM       Stream流\n\n可以看到，string有三种编码方式，list有3中编码方式，set有三种编码方式。\n\n----------------------------------------\n\n\n# 4. 数据结构\n\n\n# 4.1 string\n\nstring是Redis最常见的数据存储类型。\n\n * 如果存储的字符串长度小于44字节，则会使用EMBSTR编码。此时object head与SDS是一片连续空间，申请内存时只需要调用一次内存内存分配函数，效率更高。\n\n * SDS长度大于44，编码方式是RAW。object head与SDS不再连续\n\n\n\n * 如果SDS的内容是数字，并且这个数字在Long_MAX范围内就使用INT编码方式。INT编码方式直接将数据存在RedisObject的ptr指针位置（刚好8字节），不需要SDS了。\n\n\n\n可以看出明显区别 ：EMBSTR的空间是连续的，因为字符串体积小，容易申请连续空间。\n\n以下向Redis存储四个值，分别为 数字、短字符串、44位字符串、45位字符串，查看的编码方式结果如下：\n\nyun:0>set a 12\n"OK"\nyun:0>object encoding a\n"int"\nyun:0>set b xiaoming\n"OK"\nyun:0>object encoding b\n"embstr"\nyun:0>set c 01234567890123456789012345678901234567890123\n"OK"\nyun:0>object encoding c\n"embstr"\nyun:0>set d 012345678901234567890123456789012345678901234\n"OK"\nyun:0>object encoding d\n"raw"\n\n\n\n# 4.2 list\n\nlist拥有三种编码方式 ：linkedlist、ziplist、quicklist。自从QuickList出现后就很少用LinkedList了。\n\n所以在Redis3.2版本后，Redis统一采用QuickList实现List。\n\n\n\n\n# 4.3 set\n\n * 当存储的数据全部为整数，且元素数量不超过set-max-intset-emtries时，set使用intset编码\n\n * 其他情况使用Dict编码，使用它的key，value统一为null。\n\n\n\n\n# 4.4 zset\n\nzset也就是sortedset，每一个元素都有一个用于排序的score值。zset的特点 ：\n\n * score值用于排序\n * 键唯一\n * 可以根据键查询分数\n\n看起来可以用SkipList，但是跳表的键不唯一，而且它的score虽然可以排序，但无法查询。\n\n看起来可以用Dict，但Dict无法排序。\n\n那么我们将它们结合起来不就行了？一个zset包含一个SkipList和一个Dict，添加元素时先向Dict添加，保证元素唯一，如果元素唯一再向SkipList添加，保证可排序。\n\ntypedef struct zset {\n    dict *dict;\n    zskiplist *zsl;\n}\n\n\n虽然zset使用了两种结构，但它的编码写成skiplist。\n\n但是当元素数量小于128或元素大小小于64字节时，zset会使用ZipList节省空间。\n\n * 元素数量小于128或元素大小小于64字节时，使用ZipList节省空间。\n * 其他情况使用 Dict + SkipList。\n\n\n\n\n# 4.5 hash\n\nHash结构与Redis中的Zset很像\n\n * 键值存储\n * 可以根据键获取值\n * 键唯一\n\n二者差别例如zset的值必须是数字，用于排序。而Hash结构不用排序。\n\nHash底层采用的编码与Zset基本一致，只需要把排序有关的SkipList去掉即可 ：\n\n * Hash默认使用ZipList编码，以节省内存。ZipList的相邻两个entry分别存储键、值。\n * 当元素数量超过512或任意一个entry节点大小超过64字节时Hash结构会转为HT编码，也就是Dict。\n\n\n\n\n# 4.6 总结\n\n\n# 5. 应用场景\n\n\n# 5.1 string\n\n 1. 用于做缓存\n 2. setnx 操作生成分布式锁\n 3. 这时可以用于计数器。当数据是数字时，string不会创建新的SDS对象，而是将数字存储在RedisObject的ptr上，非常节省空间。\n\n用于计数器且并发量高的情况下，假如用于文章浏览量，你的服务拆分为10台机器，这10台机器可能同时抢夺浏览量为100的这个数字，那么只有一台机器可以成功，剩下9台都会失败，效率太低。此时我们可以使用INCRBY，一台机器过来，我们给它100个浏览量，它自己用去吧，Redis中的数据直接INCRBY 100即可。这样就可以提高效率。\n\n\n# 5.2 list\n\nlist支持双端插入、访问\n\n用作信息流。例如你关注很多公众号，这些公众号发的文章都可以塞进你的list中\n\n\n# 5.3 set\n\n很多人用set的原因估计就是值唯一吧，这个就可以用作点赞列表、好友列表、关注列表、收藏等等..\n\n同时它可以求交集、并集，这样就支持“共同好友”、“你可能认识的人”等等操作\n\n\n# 5.4 zset\n\nzset可以根据score排序，同时保证值唯一。常用于排行榜。\n\n\n# 5.5 hash\n\n可用于购物车，hash的操作很契合“购物车”这一功能需求 ：增加删除商品、增加减小某个商品的数量、选中全部、获取全部商品的数量....',normalizedContent:'# redis数据结构\n\n\n# 1. 简述\n\n想必大家已经了解了redis的几大数据结构，那么数据类型是什么？\n\n😜其实是我自己编的，为了让自己理解这些东西造出来的~~\n\n> 数据结构 ：像string、set、list、zset，我们可以直接使用的这些redis具体的类型。\n> \n> 数据类型 ：上述数据结构底层的实现。\n\n该如何理解这两个词呢？\n\n学习各种语言都是先学各种数据类型，例如int、float、char...\n\n再学各种数据结构，例如栈、队列、树...\n\n数据结构由数据类型组成，就像栈、队列这些结构的底层可以由数组实现。\n\n本篇将会讲述以下内容 ：\n\n * 数据类型 ：sds、intset、dit、ziplist、quicklist、skiplist\n * 用于确认数据结构使用哪种数据结构的redisobject\n * 数据类型 ：string、list、set、zset、hash以及它们的应用场景。\n\n再说一句！本文的数据类型、数据结构都是本人杜撰！便于自己理解，实际上它们都是数据类型\n\n\n# 2. 数据类型\n\n看了一些面试题，出现redis数据类型这一块知识的，对于sds和skiplist较多，dict也有，intset、ziplist、quicklist就比较少了。\n\n主要还是它们的应用场景。\n\n\n# 2.1 sds动态字符串\n\nredis构建了一种结构体来完成存储字符串的功能：简单动态字符串（simple dynamic string），简称sds。\n\nstruct __attribute__ ((__packed__)) sdshdr8{\n    char buf[];\n\n    uint8_t alloc;\n \n    uint8_t len;\n\n    unsigned char flags;\n};\n\n\n * char buf[] ：字节数组，用于存储string/int/float。\n * uint8_t alloc ：记录buf数组申请的总字节数,类型为8位无符号整型。不包括结束标志\'\\0\'。\n * uint8_t len ：记录buf数组中已经使用的字节的数量,类型为:8位无符号整型。不包括结束标志。\n * unsigned char flags ：记录sds的最大空间，即决定alloc的最大值。因为存储空间不同，sds类型也不同，有很多不同类型的sds，例如16位、32位...\n\n之所以被称为动态字符串，因为这个字符串有动态扩容机制：\n\n * 扩容后的空间小于1m ：扩容后的空间大小乘以 2＋1\n * 扩容后的空间大于1m ：空间直接 +1m+1\n\n# 扩容方案:\nni -> nihao\n# 原空间: \n    len=2\n    alloc=2\n# 扩容后:\n    len=5\n    alloc=10\n# 为什么没有加一？不应该是5*2 + 1 = 11吗?\n    因为字符串后面有 \'\\0\', 而这len和alloc两个字段都不计算结束标志。\n    空间确实有了，但是alloc没有计算进去。\n\n\n但是alloc的类型是8位无符号整型，只能存储2^8个数字，太有限，所以redis提供了不同类型的sds，它们的其他特性都相同，只有alloc、len的类型不同，有5位、8位、16位、32位。\n\n如何区分？使用 flag 这个字段。flag有不同的值，分别代表字节大小，5、8、16、32.\n\n总结 ：flag规定alloc的最大值，需要扩容时需要改变alloc甚至flag。alloc规定字符串可以存储多少元素，一旦超过，需要扩容。len是当前元素个数。buf[]存储当前元素。\n\n\n# 2.2 intset\n\nintset是redis中set集合的一种实现方式，基于整数数组来实现，具有长度可变、唯一、有序等特点。\n\ntypedef struct intset {\n    uint32_t encoding;\n    \n    uint32_t length;\n    \n    int8_t contents[];\n} intset;\n\n\n * uint32_t encoding ：数据编码方式，支持存放16位、32位、64位的数据。\n * uint32_t length ：元素个数。\n * int8_t contents[] ：整数数组，保存集合数据。数据范围由encoding确认。\n\n> 那么intset如何维持有序、唯一的特点？\n\n在插入时 ：\n\n 1. 检查插入数据是否太大或太小，是否需要改变encoding编码。\n    \n    如果重置编码，假如重置编码后原来的16位变成32位，需要重新拷贝数组的原有数据到升级后的内存而且需要倒序拷贝防止数据丢失。\n\n 2. 查看数组中是否已经存在该数据，若已存在就不插入，若不存在，二分法获得该数据的插入位置。\n    \n    二分法保证数据有序，数据有序可以使用二分法。\n\n 3. 数组原地扩容，将待插入元素插入\n\n通过第二点就可以保证intset的唯一性和有序性。\n\n上述具体步骤可以打开redis源码阅读。将redi安装包打开即可。\n\n\n# 2.3 dict\n\nredis是典型的键值型（key-value）数据库，它就是靠dict来保持键与值的映射关系的。\n\njava中的map是基于hash的字典结构，redis中的字典dict也是。\n\ndict由三部分组成 ：哈希节点（dictentry）、哈希表（dicthashtable）、字典（dict）。\n\n从小往大说，先说哈希节点与哈希表，一个哈希表可以包含多个哈希节点，哈希节点是键-值型的。\n\n哈希节点：\n\ntypedef struct dictentry {\n    void *key;\n    \n    union {\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n        double d;\n    } value;\n    \n    struct dictentry *next;\n} dictentry;\n\n\n * key：哈希节点的键。\n * value ：哈希节点的值，为联合体类型。\n * *next ：为了方便寻址，每个哈希节点都有指向下一个哈希节点的指针。\n\n哈希表 ：\n\ntypedef struct dictht {\n    dictentry **table;\n    unsigned long size;\n    unsigned long sizemask;\n    unsigned long used;\n} dictht;   \n\n\n * table ：指向键值对数组的指针。数组是指针，table是指向数组的指针，所以table是二级指针。\n * size ：哈希表大小。总等于 2^n （n为整数）。\n * sizemark ：哈希表大小的掩码，总等于size - 1 。\n * used ：哈希节点个数。\n\n为什么有了size表示哈希节点个数，还要使用used多此一举呢？\n\nhash运算会产生hash冲突，会在数组的基础上多一些链表，size表示数组元素个数，used表示数组+链表的元素个数。\n\n当我们向dict添加键值对时，redis首先根据key计算出hash值，然后通过hash & sizemark计算该数据应该放到数组中哪个位置。\n\n\n\n除了哈希节点与哈希表之外，dict最后一个组成：字典 dicthashtable.\n\ntypedef struct dict {\n\tdicttype *type;\n    void *privdata;\n    dictht ht[2];\n    long rehashidx;\n    int16_t pauserehash;\n} ;\n\n\n * *type：本字典的类型，不同类型使用不同hash函数。\n * *privdata ：私有数据，在做特殊hash运算时使用。\n * ht[2] ：一个字典拥有两个哈希表，一个放哈希节点，一个为rehash时使用。\n * rehashidx ：rehash的进度，-1代表未开始。\n * pauserehash ：rehash是否暂停，1则暂停，0则继续。\n\n总结 ：dict底层是基于数组、链表的hash表，数组中保存的是一个个entry键值对，键值对的类型大多是指针，指向sds对象。数组中的entry键值对由next指针连接，便于寻址。\n\n\n# 2.4 ziplist\n\n压缩链表，为了节省内存而设计的链表，由一系列特殊编码的连续空间组成，可以在任意一端进行压入/弹出操作，并且该操作的时间复杂度为 o(1)。\n\n但是成也连续，败也连续，ziplist的诞生是为了解决dict指针过多且内存不连续的问题，不过产生了新问题 ：一旦数据量太大，上哪去找这么多连续的空间？所以很多redis的数据类型只在数据量小的时候用ziplist。\n\ntypedef struct ziplist {\n    uint32_t albytes;\n    uint32_t zltail;\n    uint16_t zllen;\n    entry *entry;\n    uint8_t zlend;\n} ziplist;\n\n\n * zlbytes ：总字节数\n * zltail ：尾节点与起始地址之间的字节数\n * zllen ：entry节点的个数\n * zlend ：结束标志，0xff\n * entry ：ziplist中所有节点，个数、字节大小不定。\n\n\n\nentry字节大小不确定，那遍历的时候该如何遍历呢？数组中的元素字节大小固定，可以知道每次读取几个字节的空间，链表直接使用指针指向下一个元素，那么entry该如何遍历？\n\n只要在entry这个结构内部记录一下使用的空间就行了。\n\n但是entry记录的是上一个entry占用的字节数。（redis7改为此entry字节数）\n\n每一个entry有三个字段 ：\n\n * previous_entry_length ：前一节点的长度，1-5个字节。\n * encoding ：本节点属性，记录content的数据类型（整数/字符串）以及长度。\n * contents ：保存节点数据，可以是字符串或整数。\n\n只要知道前一个节点/本节点的字节数，就可以遍历。\n\n\n# 2.5 quicklist\n\n为了解决ziplist的问题，quicklist诞生了。\n\nziplist的问题是空间连续，但是找不到太大的连续空间。\n\n为了解决这个问题，quicklist采用两种方法 ：\n\n * 限制entry的个数及大小。\n * 使用多个ziplist。\n\n一个5m的数据，使用一个ziplist可能找不到连续的5m空间，但如果可以找到5个连续的1m空间，就可以将这个数据分为5份，使用5个ziplist存储。\n\nredis3.2之后引入的quicklist是一个双端链表，只不过每一个节点都是一个ziplist。\n\n除了控制ziplist的大小，quicklist还对节点的ziplist进行压缩\n\nquicklistnode（节点）源码：\n\ntypedef struct quicklistnode {\n    // 指向前一个结点的指针\n    struct quicklistnode *pre;\n    // 指向后一个节点的指针\n    struct quicklistnode *next;\n    // 当前节点的ziplist指针\n    unsigned char *zl;\n    // 当前节点的ziplist的字节数\n    unsigned int sz;\n    // 当前节点所属的ziplist的entry个数\n    unsigned int count;\n    // 编码方式 1.ziplist  2.lzf压缩模式\n    unsigned int encoding;\n    // 是否被解压缩 1说明被解压了，以后要重新压缩\n    unsigned int recompress;\n}\n\n\nquicklist源码：\n\ntypedef struct quicklist {\n    // 头节点指针\n    quicklistnode *head;\n    // 尾节点指针\n    quicklistnode *tail;\n    // 所有ziplist中的entry个数\n    unsigned long count;\n    // ziplist个数\n    unsigned long len;\n    // ziplist的entry数量上限\n    int fill; // 默认为2\n}\n\n\n\n（源码删了一点没用的）\n\n当存储一定数据时，quicklist的模样 ：\n\n\n\n总结 quicklist特点：\n\n 1. 节点为ziplist的双端链表。\n 2. 控制ziplist中entry的个数以及每个entry的大小。\n 3. 中间节点可以压缩，进一步节省内存。\n\n\n# 2.6 skiplist\n\nskiplist，面试中经常问的跳表，被称为跳表是因为它遍历的时候可以“跳”着遍历。\n\n对于一个有序数组，可以使用二分法快速查找，但是链表怎么快速呢？\n\n正常的链表只有指向前后节点的指针，但是跳表不一样，它有随机个随机指针。对于1-10这几个数组成的跳表，可能1这个元素中有指向5、6、9、10的指针，2有指向3、4、8、10的，10可能有指向1、4、7的指针。这样就可以通过不断的跳跃、比较，快速得到想要的值。此结构正因为这个特点被称为跳表。\n\n当然了，跳表的指针是随机生成的，随机性太大，可能一次就找到值，可能需要一个一个遍历。\n\nskiplist（跳表）首先是链表，但与传统链表有几点差异 ：\n\n * 元素升序排列，不过不是按照元素进行排序，而是根据元素生成的score排序。\n * 节点可能包含多个指针，指针跨度随机。\n\n正因为这两个特点，跳表可以边跳跃边比较，大大提高查询效率。\n\n跳表节点\n\ntypedef struct zskiplistnode {\n    sds ele;\n    double score;\n    zskiplistnode *backward;\n    struct zskiplistlevel {\n        zskiplistnode *forward;\n        unsigned long span;\n    } level[];\n}zskiplistnode;\n\n\n * ele ：节点存储的值。\n * score ：节点的分数，用于排序。\n * backward ：前一个节点的指针。\n * level ：多级索引数组，所有后继节点\n * forward ：一个节点可能有多个level，forward指向这个level代表的节点。\n * span ：索引跨度，第一个节点指向第十个节点，跨度为9\n\n跳表\n\ntypedef struct zskiplist {\n    struct zskiplistnode *header, *tail;\n    unsigned long length;\n    int level;\n}\n\n\n * header tail ：头节点、尾节点。\n * length ：节点数量。\n * level ：最大索引层级，默认为1，最大为32，即一个节点的后继指针可以有1-32个。\n\n\n\nskiplist特点：\n\n 1. 双向链表，每个节点包含score和ele值\n 2. 节点按照score排序，score值一样则按照ele排序\n 3. 每个节点都可以包含多层指针，层数是1-32的随机值\n 4. 不同指针到下一个节点的跨度不同，层级越高，跨度越大。\n 5. 增删改查效率与红黑树基本一致，实现却更简单。\n\n\n# 3. redisobject\n\n学习了以上几种数据类型，有什么用呢？对，组成redis中可以使用的数据结构，那么各个数据结构用什么样的底层实现呢？在哪里可以看到呢？在哪里记录下来呢？\n\nredisobject\n\nredis中的任何数据类型都会被封装为一个redisobject，也叫做redis对象。\n\ntypedef struct redisobject {\n    unsigned type:4;\n    unsigned encoding:4;\n    unsigned lru:24; \n    int refcount;\n    void *ptr;\n}\n\n\n * type ：此对象的类型，分别为string、list、set、zset、hash\n\n * encoding ：此对象的底层实现，上述sds、intset、dict、skiplist...有11个值。\n\n * lru ：记录当前redis对象最近一次访问时间，以便将长时间未使用的对象回收。\n\n * refcount ：对象引用计数器，计数器为0则说明对象无人使用，可以被回收。\n\n * *ptr ：指向具体存放数据的空间。\n\ntype和encoding字段是本篇文章关注的地方。\n\n先来看看encoding字段的11个值 ：\n\n编号   编码方式                      说明\n0    obj_encoding_int          long类型的整数字符串\n1    obj_encoding_raw          raw编码的动态字符串\n2    obj_encoding_embstr       embstr编码的动态字符串\n3    obj_encoding_intset       整数集合\n4    obj_encoding_ziplist      压缩列表\n5    obj_encoding_quicklist    快速列表\n6    obj_encoding_skiplist     跳表\n7    obj_encoding_linkedlist   双端链表\n8    obj_encoding_ht           字典\n9    obj_encoding_zipmap       已废弃\n10   obj_encoding_stream       stream流\n\n可以看到，string有三种编码方式，list有3中编码方式，set有三种编码方式。\n\n----------------------------------------\n\n\n# 4. 数据结构\n\n\n# 4.1 string\n\nstring是redis最常见的数据存储类型。\n\n * 如果存储的字符串长度小于44字节，则会使用embstr编码。此时object head与sds是一片连续空间，申请内存时只需要调用一次内存内存分配函数，效率更高。\n\n * sds长度大于44，编码方式是raw。object head与sds不再连续\n\n\n\n * 如果sds的内容是数字，并且这个数字在long_max范围内就使用int编码方式。int编码方式直接将数据存在redisobject的ptr指针位置（刚好8字节），不需要sds了。\n\n\n\n可以看出明显区别 ：embstr的空间是连续的，因为字符串体积小，容易申请连续空间。\n\n以下向redis存储四个值，分别为 数字、短字符串、44位字符串、45位字符串，查看的编码方式结果如下：\n\nyun:0>set a 12\n"ok"\nyun:0>object encoding a\n"int"\nyun:0>set b xiaoming\n"ok"\nyun:0>object encoding b\n"embstr"\nyun:0>set c 01234567890123456789012345678901234567890123\n"ok"\nyun:0>object encoding c\n"embstr"\nyun:0>set d 012345678901234567890123456789012345678901234\n"ok"\nyun:0>object encoding d\n"raw"\n\n\n\n# 4.2 list\n\nlist拥有三种编码方式 ：linkedlist、ziplist、quicklist。自从quicklist出现后就很少用linkedlist了。\n\n所以在redis3.2版本后，redis统一采用quicklist实现list。\n\n\n\n\n# 4.3 set\n\n * 当存储的数据全部为整数，且元素数量不超过set-max-intset-emtries时，set使用intset编码\n\n * 其他情况使用dict编码，使用它的key，value统一为null。\n\n\n\n\n# 4.4 zset\n\nzset也就是sortedset，每一个元素都有一个用于排序的score值。zset的特点 ：\n\n * score值用于排序\n * 键唯一\n * 可以根据键查询分数\n\n看起来可以用skiplist，但是跳表的键不唯一，而且它的score虽然可以排序，但无法查询。\n\n看起来可以用dict，但dict无法排序。\n\n那么我们将它们结合起来不就行了？一个zset包含一个skiplist和一个dict，添加元素时先向dict添加，保证元素唯一，如果元素唯一再向skiplist添加，保证可排序。\n\ntypedef struct zset {\n    dict *dict;\n    zskiplist *zsl;\n}\n\n\n虽然zset使用了两种结构，但它的编码写成skiplist。\n\n但是当元素数量小于128或元素大小小于64字节时，zset会使用ziplist节省空间。\n\n * 元素数量小于128或元素大小小于64字节时，使用ziplist节省空间。\n * 其他情况使用 dict + skiplist。\n\n\n\n\n# 4.5 hash\n\nhash结构与redis中的zset很像\n\n * 键值存储\n * 可以根据键获取值\n * 键唯一\n\n二者差别例如zset的值必须是数字，用于排序。而hash结构不用排序。\n\nhash底层采用的编码与zset基本一致，只需要把排序有关的skiplist去掉即可 ：\n\n * hash默认使用ziplist编码，以节省内存。ziplist的相邻两个entry分别存储键、值。\n * 当元素数量超过512或任意一个entry节点大小超过64字节时hash结构会转为ht编码，也就是dict。\n\n\n\n\n# 4.6 总结\n\n\n# 5. 应用场景\n\n\n# 5.1 string\n\n 1. 用于做缓存\n 2. setnx 操作生成分布式锁\n 3. 这时可以用于计数器。当数据是数字时，string不会创建新的sds对象，而是将数字存储在redisobject的ptr上，非常节省空间。\n\n用于计数器且并发量高的情况下，假如用于文章浏览量，你的服务拆分为10台机器，这10台机器可能同时抢夺浏览量为100的这个数字，那么只有一台机器可以成功，剩下9台都会失败，效率太低。此时我们可以使用incrby，一台机器过来，我们给它100个浏览量，它自己用去吧，redis中的数据直接incrby 100即可。这样就可以提高效率。\n\n\n# 5.2 list\n\nlist支持双端插入、访问\n\n用作信息流。例如你关注很多公众号，这些公众号发的文章都可以塞进你的list中\n\n\n# 5.3 set\n\n很多人用set的原因估计就是值唯一吧，这个就可以用作点赞列表、好友列表、关注列表、收藏等等..\n\n同时它可以求交集、并集，这样就支持“共同好友”、“你可能认识的人”等等操作\n\n\n# 5.4 zset\n\nzset可以根据score排序，同时保证值唯一。常用于排行榜。\n\n\n# 5.5 hash\n\n可用于购物车，hash的操作很契合“购物车”这一功能需求 ：增加删除商品、增加减小某个商品的数量、选中全部、获取全部商品的数量....',charsets:{cjk:!0},lastUpdated:"2023/06/11, 12:28:11",lastUpdatedTimestamp:1686457691e3},{title:"Redis内存回收",frontmatter:{title:"Redis内存回收",date:"2023-06-11T12:25:09.000Z",permalink:"/pages/73749d/"},regularPath:"/02.%E6%96%87%E7%AB%A0/10.Redis/30.Redis%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6.html",relativePath:"02.文章/10.Redis/30.Redis内存回收.md",key:"v-f8cd9c4a",path:"/pages/73749d/",headers:[{level:2,title:"1. 过期回收",slug:"_1-过期回收",normalizedTitle:"1. 过期回收",charIndex:16},{level:2,title:"2. 内存淘汰",slug:"_2-内存淘汰",normalizedTitle:"2. 内存淘汰",charIndex:853}],headersStr:"1. 过期回收 2. 内存淘汰",content:"# Redis内存回收\n\n\n# 1. 过期回收\n\nRedis支持设置数据有效时间，有效期过了数据就删除掉，那么Redis肯定要增加字段记录数据的有效期，如何增加字段呢？数据到期立马删除吗？\n\n接下来看看Redis采用的过期回收策略：\n\nRedis本身是一个键值型的数据库，因此所有的数据都保存在Dict中，不过在其database结构体中有两个Dict，一个存储所有数据，一个存储有ttl的数据。\n\ntypedef struct redisdb {\n    dict *dict;\n    dict *expires;\n    ...\n    ...\n}\n\n\n * dict ：以key-value形式存储所有数据\n * expires ：以key-ttl形式存储带有过期时间的数据。\n\n想知道一个key是否过期，拿着key去第二个Dict查就行了。\n\n那么数据到期立即删除吗？\n\n不同的key带有不同的过期时间，如果给每一个key都设置定时任务，太浪费资源。\n\nRedis采用两种删除机制：\n\n 1. 惰性删除 ：每次访问时判断是否过期，过期则删除。\n 2. 周期删除 ：通过定时任务周期性的抽部分过期key删除。\n\n惰性删除的优点和缺点都很明显，它不必开启额外的任务，只需要在访问时判断。但是过期数据一直不访问呢？就会遗留在内存。\n\n周期删除又有两种方式：\n\n 1. SLOW ：Redis设置一个定时任务serverCron()，按照1秒10次的频率执行过期Key清理。\n 2. FAST ：Redis的每个事件循环前会调用beforeSleep()，执行过期Key清理。\n\n这两种策略感觉就像迷你版的FullGC和MinorGC。\n\n> Q ：Redis如何知道哪些key过期了？\n> \n> A ：使用两个Dict，一个存放key-value，一个存放key-ttl\n\n> Q ：数据过期立马删除吗？\n> \n> A ：有惰性删除和周期删除两种策略，周期删除有两种方式：FAST、SLOW。\n\n\n# 2. 内存淘汰\n\n内存淘汰 ：当Redis内存使用达到设置的阈值时，Redis主动挑选部分key删除来释放更多的内存。\n\nRedis有八种不同的淘汰策略 ：\n\n策略                作用\nnoeviction        默认策略，不淘汰任何数据，不允许写入新数据\nvolatile-ttl      对设置了ttl的数据比较，淘汰快过期的数据\nallkeys-random    全体数据随即淘汰\nvolatile-random   设置了ttl的数据，随即淘汰\nallkeys-lru       全体数据，基于lru算法进行淘汰\nvolatile-lru      设置了ttl的数据，基于lru算法进行淘汰\nallkeys-lfu       全体数据，基于lfu算法进行淘汰\nvolatile-lfu      设置了ttl的数据，基于lfu算法进行淘汰\n\n * ==LRU==\n   \n   Least Recently Used 最少最近使用\n   \n   用当前时间减去最后一次访问时间，这个值越大，淘汰优先级越高。\n\n * ==LFU==\n   \n   Least Frequently Used 最少频率使用\n   \n   统计每一个key的访问频率，频率越小淘汰优先级越高。",normalizedContent:"# redis内存回收\n\n\n# 1. 过期回收\n\nredis支持设置数据有效时间，有效期过了数据就删除掉，那么redis肯定要增加字段记录数据的有效期，如何增加字段呢？数据到期立马删除吗？\n\n接下来看看redis采用的过期回收策略：\n\nredis本身是一个键值型的数据库，因此所有的数据都保存在dict中，不过在其database结构体中有两个dict，一个存储所有数据，一个存储有ttl的数据。\n\ntypedef struct redisdb {\n    dict *dict;\n    dict *expires;\n    ...\n    ...\n}\n\n\n * dict ：以key-value形式存储所有数据\n * expires ：以key-ttl形式存储带有过期时间的数据。\n\n想知道一个key是否过期，拿着key去第二个dict查就行了。\n\n那么数据到期立即删除吗？\n\n不同的key带有不同的过期时间，如果给每一个key都设置定时任务，太浪费资源。\n\nredis采用两种删除机制：\n\n 1. 惰性删除 ：每次访问时判断是否过期，过期则删除。\n 2. 周期删除 ：通过定时任务周期性的抽部分过期key删除。\n\n惰性删除的优点和缺点都很明显，它不必开启额外的任务，只需要在访问时判断。但是过期数据一直不访问呢？就会遗留在内存。\n\n周期删除又有两种方式：\n\n 1. slow ：redis设置一个定时任务servercron()，按照1秒10次的频率执行过期key清理。\n 2. fast ：redis的每个事件循环前会调用beforesleep()，执行过期key清理。\n\n这两种策略感觉就像迷你版的fullgc和minorgc。\n\n> q ：redis如何知道哪些key过期了？\n> \n> a ：使用两个dict，一个存放key-value，一个存放key-ttl\n\n> q ：数据过期立马删除吗？\n> \n> a ：有惰性删除和周期删除两种策略，周期删除有两种方式：fast、slow。\n\n\n# 2. 内存淘汰\n\n内存淘汰 ：当redis内存使用达到设置的阈值时，redis主动挑选部分key删除来释放更多的内存。\n\nredis有八种不同的淘汰策略 ：\n\n策略                作用\nnoeviction        默认策略，不淘汰任何数据，不允许写入新数据\nvolatile-ttl      对设置了ttl的数据比较，淘汰快过期的数据\nallkeys-random    全体数据随即淘汰\nvolatile-random   设置了ttl的数据，随即淘汰\nallkeys-lru       全体数据，基于lru算法进行淘汰\nvolatile-lru      设置了ttl的数据，基于lru算法进行淘汰\nallkeys-lfu       全体数据，基于lfu算法进行淘汰\nvolatile-lfu      设置了ttl的数据，基于lfu算法进行淘汰\n\n * ==lru==\n   \n   least recently used 最少最近使用\n   \n   用当前时间减去最后一次访问时间，这个值越大，淘汰优先级越高。\n\n * ==lfu==\n   \n   least frequently used 最少频率使用\n   \n   统计每一个key的访问频率，频率越小淘汰优先级越高。",charsets:{cjk:!0},lastUpdated:"2023/06/11, 12:28:11",lastUpdatedTimestamp:1686457691e3},{title:"Redis哨兵集群",frontmatter:{title:"Redis哨兵集群",date:"2023-07-03T21:08:01.000Z",permalink:"/pages/3743cc/"},regularPath:"/02.%E6%96%87%E7%AB%A0/10.Redis/50.Redis%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4.html",relativePath:"02.文章/10.Redis/50.Redis哨兵集群.md",key:"v-1ca94746",path:"/pages/3743cc/",headers:[{level:2,title:"1. 什么是哨兵",slug:"_1-什么是哨兵",normalizedTitle:"1. 什么是哨兵",charIndex:213},{level:2,title:"2. 监控",slug:"_2-监控",normalizedTitle:"2. 监控",charIndex:553},{level:2,title:"3. 自动故障迁移",slug:"_3-自动故障迁移",normalizedTitle:"3. 自动故障迁移",charIndex:395},{level:2,title:"4. sentinel选举领导者",slug:"_4-sentinel选举领导者",normalizedTitle:"4. sentinel选举领导者",charIndex:1531}],headersStr:"1. 什么是哨兵 2. 监控 3. 自动故障迁移 4. sentinel选举领导者",content:"# Redis哨兵集群\n\n在上一篇Redis主从集群原理中，我们学习了主从架构，明白了使用主从集群保证系统高可用的原理，但是在结尾也强调了一个问题：\n\n主从集群的缺点\n\n在一主一从或者一主多从的情况下，如果主服务器挂了，对外提供的服务就不可用了，单点问题没有解决。\n\n怎么解决呢？我们可以借鉴ZooKeeper的做法，如果主节点宕机，在诸多从节点中选一个当主节点就行了。那么谁来选呢？这就是本篇将要学习的内容：哨兵。\n\n\n# 1. 什么是哨兵\n\n哨兵模式是Redis的高可用方式，哨兵节点也是一个Redis节点，不过它不提供数据读写服务，主要用来监控Redis的所有节点。\n\nRedis哨兵的作用：\n\n 1. 监视 ：哨兵会不断检查主节点与从节点是否正常运行。\n 2. 提醒 ：Sentine充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新消息推送给Redis客户端。\n 3. 自动故障迁移 ：如果master出现故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主。\n\n当部署Redis主从集群后，可以再部署哨兵集群用于监视主从集群：\n\n\n\n从图中可以看出来，哨兵也可以是一个集群，你是来监控别人的，结果你自己挂了，这不笑话吗。\n\n\n# 2. 监控\n\nSentinel基于心跳机制检测服务状态，每隔1s向集群中的每一个节点发送ping命令，如果节点回复证明它没问题，如果 master 节点回复 PING 命令的时间超过 down-after-milliseconds 设定的阈值（默认30s），则这个节点会被 sentinel 标记为主观下线，因为这个ping命令可能因为网络延迟没有及时收到回复，所以这是此哨兵主观认为节点下线了。\n\n当sentinel 哨兵节点将节点标记为主观下线后，会向其余所有的 sentinel 发送sentinel is-master-down-by-addr消息，询问其他sentinel是否同意该节点下线，如果超过规定数量(默认一半)的setinel同意，也就是超过一般数量的setinel都认为这个节点主观下线，那么它就会被标记为客观下线。\n\n * 主观下线 ：如果某setinel发现某节点未在规定时间内响应，则认为该节点主观下线。\n * 客观下线 ：若超过指定数量的sentinel都认为该节点主观下线，则该节点客观下线，会触发通知服务将该节点的情况通知给客户端。（指定数量最好设置为哨兵数量的一半多）\n\n\n# 3. 自动故障迁移\n\n也就是重新选举主节点。\n\n一旦发现 master 故障，sentinel 需要在slave中选择一个作为新的master。选举的依据：\n\n 1. 选择优先级最高的节点，通过sentinel配置文件中的replica-priority配置项，这个参数越小，表示优先级越高\n 2. 如果第一步中的优先级相同，选择offset最大的，offset表示主节点向从节点同步数据的偏移量，越大表示同步的数据越多\n 3. 如果第二步offset也相同，选择run id较小的\n\n当选中了其中一个slave为新的master (假如为slave1)后，故障的转移过程如下：\n\n * sentinel集群给slave1发送slaveof no one命令，让该节点称为master。\n * sentinel集群给其他节点发送广播消息，让其他slave节点称为新master的从节点，开始从新的master中同步数据。\n * sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点。\n\n\n# 4. sentinel选举领导者\n\n其实上面的描述并不准确，故障转移是某一个sentinel节点做的，而不是整个sentinel集群做的，那么谁来做这件事呢？一个sentinel集群是有一个头sentinel的，由它来完成主节点的选举。\n\n当主节点被客观下线后，各个哨兵节点会选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。\n\n监视该主节点的所有哨兵都有可能称为领导者，选举使用Raft算法，在没有数据可以进行比较的情况下，Raft的选举更像是先到先得：在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程可以查阅Raft算法。\n\n‍",normalizedContent:"# redis哨兵集群\n\n在上一篇redis主从集群原理中，我们学习了主从架构，明白了使用主从集群保证系统高可用的原理，但是在结尾也强调了一个问题：\n\n主从集群的缺点\n\n在一主一从或者一主多从的情况下，如果主服务器挂了，对外提供的服务就不可用了，单点问题没有解决。\n\n怎么解决呢？我们可以借鉴zookeeper的做法，如果主节点宕机，在诸多从节点中选一个当主节点就行了。那么谁来选呢？这就是本篇将要学习的内容：哨兵。\n\n\n# 1. 什么是哨兵\n\n哨兵模式是redis的高可用方式，哨兵节点也是一个redis节点，不过它不提供数据读写服务，主要用来监控redis的所有节点。\n\nredis哨兵的作用：\n\n 1. 监视 ：哨兵会不断检查主节点与从节点是否正常运行。\n 2. 提醒 ：sentine充当redis客户端的服务发现来源，当集群发生故障转移时，会将最新消息推送给redis客户端。\n 3. 自动故障迁移 ：如果master出现故障，sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主。\n\n当部署redis主从集群后，可以再部署哨兵集群用于监视主从集群：\n\n\n\n从图中可以看出来，哨兵也可以是一个集群，你是来监控别人的，结果你自己挂了，这不笑话吗。\n\n\n# 2. 监控\n\nsentinel基于心跳机制检测服务状态，每隔1s向集群中的每一个节点发送ping命令，如果节点回复证明它没问题，如果 master 节点回复 ping 命令的时间超过 down-after-milliseconds 设定的阈值（默认30s），则这个节点会被 sentinel 标记为主观下线，因为这个ping命令可能因为网络延迟没有及时收到回复，所以这是此哨兵主观认为节点下线了。\n\n当sentinel 哨兵节点将节点标记为主观下线后，会向其余所有的 sentinel 发送sentinel is-master-down-by-addr消息，询问其他sentinel是否同意该节点下线，如果超过规定数量(默认一半)的setinel同意，也就是超过一般数量的setinel都认为这个节点主观下线，那么它就会被标记为客观下线。\n\n * 主观下线 ：如果某setinel发现某节点未在规定时间内响应，则认为该节点主观下线。\n * 客观下线 ：若超过指定数量的sentinel都认为该节点主观下线，则该节点客观下线，会触发通知服务将该节点的情况通知给客户端。（指定数量最好设置为哨兵数量的一半多）\n\n\n# 3. 自动故障迁移\n\n也就是重新选举主节点。\n\n一旦发现 master 故障，sentinel 需要在slave中选择一个作为新的master。选举的依据：\n\n 1. 选择优先级最高的节点，通过sentinel配置文件中的replica-priority配置项，这个参数越小，表示优先级越高\n 2. 如果第一步中的优先级相同，选择offset最大的，offset表示主节点向从节点同步数据的偏移量，越大表示同步的数据越多\n 3. 如果第二步offset也相同，选择run id较小的\n\n当选中了其中一个slave为新的master (假如为slave1)后，故障的转移过程如下：\n\n * sentinel集群给slave1发送slaveof no one命令，让该节点称为master。\n * sentinel集群给其他节点发送广播消息，让其他slave节点称为新master的从节点，开始从新的master中同步数据。\n * sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点。\n\n\n# 4. sentinel选举领导者\n\n其实上面的描述并不准确，故障转移是某一个sentinel节点做的，而不是整个sentinel集群做的，那么谁来做这件事呢？一个sentinel集群是有一个头sentinel的，由它来完成主节点的选举。\n\n当主节点被客观下线后，各个哨兵节点会选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。\n\n监视该主节点的所有哨兵都有可能称为领导者，选举使用raft算法，在没有数据可以进行比较的情况下，raft的选举更像是先到先得：在一轮选举中，哨兵a向b发送成为领导者的申请，如果b没有同意过其他哨兵，则会同意a成为领导者。选举的具体过程可以查阅raft算法。\n\n‍",charsets:{cjk:!0},lastUpdated:"2023/07/03, 21:12:04",lastUpdatedTimestamp:1688389924e3},{title:"常用工具类",frontmatter:{title:"常用工具类",date:"2023-06-13T15:06:07.000Z",permalink:"/pages/70ea3d/"},regularPath:"/02.%E6%96%87%E7%AB%A0/100.%E5%85%B6%E4%BB%96/100.%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB.html",relativePath:"02.文章/100.其他/100.常用工具类.md",key:"v-87b51ada",path:"/pages/70ea3d/",headers:[{level:2,title:"密码加密工具类",slug:"密码加密工具类",normalizedTitle:"密码加密工具类",charIndex:2},{level:2,title:"验证工具类",slug:"验证工具类",normalizedTitle:"验证工具类",charIndex:1772},{level:2,title:"Token生成",slug:"token生成",normalizedTitle:"token生成",charIndex:3883},{level:2,title:"跨域请求配置",slug:"跨域请求配置",normalizedTitle:"跨域请求配置",charIndex:5956}],headersStr:"密码加密工具类 验证工具类 Token生成 跨域请求配置",content:'# 密码加密工具类\n\n类名为PasswordEncoder,没学SpringSecurity时自己写的对密码进行简单的加密工具。\n加密的规则如下:\n\n 1. 用户注册时密码为 123，自动生成的盐为 bgddsa\n 2. 先将123bgddsa使用MD5编码一下，为536D2A9E796B12B877702C02F6763231\n 3. 把盐放在编码后的密码的前面，使用@符号隔开, 存入数据库的密码如下:\n    bgddsa@536D2A9E796B12B877702C02F6763231\n 4. 用户登录时输入用户名、456，根据用户名从数据库中查询出的密码为:bgddsa@536D2A9E796B12B877702C02F6763231\n 5. 将头部@前面的salt取出，为bgddsa，将456bgddsa使用MD5编码一下，再加上salt@, 判断前后两次加密的结果是否相同即可。 需要使用到hutool工具类生成随机数，当然如果自己写也可以。 如果使用hutool工具类，需要加入依赖:\n\n\x3c!--hutool--\x3e\n<dependency>\n    <groupId>cn.hutool</groupId>\n    <artifactId>hutool-all</artifactId>\n    <version>5.7.17</version>\n</dependency>\n\n\nimport cn.hutool.core.util.RandomUtil;\nimport org.springframework.util.DigestUtils;\n\nimport java.nio.charset.StandardCharsets;\n\n/**\n * @description: 密码加密、验证的工具类\n * @author : 小何\n */\npublic class PasswordEncoder {\n\n    public static String encode(String password) {\n        // 生成盐\n        String salt = RandomUtil.randomString(20);\n        // 加密\n        return encode(password,salt);\n    }\n    private static String encode(String password, String salt) {\n        // 加密\n        return salt + "@" + DigestUtils.md5DigestAsHex((password + salt).getBytes(StandardCharsets.UTF_8));\n    }\n\n    /**\n     *\n     * @param encodedPassword: 从数据库中查询的密码\n     * @param rawPassword: 用户输入的密码\n     * @return\n     */\n    public static Boolean matches(String encodedPassword, String rawPassword) {\n        if (encodedPassword == null || rawPassword == null) {\n            return false;\n        }\n        if(!encodedPassword.contains("@")){\n            throw new RuntimeException("密码格式不正确！");\n        }\n        String[] arr = encodedPassword.split("@");\n        // 获取盐\n        String salt = arr[0];\n        // 比较\n        return encodedPassword.equals(encode(rawPassword, salt));\n    }\n}\n\n\n\n# 验证工具类\n\n提供了对某些前端提交数据的验证，例如手机号、邮箱、身份证号..\n\nimport cn.hutool.core.util.StrUtil;\n\n/**\n * @description : 验证手机号、身份证号、密码、验证码、邮箱的工具类\n * @author : 小何\n */\npublic class VerifyUtils {\n    /**\n     * 手机号正则\n     */\n    public static final String PHONE_REGEX = "^1([38][0-9]|4[579]|5[0-3,5-9]|6[6]|7[0135678]|9[89])\\\\d{8}$";\n\n    /**\n     * 邮箱正则\n     */\n    public static final String EMAIL_REGEX = "^[a-zA-Z0-9_-]+@[a-zA-Z0-9_-]+(\\\\.[a-zA-Z0-9_-]+)+$";\n\n    /**\n     * 密码正则。4~32位的字母、数字、下划线\n     */\n    public static final String PASSWORD_REGEX = "^\\\\w{4,32}$";\n\n    /**\n     * 验证码正则, 6位数字或字母\n     */\n    public static final String VERIFY_CODE_REGEX = "^[a-zA-Z\\\\d]{6}$";\n\n    /**\n     * 身份证号正则\n     */\n    public static final String ID_CARD_NUMBER_REGEX_18 = "^[1-9]\\\\d{5}(18|19|([23]\\\\d))\\\\d{2}((0[1-9])|(10|11|12))(([0-2][1-9])|10|20|30|31)\\\\d{3}[0-9Xx]$";\n    public static final String ID_CARD_NUMBER_REGEX_15 = "^[1-9]\\\\d{5}\\\\d{2}((0[1-9])|(10|11|12))(([0-2][1-9])|10|20|30|31)\\\\d{2}$";\n\n    /**\n     * 手机号是否合法\n     * @param phone 要校验的手机号\n     * @return true:符合，false：不符合\n     */\n    public static boolean isPhoneLegal(String phone){\n        return match(phone, PHONE_REGEX);\n    }\n    /**\n     * 是否是无效邮箱格式\n     * @param email 要校验的邮箱\n     * @return true:符合，false：不符合\n     */\n    public static boolean isEmailLegal(String email){\n        return match(email, EMAIL_REGEX);\n    }\n\n    /**\n     * 是否是无效验证码格式\n     * @param code 要校验的验证码\n     * @return true:符合，false：不符合\n     */\n    public static boolean isCodeLegal(String code){\n        return match(code, VERIFY_CODE_REGEX);\n    }\n\n    // 校验是否不符合正则格式\n    private static boolean match(String str, String regex){\n        if (StrUtil.isBlank(str)) {\n            return false;\n        }\n        return str.matches(regex);\n    }\n\n    /**\n     * 验证身份证号是否合法\n     * @param idCard 身份证号\n     * @return true: 合法；    false:不合法\n     */\n    public static boolean isIdCardLegal(String idCard) {\n        if (idCard.length() == 18) {\n            return match(idCard, ID_CARD_NUMBER_REGEX_18);\n        } else {\n            return match(idCard, ID_CARD_NUMBER_REGEX_15);\n        }\n    }\n}\n\n\n\n# Token生成\n\n使用JWT生成工具类。提供了两种方式: 根据Map生成、根据对象生成。 需要使用到hutool依赖、jwt依赖。 需要自定义签名，下面为随便写的签名。\n\n\x3c!--hutool--\x3e\n<dependency>\n    <groupId>com.auth0</groupId>\n    <artifactId>java-jwt</artifactId>\n    <version>4.0.0</version>\n</dependency>\n\n\n<dependency>\n    <groupId>cn.hutool</groupId>\n    <artifactId>hutool-all</artifactId>\n    <version>5.7.17</version>\n</dependency>\n\n\n代码:\n\n\nimport com.auth0.jwt.JWT;\nimport com.auth0.jwt.algorithms.Algorithm;\nimport com.auth0.jwt.interfaces.Claim;\nimport com.auth0.jwt.interfaces.DecodedJWT;\nimport org.apache.commons.beanutils.PropertyUtilsBean;\n\nimport java.beans.PropertyDescriptor;\nimport java.util.Calendar;\nimport java.util.HashMap;\nimport java.util.Map;\n\npublic class JWTUtils {\n    // 签名(可以随意更换)\n    private static final String SIGN = "234as5@4123";\n\n    // 算法\n    private static final Map<String, Object> map = new HashMap<>();\n\n    // 根据map生成token\n    public static String generateToken(Map<String,Object> payload) {\n        Calendar instance = Calendar.getInstance();\n        instance.add(Calendar.HOUR, 30);\n\n        String token = JWT.create().withHeader(map) // 头\n                .withPayload(payload) // 负载\n                .withExpiresAt(instance.getTime()) // 设置过期时间。\n                .sign(Algorithm.HMAC256(SIGN));// 签名，使用算法生成。\n\n        return token;\n    }\n    // 根据对象生成token\n    public static <T> String generateToken(T bean) {\n        Map<String, Object> stringObjectMap = BeanUtil.beanToMap(bean);\n        return generateToken(stringObjectMap);\n    }\n\n\n    /**\n     * 验证token,如果token有错，直接抛出异常了。\n     * @param token token\n     */\n    public static void  verify(String token) {\n        JWT.require(Algorithm.HMAC256(SIGN)).build().verify(token);\n    }\n\n    /**\n     * 获取token信息\n     * @param token token\n     * @return 信息\n     */\n    public static Map<String, Claim> getClaims(String token) {\n        Map<String, ?> map = new HashMap<>();\n        DecodedJWT decodedJWT = JWT.require(Algorithm.HMAC256(SIGN)).build().verify(token);\n        Map<String, Claim> claims = decodedJWT.getClaims();\n        return claims;\n    }\n} \n\n\n\n# 跨域请求配置\n\n @Configuration\npublic class GlobalCorsConfig {\n\n  @Bean\n public CorsFilter getCorsFilter(){\n\n   CorsConfiguration configuration= new CorsConfiguration();\n\n   //添加哪些http方法可以跨域，比如：GET,Post，（多个方法中间以逗号分隔），*号表示所有\n   configuration.addAllowedMethod("*");\n   //添加允许哪个请求进行跨域，*表示所有,可以具体指定http://localhost:8601表示只允许http://localhost:8601/跨域\n   configuration.addAllowedOrigin("*");\n   //所有头信息全部放行\n   configuration.addAllowedHeader("*");\n   //允许跨域发送cookie\n   configuration.setAllowCredentials(true);\n\n   UrlBasedCorsConfigurationSource urlBasedCorsConfigurationSource = new UrlBasedCorsConfigurationSource();\n   urlBasedCorsConfigurationSource.registerCorsConfiguration("/**",configuration);\n   return new CorsFilter(urlBasedCorsConfigurationSource);\n  }\n} \n',normalizedContent:'# 密码加密工具类\n\n类名为passwordencoder,没学springsecurity时自己写的对密码进行简单的加密工具。\n加密的规则如下:\n\n 1. 用户注册时密码为 123，自动生成的盐为 bgddsa\n 2. 先将123bgddsa使用md5编码一下，为536d2a9e796b12b877702c02f6763231\n 3. 把盐放在编码后的密码的前面，使用@符号隔开, 存入数据库的密码如下:\n    bgddsa@536d2a9e796b12b877702c02f6763231\n 4. 用户登录时输入用户名、456，根据用户名从数据库中查询出的密码为:bgddsa@536d2a9e796b12b877702c02f6763231\n 5. 将头部@前面的salt取出，为bgddsa，将456bgddsa使用md5编码一下，再加上salt@, 判断前后两次加密的结果是否相同即可。 需要使用到hutool工具类生成随机数，当然如果自己写也可以。 如果使用hutool工具类，需要加入依赖:\n\n\x3c!--hutool--\x3e\n<dependency>\n    <groupid>cn.hutool</groupid>\n    <artifactid>hutool-all</artifactid>\n    <version>5.7.17</version>\n</dependency>\n\n\nimport cn.hutool.core.util.randomutil;\nimport org.springframework.util.digestutils;\n\nimport java.nio.charset.standardcharsets;\n\n/**\n * @description: 密码加密、验证的工具类\n * @author : 小何\n */\npublic class passwordencoder {\n\n    public static string encode(string password) {\n        // 生成盐\n        string salt = randomutil.randomstring(20);\n        // 加密\n        return encode(password,salt);\n    }\n    private static string encode(string password, string salt) {\n        // 加密\n        return salt + "@" + digestutils.md5digestashex((password + salt).getbytes(standardcharsets.utf_8));\n    }\n\n    /**\n     *\n     * @param encodedpassword: 从数据库中查询的密码\n     * @param rawpassword: 用户输入的密码\n     * @return\n     */\n    public static boolean matches(string encodedpassword, string rawpassword) {\n        if (encodedpassword == null || rawpassword == null) {\n            return false;\n        }\n        if(!encodedpassword.contains("@")){\n            throw new runtimeexception("密码格式不正确！");\n        }\n        string[] arr = encodedpassword.split("@");\n        // 获取盐\n        string salt = arr[0];\n        // 比较\n        return encodedpassword.equals(encode(rawpassword, salt));\n    }\n}\n\n\n\n# 验证工具类\n\n提供了对某些前端提交数据的验证，例如手机号、邮箱、身份证号..\n\nimport cn.hutool.core.util.strutil;\n\n/**\n * @description : 验证手机号、身份证号、密码、验证码、邮箱的工具类\n * @author : 小何\n */\npublic class verifyutils {\n    /**\n     * 手机号正则\n     */\n    public static final string phone_regex = "^1([38][0-9]|4[579]|5[0-3,5-9]|6[6]|7[0135678]|9[89])\\\\d{8}$";\n\n    /**\n     * 邮箱正则\n     */\n    public static final string email_regex = "^[a-za-z0-9_-]+@[a-za-z0-9_-]+(\\\\.[a-za-z0-9_-]+)+$";\n\n    /**\n     * 密码正则。4~32位的字母、数字、下划线\n     */\n    public static final string password_regex = "^\\\\w{4,32}$";\n\n    /**\n     * 验证码正则, 6位数字或字母\n     */\n    public static final string verify_code_regex = "^[a-za-z\\\\d]{6}$";\n\n    /**\n     * 身份证号正则\n     */\n    public static final string id_card_number_regex_18 = "^[1-9]\\\\d{5}(18|19|([23]\\\\d))\\\\d{2}((0[1-9])|(10|11|12))(([0-2][1-9])|10|20|30|31)\\\\d{3}[0-9xx]$";\n    public static final string id_card_number_regex_15 = "^[1-9]\\\\d{5}\\\\d{2}((0[1-9])|(10|11|12))(([0-2][1-9])|10|20|30|31)\\\\d{2}$";\n\n    /**\n     * 手机号是否合法\n     * @param phone 要校验的手机号\n     * @return true:符合，false：不符合\n     */\n    public static boolean isphonelegal(string phone){\n        return match(phone, phone_regex);\n    }\n    /**\n     * 是否是无效邮箱格式\n     * @param email 要校验的邮箱\n     * @return true:符合，false：不符合\n     */\n    public static boolean isemaillegal(string email){\n        return match(email, email_regex);\n    }\n\n    /**\n     * 是否是无效验证码格式\n     * @param code 要校验的验证码\n     * @return true:符合，false：不符合\n     */\n    public static boolean iscodelegal(string code){\n        return match(code, verify_code_regex);\n    }\n\n    // 校验是否不符合正则格式\n    private static boolean match(string str, string regex){\n        if (strutil.isblank(str)) {\n            return false;\n        }\n        return str.matches(regex);\n    }\n\n    /**\n     * 验证身份证号是否合法\n     * @param idcard 身份证号\n     * @return true: 合法；    false:不合法\n     */\n    public static boolean isidcardlegal(string idcard) {\n        if (idcard.length() == 18) {\n            return match(idcard, id_card_number_regex_18);\n        } else {\n            return match(idcard, id_card_number_regex_15);\n        }\n    }\n}\n\n\n\n# token生成\n\n使用jwt生成工具类。提供了两种方式: 根据map生成、根据对象生成。 需要使用到hutool依赖、jwt依赖。 需要自定义签名，下面为随便写的签名。\n\n\x3c!--hutool--\x3e\n<dependency>\n    <groupid>com.auth0</groupid>\n    <artifactid>java-jwt</artifactid>\n    <version>4.0.0</version>\n</dependency>\n\n\n<dependency>\n    <groupid>cn.hutool</groupid>\n    <artifactid>hutool-all</artifactid>\n    <version>5.7.17</version>\n</dependency>\n\n\n代码:\n\n\nimport com.auth0.jwt.jwt;\nimport com.auth0.jwt.algorithms.algorithm;\nimport com.auth0.jwt.interfaces.claim;\nimport com.auth0.jwt.interfaces.decodedjwt;\nimport org.apache.commons.beanutils.propertyutilsbean;\n\nimport java.beans.propertydescriptor;\nimport java.util.calendar;\nimport java.util.hashmap;\nimport java.util.map;\n\npublic class jwtutils {\n    // 签名(可以随意更换)\n    private static final string sign = "234as5@4123";\n\n    // 算法\n    private static final map<string, object> map = new hashmap<>();\n\n    // 根据map生成token\n    public static string generatetoken(map<string,object> payload) {\n        calendar instance = calendar.getinstance();\n        instance.add(calendar.hour, 30);\n\n        string token = jwt.create().withheader(map) // 头\n                .withpayload(payload) // 负载\n                .withexpiresat(instance.gettime()) // 设置过期时间。\n                .sign(algorithm.hmac256(sign));// 签名，使用算法生成。\n\n        return token;\n    }\n    // 根据对象生成token\n    public static <t> string generatetoken(t bean) {\n        map<string, object> stringobjectmap = beanutil.beantomap(bean);\n        return generatetoken(stringobjectmap);\n    }\n\n\n    /**\n     * 验证token,如果token有错，直接抛出异常了。\n     * @param token token\n     */\n    public static void  verify(string token) {\n        jwt.require(algorithm.hmac256(sign)).build().verify(token);\n    }\n\n    /**\n     * 获取token信息\n     * @param token token\n     * @return 信息\n     */\n    public static map<string, claim> getclaims(string token) {\n        map<string, ?> map = new hashmap<>();\n        decodedjwt decodedjwt = jwt.require(algorithm.hmac256(sign)).build().verify(token);\n        map<string, claim> claims = decodedjwt.getclaims();\n        return claims;\n    }\n} \n\n\n\n# 跨域请求配置\n\n @configuration\npublic class globalcorsconfig {\n\n  @bean\n public corsfilter getcorsfilter(){\n\n   corsconfiguration configuration= new corsconfiguration();\n\n   //添加哪些http方法可以跨域，比如：get,post，（多个方法中间以逗号分隔），*号表示所有\n   configuration.addallowedmethod("*");\n   //添加允许哪个请求进行跨域，*表示所有,可以具体指定http://localhost:8601表示只允许http://localhost:8601/跨域\n   configuration.addallowedorigin("*");\n   //所有头信息全部放行\n   configuration.addallowedheader("*");\n   //允许跨域发送cookie\n   configuration.setallowcredentials(true);\n\n   urlbasedcorsconfigurationsource urlbasedcorsconfigurationsource = new urlbasedcorsconfigurationsource();\n   urlbasedcorsconfigurationsource.registercorsconfiguration("/**",configuration);\n   return new corsfilter(urlbasedcorsconfigurationsource);\n  }\n} \n',charsets:{cjk:!0},lastUpdated:"2023/06/14, 09:41:46",lastUpdatedTimestamp:1686706906e3},{title:"Java学习路线",frontmatter:{title:"Java学习路线",date:"2023-06-14T09:28:34.000Z",permalink:"/pages/7ca562/"},regularPath:"/02.%E6%96%87%E7%AB%A0/100.%E5%85%B6%E4%BB%96/1000.Java%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF.html",relativePath:"02.文章/100.其他/1000.Java学习路线.md",key:"v-0d72e0be",path:"/pages/7ca562/",headers:[{level:2,title:"1. 路线",slug:"_1-路线",normalizedTitle:"1. 路线",charIndex:2},{level:2,title:"2. 推荐工具",slug:"_2-推荐工具",normalizedTitle:"2. 推荐工具",charIndex:1156},{level:2,title:"3. 部分技术栈的推荐视频",slug:"_3-部分技术栈的推荐视频",normalizedTitle:"3. 部分技术栈的推荐视频",charIndex:1813},{level:2,title:"4. 一些建议",slug:"_4-一些建议",normalizedTitle:"4. 一些建议",charIndex:2862}],headersStr:"1. 路线 2. 推荐工具 3. 部分技术栈的推荐视频 4. 一些建议",content:"# 1. 路线\n\n 1.  Java基础 -> 集合 -> IO -> stream流 -> 多线程 -> 网络编程\n\n 2.  MySQL\n\n 3.  JDBC\n\n 4.  前端三剑客（建议学习时间1周以内，学html、javascript，会显示数据就行。重点学ajax）\n\n 5.  Servlet （别在jsp上花太多时间）\n\n 6.  跟B站做个Servlet项目，前端做不出来正常，直接领资料\n\n 7.  Maven （后面很多bug都会跟Maven有关~但是只要真的学会了就不会出bug）\n\n 8.  Spring、Mybatis、SpringMVC\n     \n     Spring和Mybatis的顺序看你自己吧。反正最后学MVC。\n     \n     SSM阶段出很多bug很正常，出的bug越多越好，尝试多debug。不用做SSM项目，B站没啥好的SSM项目，自己用SSM写几个增删改查就行了。\n     \n     源码慎学，会打击自己。\n\n 9.  SpringBoot\n\n 10. 可以做SpringBoot项目，也可以学了Mybatis-plus之后做项目，B站有很多SpringBoot项目。\n\n 11. 可以学一下Vue，但是不建议花太多时间\n\n 12. Linux（不需要学很多，会安装卸载，会关防火墙就行了。命令随用随查）\n\n 13. Redis\n\n 14. 给上面你做的项目加上Redis，也可以找个SpringBoot+Redis的项目做做，这边推荐黑马点评\n\n 15. MQ，三个MQ选一个学：RabbitMQ、RocketMQ、Kafka。我推荐 RocketMQ\n\n 16. 做项目，黑马点评 或者 牛客论坛，真的不要小看秒杀在面试里的含金量\n\n 17. Docker （快速安装中间件，可以和下面换顺序）Docker真的很方便家人们，学会了Docker，下面的SpringCloud省好大的力气。\n\n 18. SpringCloud、SpringCloud Alibaba...\n\n 19. 接下来就是JUC、JVM这些面试常用的，同时，计算机基础也要打好~例如计网、操作系统，面试的时候经常会被问到。\n\nSSM、SpringBoot要多花时间。同时算法题和SQL也要多刷。\n\n同时也可以学一些其他的工具或者技术，例如Git，把代码放到Gitee或者Github上，绿油油一片好看的嘞~\n\n最后\n\n最后，上面的技术栈学完了之后可以去看书，因为你技术栈看似“学完了”，但是掌握的怎么样呢？\n同时，可以培养自己根据文档/博客去写项目的能力，给你一个模块的大致描述和完整代码，你可以将模块完整的写出来吗？\n公司总不能为了几个实习生去录制项目的学习视频吧~\n\n\n# 2. 推荐工具\n\n * IDEA ：不用多说吧~\n\n * Postman ：用来发请求的\n\n * DataGrip ：连接数据库的远程工具，跟IDEA是同一个公司的，代码提示很友好\n\n * Navicat ：连接数据库的远程工具，挺好用\n\n * Typora ：记笔记的工具，格式是Markdown格式，各大博客网站都支持。\n   \n   不过图片保存在本地，直接复制粘贴到CSDN后图片会“消失”，可以尝试搭建图床，\n   \n   （关键词搜 ：Typora + picgo + 阿里云 或 Typora + gitee/github）\n   \n   推荐Typora + picgo + 阿里云，一年10块钱速度嘎嘎快\n\n * 思源笔记 ：如果不想发博客，只是想记录一下自己平时的笔记，强烈推荐思源笔记。（付费可以搭图床）\n\n * 魔法 ：dddd，如果没有刚需，只是日常用一下Github，可以下载Steam++。如果想看看外面的世界，可以钞能力，链接就不放了，你去各种编程交流群一问就有。\n\n * FinalShell ：自己的电脑连接Linux的工具，也可以连接云服务器（功能是XShell + Xftp）\n\n * XShell ：连接Linux的工具\n\n * Xftp ：连接Linux后快速上传文件的工具\n\n * ChatGPT ：这个不用我多说了吧，但是如果你不想花钱买外国的手机号并且使用场景不多的话，可以用用盗版的，其实大多数人对 AI 的用处也就水个平时作业，用用国内的那些足够了。\n\n\n# 3. 部分技术栈的推荐视频\n\n不得不说，黑马在Java视频这块很牛逼。\n\n 1. 数据结构与算法\n    \n    【算法大神！爆肝3个月打造【Leetcode算法500题】算法与数据结构从基础到高级全家桶教程，BTAJ等一线大厂面试必问详解！】\n    \n    左程云的算法课，这个视频是阉割版，但是他的分集很好。\n    \n    看完之后可以看B站完整的80h，搜左程云就有了。\n    \n    再看完可以使用钞能力找盗版~\n    \n    关于算法题也可以看看这位哥，他的视频是对力扣一些题的讲解，每集10mins，清晰易懂：\n    \n    \n    \n    算法题建议一天一题。还有SQL，这两个真的很重要。\n\n 2. MySQL\n    \n    https://www.bilibili.com/video/BV1Kr4y1i7ru/?spm_id_from=333.337.search-card.all.click\n\n 3. SSM\n    \n    【黑马程序员SSM框架教程_Spring+SpringMVC+Maven高级+SpringBoot+MyBatisPlus企业实用开发技术】\n    \n    推荐UP主：\n    \n    \n    \n    他的SSM视频每个大概30h，不建议一开始入门看这个，可以先看黑马的SSM，再单看他的视频。\n\n 4. SpringBoot\n    \n    【黑马程序员SpringBoot2全套视频教程，springboot零基础到项目实战（spring boot2完整版）】\n\n 5. Redis\n    \n    【黑马程序员Redis入门到实战教程，深度透析redis底层原理+redis分布式锁+企业解决方案+黑马点评实战项目】\n\n 6. SpringCloud\n    \n    【SpringCloud+RabbitMQ+Docker+Redis+搜索+分布式，系统详解springcloud微服务技术栈课程|黑马程序员Java微服务】\n\n 7. 推荐UP主：\n    \n    \n    \n    他的视频是一些小技术点，例如JWT、Docker快速使用、Vue快速使用、云服务器搭建，后端学Vue的可以看他的Vue的前几集，把生命周期看完就可以了。\n\n 8. 计算机网络\n    \n    湖科大教书匠的计算机网络全网最强无争议\n    \n    【计算机网络微课堂（有字幕无背景音乐版）】\n\n\n# 4. 一些建议\n\n不要刷牛客，因为上面有形形色色的人，你可能会因为他们的成功/失败感到焦虑，如果能化焦虑为动力那其实挺好，但是我们大多数都是普通人，总会被焦虑打垮，所以不到必要的时候千万不要刷牛客！\n如果你还是感到焦虑，点击联系我（女娃点😘，男娃滚😋）\n\n不要摇摆不定，选个方向 all in 就完事了 ，不管是就业还是考研，不管是开发测试运维算法，你要懂得all in的智慧。\n\n我最不推荐的就是临时转换方向，比如你看到今年Java不好今年C++不好，赶紧转方向。这种最愚蠢了。我也不推荐螳臂当车，学历不好就不要 all in 那种学历要求高的方向。\n\n养成 看书/文章/博客 的习惯，并且写读后感，哪怕照着书抄一遍都会有收获。写博客/笔记不是为了哪个平台的那点粉丝的，这个在你准备面试的时候会有很大帮助。\n\n多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题",normalizedContent:"# 1. 路线\n\n 1.  java基础 -> 集合 -> io -> stream流 -> 多线程 -> 网络编程\n\n 2.  mysql\n\n 3.  jdbc\n\n 4.  前端三剑客（建议学习时间1周以内，学html、javascript，会显示数据就行。重点学ajax）\n\n 5.  servlet （别在jsp上花太多时间）\n\n 6.  跟b站做个servlet项目，前端做不出来正常，直接领资料\n\n 7.  maven （后面很多bug都会跟maven有关~但是只要真的学会了就不会出bug）\n\n 8.  spring、mybatis、springmvc\n     \n     spring和mybatis的顺序看你自己吧。反正最后学mvc。\n     \n     ssm阶段出很多bug很正常，出的bug越多越好，尝试多debug。不用做ssm项目，b站没啥好的ssm项目，自己用ssm写几个增删改查就行了。\n     \n     源码慎学，会打击自己。\n\n 9.  springboot\n\n 10. 可以做springboot项目，也可以学了mybatis-plus之后做项目，b站有很多springboot项目。\n\n 11. 可以学一下vue，但是不建议花太多时间\n\n 12. linux（不需要学很多，会安装卸载，会关防火墙就行了。命令随用随查）\n\n 13. redis\n\n 14. 给上面你做的项目加上redis，也可以找个springboot+redis的项目做做，这边推荐黑马点评\n\n 15. mq，三个mq选一个学：rabbitmq、rocketmq、kafka。我推荐 rocketmq\n\n 16. 做项目，黑马点评 或者 牛客论坛，真的不要小看秒杀在面试里的含金量\n\n 17. docker （快速安装中间件，可以和下面换顺序）docker真的很方便家人们，学会了docker，下面的springcloud省好大的力气。\n\n 18. springcloud、springcloud alibaba...\n\n 19. 接下来就是juc、jvm这些面试常用的，同时，计算机基础也要打好~例如计网、操作系统，面试的时候经常会被问到。\n\nssm、springboot要多花时间。同时算法题和sql也要多刷。\n\n同时也可以学一些其他的工具或者技术，例如git，把代码放到gitee或者github上，绿油油一片好看的嘞~\n\n最后\n\n最后，上面的技术栈学完了之后可以去看书，因为你技术栈看似“学完了”，但是掌握的怎么样呢？\n同时，可以培养自己根据文档/博客去写项目的能力，给你一个模块的大致描述和完整代码，你可以将模块完整的写出来吗？\n公司总不能为了几个实习生去录制项目的学习视频吧~\n\n\n# 2. 推荐工具\n\n * idea ：不用多说吧~\n\n * postman ：用来发请求的\n\n * datagrip ：连接数据库的远程工具，跟idea是同一个公司的，代码提示很友好\n\n * navicat ：连接数据库的远程工具，挺好用\n\n * typora ：记笔记的工具，格式是markdown格式，各大博客网站都支持。\n   \n   不过图片保存在本地，直接复制粘贴到csdn后图片会“消失”，可以尝试搭建图床，\n   \n   （关键词搜 ：typora + picgo + 阿里云 或 typora + gitee/github）\n   \n   推荐typora + picgo + 阿里云，一年10块钱速度嘎嘎快\n\n * 思源笔记 ：如果不想发博客，只是想记录一下自己平时的笔记，强烈推荐思源笔记。（付费可以搭图床）\n\n * 魔法 ：dddd，如果没有刚需，只是日常用一下github，可以下载steam++。如果想看看外面的世界，可以钞能力，链接就不放了，你去各种编程交流群一问就有。\n\n * finalshell ：自己的电脑连接linux的工具，也可以连接云服务器（功能是xshell + xftp）\n\n * xshell ：连接linux的工具\n\n * xftp ：连接linux后快速上传文件的工具\n\n * chatgpt ：这个不用我多说了吧，但是如果你不想花钱买外国的手机号并且使用场景不多的话，可以用用盗版的，其实大多数人对 ai 的用处也就水个平时作业，用用国内的那些足够了。\n\n\n# 3. 部分技术栈的推荐视频\n\n不得不说，黑马在java视频这块很牛逼。\n\n 1. 数据结构与算法\n    \n    【算法大神！爆肝3个月打造【leetcode算法500题】算法与数据结构从基础到高级全家桶教程，btaj等一线大厂面试必问详解！】\n    \n    左程云的算法课，这个视频是阉割版，但是他的分集很好。\n    \n    看完之后可以看b站完整的80h，搜左程云就有了。\n    \n    再看完可以使用钞能力找盗版~\n    \n    关于算法题也可以看看这位哥，他的视频是对力扣一些题的讲解，每集10mins，清晰易懂：\n    \n    \n    \n    算法题建议一天一题。还有sql，这两个真的很重要。\n\n 2. mysql\n    \n    https://www.bilibili.com/video/bv1kr4y1i7ru/?spm_id_from=333.337.search-card.all.click\n\n 3. ssm\n    \n    【黑马程序员ssm框架教程_spring+springmvc+maven高级+springboot+mybatisplus企业实用开发技术】\n    \n    推荐up主：\n    \n    \n    \n    他的ssm视频每个大概30h，不建议一开始入门看这个，可以先看黑马的ssm，再单看他的视频。\n\n 4. springboot\n    \n    【黑马程序员springboot2全套视频教程，springboot零基础到项目实战（spring boot2完整版）】\n\n 5. redis\n    \n    【黑马程序员redis入门到实战教程，深度透析redis底层原理+redis分布式锁+企业解决方案+黑马点评实战项目】\n\n 6. springcloud\n    \n    【springcloud+rabbitmq+docker+redis+搜索+分布式，系统详解springcloud微服务技术栈课程|黑马程序员java微服务】\n\n 7. 推荐up主：\n    \n    \n    \n    他的视频是一些小技术点，例如jwt、docker快速使用、vue快速使用、云服务器搭建，后端学vue的可以看他的vue的前几集，把生命周期看完就可以了。\n\n 8. 计算机网络\n    \n    湖科大教书匠的计算机网络全网最强无争议\n    \n    【计算机网络微课堂（有字幕无背景音乐版）】\n\n\n# 4. 一些建议\n\n不要刷牛客，因为上面有形形色色的人，你可能会因为他们的成功/失败感到焦虑，如果能化焦虑为动力那其实挺好，但是我们大多数都是普通人，总会被焦虑打垮，所以不到必要的时候千万不要刷牛客！\n如果你还是感到焦虑，点击联系我（女娃点😘，男娃滚😋）\n\n不要摇摆不定，选个方向 all in 就完事了 ，不管是就业还是考研，不管是开发测试运维算法，你要懂得all in的智慧。\n\n我最不推荐的就是临时转换方向，比如你看到今年java不好今年c++不好，赶紧转方向。这种最愚蠢了。我也不推荐螳臂当车，学历不好就不要 all in 那种学历要求高的方向。\n\n养成 看书/文章/博客 的习惯，并且写读后感，哪怕照着书抄一遍都会有收获。写博客/笔记不是为了哪个平台的那点粉丝的，这个在你准备面试的时候会有很大帮助。\n\n多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题多刷题",charsets:{cjk:!0},lastUpdated:"2024/02/15, 16:56:10",lastUpdatedTimestamp:170798737e4},{title:"如何将IP地址存入MySQL",frontmatter:{title:"如何将IP地址存入MySQL",date:"2023-06-11T19:28:31.000Z",permalink:"/pages/ad5a8e/"},regularPath:"/02.%E6%96%87%E7%AB%A0/100.%E5%85%B6%E4%BB%96/5.%E5%A6%82%E4%BD%95%E5%B0%86IP%E5%9C%B0%E5%9D%80%E5%AD%98%E5%85%A5MySQL.html",relativePath:"02.文章/100.其他/5.如何将IP地址存入MySQL.md",key:"v-689aeb6e",path:"/pages/ad5a8e/",headersStr:null,content:"之前被问过这样一个面试题：这边想要记录用户的IP地址，该怎么存储呢？\nhiahiahia😁我看过这篇文章~\n现在重新总结一下\n假如IP地址为：192.168.101.24\n\n可见IP地址共分为4块，每一块用点相连接，可以使用MySQL中的int类型，一共32位，每8位存储一小块IP地址。\n\n例如 192 的二进制为 00000000 00000000 00000000 11000000，将其左移24位后得到：\n11000000 00000000 00000000 00000000\n后面的那么多0可以直接抛弃掉。\n\n接下来是168，它的二进制为: 00000000 00000000 00000000 10101000\n由于192用了最高的8位(第一个字节)，168就用后面的8位(第二个字节)，将168移位16位后：\n00000000 10101000 0000000 000000000\n\n接下来是101，它的二进制为：00000000 00000000 00000000 1100101\n前两个字节都被用了，现在就用第三个字节：\n00000000 00000000 10101000 00000000\n\n最后是24，它只剩最后一个字节可用，不需要移位。00000000 00000000 00000000 00011000 移0位后：\n00000000 00000000 00000000 00011000\n\n将这四部分组成一起：11000000 10101000 11001010 00011000，于是得到一个无符号整数，存入数据库。 取出来的时候反方向的钟就行了~\n\n注意\n\n那一大串可不是直接当字符串存入MySQL，而是将其对应的十进制数以int类型存入MySQL。",normalizedContent:"之前被问过这样一个面试题：这边想要记录用户的ip地址，该怎么存储呢？\nhiahiahia😁我看过这篇文章~\n现在重新总结一下\n假如ip地址为：192.168.101.24\n\n可见ip地址共分为4块，每一块用点相连接，可以使用mysql中的int类型，一共32位，每8位存储一小块ip地址。\n\n例如 192 的二进制为 00000000 00000000 00000000 11000000，将其左移24位后得到：\n11000000 00000000 00000000 00000000\n后面的那么多0可以直接抛弃掉。\n\n接下来是168，它的二进制为: 00000000 00000000 00000000 10101000\n由于192用了最高的8位(第一个字节)，168就用后面的8位(第二个字节)，将168移位16位后：\n00000000 10101000 0000000 000000000\n\n接下来是101，它的二进制为：00000000 00000000 00000000 1100101\n前两个字节都被用了，现在就用第三个字节：\n00000000 00000000 10101000 00000000\n\n最后是24，它只剩最后一个字节可用，不需要移位。00000000 00000000 00000000 00011000 移0位后：\n00000000 00000000 00000000 00011000\n\n将这四部分组成一起：11000000 10101000 11001010 00011000，于是得到一个无符号整数，存入数据库。 取出来的时候反方向的钟就行了~\n\n注意\n\n那一大串可不是直接当字符串存入mysql，而是将其对应的十进制数以int类型存入mysql。",charsets:{cjk:!0},lastUpdated:"2023/06/11, 21:22:31",lastUpdatedTimestamp:1686489751e3},{title:"Git踩坑",frontmatter:{title:"Git踩坑",date:"2023-07-04T18:32:54.000Z",permalink:"/pages/f63fe9/"},regularPath:"/02.%E6%96%87%E7%AB%A0/1000.%E5%AE%9E%E4%B9%A0%E5%B0%8F%E7%BB%93/1.Git%E8%B8%A9%E5%9D%91.html",relativePath:"02.文章/1000.实习小结/1.Git踩坑.md",key:"v-30dbcc76",path:"/pages/f63fe9/",headers:[{level:2,title:"1. 切换分支",slug:"_1-切换分支",normalizedTitle:"1. 切换分支",charIndex:87},{level:2,title:"2. 忘记切换分支",slug:"_2-忘记切换分支",normalizedTitle:"2. 忘记切换分支",charIndex:580},{level:2,title:"3. poll",slug:"_3-poll",normalizedTitle:"3. poll",charIndex:1062},{level:2,title:"4. 部署到测试环境",slug:"_4-部署到测试环境",normalizedTitle:"4. 部署到测试环境",charIndex:1568}],headersStr:"1. 切换分支 2. 忘记切换分支 3. poll 4. 部署到测试环境",content:'笔记\n\n尽管在实习前我在B站看了很多关于实习踩坑的视频，也问了一些学长他们踩的坑，但是该踩的坑还是一个都不会少的~\n本篇笔记记录一下自己在公司使用Git时出的bug\n\n\n# 1. 切换分支\n\n一般的流程应该是: 老大跟你说要参与哪个项目，把项目源码链接发你（GitLab/Github/Gitee），拿到手上后拉下来默认是主分支， 也就是master，但是一般来说是不允许开发人员往 master 分支中 push 代码的，这时候你就要切换到当前版本的分支。\n切换方法： 打开IDEA中Git的管理框（我的是2023新UI，旧UI应该在最上面的中间）\n然后点击Fatch\n点击之后就会看到右下角除了master之外又蹦出来项目中的其他的分支\n这时你又会看到分为 Local Branches 和 Remote Branches\nLocal Branches： 本地的分支，也就是你在远程仓库中拉取的分支。\nRemote Branches：远程的分支，也就是现在仓库中的所有分支。\n我们就在Remote Branches中选择将要切换的分支\n\n\n点击某个远程分支之后有一个checkout，点击checkout就可以把这个分支拉到本地，应该会默认切换本地的分支，如果没有切换就手动checkout一下。\n\n切换到当前版本的分支之后就可以愉快的写代码了~\n\n\n# 2. 忘记切换分支\n\n我就忘记切换分支了，然后在master中写的代码，写完之后 commit -> push 一条龙，哇趣 master 不让 push！！！\n于是我赶紧切换回开发版本，暂且称它为 dev1.0.0 吧。\n切换到 dev1.0.0 之后发现我的代码没了！！ 好的嘛，现在的问题就是：我在 master 写的代码 commit 之后，切换回 dev1.0 发现消失了。\n那肯定不能重新写啊，现在要做的就是把 master 中已经commit的代码拉到dev分支的本地，然后重新上传。\n解决：要确保代码在msater中已经commit了，并且现在dev1.0分支是最新的（别忘记poll一下哦）。\n现在是dev1.0分支，打开Git Log\n\n在这里你可以看到所有人的 commit/push 记录，找到 master 并且找到你自己，并且找到那一条需要恢复的记录。\n\n假如我刚才commit的是 "队列的最大值" 这一条记录，我现在想把它拉回到dev本地，那么我右键之后点击Cherry-Pick然后稍等片刻就可以看到刚才写的代码了~。\n\n\n\n# 3. poll\n\n自己写项目的时候往往就一个分支用到底，而且不会有别人往这个项目里面写代码。但是在公司时时刻刻都会有人往Github上放代码。\n设想这个场景：你和我咱俩人同一天入职，同一天写代码，你负责订单order模块，我负责送餐sendFood模块。\n我们同一天拉取代码，那么这个时候咱俩得到的代码就是一样的，但是几天之后，你在order模块添加了A类与B类，我在sendFood模块中添加了G类与O类。\n现在咱俩人的代码不一样，你的电脑里没有我写的G和O，我的电脑里没有你写的A和B。\n你先写完push上去了，现在的Github代码在我们入职时初始代码的前提下增加了你的A和B。但是我写完之后也push了一下，会发生什么事情？\n我 push 上去的代码没有你的代码，那么你之前push上去的代码就会被覆盖！。\n简而言之：你白干了。\n想要避免这种情况（也是实习生非常非常容易出现的问题）：push代码之前先poll代码。\n也就是往上放代码之前先把代码拉到你的电脑上。流程是：poll -> commit -> push\n在IDEA中就更简单了，下面这三个按钮从左到右挨个按一遍就可以避免上述问题：\n\n\n\n# 4. 部署到测试环境\n\n一大早醒来，测试跟我说我写的接口全没有过😢🥲，把我吓得心惊胆战，我想这怎么可能呢？于是我打开线上地址，测试了一下还真是全都没有过....但是我在本地是全部都可以跑通的啊，于是我开始打开测试环境的日志去查（公司用的ES），发现这跟我写的代码逻辑查库顺序不太一样但是似曾相识啊！！\n这是我前天写的代码！这时基本已经定位到问题了：我的代码没有放到测试环境下！\n为了验证是不是这个问题，我把之前写的导出文件的接口测试了一下，发现Excel文件确实跟我刚调好的格式不一样。\n现在的问题是：我的代码放到开发环境了，但是没有放到测试环境。\n于是我打开IDEA看远程分支，确实有一个 “xxx_test”，于是我把它拉到本地，但是我发现我commit的时候本地并没有代码需要提交到test分支里\n不对劲啊，我的代码应该没有在test分支commit过啊。后来带我的大哥说，你要把开发分支中已经commit的代码merge到测试分支。\n\n于是步骤如下：\n\n 1. 切换到test分支\n 2. 将开发分支的代码merge到test分支\n 3. 将合并后的代码push到仓库中。',normalizedContent:'笔记\n\n尽管在实习前我在b站看了很多关于实习踩坑的视频，也问了一些学长他们踩的坑，但是该踩的坑还是一个都不会少的~\n本篇笔记记录一下自己在公司使用git时出的bug\n\n\n# 1. 切换分支\n\n一般的流程应该是: 老大跟你说要参与哪个项目，把项目源码链接发你（gitlab/github/gitee），拿到手上后拉下来默认是主分支， 也就是master，但是一般来说是不允许开发人员往 master 分支中 push 代码的，这时候你就要切换到当前版本的分支。\n切换方法： 打开idea中git的管理框（我的是2023新ui，旧ui应该在最上面的中间）\n然后点击fatch\n点击之后就会看到右下角除了master之外又蹦出来项目中的其他的分支\n这时你又会看到分为 local branches 和 remote branches\nlocal branches： 本地的分支，也就是你在远程仓库中拉取的分支。\nremote branches：远程的分支，也就是现在仓库中的所有分支。\n我们就在remote branches中选择将要切换的分支\n\n\n点击某个远程分支之后有一个checkout，点击checkout就可以把这个分支拉到本地，应该会默认切换本地的分支，如果没有切换就手动checkout一下。\n\n切换到当前版本的分支之后就可以愉快的写代码了~\n\n\n# 2. 忘记切换分支\n\n我就忘记切换分支了，然后在master中写的代码，写完之后 commit -> push 一条龙，哇趣 master 不让 push！！！\n于是我赶紧切换回开发版本，暂且称它为 dev1.0.0 吧。\n切换到 dev1.0.0 之后发现我的代码没了！！ 好的嘛，现在的问题就是：我在 master 写的代码 commit 之后，切换回 dev1.0 发现消失了。\n那肯定不能重新写啊，现在要做的就是把 master 中已经commit的代码拉到dev分支的本地，然后重新上传。\n解决：要确保代码在msater中已经commit了，并且现在dev1.0分支是最新的（别忘记poll一下哦）。\n现在是dev1.0分支，打开git log\n\n在这里你可以看到所有人的 commit/push 记录，找到 master 并且找到你自己，并且找到那一条需要恢复的记录。\n\n假如我刚才commit的是 "队列的最大值" 这一条记录，我现在想把它拉回到dev本地，那么我右键之后点击cherry-pick然后稍等片刻就可以看到刚才写的代码了~。\n\n\n\n# 3. poll\n\n自己写项目的时候往往就一个分支用到底，而且不会有别人往这个项目里面写代码。但是在公司时时刻刻都会有人往github上放代码。\n设想这个场景：你和我咱俩人同一天入职，同一天写代码，你负责订单order模块，我负责送餐sendfood模块。\n我们同一天拉取代码，那么这个时候咱俩得到的代码就是一样的，但是几天之后，你在order模块添加了a类与b类，我在sendfood模块中添加了g类与o类。\n现在咱俩人的代码不一样，你的电脑里没有我写的g和o，我的电脑里没有你写的a和b。\n你先写完push上去了，现在的github代码在我们入职时初始代码的前提下增加了你的a和b。但是我写完之后也push了一下，会发生什么事情？\n我 push 上去的代码没有你的代码，那么你之前push上去的代码就会被覆盖！。\n简而言之：你白干了。\n想要避免这种情况（也是实习生非常非常容易出现的问题）：push代码之前先poll代码。\n也就是往上放代码之前先把代码拉到你的电脑上。流程是：poll -> commit -> push\n在idea中就更简单了，下面这三个按钮从左到右挨个按一遍就可以避免上述问题：\n\n\n\n# 4. 部署到测试环境\n\n一大早醒来，测试跟我说我写的接口全没有过😢🥲，把我吓得心惊胆战，我想这怎么可能呢？于是我打开线上地址，测试了一下还真是全都没有过....但是我在本地是全部都可以跑通的啊，于是我开始打开测试环境的日志去查（公司用的es），发现这跟我写的代码逻辑查库顺序不太一样但是似曾相识啊！！\n这是我前天写的代码！这时基本已经定位到问题了：我的代码没有放到测试环境下！\n为了验证是不是这个问题，我把之前写的导出文件的接口测试了一下，发现excel文件确实跟我刚调好的格式不一样。\n现在的问题是：我的代码放到开发环境了，但是没有放到测试环境。\n于是我打开idea看远程分支，确实有一个 “xxx_test”，于是我把它拉到本地，但是我发现我commit的时候本地并没有代码需要提交到test分支里\n不对劲啊，我的代码应该没有在test分支commit过啊。后来带我的大哥说，你要把开发分支中已经commit的代码merge到测试分支。\n\n于是步骤如下：\n\n 1. 切换到test分支\n 2. 将开发分支的代码merge到test分支\n 3. 将合并后的代码push到仓库中。',charsets:{cjk:!0},lastUpdated:"2023/07/13, 12:36:57",lastUpdatedTimestamp:1689223017e3},{title:"xxl job Access token is wrong",frontmatter:{title:"xxl job Access token is wrong",date:"2023-11-09T13:14:25.000Z",permalink:"/pages/65cd6f/"},regularPath:"/02.%E6%96%87%E7%AB%A0/200.%E8%B8%A9%E5%9D%91/10.xxl%20job%20Access%20token%20is%20wrong.html",relativePath:"02.文章/200.踩坑/10.xxl job Access token is wrong.md",key:"v-aebcce32",path:"/pages/65cd6f/",headersStr:null,content:"朋友遇到了XXL-JOB的一个问题：\n\nxxl-job registry fail, registryParam:RegistryParam{registryGroup= EXECUTOR , registryKey= xxl-job-executor-sample , registryValue= http://10.16.245.130:9999/ }, registryResult:ReturnT [code=500, msg=The accessToken is wrong.]\n\n\n意思就是执行器注册失败了，报错信息是 token错了。\n\n解决：\n\n 1. 检查版本。\n    \n    我们都知道使用 xxl-job 的时候需要在配置文件中配置一下\n    \n    xxl.job.accessToken=default_token\n    \n    \n    但是 2.4.0 跟 2.2.0 用的是不一样的。\n    \n    2.2.0版本的 xxl-job 解析时读的是：\n    \n    @Value(${xxl.job.admin.accessToken})\n    \n    \n    所以你看看自己的版本，如果是2.2.0 就要多加一个 admin\n\n 2. 检查配置\n    \n    自己配置的配置类有可能出错，就是那个叫 XxlJobConfig 的类，看看到底有没有指定 accessToken\n    \n    同样别忘了其他配置，尽量在源码里面抄。\n    \n    \n\n原因：第一个就不说了，连配置都出错了肯定连不上。说一下第二个的原因。\n\n我们引入的 xxl-job-core 依赖中有一个类：AdminBizClient ，这个是执行器给调度中心发消息，也就是发HTTP请求的类，是HTTP请求就有可能带token，那么token从哪里来？对，从 XxlJobSpringExecutor 中由你来配置，但是！你没有配置，那么发过去的请求就没有token！所以就没法注册喽~",normalizedContent:"朋友遇到了xxl-job的一个问题：\n\nxxl-job registry fail, registryparam:registryparam{registrygroup= executor , registrykey= xxl-job-executor-sample , registryvalue= http://10.16.245.130:9999/ }, registryresult:returnt [code=500, msg=the accesstoken is wrong.]\n\n\n意思就是执行器注册失败了，报错信息是 token错了。\n\n解决：\n\n 1. 检查版本。\n    \n    我们都知道使用 xxl-job 的时候需要在配置文件中配置一下\n    \n    xxl.job.accesstoken=default_token\n    \n    \n    但是 2.4.0 跟 2.2.0 用的是不一样的。\n    \n    2.2.0版本的 xxl-job 解析时读的是：\n    \n    @value(${xxl.job.admin.accesstoken})\n    \n    \n    所以你看看自己的版本，如果是2.2.0 就要多加一个 admin\n\n 2. 检查配置\n    \n    自己配置的配置类有可能出错，就是那个叫 xxljobconfig 的类，看看到底有没有指定 accesstoken\n    \n    同样别忘了其他配置，尽量在源码里面抄。\n    \n    \n\n原因：第一个就不说了，连配置都出错了肯定连不上。说一下第二个的原因。\n\n我们引入的 xxl-job-core 依赖中有一个类：adminbizclient ，这个是执行器给调度中心发消息，也就是发http请求的类，是http请求就有可能带token，那么token从哪里来？对，从 xxljobspringexecutor 中由你来配置，但是！你没有配置，那么发过去的请求就没有token！所以就没法注册喽~",charsets:{cjk:!0},lastUpdated:"2023/11/09, 13:28:41",lastUpdatedTimestamp:1699507721e3},{title:"国际化时需要返回给前端一段json，json工具不同结果报错",frontmatter:{title:"国际化时需要返回给前端一段json，json工具不同结果报错",date:"2023-11-09T13:16:56.000Z",permalink:"/pages/3cac9b/"},regularPath:"/02.%E6%96%87%E7%AB%A0/200.%E8%B8%A9%E5%9D%91/20.%E5%9B%BD%E9%99%85%E5%8C%96%E6%97%B6%E9%9C%80%E8%A6%81%E8%BF%94%E5%9B%9E%E7%BB%99%E5%89%8D%E7%AB%AF%E4%B8%80%E6%AE%B5json%EF%BC%8Cjson%E5%B7%A5%E5%85%B7%E4%B8%8D%E5%90%8C%E7%BB%93%E6%9E%9C%E6%8A%A5%E9%94%99.html",relativePath:"02.文章/200.踩坑/20.国际化时需要返回给前端一段json，json工具不同结果报错.md",key:"v-59982f2a",path:"/pages/3cac9b/",headersStr:null,content:'在 xxl-job 中用到了I18Util，也就是国际化，这个东西配置后需要在 cookie 中 进行国际化。前端需要的时候再调用对应的后端返回的json串。\n\n源码中使用 com.fasterxml.jackson.databind.ObjectMapper 进行json的格式化，我用了 com.google.gson.Gson 。\n\n但是我报错：\n\n10:34:17.510 logback [http-nio-8080-exec-3] ERROR freemarker.runtime - Error executing FreeMarker template\nfreemarker.core._MiscTemplateException: Failed to "?eval" string with this error:\n\n---begin-message---\nSyntax error in ?eval-ed string in line 1, column 6248:\nLexical error: encountered "u" (117), after "\\"{0}/{1} [\\u4efb\\u52a1ID\\\\".\n---end-message---\n\nThe failing expression:\n==> I18nUtil.getMultString()?eval  [in template "common/common.macro.ftl" at line 32, column 25]\n\n----\nFTL stack trace ("~" means nesting-related):\n\t- Failed at: #global I18n = I18nUtil.getMultString...  [in template "common/common.macro.ftl" in macro "commonStyle" at line 32, column 9]\n\t- Reached through: @netCommon.commonStyle  [in template "login.ftl" at line 5, column 9]\n----\n\n\n生成的json串是一样的：\n\n\n\n但是我还没找到原因。\n\n参考文章：\n\n[[FreeMarker Error] Failed to "?eval" string]',normalizedContent:'在 xxl-job 中用到了i18util，也就是国际化，这个东西配置后需要在 cookie 中 进行国际化。前端需要的时候再调用对应的后端返回的json串。\n\n源码中使用 com.fasterxml.jackson.databind.objectmapper 进行json的格式化，我用了 com.google.gson.gson 。\n\n但是我报错：\n\n10:34:17.510 logback [http-nio-8080-exec-3] error freemarker.runtime - error executing freemarker template\nfreemarker.core._misctemplateexception: failed to "?eval" string with this error:\n\n---begin-message---\nsyntax error in ?eval-ed string in line 1, column 6248:\nlexical error: encountered "u" (117), after "\\"{0}/{1} [\\u4efb\\u52a1id\\\\".\n---end-message---\n\nthe failing expression:\n==> i18nutil.getmultstring()?eval  [in template "common/common.macro.ftl" at line 32, column 25]\n\n----\nftl stack trace ("~" means nesting-related):\n\t- failed at: #global i18n = i18nutil.getmultstring...  [in template "common/common.macro.ftl" in macro "commonstyle" at line 32, column 9]\n\t- reached through: @netcommon.commonstyle  [in template "login.ftl" at line 5, column 9]\n----\n\n\n生成的json串是一样的：\n\n\n\n但是我还没找到原因。\n\n参考文章：\n\n[[freemarker error] failed to "?eval" string]',charsets:{cjk:!0},lastUpdated:"2023/11/09, 20:11:15",lastUpdatedTimestamp:1699531875e3},{title:"mp使用@TableField注解未生效反而报错",frontmatter:{title:"mp使用@TableField注解未生效反而报错",date:"2023-11-09T13:17:31.000Z",permalink:"/pages/0e629c/"},regularPath:"/02.%E6%96%87%E7%AB%A0/200.%E8%B8%A9%E5%9D%91/30.mp%E4%BD%BF%E7%94%A8@TableField%E6%B3%A8%E8%A7%A3%E6%9C%AA%E7%94%9F%E6%95%88%E5%8F%8D%E8%80%8C%E6%8A%A5%E9%94%99.html",relativePath:"02.文章/200.踩坑/30.mp使用@TableField注解未生效反而报错.md",key:"v-54af3d7f",path:"/pages/0e629c/",headersStr:null,content:"在使用MybatisPlus的@TableField注解指定字段时，我的代码是这样写的：\n\n\n\n报错如下：\n\n\n\n表如下：\n\n\n\n错误原因 ：在同时使用@TableField和@TableId时，两个注解中都需要指定字段名",normalizedContent:"在使用mybatisplus的@tablefield注解指定字段时，我的代码是这样写的：\n\n\n\n报错如下：\n\n\n\n表如下：\n\n\n\n错误原因 ：在同时使用@tablefield和@tableid时，两个注解中都需要指定字段名",charsets:{cjk:!0},lastUpdated:"2023/11/09, 20:11:15",lastUpdatedTimestamp:1699531875e3},{title:"开发规范",frontmatter:{title:"开发规范",date:"2023-06-22T10:38:58.000Z",permalink:"/pages/99f624/"},regularPath:"/02.%E6%96%87%E7%AB%A0/1000.%E5%AE%9E%E4%B9%A0%E5%B0%8F%E7%BB%93/150.%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83.html",relativePath:"02.文章/1000.实习小结/150.开发规范.md",key:"v-5b394e2a",path:"/pages/99f624/",headersStr:null,content:"# 开发规范\n\n写一篇笔记记录一下公司的开发规范，以免以后踩坑🥲\n\n 1.  避免使用魔法值，而是使用枚举类或者静态常量\n 2.  针对不同的异常要使用不同的 catch 语句，禁止任何异常都使用Exception捕获\n 3.  使用try{}catch{}捕获异常后，必须记录日志，禁止使用System.out.println()、printStackTrace打印日志。\n 4.  避免使用三层及以上的if/else嵌套，可以使用卫语句、策略模式实现\n 5.  设计了复杂的方法/使用了巧妙设计的方法（如使用了设计模式）必须要添加注释\n 6.  单个方法限制长度为200行\n 7.  禁止在循环中调用数据库\n 8.  抽象方法使用javadoc注释，包括参数、返回值、异常、方法以及方法实现的功能\n 9.  无用的代码直接删掉，而不是注释\n 10. 不要在代码后面写注释，在代码上面写\n 11. 文件资源、数据库资源或者流对象使用后必须close\n 12. 访问数据库使用默认字符集，不要自己指定字符集\n 13. 一般情况下 SQL连表不超过三张，实在不行可以分开查\n 14. 不要在项目中使用SQL递归（其他情况下可以使用）\n 15. 使用多线程时尽量使用 ThreadPoolExecutor 来创建线程池，设置合理的参数，避免资源浪费。\n 16. 避免常规的空指针，尽量使用工具类判空如Strings.isEmpty、Collections.emptyList、Collections.emptyMap\n 17. 包装类使用equals比较，BigDecimal使用compareTo比较\n 18. redis的key设计原则：systemName:env:businessGroup:businessKey\n 19. 一般情况下方法的参数不超过5个，多了推荐封装为对象。\n 20. 后端所有接口采用统一的返回实体。\n\n笔记\n\n我是在循环中使用数据库操作被老大提醒了~~",normalizedContent:"# 开发规范\n\n写一篇笔记记录一下公司的开发规范，以免以后踩坑🥲\n\n 1.  避免使用魔法值，而是使用枚举类或者静态常量\n 2.  针对不同的异常要使用不同的 catch 语句，禁止任何异常都使用exception捕获\n 3.  使用try{}catch{}捕获异常后，必须记录日志，禁止使用system.out.println()、printstacktrace打印日志。\n 4.  避免使用三层及以上的if/else嵌套，可以使用卫语句、策略模式实现\n 5.  设计了复杂的方法/使用了巧妙设计的方法（如使用了设计模式）必须要添加注释\n 6.  单个方法限制长度为200行\n 7.  禁止在循环中调用数据库\n 8.  抽象方法使用javadoc注释，包括参数、返回值、异常、方法以及方法实现的功能\n 9.  无用的代码直接删掉，而不是注释\n 10. 不要在代码后面写注释，在代码上面写\n 11. 文件资源、数据库资源或者流对象使用后必须close\n 12. 访问数据库使用默认字符集，不要自己指定字符集\n 13. 一般情况下 sql连表不超过三张，实在不行可以分开查\n 14. 不要在项目中使用sql递归（其他情况下可以使用）\n 15. 使用多线程时尽量使用 threadpoolexecutor 来创建线程池，设置合理的参数，避免资源浪费。\n 16. 避免常规的空指针，尽量使用工具类判空如strings.isempty、collections.emptylist、collections.emptymap\n 17. 包装类使用equals比较，bigdecimal使用compareto比较\n 18. redis的key设计原则：systemname:env:businessgroup:businesskey\n 19. 一般情况下方法的参数不超过5个，多了推荐封装为对象。\n 20. 后端所有接口采用统一的返回实体。\n\n笔记\n\n我是在循环中使用数据库操作被老大提醒了~~",charsets:{cjk:!0},lastUpdated:"2023/06/22, 14:29:37",lastUpdatedTimestamp:1687415377e3},{title:"使用@Validated注解进行参数校验时报错：UnexpectedTypeException",frontmatter:{title:"使用@Validated注解进行参数校验时报错：UnexpectedTypeException",date:"2023-11-09T13:20:32.000Z",permalink:"/pages/e96a9e/"},regularPath:"/02.%E6%96%87%E7%AB%A0/200.%E8%B8%A9%E5%9D%91/40.%E4%BD%BF%E7%94%A8@Validated%E6%B3%A8%E8%A7%A3%E8%BF%9B%E8%A1%8C%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C%E6%97%B6%E6%8A%A5%E9%94%99%EF%BC%9AUnexpectedTypeException.html",relativePath:"02.文章/200.踩坑/40.使用@Validated注解进行参数校验时报错：UnexpectedTypeException.md",key:"v-f080616e",path:"/pages/e96a9e/",headersStr:null,content:"起因是使用 @Validated 注解对一个对象进行参数校验，设想的是出现MethodArgumentNotValidException这个异常，但是出现了UnexpectedTypeExeption异常。\n\n原因是这个对象里有字段为 int、float类型，并且我使用了 @NotEmpty对其校验。不能这样，对于基本数据类型，要使用@NotNull。\n\n注解          用处\n@NotEmpty   对数组、集合进行校验，判断是否为空\n@NotNull    对基本数据类型 int、float、double以及他们的包装类判断不能为空\n@NotBlank   对字符串判断是否为空",normalizedContent:"起因是使用 @validated 注解对一个对象进行参数校验，设想的是出现methodargumentnotvalidexception这个异常，但是出现了unexpectedtypeexeption异常。\n\n原因是这个对象里有字段为 int、float类型，并且我使用了 @notempty对其校验。不能这样，对于基本数据类型，要使用@notnull。\n\n注解          用处\n@notempty   对数组、集合进行校验，判断是否为空\n@notnull    对基本数据类型 int、float、double以及他们的包装类判断不能为空\n@notblank   对字符串判断是否为空",charsets:{cjk:!0},lastUpdated:"2023/11/09, 20:11:15",lastUpdatedTimestamp:1699531875e3},{title:"connection.setReadTimeout",frontmatter:{title:"connection.setReadTimeout",date:"2023-11-09T13:25:08.000Z",permalink:"/pages/4e379b/"},regularPath:"/02.%E6%96%87%E7%AB%A0/200.%E8%B8%A9%E5%9D%91/50.connection.setReadTimeout.html",relativePath:"02.文章/200.踩坑/50.connection.setReadTimeout.md",key:"v-e594d938",path:"/pages/4e379b/",headersStr:null,content:"发送 HTTP 请求时有一个属性是这样的：\n\nconnection.setReadTimeout(long timestamp)\n\n\n之前我以为这个 readTimeout 属性是请求发出去直到收到响应的时间，在实践之后发现不是这样的。\n\n正确解释：\n\nconnectTimeout : 连接超时时间，tcp要建立连接，如果建立连接的时间超过这个就会抛异常\nreadTimeout : 数据在管道中的传输时间，接收方在收到这个消息之后就不再计算了\n",normalizedContent:"发送 http 请求时有一个属性是这样的：\n\nconnection.setreadtimeout(long timestamp)\n\n\n之前我以为这个 readtimeout 属性是请求发出去直到收到响应的时间，在实践之后发现不是这样的。\n\n正确解释：\n\nconnecttimeout : 连接超时时间，tcp要建立连接，如果建立连接的时间超过这个就会抛异常\nreadtimeout : 数据在管道中的传输时间，接收方在收到这个消息之后就不再计算了\n",charsets:{cjk:!0},lastUpdated:"2023/11/09, 20:11:15",lastUpdatedTimestamp:1699531875e3},{title:"用户态和内核态",frontmatter:{title:"用户态和内核态",date:"2023-08-02T01:05:40.000Z",permalink:"/pages/c6965c/"},regularPath:"/02.%E6%96%87%E7%AB%A0/60.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/10.%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81.html",relativePath:"02.文章/60.操作系统/10.用户态和内核态.md",key:"v-619d565d",path:"/pages/c6965c/",headers:[{level:2,title:"1. 什么是用户态和内核态",slug:"_1-什么是用户态和内核态",normalizedTitle:"1. 什么是用户态和内核态",charIndex:2},{level:2,title:"2. 为什么要区分用户态和内核态",slug:"_2-为什么要区分用户态和内核态",normalizedTitle:"2. 为什么要区分用户态和内核态",charIndex:971},{level:2,title:"3. 什么是系统调用",slug:"_3-什么是系统调用",normalizedTitle:"3. 什么是系统调用",charIndex:1282}],headersStr:"1. 什么是用户态和内核态 2. 为什么要区分用户态和内核态 3. 什么是系统调用",content:"# 1. 什么是用户态和内核态\n\n根据进程访问资源的特点，可以把进程在系统的运行分为两个级别 ：用户态、内核态。\n\n 1. 用户态（User Mode） ：用户态级进程可以直接读取用户程序的数据，拥有较低的权限。\n    \n    当应用程序需要执行某些特殊权限的操作，例如读写磁盘、网络通信等，就需要向操作系统发起系统调用请求，并进入内核态。\n\n 2. 内核态（Kernel Mode）：内核态运行的进程几乎可以访问计算机的任何资源，包括系统的内存空间、设备、驱动程序等，不受限制，拥有非常高的权限。\n    \n    当操作系统接收到进程的系统调用请求时，就会从用户态切换到内核态，执行相应的系统调用，并将结果返回给进程，最后再从内核态切换回用户态。\n\n什么时候会发起系统调用？应用程序想要访问系统资源时，例如读写文件、分配内存....\n\n再次强调，我们平时运行的应用程序是在用户空间中的，只有当出现内存分配、文件操作等操作时 才会切换为内核空间，并且用户空间是无法访问这些资源的，用户进程想要访问系统资源就必须要 进行系统调用从用户空间切换到内核空间。\n\n\n\n内核态相比于用户态拥有更高的权限，因此能够执行更底层、更敏感的操作。不过，由于进入内核态需要付出较高的开销（一系列上下文切换和权限检查），应该尽量减少用户态与内核态切换的次数以提高系统的性能和稳定性。\n\n用户态和内核态之间如何切换 ？\n\n有三种方式可以将用户态切换为内核态 ：系统调用、中断、异常。\n\n 1. 系统调用 ：用户态主动要求切换为内核态，主要是为了使用内核态才能做的事。系统调用的机制核心还是使用了操作系统为用户特别开放的一个中断来实现。\n\n 2. 中断 ：当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条指令而去执行与中断信号对应的处理程序。\n    \n    如果先前执行的指令是用户态下的程序并且中断信号对应的处理程序是内核态，那么这个转换的过程自然也就发生了用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续逻辑。\n\n 3. 异常 ：当CPU在执行用户态下的程序时，发生了异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。\n\n\n# 2. 为什么要区分用户态和内核态\n\n 1. 在CPU的所有指令中，有一些执行是比较危险的，比如内存分配、设置时钟、文件IO处理 等，如果所有程序都能使用这些指令，会对系统的正常运行造成灾难性的影响。因此，我们需要限制这些危险指令只能在内核态运行。这些只能由操作系统内核态执行的指令也被叫做特权指令。\n 2. 如果计算机中只有一个内核态，那么所有程序或进程都必须共享系统资源，例如内存、CPU、硬盘等，这将导致系统资源的竞争和冲突，从而影响系统性能和效率。并且，这样也会让系统的安全性降低，毕竟所有程序或进程都有相同的特权级别和访问权限。\n\n因此，同时具有用户态和内核态主要是为了计算机系统的安全性、稳定性和性能。\n\n\n# 3. 什么是系统调用\n\n刚才一直在说“只有经过系统调用，进程才会从用户态切换为内核态”，那么什么是系统调用呢？常用的又有哪些系统调用呢？\n\n系统调用大致可以分为以下几类：\n\n 1. 设备管理 ：完成设备（输入输出设备和外部存储设备）的请求或释放、设备启动等。\n 2. 文件管理 ：文件的读写、创建、删除\n 3. 进程管理 ：进程的创建、撤销、阻塞、唤醒、进程之间的通信\n 4. 内存管理 ：内存和分配、回收、获取内存地址等。\n\n系统调用是应用程序与操作系统之间进行交互的一种方式，通过系统调用，应用程序可以访问操作系统底层资源，如文件、设备、网络等。\n\n系统调用的过程 ：\n\n 1. 用户态发起系统调用，因为系统调用中涉及一些特权指令（只能由操作系统内核态执行的指令），用户态程序权限不足，因此会中断执行，也就是 Trap（Trap是一种中断）\n 2. 发生中断后，当前CPU执行的程序会中断，跳转到中断处理程序。内核程序开始执行，也就是开始处理系统调用。\n 3. 内核处理完成后，主动触发 Trap，这样会再次发生中断，切换回用户态。\n\n常用的系统调用：文件操作，例如read、write",normalizedContent:"# 1. 什么是用户态和内核态\n\n根据进程访问资源的特点，可以把进程在系统的运行分为两个级别 ：用户态、内核态。\n\n 1. 用户态（user mode） ：用户态级进程可以直接读取用户程序的数据，拥有较低的权限。\n    \n    当应用程序需要执行某些特殊权限的操作，例如读写磁盘、网络通信等，就需要向操作系统发起系统调用请求，并进入内核态。\n\n 2. 内核态（kernel mode）：内核态运行的进程几乎可以访问计算机的任何资源，包括系统的内存空间、设备、驱动程序等，不受限制，拥有非常高的权限。\n    \n    当操作系统接收到进程的系统调用请求时，就会从用户态切换到内核态，执行相应的系统调用，并将结果返回给进程，最后再从内核态切换回用户态。\n\n什么时候会发起系统调用？应用程序想要访问系统资源时，例如读写文件、分配内存....\n\n再次强调，我们平时运行的应用程序是在用户空间中的，只有当出现内存分配、文件操作等操作时 才会切换为内核空间，并且用户空间是无法访问这些资源的，用户进程想要访问系统资源就必须要 进行系统调用从用户空间切换到内核空间。\n\n\n\n内核态相比于用户态拥有更高的权限，因此能够执行更底层、更敏感的操作。不过，由于进入内核态需要付出较高的开销（一系列上下文切换和权限检查），应该尽量减少用户态与内核态切换的次数以提高系统的性能和稳定性。\n\n用户态和内核态之间如何切换 ？\n\n有三种方式可以将用户态切换为内核态 ：系统调用、中断、异常。\n\n 1. 系统调用 ：用户态主动要求切换为内核态，主要是为了使用内核态才能做的事。系统调用的机制核心还是使用了操作系统为用户特别开放的一个中断来实现。\n\n 2. 中断 ：当外围设备完成用户请求的操作后，会向cpu发出相应的中断信号，这时cpu会暂停执行下一条指令而去执行与中断信号对应的处理程序。\n    \n    如果先前执行的指令是用户态下的程序并且中断信号对应的处理程序是内核态，那么这个转换的过程自然也就发生了用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续逻辑。\n\n 3. 异常 ：当cpu在执行用户态下的程序时，发生了异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。\n\n\n# 2. 为什么要区分用户态和内核态\n\n 1. 在cpu的所有指令中，有一些执行是比较危险的，比如内存分配、设置时钟、文件io处理 等，如果所有程序都能使用这些指令，会对系统的正常运行造成灾难性的影响。因此，我们需要限制这些危险指令只能在内核态运行。这些只能由操作系统内核态执行的指令也被叫做特权指令。\n 2. 如果计算机中只有一个内核态，那么所有程序或进程都必须共享系统资源，例如内存、cpu、硬盘等，这将导致系统资源的竞争和冲突，从而影响系统性能和效率。并且，这样也会让系统的安全性降低，毕竟所有程序或进程都有相同的特权级别和访问权限。\n\n因此，同时具有用户态和内核态主要是为了计算机系统的安全性、稳定性和性能。\n\n\n# 3. 什么是系统调用\n\n刚才一直在说“只有经过系统调用，进程才会从用户态切换为内核态”，那么什么是系统调用呢？常用的又有哪些系统调用呢？\n\n系统调用大致可以分为以下几类：\n\n 1. 设备管理 ：完成设备（输入输出设备和外部存储设备）的请求或释放、设备启动等。\n 2. 文件管理 ：文件的读写、创建、删除\n 3. 进程管理 ：进程的创建、撤销、阻塞、唤醒、进程之间的通信\n 4. 内存管理 ：内存和分配、回收、获取内存地址等。\n\n系统调用是应用程序与操作系统之间进行交互的一种方式，通过系统调用，应用程序可以访问操作系统底层资源，如文件、设备、网络等。\n\n系统调用的过程 ：\n\n 1. 用户态发起系统调用，因为系统调用中涉及一些特权指令（只能由操作系统内核态执行的指令），用户态程序权限不足，因此会中断执行，也就是 trap（trap是一种中断）\n 2. 发生中断后，当前cpu执行的程序会中断，跳转到中断处理程序。内核程序开始执行，也就是开始处理系统调用。\n 3. 内核处理完成后，主动触发 trap，这样会再次发生中断，切换回用户态。\n\n常用的系统调用：文件操作，例如read、write",charsets:{cjk:!0},lastUpdated:"2023/08/02, 01:36:29",lastUpdatedTimestamp:1690911389e3},{title:"零拷贝",frontmatter:{title:"零拷贝",date:"2023-08-02T01:14:35.000Z",permalink:"/pages/dbd03e/"},regularPath:"/02.%E6%96%87%E7%AB%A0/60.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/110.%E9%9B%B6%E6%8B%B7%E8%B4%9D.html",relativePath:"02.文章/60.操作系统/110.零拷贝.md",key:"v-c1afabda",path:"/pages/dbd03e/",headers:[{level:2,title:"0. 简述",slug:"_0-简述",normalizedTitle:"0. 简述",charIndex:2},{level:2,title:"1. DMA",slug:"_1-dma",normalizedTitle:"1. dma",charIndex:225},{level:2,title:"2. 传输文件时发生了什么",slug:"_2-传输文件时发生了什么",normalizedTitle:"2. 传输文件时发生了什么",charIndex:512},{level:2,title:"3. 零拷贝的实现方式",slug:"_3-零拷贝的实现方式",normalizedTitle:"3. 零拷贝的实现方式",charIndex:1430},{level:3,title:"3.1 mmap",slug:"_3-1-mmap",normalizedTitle:"3.1 mmap",charIndex:1499},{level:3,title:"3.2 sendfile",slug:"_3-2-sendfile",normalizedTitle:"3.2 sendfile",charIndex:1815}],headersStr:"0. 简述 1. DMA 2. 传输文件时发生了什么 3. 零拷贝的实现方式 3.1 mmap 3.2 sendfile",content:"# 0. 简述\n\n零拷贝这个东西实际上我不想放在 Java基础 这部分说，因为严格来说它设计的操作系统知识比较多，但是也不想思考这么多了~\n\n如果你还没有相关的操作系统知识，这篇文章不建议看哦~\n\n或者可以先看一下前置的操作系统知识： 用户态和内核态 （包含用户态内核态、系统调用的知识）\n\n零拷贝这个技术这个很多中间件都有用过，例如RocketMQ、netty。\n\n并且由于技术是拷贝，所以下文所有的用户态、内核态之间的切换都基于 文件。\n\n\n# 1. DMA\n\n在很久之前，用户态与内核态切换后的 数据读取操作 是完全由CPU负责的。\n\n\n\n这个过程中CPU是阻塞的，如果只读几个字符也就算了，但是如果要读几个G的文件，那CPU就有的受了。\n\n所以就发明了 DMA 技术\n\nDMA ：Direct Memory Access，在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。如图。\n\n但是 CPU 在这个过程中也是必不可少的，因为要读哪个文件、读多少这些基本信息都需要CPU去告诉DMA。\n\n\n\n\n# 2. 传输文件时发生了什么\n\n在进行文件传输时一般会涉及两个系统调用 ：read、write\n\nread(file, tmp_buf, len);\nwrite(socket, tmp_buf, len);\n\n\n一个 read() 可以发起系统调用，使进程从用户态切换为内核态，数据准备好后又从 内核态切换回 用户态。即：一次系统调用会发生两次上下文切换。（一次write同理）\n\n文件传输虽然只有两行代码，但却做了不少事情：\n\n\n\n一共 2 次系统调用，也就是 4 次用户态与内核态 上下文的切换。上下文切换的成本很高，一次切换需要几十纳秒到几微秒。其次还发生了 4 次数据拷贝（2次DMA拷贝 + 2次CPU拷贝）\n\n这四次拷贝：\n\n 1. 第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。\n 2. 第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。\n 3. 第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。\n 4. 第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。\n\n这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。\n\n所以，要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「数据拷贝」的次数。\n\n * 减少用户态和内核态的上下文切换就是 减少系统调用的次数\n\n * 减少数据拷贝次数 ：「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此用户的缓冲区是没有必要存在的。我们可以直接将数据从内核缓冲区拷贝到socket缓冲区\n\n现在就要正式介绍零拷贝了，零拷贝也正是实现上述提高性能的实现方法。\n\n\n# 3. 零拷贝的实现方式\n\n零拷贝的实现通常有两种 ：\n\n>  1. mmap + write\n> \n>  2. sendfile\n\n\n# 3.1 mmap\n\n首先介绍一下大名鼎鼎的 mmap + write。\n\n之前说过，减少数据拷贝次数主要是减少 “从内核态缓冲区拷贝到用户态缓冲区”这一步，想要把它删掉。\n\n现在使用 mmap 替代 read 进行读操作\n\nbuf = mmap(file, len);\nwrite(sockfd, buf, len);\n\n\nmmap() 系统调用函数会直接把内核缓冲区里的数据「映射」(不是拷贝) 到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。也可以说用户态和内核态现在共享缓冲区了。\n\n\n\n虽然可以减少一次 数据拷贝，可这仍旧不是理想的零拷贝，我们最终的目的是：减少系统调用带来的上下文切换。\n\n\n# 3.2 sendfile\n\n再来介绍一下sendfile\n\nssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);\n\n\n这个sendfile函数是Linux用于专门发送文件的函数，目的就是替代 read + write。\n\n它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。 其次，该系统调用可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态。这样就只剩下 2 次上下文切换，和 3 次数据拷贝。 如下图：\n\n\n\n当然，这还不是完美的零拷贝技术，如果网卡支持 scatter-gather 特性，那么sendfile可以不需要第二部的CPU拷贝和第三步的DMA拷贝，直接将数据从内核缓冲区发送到网卡。 这被称为 SG-DMA拷贝。\n\n\n\n那么优化到现在，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。\n\n所以，总体来看，零拷贝技术可以把文件传输的性能提高至少一倍以上。\n\n而在Java中，MappedByteBuffer就调用了mmap，transferTo/transferFrom就是sendfile方法。\n\n如果涉及到文件传输，transferTo是首选，但是如果涉及到对内存数据的修改选用MappedByteBuffer。",normalizedContent:"# 0. 简述\n\n零拷贝这个东西实际上我不想放在 java基础 这部分说，因为严格来说它设计的操作系统知识比较多，但是也不想思考这么多了~\n\n如果你还没有相关的操作系统知识，这篇文章不建议看哦~\n\n或者可以先看一下前置的操作系统知识： 用户态和内核态 （包含用户态内核态、系统调用的知识）\n\n零拷贝这个技术这个很多中间件都有用过，例如rocketmq、netty。\n\n并且由于技术是拷贝，所以下文所有的用户态、内核态之间的切换都基于 文件。\n\n\n# 1. dma\n\n在很久之前，用户态与内核态切换后的 数据读取操作 是完全由cpu负责的。\n\n\n\n这个过程中cpu是阻塞的，如果只读几个字符也就算了，但是如果要读几个g的文件，那cpu就有的受了。\n\n所以就发明了 dma 技术\n\ndma ：direct memory access，在进行 i/o 设备和内存的数据传输的时候，数据搬运的工作全部交给 dma 控制器，而 cpu 不再参与任何与数据搬运相关的事情，这样 cpu 就可以去处理别的事务。如图。\n\n但是 cpu 在这个过程中也是必不可少的，因为要读哪个文件、读多少这些基本信息都需要cpu去告诉dma。\n\n\n\n\n# 2. 传输文件时发生了什么\n\n在进行文件传输时一般会涉及两个系统调用 ：read、write\n\nread(file, tmp_buf, len);\nwrite(socket, tmp_buf, len);\n\n\n一个 read() 可以发起系统调用，使进程从用户态切换为内核态，数据准备好后又从 内核态切换回 用户态。即：一次系统调用会发生两次上下文切换。（一次write同理）\n\n文件传输虽然只有两行代码，但却做了不少事情：\n\n\n\n一共 2 次系统调用，也就是 4 次用户态与内核态 上下文的切换。上下文切换的成本很高，一次切换需要几十纳秒到几微秒。其次还发生了 4 次数据拷贝（2次dma拷贝 + 2次cpu拷贝）\n\n这四次拷贝：\n\n 1. 第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 dma 搬运的。\n 2. 第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 cpu 完成的。\n 3. 第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 cpu 搬运的。\n 4. 第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 dma 搬运的。\n\n这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。\n\n所以，要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「数据拷贝」的次数。\n\n * 减少用户态和内核态的上下文切换就是 减少系统调用的次数\n\n * 减少数据拷贝次数 ：「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此用户的缓冲区是没有必要存在的。我们可以直接将数据从内核缓冲区拷贝到socket缓冲区\n\n现在就要正式介绍零拷贝了，零拷贝也正是实现上述提高性能的实现方法。\n\n\n# 3. 零拷贝的实现方式\n\n零拷贝的实现通常有两种 ：\n\n>  1. mmap + write\n> \n>  2. sendfile\n\n\n# 3.1 mmap\n\n首先介绍一下大名鼎鼎的 mmap + write。\n\n之前说过，减少数据拷贝次数主要是减少 “从内核态缓冲区拷贝到用户态缓冲区”这一步，想要把它删掉。\n\n现在使用 mmap 替代 read 进行读操作\n\nbuf = mmap(file, len);\nwrite(sockfd, buf, len);\n\n\nmmap() 系统调用函数会直接把内核缓冲区里的数据「映射」(不是拷贝) 到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。也可以说用户态和内核态现在共享缓冲区了。\n\n\n\n虽然可以减少一次 数据拷贝，可这仍旧不是理想的零拷贝，我们最终的目的是：减少系统调用带来的上下文切换。\n\n\n# 3.2 sendfile\n\n再来介绍一下sendfile\n\nssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);\n\n\n这个sendfile函数是linux用于专门发送文件的函数，目的就是替代 read + write。\n\n它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。 其次，该系统调用可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态。这样就只剩下 2 次上下文切换，和 3 次数据拷贝。 如下图：\n\n\n\n当然，这还不是完美的零拷贝技术，如果网卡支持 scatter-gather 特性，那么sendfile可以不需要第二部的cpu拷贝和第三步的dma拷贝，直接将数据从内核缓冲区发送到网卡。 这被称为 sg-dma拷贝。\n\n\n\n那么优化到现在，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 cpu，2 次都是由 dma 来搬运。\n\n所以，总体来看，零拷贝技术可以把文件传输的性能提高至少一倍以上。\n\n而在java中，mappedbytebuffer就调用了mmap，transferto/transferfrom就是sendfile方法。\n\n如果涉及到文件传输，transferto是首选，但是如果涉及到对内存数据的修改选用mappedbytebuffer。",charsets:{cjk:!0},lastUpdated:"2023/08/06, 23:48:49",lastUpdatedTimestamp:1691336929e3},{title:"缓存一致性协议：MESI",frontmatter:{title:"缓存一致性协议：MESI",date:"2023-08-02T13:17:16.000Z",permalink:"/pages/ee38bc/"},regularPath:"/02.%E6%96%87%E7%AB%A0/60.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/20.%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE%EF%BC%9AMESI.html",relativePath:"02.文章/60.操作系统/20.缓存一致性协议：MESI.md",key:"v-62c5b9aa",path:"/pages/ee38bc/",headers:[{level:2,title:"1. Cache",slug:"_1-cache",normalizedTitle:"1. cache",charIndex:2},{level:2,title:"2. 缓存一致性问题",slug:"_2-缓存一致性问题",normalizedTitle:"2. 缓存一致性问题",charIndex:592},{level:2,title:"3. 总线嗅探",slug:"_3-总线嗅探",normalizedTitle:"3. 总线嗅探",charIndex:1331},{level:2,title:"4. MESI协议",slug:"_4-mesi协议",normalizedTitle:"4. mesi协议",charIndex:1622}],headersStr:"1. Cache 2. 缓存一致性问题 3. 总线嗅探 4. MESI协议",content:"# 1. Cache\n\n为什么 CPU 要有缓存？\n\nCPU 要从内存中取数据，但是 CPU 太快了，内存太慢了，速度差异过大导致 CPU 的性能无法利用。所以操作系统使用 Cache 作为 CPU 与内存之间的缓存。就像 Redis 在 Java程序与MySQL之间充当缓存作用似的。\n\nCache 通常分为三级 ：L1、L2、L3。级别越低，离 CPU 越近，速度越快，但是存储容量越小。\n\n在多核 CPU 中，每个 CPU 都有各自的 L1 与 L2，而L3是所有 CPU 共享的 。\n\nCache 是由很多个 Cache Line 组成的，CPU Line 是 CPU 从内存读取数据的基本单位，而 CPU Line 是由各种标志（Tag）+ 数据块（Data Block）组成，你可以在下图清晰的看到：\n\n事实上，数据不光是只有读操作，还有写操作，那么如果数据写入 Cache 之后，内存与 Cache 相对应的数据将会不同，这种情况下 Cache 和内存数据都不一致了，于是我们肯定是要把 Cache 中的数据同步到内存里的。\n\n有两种写方式：\n\n 1. 写直达 ：Write Through，写入数据时不仅往缓存中写，还要往内存中写。\n 2. 写回 ：Write Back，写数据时只往缓存中写，并把数据标记为脏数据，写数据时遇到脏数据就会将脏数据同步到内存。\n\n\n# 2. 缓存一致性问题\n\n现在的 CPU 都是多核的，由于 L1 与 L2 是 CPU 独自拥有的，那么就会带来缓存一致性问题，如果不能解决缓存一致性问题，那就会造成结果错误。\n\n那么什么是缓存一致性问题呢？为什么会出现缓存一致性问题？\n\n假如现在又两个核：CPU A 与 CPU B，在他们的 L1 中都有一个变量 i = 0。\n\n现在 A 将它修改为1，还没来的及刷到内存中就被 B 读取了，B 读取的数据 i = 0。\n\n但是 B 比 A 执行的晚，A 又把 i 改了，那么 B 得到的 i 理应为 1。\n\n这就是缓存一致性问题。\n\n想要解决这个问题，就要保证以下两点 ：\n\n>  1. 写传播 ：一个 CPU 修改了共享变量，要 通知 其他所有 CPU。\n>  2. 事物的串行化 ：这个 “通知” 被 不同CPU 接收的顺序应该相同。\n\n第一点很容易理解，一个 CPU 修改了共享变量，在刷新到内存之前就要通知别的 CPU，以免出现缓存不一致问题。\n\n第二点有点犯迷糊，来举个例子：\n\nCPU A 发出了两条通知 ：A 将 i 修改为 100、A 将 i 修改为 200\n\n如果出现以下情况，那么最终结果就会导致不一样：\n\n * CPU B 接收的通知顺序为 ：A 将 i 修改为 200、A 将 i 修改为 100。\n   在 CPU B 中，i 的最终结果为 100\n * CPU C 接收的通知顺序为 ：A 将 i 修改为 100、A 将 i 修改为 200。\n   在 CPU C 中，i 的最终结果为 200\n\n所以，我们要保证 B 号核心和 C 号核心都能看到相同顺序的数据变化。\n\n接下来看一下 CPU 是如何实现 写传播 和 事务的串行化 的。\n\n\n# 3. 总线嗅探\n\n写传播机制很简单 ：当某个 CPU 核心更新了 Cache 中的数据，要把该事件广播通知到其他核心。\n\n最常见实现的方式是总线嗅探（Bus Snooping） ：某个 CPU 更新了数据时会将修改以广播的形式发送到 总线，而其他 CPU时刻监听总线，一旦发生写信号，立刻检查自己的 Cache 中是否有这个数据，如果有就把这个写操作同步过来。\n\n总线嗅探机制很简单，但是 CPU 要时刻监听总线，这无异于会增加很多负担。并且总线嗅探只能实现写传播，不能实现 事务的串行化。\n\nMESI 协议就通过 总线嗅探机制 实现了 事务的串行化，做到了缓存的一致性。\n\n\n# 4. MESI协议\n\nMESI 协议其实是 4 个状态单词的开头字母缩写，分别是：\n\n * Modified，已修改\n * Exclusive，独占\n * Shared，共享\n * Invalidated，已失效\n\n这四个状态来标记 Cache Line 四个不同的状态。\n\n「已修改」状态就是我们前面提到的脏标记，代表该 Cache Block 上的数据已经被更新过，但是还没有写到内存里。如果 CPU 中某个数据是已修改，那么可以直接对这个数据写，不需要通知其他 CPU。\n\n「已失效」状态，表示的是这个 Cache Block 里的数据已经失效了，不可以读取该状态的数据。\n\n「独占」和「共享」状态都代表 Cache Block 里的数据是干净的，也就是说，这个时候 Cache Block 里的数据和内存里面的数据是一致性的。\n\n「独占」和「共享」的差别在于，独占状态的时候，数据只存储在一个 CPU 核心的 Cache 里，而其他 CPU 核心的 Cache 没有该数据。这个时候，如果要向独占的 Cache 写数据，就可以直接自由地写入，而不需要通知其他 CPU 核心，因为只有你这有这个数据，就不存在缓存一致性的问题了，于是就可以随便操作该数据。\n\n另外，在「独占」状态下的数据，如果有其他核心从内存读取了相同的数据到各自的 Cache ，那么这个时候，独占状态下的数据就会变成共享状态。\n\n那么，「共享」状态代表着相同的数据在多个 CPU 核心的 Cache 里都有，所以当我们要更新 Cache 里面的数据的时候不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后再更新当前 Cache 里面的数据。\n\n那么MESI如何实现事务的串行化呢？\n\n当一个处理器要修改一个缓存行时，它首先将该缓存行的状态设置为修改状态，然后将该缓存行的数据复制到自己的缓存中。 此时，其他处理器无法访问该缓存行。其他处理器如果要访问该缓存行，必须先将其状态设置为无效，然后从主存中读取最新的数据。 这样，每个处理器都可以按照顺序执行事务，保证了事务的串行化。",normalizedContent:"# 1. cache\n\n为什么 cpu 要有缓存？\n\ncpu 要从内存中取数据，但是 cpu 太快了，内存太慢了，速度差异过大导致 cpu 的性能无法利用。所以操作系统使用 cache 作为 cpu 与内存之间的缓存。就像 redis 在 java程序与mysql之间充当缓存作用似的。\n\ncache 通常分为三级 ：l1、l2、l3。级别越低，离 cpu 越近，速度越快，但是存储容量越小。\n\n在多核 cpu 中，每个 cpu 都有各自的 l1 与 l2，而l3是所有 cpu 共享的 。\n\ncache 是由很多个 cache line 组成的，cpu line 是 cpu 从内存读取数据的基本单位，而 cpu line 是由各种标志（tag）+ 数据块（data block）组成，你可以在下图清晰的看到：\n\n事实上，数据不光是只有读操作，还有写操作，那么如果数据写入 cache 之后，内存与 cache 相对应的数据将会不同，这种情况下 cache 和内存数据都不一致了，于是我们肯定是要把 cache 中的数据同步到内存里的。\n\n有两种写方式：\n\n 1. 写直达 ：write through，写入数据时不仅往缓存中写，还要往内存中写。\n 2. 写回 ：write back，写数据时只往缓存中写，并把数据标记为脏数据，写数据时遇到脏数据就会将脏数据同步到内存。\n\n\n# 2. 缓存一致性问题\n\n现在的 cpu 都是多核的，由于 l1 与 l2 是 cpu 独自拥有的，那么就会带来缓存一致性问题，如果不能解决缓存一致性问题，那就会造成结果错误。\n\n那么什么是缓存一致性问题呢？为什么会出现缓存一致性问题？\n\n假如现在又两个核：cpu a 与 cpu b，在他们的 l1 中都有一个变量 i = 0。\n\n现在 a 将它修改为1，还没来的及刷到内存中就被 b 读取了，b 读取的数据 i = 0。\n\n但是 b 比 a 执行的晚，a 又把 i 改了，那么 b 得到的 i 理应为 1。\n\n这就是缓存一致性问题。\n\n想要解决这个问题，就要保证以下两点 ：\n\n>  1. 写传播 ：一个 cpu 修改了共享变量，要 通知 其他所有 cpu。\n>  2. 事物的串行化 ：这个 “通知” 被 不同cpu 接收的顺序应该相同。\n\n第一点很容易理解，一个 cpu 修改了共享变量，在刷新到内存之前就要通知别的 cpu，以免出现缓存不一致问题。\n\n第二点有点犯迷糊，来举个例子：\n\ncpu a 发出了两条通知 ：a 将 i 修改为 100、a 将 i 修改为 200\n\n如果出现以下情况，那么最终结果就会导致不一样：\n\n * cpu b 接收的通知顺序为 ：a 将 i 修改为 200、a 将 i 修改为 100。\n   在 cpu b 中，i 的最终结果为 100\n * cpu c 接收的通知顺序为 ：a 将 i 修改为 100、a 将 i 修改为 200。\n   在 cpu c 中，i 的最终结果为 200\n\n所以，我们要保证 b 号核心和 c 号核心都能看到相同顺序的数据变化。\n\n接下来看一下 cpu 是如何实现 写传播 和 事务的串行化 的。\n\n\n# 3. 总线嗅探\n\n写传播机制很简单 ：当某个 cpu 核心更新了 cache 中的数据，要把该事件广播通知到其他核心。\n\n最常见实现的方式是总线嗅探（bus snooping） ：某个 cpu 更新了数据时会将修改以广播的形式发送到 总线，而其他 cpu时刻监听总线，一旦发生写信号，立刻检查自己的 cache 中是否有这个数据，如果有就把这个写操作同步过来。\n\n总线嗅探机制很简单，但是 cpu 要时刻监听总线，这无异于会增加很多负担。并且总线嗅探只能实现写传播，不能实现 事务的串行化。\n\nmesi 协议就通过 总线嗅探机制 实现了 事务的串行化，做到了缓存的一致性。\n\n\n# 4. mesi协议\n\nmesi 协议其实是 4 个状态单词的开头字母缩写，分别是：\n\n * modified，已修改\n * exclusive，独占\n * shared，共享\n * invalidated，已失效\n\n这四个状态来标记 cache line 四个不同的状态。\n\n「已修改」状态就是我们前面提到的脏标记，代表该 cache block 上的数据已经被更新过，但是还没有写到内存里。如果 cpu 中某个数据是已修改，那么可以直接对这个数据写，不需要通知其他 cpu。\n\n「已失效」状态，表示的是这个 cache block 里的数据已经失效了，不可以读取该状态的数据。\n\n「独占」和「共享」状态都代表 cache block 里的数据是干净的，也就是说，这个时候 cache block 里的数据和内存里面的数据是一致性的。\n\n「独占」和「共享」的差别在于，独占状态的时候，数据只存储在一个 cpu 核心的 cache 里，而其他 cpu 核心的 cache 没有该数据。这个时候，如果要向独占的 cache 写数据，就可以直接自由地写入，而不需要通知其他 cpu 核心，因为只有你这有这个数据，就不存在缓存一致性的问题了，于是就可以随便操作该数据。\n\n另外，在「独占」状态下的数据，如果有其他核心从内存读取了相同的数据到各自的 cache ，那么这个时候，独占状态下的数据就会变成共享状态。\n\n那么，「共享」状态代表着相同的数据在多个 cpu 核心的 cache 里都有，所以当我们要更新 cache 里面的数据的时候不能直接修改，而是要先向所有的其他 cpu 核心广播一个请求，要求先把其他核心的 cache 中对应的 cache line 标记为「无效」状态，然后再更新当前 cache 里面的数据。\n\n那么mesi如何实现事务的串行化呢？\n\n当一个处理器要修改一个缓存行时，它首先将该缓存行的状态设置为修改状态，然后将该缓存行的数据复制到自己的缓存中。 此时，其他处理器无法访问该缓存行。其他处理器如果要访问该缓存行，必须先将其状态设置为无效，然后从主存中读取最新的数据。 这样，每个处理器都可以按照顺序执行事务，保证了事务的串行化。",charsets:{cjk:!0},lastUpdated:"2023/08/02, 23:56:18",lastUpdatedTimestamp:1690991778e3},{title:"TCP、UDP协议",frontmatter:{title:"TCP、UDP协议",date:"2023-06-14T19:44:57.000Z",permalink:"/pages/424c75/"},regularPath:"/02.%E6%96%87%E7%AB%A0/70.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/10.TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.html",relativePath:"02.文章/70.计算机网络/10.TCP、UDP协议.md",key:"v-04afedb8",path:"/pages/424c75/",headers:[{level:2,title:"1. 概述",slug:"_1-概述",normalizedTitle:"1. 概述",charIndex:16},{level:2,title:"2. 端口号 复用 分用",slug:"_2-端口号-复用-分用",normalizedTitle:"2. 端口号 复用 分用",charIndex:689},{level:2,title:"3. TCP",slug:"_3-tcp",normalizedTitle:"3. tcp",charIndex:1147},{level:3,title:"3.1 TCP首部格式",slug:"_3-1-tcp首部格式",normalizedTitle:"3.1 tcp首部格式",charIndex:1158},{level:3,title:"3.2 建立连接-三次握手",slug:"_3-2-建立连接-三次握手",normalizedTitle:"3.2 建立连接-三次握手",charIndex:3131},{level:3,title:"3.3 释放连接-四次挥手",slug:"_3-3-释放连接-四次挥手",normalizedTitle:"3.3 释放连接-四次挥手",charIndex:4816},{level:3,title:"3.4 TCP流量控制",slug:"_3-4-tcp流量控制",normalizedTitle:"3.4 tcp流量控制",charIndex:6329},{level:3,title:"3.5 TCP拥塞控制",slug:"_3-5-tcp拥塞控制",normalizedTitle:"3.5 tcp拥塞控制",charIndex:7173},{level:3,title:"3.6 TCP可靠传输的实现",slug:"_3-6-tcp可靠传输的实现",normalizedTitle:"3.6 tcp可靠传输的实现",charIndex:7724},{level:3,title:"3.7 TCP超时重传",slug:"_3-7-tcp超时重传",normalizedTitle:"3.7 tcp超时重传",charIndex:8906},{level:2,title:"4. UDP",slug:"_4-udp",normalizedTitle:"4. udp",charIndex:9616},{level:2,title:"5.TCP与UDP的区别",slug:"_5-tcp与udp的区别",normalizedTitle:"5.tcp与udp的区别",charIndex:9845}],headersStr:"1. 概述 2. 端口号 复用 分用 3. TCP 3.1 TCP首部格式 3.2 建立连接-三次握手 3.3 释放连接-四次挥手 3.4 TCP流量控制 3.5 TCP拥塞控制 3.6 TCP可靠传输的实现 3.7 TCP超时重传 4. UDP 5.TCP与UDP的区别",content:"# TCP UDP协议\n\n\n# 1. 概述\n\nTCP、UDP协议是TCP/IP体系结构传输层中的两个重要协议。\n\n如图所示为计算机网络四层模型：\n\n\n\n**IP协议**是网际层中的核心协议，它可以互联不同的网络接口，并向其上层提供无连接、不可靠的数据传输服务。\n\nTCP/IP体系结构的应用层中包含许大量的应用层协议，其中有些应用层协议需要使用可靠传输服务，例如浏览网页、传输文件等，这些数据一旦传输失败会造成无法挽回的危害。而有些则需要使用不可靠传输服务，例如音视频通话等，少量的数据传输错误并不会对播放造成大影响。\n\n由于应用层需要使用可靠和不可靠两种传输服务，但IP协议只能提供不可靠传输服务，于是就需要传输层来提供可靠/不可靠的传输服务。\n\n其中TCP提供可靠性传输服务，UDP提供不可靠传输服务。\n\nTCP ：Transmission Control Protocol，传输控制协议，为上层提供的是面向连接的可靠的数据传输服务。使用TCP通信的双方，在传送数据之前必须首先建立TCP连接（逻辑连接，而非物理连接）。数据传输结束后必须要释放TCP连接。TCP为了实现可靠传输，就必须使用很多措施，例如TCP连接管理、确认机制、超时重传、流量控制、拥塞控制等。TCP的实现复杂，报文首部较大，占用处理机资源比较多。\n\nUDP ：User Datagram Protocol，用户数据报协议，为其上层提供的是无连接的不可靠的数据传输服务，因此不需要实现可靠传输的各种机制。使用UDP通信的双方，在传送数据之前不需要建立连接。UDP的实现简单，用户数据报首部比较小。\n\n\n# 2. 端口号 复用 分用\n\n端口号 ：运行在计算机上的进程使用进程标识符PID来区分，但是因特网上的计算机使用操作系统复杂，不同的操作系统又有不同格式的进程标识符，为了使运行在不同操作系统的计算机的应用进程之间能够进行通信，就必须使用统一的方法对TCP/IP体系的应用进程进行标识，而这个标识方法就是**端口号**，运输层使用端口号来区分应用层的不同应用进程。端口号只具有本地意义，即端口号只是为了标识本计算机应用进程，在因特网中，不同的计算机中的相同端口没有联系，你电脑上的8080端口跟我电脑上的8080端口一点关系没有。\n\n发送方的复用 ：应用层报文经过传输层TCP协议进行封装，称为TCP复用。应用层报文经过传输层UDP协议封装，称为UDP复用。传输层的报文经过网络层IP协议的封装，称为IP复用\n\n接收方的分用：网络层使用IP协议解析接受的IP数据报，称为IP分用。传输层使用TCP协议解析接受的TCP数据报，称为TCP分用。传输层使用UDP协议解析接受的UDP数据报，称为UDP分用。\n\n\n\n‍\n\n\n# 3. TCP\n\n\n# 3.1 TCP首部格式\n\nTCP协议处于传输层，它向上层（应用层）提供面向连接的可靠传输服务，为了实现可靠传输，采用了**面向字节流**的方式。\n\nTCP在发送数据时从发送缓存中取出一部分或全部字节并给其添加一个首部使之成为TCP报文段后在发送给下层。一个TCP报文段由首部和数据载荷两部分组成，TCP实现连接管理、确认机制、超时重传、流量控制、拥塞控制这些功能都体现在它首部中各字段的作用。\n\nTCP首部由两部分构成 ：20字节的固定首部和最大40字节的扩展首部。也就是说，一个TCP首部的字节数在20~60字节之间。\n\n\n\n源端口 ：16比特，即两字节，写入源端口号，用于标识发送该TCP报文段的应用进程。\n\n目的端口 ：16比特，即两字节，写入目的端口号，用于标识接受该TCP报文段的应用进程。\n\n假如我们使用web服务127.0.0.1:8080远程访问MySQL服务器48.104.60.218:3306；源端口就是我们自己的IP地址中的端口8080，目的端口就是MySQL服务器的IP地址中的端口3306。\n\n接下来看看与TCP实现可靠性传输有关的三个字段 ：序号、确认号、ACK。\n\n序号 ：占32比特，取值范围[0, 2^32 - 1]，序号增加到最后一个后，下一个序号就又回到0。序号的值用来指出本TCP报文段**数据载荷**第一个字节的序号。如图所示，首部的序号即为数据载荷第一个字节的序号122。\n\n\n\n确认号 ：占32比特，取值范围[0, 2^32 - 1]，确认好增加到最后一个后，下一个确认好又回到0。确认号的值用于指出期望收到对方下一个TCP报文段的数据载荷的第一个字节的序号，同时也是对之前收到的所有数据的确认。可以这样理解：若确认号为n，则代表之前已经成功接收到序号为n-1的报文段，下一次期望收到序号为n的报文段。只有ACK标识的值为1时，确认号字段才有效。\n\nACK ：确标志位，取值为1时确认号才有效；取值为0时确认号无效。TCP规定，连接建立后所有的TCP报文段都必须把ACK置为1。\n\n如图，客户端向服务端发送一个TCP数据报，序号为200代表此数据报的数据载荷部分的第一个字节的序号为200。确认号为800代表客户端已经收到服务端发送的序号为799号以及之前的数据报，现在想要序号为800的数据报。ACK的值为1保证确认号有效。数据载荷长度代表此次传输的字节数。也就是说，此次传输的数据载荷部分的序号为 200 - 300。\n\n\n\n数据偏移 ：占4比特，并以4字节为单位。用于指出TCP报文段的数据载荷部分的起始处距离TCP报文段的起始处有多远。这个字段实际上是指出了TCP报文段的首部有多少个字节。同时，它的值是首部字节数除以4的。首部的字节数范围为：20 ~ 60，所以数据偏移字段的值范围为 5~15，即 0101到1111。\n\n保留 ：占6比特，保留以后使用。目前值为0。\n\n窗口 ：占16比特，以字节为单位。指出发送本报文段的一方的接收窗口。窗口值作为接收方让发送方设置其发送窗口的依据。这是以接收方的接受能力来控制发送方的发送能力，称为流量控制。需要注意的是，发送窗口的大小还取决于拥塞窗口的大小，也就是从接收窗口和拥塞窗口中取最小值。\n\n校验和 ：占16比特，用于检查整个TCP报文段在传输过程中是否出现了误码。\n\n紧急指针 ：占16比特，以字节为单位，用来指明紧急数据的长度。当发送方有紧急数据时，可将紧急数据插队到发送缓存的最前面，并立刻封装到一个TCP报文中进行发送。紧急指针会指出本报文段数据载荷部分包含了多长的紧急数据，紧急数据之后是普通数据。\n\nSYN ：同步标志位，在TCP连接建立时用来同步序号。TCP规定，SYN值为1时代表正在建立连接，此报文段不能携带数据。\n\nFIN ：终止标志位，用于释放TCP连接。TCP规定，FIN值为1时代表正在释放连接，此报文段不能携带数据。\n\nRST ：复位标志位，用于复位TCP连接。当RST为1时，表示TCP连接出现了异常，此时必须先断开连接，再重新建立连接。RST还用来拒绝非法报文段或拒绝TCP连接。\n\nPSH ：推送标志位，用来实现推送操作。当接受方收到该标志位为1的报文段会尽快上交应用进程，而不必等到接收缓存都填满后再向上交付。\n\nURG ：紧急标志位，与紧急指针字段共同实现紧急操作。紧急标志位URG为1时，紧急指针有效，为0时紧急指针无效。\n\n选项 ：选项中的字段都是可选值，扩展功能。选项的字节数可变\n\n填充 ：由于选项的字节数可变，那就使用填充字段确保报文段首部能被4整除。假如选项有3字节，那么填充就只有1个字节。\n\n为什么一定要确保首部字节数要能被4整除？因为数据偏移字段的值是首部字节数除以4。\n\n\n\n\n# 3.2 建立连接-三次握手\n\nTCP是面向连接的协议，它基于运输连接来传送TCP报文段。TCP运输连接的建立和释放是每一次面向娘连接的通信中必不可少的过程。\n\nTCP运输连接分为以下三个阶段：\n\n 1. 通过三次握手建立TCP连接\n 2. 进行数据传输\n 3. 通过四次挥手断开TCP连接\n\n先来介绍一下TCP连接的建立 ：三报文握手\n\n最初，TCP客户端与TCP服务端的TCP进程都处于关闭状态，即CLOSED。\n\n一开始，TCP服务端先创建TCP传输控制块，用于存储TCP连接中的以下重要信息，例如TCP连接表、指向发送和接受缓存的指针、指向重传队列的指针...TCP服务端创建传输控制块后就进入监听状态（LISTEN）等待接受TCP客户端的连接请求。\n\nTCP客户端在发起连接请求之前也要创建传输控制块，之后发起连接请求。\n\n\n\n第一次握手 ：\n\nTCP客户端进程向TCP服务端进程发送TCP连接请求报文段，并进入同步已发送状态（SYN-SEND）。\n\n此连接请求报文段首部中的值：\n\n * SYN ：1，表明这是一个TCP连接请求报文段。同时规定此时的报文段不能携带数据。\n\n * 序号(seq) ：初始值x\n\n\n\n第二次握手 ：\n\nTCP服务端接收到请求连接报文后，如果同意连接，会向TCP客户端发送 连接请求确认报文段，并进入同步已接受状态（SYN-RCVD）。\n\n该报文段首部中的值：\n\n * SYN ：1，表明现在正在进行TCP连接。同时规定此时的报文段不能携带数据。\n\n * ACK ：使确认号生效。\n\n * 确认号(ack) ：由于客户端发送的序号为x，那么确认号就是x+1，代表“我已经收到序号为x以及之前的数据了，你下次给我发x+1吧”。\n\n * 序号(seq) ：初始值y。\n\n第三次握手 ：\n\nTCP客户端收到连接请求确认报文段后，还需要向TCP服务端进程发送一个**普通的TCP确认报文段，并进入连接已建立状态（ESTABLISHED）。由于是一个普通**的连接建立报文段，所以它的SYN字段值并不为1，所以这个报文段可以携带数据，但是它不携带数据。\n\n（TCP规定，SYN为1的报文段不能携带数据，报文段发送时消耗一个序号。SYN不为1的报文段可以携带数据，如果不携带数据，不消耗序号）\n\n该报文段的首部值：\n\n * ACK ：1，保证确认位可用。\n * 序号(seq) ：x+1，因为TCP服务端上次发的报文中的确认号为x+1。由于SYN值不为1，并且没有携带数据，故x+1这个序号下次还能用，也就是建立连接后还可以再使用一次x+1这个序号。\n * 确认号(ack) ：y+1，因为TCP服务端上次发送的报文段的序号为y，所以我们这次发送y+1，表示我们已经接收到了序号y以及之前的数据，下次我们想要序号为y+1的数据。\n\n\n\n当TCP服务端接收到TCP客户端第二次报文时，服务端也进入连接已建立状态（ESTABLISHED）。\n\n\n\n现在，双方都已进入连接建立状态，可以根据已经建立好的TCP连接进行可靠的数据传输。\n\n> 那么为什么建立TCP连接一定需要三次呢？为什么不能是两次？为什么不能使用两次报文握手建立连接呢？\n\n接下来看看两报文握手会出现的问题 ：\n\nTCP客户端发出请求连接报文，但是因为网络问题长时间停滞在网络中，于是触发超时重传机制，TCP客户端重新发起TCP连接请求报文段，这次成功建立连接。之后便是数据的传输，最后数据传输完成，服务端与客户端断开连接。\n\n\n\n断开连接后突然，上次因为网络问题滞后的TCP连接请求发送到了TCP服务端，服务端以为客户端想要再次建立TCP连接，于是服务端进入监听（LISTEN）状态并向客户端发送连接请求确认报文，但是客户端此时为关闭状态，对连接请求确认报文不予理睬，于是服务端一直处于监听状态并发送连接请求确认报文。这就造成了TCP服务端资源的浪费。\n\n\n\n综上所述，采用三报文握手而不是两报文握手是为了防止已失效的连接请求报文段突然传送到了TCP服务端因而导致的错误。\n\n\n# 3.3 释放连接-四次挥手\n\nTCP通过四次挥手来结束TCP的连接。\n\n在断开连接之前，客户端与服务端都处于连接已建立状态（ESTABLISHED）。\n\n第一次挥手 ：\n\nTCP客户端会发送TCP连接释放报文段，进入终止等待1状态（FIN-WAIT-1）。TCP连接释放报文段的字段值为：\n\n * FIN ：1，代表此时正在释放TCP连接，此报文段不能携带数据。\n * ACK ：使确认号生效。\n * seq(序号) ：u，代表此报文段的数据载荷的第一个字节的序号为u。\n * ack(确认号) ：v，代表已经收到序号为v-1的数据，下次想要序号为v的数据。\n\n\n\n第二次挥手 ：\n\n服务端接收到客户端发送的TCP连接释放报文段后，会向客户端发送一个普通的TCP确认报文段，并进入关闭等待状态（CLOSE-WAIT）。\n\n（此时的TCP连接进入了半关闭状态，因为客户端到服务端的TCP连接进入关闭状态，因为客户端已经没有数据要发送了；但是服务端到客户端的TCP连接通道还没关闭，因为服务端要继续发送那些还未发送完毕的数据。）\n\n此报文段的字段值 ：\n\n * ACK ：1，保证确认号有效\n * 序号(seq) ：v，代表此报文段的数据载荷的第一个字节的序号为v。\n * 确认号(ack) ：u+1，代表已经收到客户端发送的第u条数据，下次想要u+1。\n\nTCP客户端收到TCP服务端发送的TCP确认报文段后就会进入终止等待2状态（FIN-WAIT2）。\n\n\n\n第三次挥手 ：\n\n当TCP服务端所有剩余数据发送完毕后，TCP服务端会发送TCP连接释放报文段，并进入最后确认状态（LAST-ACK）。\n\n该报文段的字段：\n\n * FIN ：1，表示正在释放连接。\n * ACK ：1，保证确认号有效。\n * 序号(seq) ：w，为什么不是v+1？因为第二次挥手之后可能传输了其他剩余数据报。\n * 确认号(ack) ：u+1。为什么是u+1？不是又发送了剩余数据吗？因为剩余数据报只是服务端向客户端发送，客户端向服务端的TCP连接通道已经断开。\n\n\n\n第四次挥手：\n\n收到服务端发送的TCP连接释放报文段后，客户端发送普通的确认报文段，之后进入时间等待状态（TIME-WAIT）。\n\n收到该报文段后，服务端关闭。处于时间等待状态2MSL(2mins)后，客户端TCP连接关闭。\n\n该报文字段值 ：\n\n * ACK ：1，保证确认号有效\n * 序号(seq) ：u+1\n * 确认号(ack) ：w+1\n\n> 为什么客户端还要等待两分钟再关闭TCP连接呢？\n> \n> 假如不进行等待而直接关闭，也就是客户端发送第四次挥手之后立即关闭TCP连接。那么如果最后一个确认报文丢失，此时客户端已经关闭，但服务端还在等待最后的确认保报文，一直没等到就会触发超时重传机制发送第三次挥手报文，但是客户端已经关闭，那么服务端就会一直发送第三次挥手报文，非常浪费资源。而等待两分钟就可以解决这个问题，客户端有足够时间等待服务端发送的超时重传报文。\n\n\n\n至此，四报文挥手过程完毕。\n\n接下来看看保活计时器 ：\n\n在客户端与服务端建立连接后，如果客户端出现故障，应当有措施让服务端主动断开连接而不是一直等待下去。这时就要使用到保活计时器。\n\n * TCP服务器进程每收到一次TCP客户进程的数据，就重新设置并启动保活计时器(定时2小时)。\n * 若2小时内没接收到TCP客户端发送的数据，则当保活计时器到时后，TCP服务器向TCP客户端发送一个探测报文段，以后则每75秒发送一次，若连续10个报文段都无响应，TCP服务端主动断开TCP连接。\n\n\n# 3.4 TCP流量控制\n\n为什么需要流量控制？一般来说，我们更加希望传输速度越快越好，但是如果发送方发送数据的速度过快，会导致接受方来不及接收，这就会造成数据的丢失。\n\n所以流量控制就是为了让发送方发送的速率不要太快，要让接受方来得及接收。\n\nTCP的流量控制是通过滑动窗口来实现的。如果此时A向B传输数据，在传输数据前B告诉A：我的接收窗口rwnd=400(receiver window)。这表示 ：发送方A的发送窗口不能超过接受方B的接收窗口的值，也就是400字节。\n\n假如B最初的接收窗口大小为400，那么A可以发送400字节的数据。B接收400字节数据并发送确认后，这400字节的数据会先从A的发送缓存中删除。现在A成功向B发送了400字节的数据，但是B的接收缓存没多少空间了，于是B对A说：我的接收窗口为rwnd=300。这表示发送方A的发送窗口不能超过300字节。就这样，如果发送后B的发送缓存还没腾出空间，会继续减小接收窗口直到B的发送缓存没有空间，这时B向A发送的rwnd=0，即零窗口通知，代表不要再发送数据了，等我腾出空间再说吧。\n\n> 如果A发送的数据丢失怎么办呢？\n\nA给B发送消息，如果数据丢失，并不会影响A后续数据的发送，B发送的ack消息会告诉A哪些数据还没有发送，到时A重新发送即可。\n\n> 如果B发送的rwnd丢失怎么办呢？\n\n如果B发送给A的rwnd丢失，A一直在等待B发送的窗口通知(rwnd)以便设置自己的发送窗口，而主机B以为A已经接收到窗口通知，他就一直等待A发送的数据，这就会造成死锁的局面。为了解决这个问题，TCP为每一个连接设置一个持续定时器。\n\n如果B给A发送零窗口通知，持续计时器会重新计时，当持续计时器超时时，证明已经很久没有收到零窗口通知了，A就给B发送一个探测报文，B接收该报文后，将自己的接收窗口值发送给A，如果此值为0，则持续计时器重新计时；如果此值为其他值，A将其发送窗口大小设置为此值。于是死锁问题得以解决。\n\n\n# 3.5 TCP拥塞控制\n\n拥塞 ：对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏。这种情况叫做拥塞（congestion）。\n\n若出现拥塞而不进行控制，整个网络的吞吐量将随输入负荷的增大而下降。\n\nTCP对拥塞控制提供了四种算法 ：\n\n 1. 慢开始（slow-start）\n 2. 拥塞避免（congestion avoidance）\n 3. 快重传（fast retransmit）\n 4. 快恢复（fast recovery）\n\n为了简单起见，我们假设发送方A，接收方B，A只发送数据报，B只发送确认报。并且接收方的接收窗口足够大，此时发送方的发送窗口就只受拥塞控制的影响。\n\n发送方维护一个叫做拥塞窗口cwnd的状态变量，其值取决于网络的拥塞程度，并且动态变化。\n\n * 拥塞窗口cwnd的维护原则：只要网络没有出现拥塞，拥塞窗口就再增大一些。网络出现拥塞，拥塞窗口就减小一些。\n * 判断出现网络拥塞的依据：没有按时收到应当到达的确认报文段（即发生超时）\n\n发送方将拥塞窗口作为发送窗口swnd，即swnd = cwnd。\n\n具体的拥塞控制可以参考 ：https://juejin.cn/post/6844903664566403085\n\n实在是讲不出来😢\n\n\n# 3.6 TCP可靠传输的实现\n\nTCP基于以字节为单位的滑动窗口来实现可靠传输。\n\n如图A与B建立了TCP连接\n\n（简单起见，我们假设数据单方面发送并且没有拥塞影响，即A发送数据报文段，B只发送确认报文段，并且发送窗口不会受到拥塞控制的影响）\n\n上方表格为待传输的数据的序号。\n\n\n\n连接建立后B给A发送一个确认报文段：rwnd=20, ack=23，代表滑动窗口大小为20，下一次给我传序号为23的数据。\n\n发送方接收到这个确认报文段后构造出自己的发送窗口，大小为20字节，发送窗口从序号为23的数据开始，它称为后沿；直到序号为42的数据结束，它称为前沿。\n\n并且，由于ack=23，发送方A可以将23号以前的数据从发送缓存中删除，在接收到ack之前，发送窗口中的数据都要留在发送缓存中。\n\n发送窗口中的数据都是可以发送的数据，发送窗口前沿右边的数据都是不允许发送的数据。\n\n后沿的移动情况有两种 ：不动、前移\n\n前沿的移动情况有三种 ：不动、前移、后移。\n\n接下来A向B发送10个字节的数据，序号为23-33的数据被发送出去，但是并不会从发送缓存中删除，因为还没有收到确认ack。\n\n\n\n假如接收方B收到了序号为25-27的数据，由于23-24的数据还没接收到，所以B发送的确认报文的确认号仍为23。这是接收方对23号数据发起的第一次重复确认，因此不会触发超时重传机制。同时接收窗口为20没变。\n\n\n\n当以后23-24号数据传到接收方，接收方就会发送对于23-27号数据的确认报文，如果rwnd的值仍为20，接收方就会将接收窗口移动到28-47号数据。\n\n发送方收到该确认报文后将23-27号数据从发送缓存中删除。同时发送窗口移动到28-47号数据。\n\n\n\n当发送方发送的数据迟迟无法到达接收方，重传计时器超时，会重传发送窗口内已发送的数据，并重新启动重传计时器。\n\n注意 ：\n\n 1. 虽然发送方的发送窗口是根据接收方的接收窗口设置的，但是在同一时刻，发送方的发送窗口并不总是和接收方的接收窗口一样大。\n    \n    因为网络具有一定的延时性。\n\n 2. 对于不按序列号到达的数据应该如何处理，TCP并无明确规定\n    \n    * 如果丢弃，虽然实现更简单了，但是会浪费很多网络资源。\n    * 通常存储在接收窗口中，等到字节流中所缺少的字节收到后，再按序号交付给上层的应用进程。\n\n 3. TCP要求接收方必须有累积确认和捎带确认机制，这样可以减小传输开销。接收方可以在合适的时候发送确认，也可以在自己有数据要发送时把确认信息捎带上。但是接收方不应该过分推迟发送确认消息，否则会触发超时重传浪费资源。\n\n 4. TCP是全双工通信，通信双方都在发送和接受报文段，因此，每一方都有自己的发送窗口和接收窗口。在谈到这些窗口时，一定要区分开。\n\n\n# 3.7 TCP超时重传\n\n刚才一直再说如果有一段报文迟迟没有发送会触发超时重传，但并没有说如何选择重传的时机，现在就来说说TCP对于超时重传的时机选择。\n\n超时重传时间（RTO）的选择是计算机网络最复杂的问题之一。\n\n假如发送方为A，接收方为B。发送方A向接收方B发送数据报，并记录时间，A收到B的返回的确认报文段后再次记录时间。\n\n这两个时间的差值为往返时间RTT。如果超时重传时间设置的比RTT小很多，会触发不必要的重传。如果设置的比RTT大很多，迟迟不超时重传太影响效率。所以我们要找到一个正好的时间，这个时间比RTT大一点，但大的不多。\n\n\n\n听起来很简单，但是复杂的网络环境使传输速率复杂多变，RTT也跟着变化，早上跟晚上的网络速率差别都很大。所以超时重传时间（RTO）的选择是计算机网络最复杂的问题之一。\n\n这时候就不能以单次RTT的值确定RTO的值，而是使用很多次RTT的值通过一定的算法来计算出一个更加合适的RTO。\n\n我们使用RTT代表通过计算得出的RTT的值，RTT(i)代表每一次TCP通信产生的RTT值\n\n当第一次RTT产生时，最终RTT的值等于第一次RTT的值。RTT = RTT(1)\n\nRTT多起来的时候，使用公式 ：\n\n> RTT = (1-a)* 上一次RTT + a*RTT(i)\n\n在上式中，0 ≤ a < 1，若a接近于0，则RTT(i)对RTT的值的影响不大。若a接近于1，则RTT(i)对RTT的影响较大。标准RFC298建议a的值为1/8\n\n当通过每一次的样本计算得出最终RTT后，我们就可以规定超时重传时间RTO略大于RTT了。\n\n> 至此，TCP就告一段落了。\n\n\n# 4. UDP\n\n由于UDP向应用层提供无连接不可靠的通信服务，所以它无需像TCP那样实现流量控制、拥塞控制等等功能，它的字段也十分简单。\n\n一个UDP用户数据报同样由首部与数据载荷两部分组成，首部格式如图所示。\n\n\n\n它只有四个字段，每个字段两个字节共八个字节。由于UDP提供无连接不可靠的服务，所以它只在网际层的基础上添加了端口号的区分。\n\n> 至此，UDP告一段落。。。才怪，UDP的功能会在下小节UDP与TCP的区别中注明。因为实在太少。。。\n\n\n# 5.TCP与UDP的区别\n\nTCP与UDP所有的区别都是基于一个条件 ：TCP提供有连接可靠性传输服务，UDP提供无连接不可靠服务。\n\n如果TCP不提供可靠服务，那他俩就一样了。\n\n 1. TCP传输数据前需要三报文握手建立连接，传输数据结束时四报文挥手断开连接。\n    \n    UDP可以随时发送数据。只要你知道它的IP就可以突然发送数据。\n\n 2. TCP只支持一对一的solo模式，连接只能在两个主机之间进行。\n    \n    UDP支持单播、多播、广播。\n\n 3. 当应用层报文发送到传输层时\n    \n    TCP将应用层传输的报文拆分为多个字节流标上序号，再加上TCP首部封装为TCP数据报，再根据发送策略发送给下层。TCP是面向字节流的。\n    \n    UDP仅仅将应用层报文首部添加一个UDP首部封装为UDP数据报，就将该数据报发送给接受方。UDP是面向数据报的。\n\n 4. 如果数据传输过程中数据丢失、误码\n    \n    TCP会重新发送或触发重传机制。\n    \n    UDP啥也不干。\n\n最后，对比一下UDP数据报首部以及TCP数据报的首部格式：\n\n",normalizedContent:"# tcp udp协议\n\n\n# 1. 概述\n\ntcp、udp协议是tcp/ip体系结构传输层中的两个重要协议。\n\n如图所示为计算机网络四层模型：\n\n\n\n**ip协议**是网际层中的核心协议，它可以互联不同的网络接口，并向其上层提供无连接、不可靠的数据传输服务。\n\ntcp/ip体系结构的应用层中包含许大量的应用层协议，其中有些应用层协议需要使用可靠传输服务，例如浏览网页、传输文件等，这些数据一旦传输失败会造成无法挽回的危害。而有些则需要使用不可靠传输服务，例如音视频通话等，少量的数据传输错误并不会对播放造成大影响。\n\n由于应用层需要使用可靠和不可靠两种传输服务，但ip协议只能提供不可靠传输服务，于是就需要传输层来提供可靠/不可靠的传输服务。\n\n其中tcp提供可靠性传输服务，udp提供不可靠传输服务。\n\ntcp ：transmission control protocol，传输控制协议，为上层提供的是面向连接的可靠的数据传输服务。使用tcp通信的双方，在传送数据之前必须首先建立tcp连接（逻辑连接，而非物理连接）。数据传输结束后必须要释放tcp连接。tcp为了实现可靠传输，就必须使用很多措施，例如tcp连接管理、确认机制、超时重传、流量控制、拥塞控制等。tcp的实现复杂，报文首部较大，占用处理机资源比较多。\n\nudp ：user datagram protocol，用户数据报协议，为其上层提供的是无连接的不可靠的数据传输服务，因此不需要实现可靠传输的各种机制。使用udp通信的双方，在传送数据之前不需要建立连接。udp的实现简单，用户数据报首部比较小。\n\n\n# 2. 端口号 复用 分用\n\n端口号 ：运行在计算机上的进程使用进程标识符pid来区分，但是因特网上的计算机使用操作系统复杂，不同的操作系统又有不同格式的进程标识符，为了使运行在不同操作系统的计算机的应用进程之间能够进行通信，就必须使用统一的方法对tcp/ip体系的应用进程进行标识，而这个标识方法就是**端口号**，运输层使用端口号来区分应用层的不同应用进程。端口号只具有本地意义，即端口号只是为了标识本计算机应用进程，在因特网中，不同的计算机中的相同端口没有联系，你电脑上的8080端口跟我电脑上的8080端口一点关系没有。\n\n发送方的复用 ：应用层报文经过传输层tcp协议进行封装，称为tcp复用。应用层报文经过传输层udp协议封装，称为udp复用。传输层的报文经过网络层ip协议的封装，称为ip复用\n\n接收方的分用：网络层使用ip协议解析接受的ip数据报，称为ip分用。传输层使用tcp协议解析接受的tcp数据报，称为tcp分用。传输层使用udp协议解析接受的udp数据报，称为udp分用。\n\n\n\n‍\n\n\n# 3. tcp\n\n\n# 3.1 tcp首部格式\n\ntcp协议处于传输层，它向上层（应用层）提供面向连接的可靠传输服务，为了实现可靠传输，采用了**面向字节流**的方式。\n\ntcp在发送数据时从发送缓存中取出一部分或全部字节并给其添加一个首部使之成为tcp报文段后在发送给下层。一个tcp报文段由首部和数据载荷两部分组成，tcp实现连接管理、确认机制、超时重传、流量控制、拥塞控制这些功能都体现在它首部中各字段的作用。\n\ntcp首部由两部分构成 ：20字节的固定首部和最大40字节的扩展首部。也就是说，一个tcp首部的字节数在20~60字节之间。\n\n\n\n源端口 ：16比特，即两字节，写入源端口号，用于标识发送该tcp报文段的应用进程。\n\n目的端口 ：16比特，即两字节，写入目的端口号，用于标识接受该tcp报文段的应用进程。\n\n假如我们使用web服务127.0.0.1:8080远程访问mysql服务器48.104.60.218:3306；源端口就是我们自己的ip地址中的端口8080，目的端口就是mysql服务器的ip地址中的端口3306。\n\n接下来看看与tcp实现可靠性传输有关的三个字段 ：序号、确认号、ack。\n\n序号 ：占32比特，取值范围[0, 2^32 - 1]，序号增加到最后一个后，下一个序号就又回到0。序号的值用来指出本tcp报文段**数据载荷**第一个字节的序号。如图所示，首部的序号即为数据载荷第一个字节的序号122。\n\n\n\n确认号 ：占32比特，取值范围[0, 2^32 - 1]，确认好增加到最后一个后，下一个确认好又回到0。确认号的值用于指出期望收到对方下一个tcp报文段的数据载荷的第一个字节的序号，同时也是对之前收到的所有数据的确认。可以这样理解：若确认号为n，则代表之前已经成功接收到序号为n-1的报文段，下一次期望收到序号为n的报文段。只有ack标识的值为1时，确认号字段才有效。\n\nack ：确标志位，取值为1时确认号才有效；取值为0时确认号无效。tcp规定，连接建立后所有的tcp报文段都必须把ack置为1。\n\n如图，客户端向服务端发送一个tcp数据报，序号为200代表此数据报的数据载荷部分的第一个字节的序号为200。确认号为800代表客户端已经收到服务端发送的序号为799号以及之前的数据报，现在想要序号为800的数据报。ack的值为1保证确认号有效。数据载荷长度代表此次传输的字节数。也就是说，此次传输的数据载荷部分的序号为 200 - 300。\n\n\n\n数据偏移 ：占4比特，并以4字节为单位。用于指出tcp报文段的数据载荷部分的起始处距离tcp报文段的起始处有多远。这个字段实际上是指出了tcp报文段的首部有多少个字节。同时，它的值是首部字节数除以4的。首部的字节数范围为：20 ~ 60，所以数据偏移字段的值范围为 5~15，即 0101到1111。\n\n保留 ：占6比特，保留以后使用。目前值为0。\n\n窗口 ：占16比特，以字节为单位。指出发送本报文段的一方的接收窗口。窗口值作为接收方让发送方设置其发送窗口的依据。这是以接收方的接受能力来控制发送方的发送能力，称为流量控制。需要注意的是，发送窗口的大小还取决于拥塞窗口的大小，也就是从接收窗口和拥塞窗口中取最小值。\n\n校验和 ：占16比特，用于检查整个tcp报文段在传输过程中是否出现了误码。\n\n紧急指针 ：占16比特，以字节为单位，用来指明紧急数据的长度。当发送方有紧急数据时，可将紧急数据插队到发送缓存的最前面，并立刻封装到一个tcp报文中进行发送。紧急指针会指出本报文段数据载荷部分包含了多长的紧急数据，紧急数据之后是普通数据。\n\nsyn ：同步标志位，在tcp连接建立时用来同步序号。tcp规定，syn值为1时代表正在建立连接，此报文段不能携带数据。\n\nfin ：终止标志位，用于释放tcp连接。tcp规定，fin值为1时代表正在释放连接，此报文段不能携带数据。\n\nrst ：复位标志位，用于复位tcp连接。当rst为1时，表示tcp连接出现了异常，此时必须先断开连接，再重新建立连接。rst还用来拒绝非法报文段或拒绝tcp连接。\n\npsh ：推送标志位，用来实现推送操作。当接受方收到该标志位为1的报文段会尽快上交应用进程，而不必等到接收缓存都填满后再向上交付。\n\nurg ：紧急标志位，与紧急指针字段共同实现紧急操作。紧急标志位urg为1时，紧急指针有效，为0时紧急指针无效。\n\n选项 ：选项中的字段都是可选值，扩展功能。选项的字节数可变\n\n填充 ：由于选项的字节数可变，那就使用填充字段确保报文段首部能被4整除。假如选项有3字节，那么填充就只有1个字节。\n\n为什么一定要确保首部字节数要能被4整除？因为数据偏移字段的值是首部字节数除以4。\n\n\n\n\n# 3.2 建立连接-三次握手\n\ntcp是面向连接的协议，它基于运输连接来传送tcp报文段。tcp运输连接的建立和释放是每一次面向娘连接的通信中必不可少的过程。\n\ntcp运输连接分为以下三个阶段：\n\n 1. 通过三次握手建立tcp连接\n 2. 进行数据传输\n 3. 通过四次挥手断开tcp连接\n\n先来介绍一下tcp连接的建立 ：三报文握手\n\n最初，tcp客户端与tcp服务端的tcp进程都处于关闭状态，即closed。\n\n一开始，tcp服务端先创建tcp传输控制块，用于存储tcp连接中的以下重要信息，例如tcp连接表、指向发送和接受缓存的指针、指向重传队列的指针...tcp服务端创建传输控制块后就进入监听状态（listen）等待接受tcp客户端的连接请求。\n\ntcp客户端在发起连接请求之前也要创建传输控制块，之后发起连接请求。\n\n\n\n第一次握手 ：\n\ntcp客户端进程向tcp服务端进程发送tcp连接请求报文段，并进入同步已发送状态（syn-send）。\n\n此连接请求报文段首部中的值：\n\n * syn ：1，表明这是一个tcp连接请求报文段。同时规定此时的报文段不能携带数据。\n\n * 序号(seq) ：初始值x\n\n\n\n第二次握手 ：\n\ntcp服务端接收到请求连接报文后，如果同意连接，会向tcp客户端发送 连接请求确认报文段，并进入同步已接受状态（syn-rcvd）。\n\n该报文段首部中的值：\n\n * syn ：1，表明现在正在进行tcp连接。同时规定此时的报文段不能携带数据。\n\n * ack ：使确认号生效。\n\n * 确认号(ack) ：由于客户端发送的序号为x，那么确认号就是x+1，代表“我已经收到序号为x以及之前的数据了，你下次给我发x+1吧”。\n\n * 序号(seq) ：初始值y。\n\n第三次握手 ：\n\ntcp客户端收到连接请求确认报文段后，还需要向tcp服务端进程发送一个**普通的tcp确认报文段，并进入连接已建立状态（established）。由于是一个普通**的连接建立报文段，所以它的syn字段值并不为1，所以这个报文段可以携带数据，但是它不携带数据。\n\n（tcp规定，syn为1的报文段不能携带数据，报文段发送时消耗一个序号。syn不为1的报文段可以携带数据，如果不携带数据，不消耗序号）\n\n该报文段的首部值：\n\n * ack ：1，保证确认位可用。\n * 序号(seq) ：x+1，因为tcp服务端上次发的报文中的确认号为x+1。由于syn值不为1，并且没有携带数据，故x+1这个序号下次还能用，也就是建立连接后还可以再使用一次x+1这个序号。\n * 确认号(ack) ：y+1，因为tcp服务端上次发送的报文段的序号为y，所以我们这次发送y+1，表示我们已经接收到了序号y以及之前的数据，下次我们想要序号为y+1的数据。\n\n\n\n当tcp服务端接收到tcp客户端第二次报文时，服务端也进入连接已建立状态（established）。\n\n\n\n现在，双方都已进入连接建立状态，可以根据已经建立好的tcp连接进行可靠的数据传输。\n\n> 那么为什么建立tcp连接一定需要三次呢？为什么不能是两次？为什么不能使用两次报文握手建立连接呢？\n\n接下来看看两报文握手会出现的问题 ：\n\ntcp客户端发出请求连接报文，但是因为网络问题长时间停滞在网络中，于是触发超时重传机制，tcp客户端重新发起tcp连接请求报文段，这次成功建立连接。之后便是数据的传输，最后数据传输完成，服务端与客户端断开连接。\n\n\n\n断开连接后突然，上次因为网络问题滞后的tcp连接请求发送到了tcp服务端，服务端以为客户端想要再次建立tcp连接，于是服务端进入监听（listen）状态并向客户端发送连接请求确认报文，但是客户端此时为关闭状态，对连接请求确认报文不予理睬，于是服务端一直处于监听状态并发送连接请求确认报文。这就造成了tcp服务端资源的浪费。\n\n\n\n综上所述，采用三报文握手而不是两报文握手是为了防止已失效的连接请求报文段突然传送到了tcp服务端因而导致的错误。\n\n\n# 3.3 释放连接-四次挥手\n\ntcp通过四次挥手来结束tcp的连接。\n\n在断开连接之前，客户端与服务端都处于连接已建立状态（established）。\n\n第一次挥手 ：\n\ntcp客户端会发送tcp连接释放报文段，进入终止等待1状态（fin-wait-1）。tcp连接释放报文段的字段值为：\n\n * fin ：1，代表此时正在释放tcp连接，此报文段不能携带数据。\n * ack ：使确认号生效。\n * seq(序号) ：u，代表此报文段的数据载荷的第一个字节的序号为u。\n * ack(确认号) ：v，代表已经收到序号为v-1的数据，下次想要序号为v的数据。\n\n\n\n第二次挥手 ：\n\n服务端接收到客户端发送的tcp连接释放报文段后，会向客户端发送一个普通的tcp确认报文段，并进入关闭等待状态（close-wait）。\n\n（此时的tcp连接进入了半关闭状态，因为客户端到服务端的tcp连接进入关闭状态，因为客户端已经没有数据要发送了；但是服务端到客户端的tcp连接通道还没关闭，因为服务端要继续发送那些还未发送完毕的数据。）\n\n此报文段的字段值 ：\n\n * ack ：1，保证确认号有效\n * 序号(seq) ：v，代表此报文段的数据载荷的第一个字节的序号为v。\n * 确认号(ack) ：u+1，代表已经收到客户端发送的第u条数据，下次想要u+1。\n\ntcp客户端收到tcp服务端发送的tcp确认报文段后就会进入终止等待2状态（fin-wait2）。\n\n\n\n第三次挥手 ：\n\n当tcp服务端所有剩余数据发送完毕后，tcp服务端会发送tcp连接释放报文段，并进入最后确认状态（last-ack）。\n\n该报文段的字段：\n\n * fin ：1，表示正在释放连接。\n * ack ：1，保证确认号有效。\n * 序号(seq) ：w，为什么不是v+1？因为第二次挥手之后可能传输了其他剩余数据报。\n * 确认号(ack) ：u+1。为什么是u+1？不是又发送了剩余数据吗？因为剩余数据报只是服务端向客户端发送，客户端向服务端的tcp连接通道已经断开。\n\n\n\n第四次挥手：\n\n收到服务端发送的tcp连接释放报文段后，客户端发送普通的确认报文段，之后进入时间等待状态（time-wait）。\n\n收到该报文段后，服务端关闭。处于时间等待状态2msl(2mins)后，客户端tcp连接关闭。\n\n该报文字段值 ：\n\n * ack ：1，保证确认号有效\n * 序号(seq) ：u+1\n * 确认号(ack) ：w+1\n\n> 为什么客户端还要等待两分钟再关闭tcp连接呢？\n> \n> 假如不进行等待而直接关闭，也就是客户端发送第四次挥手之后立即关闭tcp连接。那么如果最后一个确认报文丢失，此时客户端已经关闭，但服务端还在等待最后的确认保报文，一直没等到就会触发超时重传机制发送第三次挥手报文，但是客户端已经关闭，那么服务端就会一直发送第三次挥手报文，非常浪费资源。而等待两分钟就可以解决这个问题，客户端有足够时间等待服务端发送的超时重传报文。\n\n\n\n至此，四报文挥手过程完毕。\n\n接下来看看保活计时器 ：\n\n在客户端与服务端建立连接后，如果客户端出现故障，应当有措施让服务端主动断开连接而不是一直等待下去。这时就要使用到保活计时器。\n\n * tcp服务器进程每收到一次tcp客户进程的数据，就重新设置并启动保活计时器(定时2小时)。\n * 若2小时内没接收到tcp客户端发送的数据，则当保活计时器到时后，tcp服务器向tcp客户端发送一个探测报文段，以后则每75秒发送一次，若连续10个报文段都无响应，tcp服务端主动断开tcp连接。\n\n\n# 3.4 tcp流量控制\n\n为什么需要流量控制？一般来说，我们更加希望传输速度越快越好，但是如果发送方发送数据的速度过快，会导致接受方来不及接收，这就会造成数据的丢失。\n\n所以流量控制就是为了让发送方发送的速率不要太快，要让接受方来得及接收。\n\ntcp的流量控制是通过滑动窗口来实现的。如果此时a向b传输数据，在传输数据前b告诉a：我的接收窗口rwnd=400(receiver window)。这表示 ：发送方a的发送窗口不能超过接受方b的接收窗口的值，也就是400字节。\n\n假如b最初的接收窗口大小为400，那么a可以发送400字节的数据。b接收400字节数据并发送确认后，这400字节的数据会先从a的发送缓存中删除。现在a成功向b发送了400字节的数据，但是b的接收缓存没多少空间了，于是b对a说：我的接收窗口为rwnd=300。这表示发送方a的发送窗口不能超过300字节。就这样，如果发送后b的发送缓存还没腾出空间，会继续减小接收窗口直到b的发送缓存没有空间，这时b向a发送的rwnd=0，即零窗口通知，代表不要再发送数据了，等我腾出空间再说吧。\n\n> 如果a发送的数据丢失怎么办呢？\n\na给b发送消息，如果数据丢失，并不会影响a后续数据的发送，b发送的ack消息会告诉a哪些数据还没有发送，到时a重新发送即可。\n\n> 如果b发送的rwnd丢失怎么办呢？\n\n如果b发送给a的rwnd丢失，a一直在等待b发送的窗口通知(rwnd)以便设置自己的发送窗口，而主机b以为a已经接收到窗口通知，他就一直等待a发送的数据，这就会造成死锁的局面。为了解决这个问题，tcp为每一个连接设置一个持续定时器。\n\n如果b给a发送零窗口通知，持续计时器会重新计时，当持续计时器超时时，证明已经很久没有收到零窗口通知了，a就给b发送一个探测报文，b接收该报文后，将自己的接收窗口值发送给a，如果此值为0，则持续计时器重新计时；如果此值为其他值，a将其发送窗口大小设置为此值。于是死锁问题得以解决。\n\n\n# 3.5 tcp拥塞控制\n\n拥塞 ：对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏。这种情况叫做拥塞（congestion）。\n\n若出现拥塞而不进行控制，整个网络的吞吐量将随输入负荷的增大而下降。\n\ntcp对拥塞控制提供了四种算法 ：\n\n 1. 慢开始（slow-start）\n 2. 拥塞避免（congestion avoidance）\n 3. 快重传（fast retransmit）\n 4. 快恢复（fast recovery）\n\n为了简单起见，我们假设发送方a，接收方b，a只发送数据报，b只发送确认报。并且接收方的接收窗口足够大，此时发送方的发送窗口就只受拥塞控制的影响。\n\n发送方维护一个叫做拥塞窗口cwnd的状态变量，其值取决于网络的拥塞程度，并且动态变化。\n\n * 拥塞窗口cwnd的维护原则：只要网络没有出现拥塞，拥塞窗口就再增大一些。网络出现拥塞，拥塞窗口就减小一些。\n * 判断出现网络拥塞的依据：没有按时收到应当到达的确认报文段（即发生超时）\n\n发送方将拥塞窗口作为发送窗口swnd，即swnd = cwnd。\n\n具体的拥塞控制可以参考 ：https://juejin.cn/post/6844903664566403085\n\n实在是讲不出来😢\n\n\n# 3.6 tcp可靠传输的实现\n\ntcp基于以字节为单位的滑动窗口来实现可靠传输。\n\n如图a与b建立了tcp连接\n\n（简单起见，我们假设数据单方面发送并且没有拥塞影响，即a发送数据报文段，b只发送确认报文段，并且发送窗口不会受到拥塞控制的影响）\n\n上方表格为待传输的数据的序号。\n\n\n\n连接建立后b给a发送一个确认报文段：rwnd=20, ack=23，代表滑动窗口大小为20，下一次给我传序号为23的数据。\n\n发送方接收到这个确认报文段后构造出自己的发送窗口，大小为20字节，发送窗口从序号为23的数据开始，它称为后沿；直到序号为42的数据结束，它称为前沿。\n\n并且，由于ack=23，发送方a可以将23号以前的数据从发送缓存中删除，在接收到ack之前，发送窗口中的数据都要留在发送缓存中。\n\n发送窗口中的数据都是可以发送的数据，发送窗口前沿右边的数据都是不允许发送的数据。\n\n后沿的移动情况有两种 ：不动、前移\n\n前沿的移动情况有三种 ：不动、前移、后移。\n\n接下来a向b发送10个字节的数据，序号为23-33的数据被发送出去，但是并不会从发送缓存中删除，因为还没有收到确认ack。\n\n\n\n假如接收方b收到了序号为25-27的数据，由于23-24的数据还没接收到，所以b发送的确认报文的确认号仍为23。这是接收方对23号数据发起的第一次重复确认，因此不会触发超时重传机制。同时接收窗口为20没变。\n\n\n\n当以后23-24号数据传到接收方，接收方就会发送对于23-27号数据的确认报文，如果rwnd的值仍为20，接收方就会将接收窗口移动到28-47号数据。\n\n发送方收到该确认报文后将23-27号数据从发送缓存中删除。同时发送窗口移动到28-47号数据。\n\n\n\n当发送方发送的数据迟迟无法到达接收方，重传计时器超时，会重传发送窗口内已发送的数据，并重新启动重传计时器。\n\n注意 ：\n\n 1. 虽然发送方的发送窗口是根据接收方的接收窗口设置的，但是在同一时刻，发送方的发送窗口并不总是和接收方的接收窗口一样大。\n    \n    因为网络具有一定的延时性。\n\n 2. 对于不按序列号到达的数据应该如何处理，tcp并无明确规定\n    \n    * 如果丢弃，虽然实现更简单了，但是会浪费很多网络资源。\n    * 通常存储在接收窗口中，等到字节流中所缺少的字节收到后，再按序号交付给上层的应用进程。\n\n 3. tcp要求接收方必须有累积确认和捎带确认机制，这样可以减小传输开销。接收方可以在合适的时候发送确认，也可以在自己有数据要发送时把确认信息捎带上。但是接收方不应该过分推迟发送确认消息，否则会触发超时重传浪费资源。\n\n 4. tcp是全双工通信，通信双方都在发送和接受报文段，因此，每一方都有自己的发送窗口和接收窗口。在谈到这些窗口时，一定要区分开。\n\n\n# 3.7 tcp超时重传\n\n刚才一直再说如果有一段报文迟迟没有发送会触发超时重传，但并没有说如何选择重传的时机，现在就来说说tcp对于超时重传的时机选择。\n\n超时重传时间（rto）的选择是计算机网络最复杂的问题之一。\n\n假如发送方为a，接收方为b。发送方a向接收方b发送数据报，并记录时间，a收到b的返回的确认报文段后再次记录时间。\n\n这两个时间的差值为往返时间rtt。如果超时重传时间设置的比rtt小很多，会触发不必要的重传。如果设置的比rtt大很多，迟迟不超时重传太影响效率。所以我们要找到一个正好的时间，这个时间比rtt大一点，但大的不多。\n\n\n\n听起来很简单，但是复杂的网络环境使传输速率复杂多变，rtt也跟着变化，早上跟晚上的网络速率差别都很大。所以超时重传时间（rto）的选择是计算机网络最复杂的问题之一。\n\n这时候就不能以单次rtt的值确定rto的值，而是使用很多次rtt的值通过一定的算法来计算出一个更加合适的rto。\n\n我们使用rtt代表通过计算得出的rtt的值，rtt(i)代表每一次tcp通信产生的rtt值\n\n当第一次rtt产生时，最终rtt的值等于第一次rtt的值。rtt = rtt(1)\n\nrtt多起来的时候，使用公式 ：\n\n> rtt = (1-a)* 上一次rtt + a*rtt(i)\n\n在上式中，0 ≤ a < 1，若a接近于0，则rtt(i)对rtt的值的影响不大。若a接近于1，则rtt(i)对rtt的影响较大。标准rfc298建议a的值为1/8\n\n当通过每一次的样本计算得出最终rtt后，我们就可以规定超时重传时间rto略大于rtt了。\n\n> 至此，tcp就告一段落了。\n\n\n# 4. udp\n\n由于udp向应用层提供无连接不可靠的通信服务，所以它无需像tcp那样实现流量控制、拥塞控制等等功能，它的字段也十分简单。\n\n一个udp用户数据报同样由首部与数据载荷两部分组成，首部格式如图所示。\n\n\n\n它只有四个字段，每个字段两个字节共八个字节。由于udp提供无连接不可靠的服务，所以它只在网际层的基础上添加了端口号的区分。\n\n> 至此，udp告一段落。。。才怪，udp的功能会在下小节udp与tcp的区别中注明。因为实在太少。。。\n\n\n# 5.tcp与udp的区别\n\ntcp与udp所有的区别都是基于一个条件 ：tcp提供有连接可靠性传输服务，udp提供无连接不可靠服务。\n\n如果tcp不提供可靠服务，那他俩就一样了。\n\n 1. tcp传输数据前需要三报文握手建立连接，传输数据结束时四报文挥手断开连接。\n    \n    udp可以随时发送数据。只要你知道它的ip就可以突然发送数据。\n\n 2. tcp只支持一对一的solo模式，连接只能在两个主机之间进行。\n    \n    udp支持单播、多播、广播。\n\n 3. 当应用层报文发送到传输层时\n    \n    tcp将应用层传输的报文拆分为多个字节流标上序号，再加上tcp首部封装为tcp数据报，再根据发送策略发送给下层。tcp是面向字节流的。\n    \n    udp仅仅将应用层报文首部添加一个udp首部封装为udp数据报，就将该数据报发送给接受方。udp是面向数据报的。\n\n 4. 如果数据传输过程中数据丢失、误码\n    \n    tcp会重新发送或触发重传机制。\n    \n    udp啥也不干。\n\n最后，对比一下udp数据报首部以及tcp数据报的首部格式：\n\n",charsets:{cjk:!0},lastUpdated:"2023/06/14, 19:46:55",lastUpdatedTimestamp:1686743215e3},{title:"原子类",frontmatter:{title:"原子类",date:"2023-07-17T21:28:31.000Z",permalink:"/pages/0776e3/"},regularPath:"/02.%E6%96%87%E7%AB%A0/75.Java%E5%B9%B6%E5%8F%91/100.%E5%8E%9F%E5%AD%90%E7%B1%BB.html",relativePath:"02.文章/75.Java并发/100.原子类.md",key:"v-4cfac2ae",path:"/pages/0776e3/",headers:[{level:2,title:"原子类",slug:"原子类",normalizedTitle:"原子类",charIndex:2}],headersStr:"原子类",content:"# 原子类\n\n原子类是对 CAS 思想的应用。\n什么是原子类？\n对于 int 类型，加/减操作并不是一次性的，虽然我们在写代码的时候直接 i++、i-- 了，但是在底层其实分为三步 ：\n\n 1. 把变量从地址中取出\n 2. 给变量加/减\n 3. 将变量放到地址中\n\n如果想要实现多线程下 int 类型 i++ 的线程安全就必须使用 synchronized 包起来。\n\nsynchronized(lock) {\n    i++\n}\n\n\n但是使用 java.util.concurrent.atomic 包下的原子类就不需要加 synchronized 锁。\n\n\n为什么说 原子类是对 CAS 思想的应用 呢 ？\n举个例子，看看 AtomicInteger 的部分代码：\n\npublic final int getAndIncrement() {\n    return unsafe.getAndAddInt(this, valueOffset, 1);\n}\npublic final int getAndDecrement() {\n    return unsafe.getAndAddInt(this, valueOffset, -1);\n}\npublic final int getAndAdd(int delta) {\n    return unsafe.getAndAddInt(this, valueOffset, delta);\n}\npublic final int incrementAndGet() {\n    return unsafe.getAndAddInt(this, valueOffset, 1) + 1;\n}\npublic final int decrementAndGet() {\n    return unsafe.getAndAddInt(this, valueOffset, -1) - 1;\n}\npublic final int addAndGet(int delta) {\n    return unsafe.getAndAddInt(this, valueOffset, delta) + delta;\n}\n\n\n全都借助了 Unsafe 类的一些方法，而 Unsafe 提供了更加底层的对于 CAS 实现。\n也就是说原子类的原子特点是 Unsafe 使用 CAS 保证的。",normalizedContent:"# 原子类\n\n原子类是对 cas 思想的应用。\n什么是原子类？\n对于 int 类型，加/减操作并不是一次性的，虽然我们在写代码的时候直接 i++、i-- 了，但是在底层其实分为三步 ：\n\n 1. 把变量从地址中取出\n 2. 给变量加/减\n 3. 将变量放到地址中\n\n如果想要实现多线程下 int 类型 i++ 的线程安全就必须使用 synchronized 包起来。\n\nsynchronized(lock) {\n    i++\n}\n\n\n但是使用 java.util.concurrent.atomic 包下的原子类就不需要加 synchronized 锁。\n\n\n为什么说 原子类是对 cas 思想的应用 呢 ？\n举个例子，看看 atomicinteger 的部分代码：\n\npublic final int getandincrement() {\n    return unsafe.getandaddint(this, valueoffset, 1);\n}\npublic final int getanddecrement() {\n    return unsafe.getandaddint(this, valueoffset, -1);\n}\npublic final int getandadd(int delta) {\n    return unsafe.getandaddint(this, valueoffset, delta);\n}\npublic final int incrementandget() {\n    return unsafe.getandaddint(this, valueoffset, 1) + 1;\n}\npublic final int decrementandget() {\n    return unsafe.getandaddint(this, valueoffset, -1) - 1;\n}\npublic final int addandget(int delta) {\n    return unsafe.getandaddint(this, valueoffset, delta) + delta;\n}\n\n\n全都借助了 unsafe 类的一些方法，而 unsafe 提供了更加底层的对于 cas 实现。\n也就是说原子类的原子特点是 unsafe 使用 cas 保证的。",charsets:{cjk:!0},lastUpdated:"2024/02/28, 21:50:33",lastUpdatedTimestamp:1709128233e3},{title:"计算机网络五层网络模型",frontmatter:{title:"计算机网络五层网络模型",date:"2023-06-14T19:44:30.000Z",permalink:"/pages/71bea1/"},regularPath:"/02.%E6%96%87%E7%AB%A0/70.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/4.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BA%94%E5%B1%82%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.html",relativePath:"02.文章/70.计算机网络/4.计算机网络五层网络模型.md",key:"v-366aefd3",path:"/pages/71bea1/",headers:[{level:2,title:"0. 概述",slug:"_0-概述",normalizedTitle:"0. 概述",charIndex:13},{level:2,title:"1. 应用层",slug:"_1-应用层",normalizedTitle:"1. 应用层",charIndex:226},{level:2,title:"2. 运输层",slug:"_2-运输层",normalizedTitle:"2. 运输层",charIndex:332},{level:2,title:"3. 网络层",slug:"_3-网络层",normalizedTitle:"3. 网络层",charIndex:628},{level:2,title:"4. 数据链路层",slug:"_4-数据链路层",normalizedTitle:"4. 数据链路层",charIndex:778},{level:2,title:"5. 物理层",slug:"_5-物理层",normalizedTitle:"5. 物理层",charIndex:1006}],headersStr:"0. 概述 1. 应用层 2. 运输层 3. 网络层 4. 数据链路层 5. 物理层",content:"# 五层网络模型\n\n\n# 0. 概述\n\n计算机网络可以分为7层、5层、4层网络模型\n\n\n\n其中5层模型从上到下依次为：\n\n 5. 应用层 ：享受其下各层提供的服务，解决通过应用进程的交互来实现特定网络应用的问题\n\n 6. 传输层 ：解决进程之间基于网络的通信问题\n\n 7. 网络层 ：解决分组在多个网络上传输的问题\n\n 8. 数据链路层 ：解决分组在一个网络（或一段链路）上传输的问题\n\n 9. 物理层 ：解决使用何种信号来传输比特的问题\n\n\n\n\n# 1. 应用层\n\n应用层时计算机网络体系结构的最顶层，是设计和建立计算机网络的最终目的，也是计算机网络中发展最快的一部分。\n\n其常用的协议有 ：动态主机配置协议DHCP，超文本传输协议HTTP、HTTPS\n\n\n# 2. 运输层\n\n物理层、数据链路层以及网络层共同解决了将主机通过异构网络互联起来所面临的问题，实现了主机到主机的通信。\n\n但实际上计算机网络中进行通信的真正实体是位于通信两端主机的进程，这个过程就由运输层完成。\n\n运输层向应用层屏蔽了下面网络核心的细节（如网络拓扑、路由选择），它使应用进程看见的好像是在两个运输层实体之间有一条端到端的逻辑通信信道。注意只是逻辑上的，不是物理上的。它给应用层提供了无连接不可靠的传输服务以及面向连接的可靠传输服务。\n\n根据应用需求的不同，运输层为应用层提供了两种不同的应用协议，即无连接的UDP和面向连接的TCP。整个运输层围绕这两个协议展开。\n\n\n\n\n# 3. 网络层\n\n网络层的主要任务就是将分组从源主机经过多个网络和多段链路传输到目的主机，可以将该任务划分为分组转发和路由选择两种重要的功能。\n\n网络层向其上层（应用层、运输层）提供的两种服务 ：面向连接的虚电路服务、无连接的数据报服务。\n\n其主要的协议为 ：网际协议IP、路由协议RIP\n\n\n\n\n# 4. 数据链路层\n\n数据链路层在五层模型中位于物理层的上部，其他部分的下部。\n\n链路（Link）是指从一个节点到相邻节点的一段物理线路，而中间没有任何其他的交换节点。\n\n数据链路（Data Link）是基于链路的。在一条链路上传输数据时，除了需要链路本身，还需要一些必要的通信协议来控制这些数据的传输，把实现这些协议的硬件和软件加到链路上，就构成了数据链路。\n\n帧（Frame）是数据链路层对等实体之间在水平方向进行逻辑通信的协议数据单元PDU。\n\n\n# 5. 物理层\n\n物理层解决了在各种传输媒体上传输比特0和1的问题，进而给数据链路层提供“透明”传输比特流的服务。所谓“透明”是指数据链路层不知道也不必知道物理层究竟如何传输比特流的，它只需要享受物理层提供的传输服务即可。\n\n‍",normalizedContent:"# 五层网络模型\n\n\n# 0. 概述\n\n计算机网络可以分为7层、5层、4层网络模型\n\n\n\n其中5层模型从上到下依次为：\n\n 5. 应用层 ：享受其下各层提供的服务，解决通过应用进程的交互来实现特定网络应用的问题\n\n 6. 传输层 ：解决进程之间基于网络的通信问题\n\n 7. 网络层 ：解决分组在多个网络上传输的问题\n\n 8. 数据链路层 ：解决分组在一个网络（或一段链路）上传输的问题\n\n 9. 物理层 ：解决使用何种信号来传输比特的问题\n\n\n\n\n# 1. 应用层\n\n应用层时计算机网络体系结构的最顶层，是设计和建立计算机网络的最终目的，也是计算机网络中发展最快的一部分。\n\n其常用的协议有 ：动态主机配置协议dhcp，超文本传输协议http、https\n\n\n# 2. 运输层\n\n物理层、数据链路层以及网络层共同解决了将主机通过异构网络互联起来所面临的问题，实现了主机到主机的通信。\n\n但实际上计算机网络中进行通信的真正实体是位于通信两端主机的进程，这个过程就由运输层完成。\n\n运输层向应用层屏蔽了下面网络核心的细节（如网络拓扑、路由选择），它使应用进程看见的好像是在两个运输层实体之间有一条端到端的逻辑通信信道。注意只是逻辑上的，不是物理上的。它给应用层提供了无连接不可靠的传输服务以及面向连接的可靠传输服务。\n\n根据应用需求的不同，运输层为应用层提供了两种不同的应用协议，即无连接的udp和面向连接的tcp。整个运输层围绕这两个协议展开。\n\n\n\n\n# 3. 网络层\n\n网络层的主要任务就是将分组从源主机经过多个网络和多段链路传输到目的主机，可以将该任务划分为分组转发和路由选择两种重要的功能。\n\n网络层向其上层（应用层、运输层）提供的两种服务 ：面向连接的虚电路服务、无连接的数据报服务。\n\n其主要的协议为 ：网际协议ip、路由协议rip\n\n\n\n\n# 4. 数据链路层\n\n数据链路层在五层模型中位于物理层的上部，其他部分的下部。\n\n链路（link）是指从一个节点到相邻节点的一段物理线路，而中间没有任何其他的交换节点。\n\n数据链路（data link）是基于链路的。在一条链路上传输数据时，除了需要链路本身，还需要一些必要的通信协议来控制这些数据的传输，把实现这些协议的硬件和软件加到链路上，就构成了数据链路。\n\n帧（frame）是数据链路层对等实体之间在水平方向进行逻辑通信的协议数据单元pdu。\n\n\n# 5. 物理层\n\n物理层解决了在各种传输媒体上传输比特0和1的问题，进而给数据链路层提供“透明”传输比特流的服务。所谓“透明”是指数据链路层不知道也不必知道物理层究竟如何传输比特流的，它只需要享受物理层提供的传输服务即可。\n\n‍",charsets:{cjk:!0},lastUpdated:"2023/06/14, 19:46:55",lastUpdatedTimestamp:1686743215e3},{title:"FutureTask中的适配器模式",frontmatter:{title:"FutureTask中的适配器模式",date:"2024-02-22T19:57:13.000Z",permalink:"/pages/c1826d/"},regularPath:"/02.%E6%96%87%E7%AB%A0/75.Java%E5%B9%B6%E5%8F%91/250.FutureTask%E4%B8%AD%E7%9A%84%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F.html",relativePath:"02.文章/75.Java并发/250.FutureTask中的适配器模式.md",key:"v-11139ae4",path:"/pages/c1826d/",headers:[{level:2,title:"1. 前言",slug:"_1-前言",normalizedTitle:"1. 前言",charIndex:2},{level:2,title:"2. 正文",slug:"_2-正文",normalizedTitle:"2. 正文",charIndex:206}],headersStr:"1. 前言 2. 正文",content:"# 1. 前言\n\nFutureTask 的源码解析 ：https://2382546457.github.io/pages/937dd3/\n\n这篇文章来讲一下 FutureTask 使用的适配器设计模式。\n\n适配器设计模式在网上的解析也很多，总而言之一句话 ：将一个类转换为想要的另一个类。\n\n抽象，很抽象，并且网上很多文章举的例子也很烂，本片文章你将看到 JDK 源码层面对于 适配器设计模式的使用。\n\n\n# 2. 正文\n\n回顾一下 FutureTask 的使用，有两种方式 ：\n\n 1. 获得任务执行返回值的 Callable\n    \n            FutureTask<Integer> task = new FutureTask<>(() -> {\n                int a = 10;\n                return a * 10;\n            });\n    \n\n 2. 获得指定返回值的 Runnable\n    \n            FutureTask<Integer> task = new FutureTask<>(() -> {\n                System.out.println();\n                System.out.println();\n                System.out.println();\n            }, 1);\n    \n\n但是如果你看过 FutureTask 的源码就会知道，FutureTask 内部只有一个 Callable 类型的变量，那我们提交的 Runnable 怎么变成 Callable 呢？这就是 FutureTask 中的适配器模式。\n\n来看提交 Runnable 时的构造方法：\n\npublic FutureTask(Runnable runnable, V result) {\n    this.callable = Executors.callable(runnable, result);\n    this.state = NEW;       // ensure visibility of callable\n}\n\n\n当提交 Runnable 时，使用 Executors.callable(runnable, result) 就可以返回一个 Callable 类型的变量。\n\n这里我们猜测 ：Executors.callable 方法会返回一个 Callable 的实现类\n\n    public static <T> Callable<T> callable(Runnable task, T result) {\n        if (task == null)\n            throw new NullPointerException();\n        return new RunnableAdapter<T>(task, result);\n    }\n\n\n果然！看到 RunnableAdapter 没 ？只要看到 Adapter 就能知道它使用了适配器模式了。RunnableAdapter 继承了 Callable ，在 call 方法中调用了 Runnable.run()\n\n    static final class RunnableAdapter<T> implements Callable<T> {\n        final Runnable task;\n        final T result;\n        RunnableAdapter(Runnable task, T result) {\n            this.task = task;\n            this.result = result;\n        }\n        public T call() {\n            task.run();\n            return result;\n        }\n    }\n\n\n那么 FutureTask 在使用 callable.call() 时有两种可能 ：\n\n 1. 调用了我们提交的 Callable 实现类\n 2. 调用了经过适配器模式修饰之后的 RunnableAdapter，在 call() 方法中调用 Runnable.run()",normalizedContent:"# 1. 前言\n\nfuturetask 的源码解析 ：https://2382546457.github.io/pages/937dd3/\n\n这篇文章来讲一下 futuretask 使用的适配器设计模式。\n\n适配器设计模式在网上的解析也很多，总而言之一句话 ：将一个类转换为想要的另一个类。\n\n抽象，很抽象，并且网上很多文章举的例子也很烂，本片文章你将看到 jdk 源码层面对于 适配器设计模式的使用。\n\n\n# 2. 正文\n\n回顾一下 futuretask 的使用，有两种方式 ：\n\n 1. 获得任务执行返回值的 callable\n    \n            futuretask<integer> task = new futuretask<>(() -> {\n                int a = 10;\n                return a * 10;\n            });\n    \n\n 2. 获得指定返回值的 runnable\n    \n            futuretask<integer> task = new futuretask<>(() -> {\n                system.out.println();\n                system.out.println();\n                system.out.println();\n            }, 1);\n    \n\n但是如果你看过 futuretask 的源码就会知道，futuretask 内部只有一个 callable 类型的变量，那我们提交的 runnable 怎么变成 callable 呢？这就是 futuretask 中的适配器模式。\n\n来看提交 runnable 时的构造方法：\n\npublic futuretask(runnable runnable, v result) {\n    this.callable = executors.callable(runnable, result);\n    this.state = new;       // ensure visibility of callable\n}\n\n\n当提交 runnable 时，使用 executors.callable(runnable, result) 就可以返回一个 callable 类型的变量。\n\n这里我们猜测 ：executors.callable 方法会返回一个 callable 的实现类\n\n    public static <t> callable<t> callable(runnable task, t result) {\n        if (task == null)\n            throw new nullpointerexception();\n        return new runnableadapter<t>(task, result);\n    }\n\n\n果然！看到 runnableadapter 没 ？只要看到 adapter 就能知道它使用了适配器模式了。runnableadapter 继承了 callable ，在 call 方法中调用了 runnable.run()\n\n    static final class runnableadapter<t> implements callable<t> {\n        final runnable task;\n        final t result;\n        runnableadapter(runnable task, t result) {\n            this.task = task;\n            this.result = result;\n        }\n        public t call() {\n            task.run();\n            return result;\n        }\n    }\n\n\n那么 futuretask 在使用 callable.call() 时有两种可能 ：\n\n 1. 调用了我们提交的 callable 实现类\n 2. 调用了经过适配器模式修饰之后的 runnableadapter，在 call() 方法中调用 runnable.run()",charsets:{cjk:!0},lastUpdated:"2024/02/28, 21:50:33",lastUpdatedTimestamp:1709128233e3},{title:"FutureTask源码解析",frontmatter:{title:"FutureTask源码解析",date:"2023-11-25T21:05:37.000Z",permalink:"/pages/937dd3/"},regularPath:"/02.%E6%96%87%E7%AB%A0/75.Java%E5%B9%B6%E5%8F%91/200.FutureTask%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90.html",relativePath:"02.文章/75.Java并发/200.FutureTask源码解析.md",key:"v-98ff3c9c",path:"/pages/937dd3/",headers:[{level:2,title:"1. 简述",slug:"_1-简述",normalizedTitle:"1. 简述",charIndex:2},{level:2,title:"2. FutureTask 中的变量",slug:"_2-futuretask-中的变量",normalizedTitle:"2. futuretask 中的变量",charIndex:1484},{level:3,title:"2.1 FutureTask 中的状态变量",slug:"_2-1-futuretask-中的状态变量",normalizedTitle:"2.1 futuretask 中的状态变量",charIndex:1647},{level:3,title:"2.2 FutureTask 中的链表变量",slug:"_2-2-futuretask-中的链表变量",normalizedTitle:"2.2 futuretask 中的链表变量",charIndex:3591},{level:2,title:"3. FutureTask.run()",slug:"_3-futuretask-run",normalizedTitle:"3. futuretask.run()",charIndex:7623},{level:2,title:"4. FutureTask.get()",slug:"_4-futuretask-get",normalizedTitle:"4. futuretask.get()",charIndex:8930},{level:2,title:"5. FutureTask.set()",slug:"_5-futuretask-set",normalizedTitle:"5. futuretask.set()",charIndex:11249},{level:2,title:"6. 总结",slug:"_6-总结",normalizedTitle:"6. 总结",charIndex:14936}],headersStr:"1. 简述 2. FutureTask 中的变量 2.1 FutureTask 中的状态变量 2.2 FutureTask 中的链表变量 3. FutureTask.run() 4. FutureTask.get() 5. FutureTask.set() 6. 总结",content:'# 1. 简述\n\nFutureTask 实现了 Runnable、Future，可以进行任务的异步执行，但是 FutureTask 会阻塞主线程。\n\n它提供了两个功能 ：\n\n 1. 执行任务\n 2. 阻塞等待任务执行完毕\n\npublic static void main(String[] args) throws ExecutionException, InterruptedException {\n    Callable<String> callable = new Callable<String>() {\n        @Override\n        public String call() throws Exception {\n            // 处理业务\n            return "执行结束";\n        }\n    };\n\n    FutureTask<String> futureTask = new FutureTask<>(callable);\n    // 执行任务\n    futureTask.run();\n    // 阻塞等待结果\n    futureTask.get();\n}\n\n\n从代码中可以猜测 ：\n\n * FutureTask 内部有一个 Callable 变量\n * FutureTask.run() 调用了 callable.call() 去获取结果\n * 此时 FutureTask.get() 的结果会是null，故执行 FutureTask.get() 的线程会阻塞，Callable.call() 方法运行。\n * Callable.run() 方法结束，将运行的结果交给 FutureTask，FutureTask 停止阻塞。\n\n\n\n想要搞懂 FutureTask 的源码，必须要搞懂它做了什么，根据上面的阐述可以简单猜测：\n\n 1. FutureTask 中的变量不仅有 Callable，还有 Callable 执行后的结果 result，Callable 执行后将结果设置给 result。\n 2. FutureTask.get() 方法用 while(true) 循环检查result，如果为空说明没执行完，继续循环；如果不为空说明已经执行结束，退出循环并返回结果。\n\n简单实现一下FutureTask\n\npublic class FutureTask<T> {\n    // 任务\n    private Callable<T> callable;\n    // 结果\n    private T result;\n    \n    public void run() {\n    \tr = callable.call();    \n    \tresult = r;\n    }\n    \n    public T get() {\n        while (true) {\n            if (result == null) {\n                // 当前线程让出执行权，也就是主线程让出执行权。\n                Thread.yield();\n            } else {\n            \treturn T;    \n            }\n        }\n    }\n}\n\n\n但是真正的 FutureTask 才不会这么简单。接下来进入 FutureTask 的源码一探究竟。\n\n\n# 2. FutureTask 中的变量\n\n根据之前的分析，FutureTask已经有了两个变量 ：\n\npublic class FutureTask<T> {\n    // 任务\n    private Callable<T> callable;\n    // 结果\n    private T outcome;\n}\n\n\n\n# 2.1 FutureTask 中的状态变量\n\n我们刚才使用 result 结果变量充当了判断任务是否结束的标志，其实 FutureTask 没有用它，而是定义了几个状态变量 ：\n\n// 当前状态\nprivate volatile int state;\n\n// NEW 新建状态，表示这个 FutureTask还没有开始运行\nprivate static final int NEW = 0;\n// COMPLETING 完成状态， 表示 FutureTask 任务已经计算完毕了，但是还有一些后续操作没有完成。\nprivate static final int COMPLETING   = 1;\n\n// FutureTask 任务完结，正常完成，没有发生异常\nprivate static final int NORMAL       = 2;\n// FutureTask 任务完结，因为发生异常。\nprivate static final int EXCEPTIONAL  = 3;\n// FutureTask 任务完结，因为取消任务\nprivate static final int CANCELLED    = 4;\n// FutureTask 任务完结，也是取消任务，不过发起了中断运行任务线程的中断请求\nprivate static final int INTERRUPTING = 5;\n// FutureTask 任务完结，也是取消任务，已经完成了中断运行任务线程的中断请求\nprivate static final int INTERRUPTED  = 6;\n\n\n为什么有了 outcome 结果变量还要使用状态变量来表示任务是否结束呢？\n\n因为 FutureTask 执行的任务既可以是 Callable，又可以是 Runnable，Runnable 可没有返回值哦，所以使用状态变量来表示任务是否执行结束\n\npublic FutureTask(Callable<V> callable);\n\npublic FutureTask(Runnable runnable, Void result);\n\n\n这些状态变量大致可以分为两种 ：已执行、未执行。\n\n如果 state > COMPLETING 就说明任务已经执行完了，不管是正常执行还是异常执行，反正现在要把结果result返回给主线程。\n\nCOMPLETING 这个状态很特殊，如果 state = COMPLETING，那么这个任务算是已经执行完了，但是还有一些变量还没有改变，所以你可以理解为 ：callable 执行完了，但 future 没执行完。\n\n讲到现在，FutureTask 中的变量共有 ：\n\npublic class FutureTask<T> {\n    // 任务\n    private Callable<T> callable;\n    // 结果\n    private Object outcome;\n    // 当前状态\n    private volatile int state;\n\n    // NEW 新建状态，表示这个 FutureTask还没有开始运行\n    private static final int NEW = 0;\n    // COMPLETING 完成状态， 表示 FutureTask 任务已经计算完毕了\n    // 但是还有一些后续操作，例如唤醒等待线程操作，还没有完成。\n    private static final int COMPLETING   = 1;\n\n    // FutureTask 任务完结，正常完成，没有发生异常\n    private static final int NORMAL       = 2;\n    // FutureTask 任务完结，因为发生异常。\n    private static final int EXCEPTIONAL  = 3;\n    // FutureTask 任务完结，因为取消任务\n    private static final int CANCELLED    = 4;\n    // FutureTask 任务完结，也是取消任务，不过发起了中断运行任务线程的中断请求\n    private static final int INTERRUPTING = 5;\n    // FutureTask 任务完结，也是取消任务，已经完成了中断运行任务线程的中断请求\n    private static final int INTERRUPTED  = 6;\n}\n\n\n\n# 2.2 FutureTask 中的链表变量\n\nFutureTask 使用的场景是并发环境，大概率是多线程拥有同一个 callable，然后一起执行 future.run、future.get\n\n所以要保证即使在并发环境下，同一个 callable 也只能执行一次。\n\n * 使用 runner 代表成功调用 future.run() 的线程，当多个线程使用 CAS 将 runner 设置为自己时，只有一个能成功\n * 其他线程调用 future.run() 失败后并不抛异常，而是继续向下执行 future.get()，如果 callable 执行时间过长，其他线程必须封装为链表的节点，阻塞等待，一直到任务执行完毕时遍历连表将他们唤醒。\n\npublic class FutureTask<V> implements RunnableFuture<V> {\n\t// 任务的执行状态\n    private volatile int state;\n    // 新建，未执行\n    private static final int NEW          = 0;\n    // 正在执行，未执行结束\n    private static final int COMPLETING   = 1;\n    // 已执行结束，正常执行结束\n    private static final int NORMAL       = 2;\n    // 已执行结束，异常执行结束\n    private static final int EXCEPTIONAL  = 3;\n    // 已执行结束，被停止\n    private static final int CANCELLED    = 4;\n    // 已执行结束，发起了中断请求\n    private static final int INTERRUPTING = 5;\n    // 已执行结束，完成了中断请求\n    private static final int INTERRUPTED  = 6;\n\n\t// 需要执行的任务\n    private Callable<V> callable;\n\t// 执行结果，如果是正常执行，outcome为结果。如果是异常执行，outcome是异常。\n    private Object outcome; \n    // 调用 callable.run() 的线程。\n    private volatile Thread runner;\n    \n    // 所有被阻塞的链表节点，内含有线程\n    private volatile WaitNode waiters;\n    static final class WaitNode {\n        volatile Thread thread;\n        volatile WaitNode next;\n        WaitNode() { thread = Thread.currentThread(); }\n    }\n}\n\n\n作为链表节点 WaitNode，其实 FutureTask 中并没有实现其他内容去维护这个链表，而是粗暴的使用 Unsafe 去执行将节点添加到链表中的操作。\n\nprivate static final sun.misc.Unsafe UNSAFE;\n// state变量的地址\nprivate static final long stateOffset;\n// runner线程的地址\nprivate static final long runnerOffset;\n// 其他调用 futureTask.get() 进入阻塞的线程的地址\nprivate static final long waitersOffset;\nstatic {\n    try {\n        UNSAFE = sun.misc.Unsafe.getUnsafe();\n        Class<?> k = FutureTask.class;\n        stateOffset = UNSAFE.objectFieldOffset\n            (k.getDeclaredField("state"));\n        runnerOffset = UNSAFE.objectFieldOffset\n            (k.getDeclaredField("runner"));\n        waitersOffset = UNSAFE.objectFieldOffset\n            (k.getDeclaredField("waiters"));\n    } catch (Exception e) {\n        throw new Error(e);\n    }\n}\n\n\n通过 Unsafe 得到 state、runner、waiter的地址，以后就可以用 Unsafe.CAS() 操作这些变量。\n\n到现在，FutureTask 的变量全部介绍完成，贴一下代码：\n\npublic class FutureTask<V> implements RunnableFuture<V> {\n\t// 任务的执行状态\n    private volatile int state;\n    // 新建，未执行\n    private static final int NEW          = 0;\n    // 正在执行，未执行结束\n    private static final int COMPLETING   = 1;\n    // 已执行结束，正常执行结束\n    private static final int NORMAL       = 2;\n    // 已执行结束，异常执行结束\n    private static final int EXCEPTIONAL  = 3;\n    // 已执行结束，被停止\n    private static final int CANCELLED    = 4;\n    // 已执行结束，发起了中断请求\n    private static final int INTERRUPTING = 5;\n    // 已执行结束，完成了中断请求\n    private static final int INTERRUPTED  = 6;\n\n\t// 需要执行的任务\n    private Callable<V> callable;\n\t// 执行结果，如果是正常执行，outcome为结果。如果是异常执行，outcome是异常。\n    private Object outcome; \n    // 调用 callable.run() 的线程。\n    private volatile Thread runner;\n    \n    // 所有被阻塞的链表节点，内含有线程\n    private volatile WaitNode waiters;\n    static final class WaitNode {\n        volatile Thread thread;\n        volatile WaitNode next;\n        WaitNode() { thread = Thread.currentThread(); }\n    }\n    \n    private static final sun.misc.Unsafe UNSAFE;\n    // state变量的地址\n    private static final long stateOffset;\n    // runner线程的地址\n    private static final long runnerOffset;\n    // 其他调用 futureTask.get() 进入阻塞的线程的地址\n    private static final long waitersOffset;\n    static {\n        try {\n            UNSAFE = sun.misc.Unsafe.getUnsafe();\n            Class<?> k = FutureTask.class;\n            stateOffset = UNSAFE.objectFieldOffset\n                (k.getDeclaredField("state"));\n            runnerOffset = UNSAFE.objectFieldOffset\n                (k.getDeclaredField("runner"));\n            waitersOffset = UNSAFE.objectFieldOffset\n                (k.getDeclaredField("waiters"));\n        } catch (Exception e) {\n            throw new Error(e);\n        }\n    }\n}\n\n\n再介绍一下 ：\n\n * callable ：被执行的任务\n * outcome ：结果变量\n * state ：状态变量\n * runner ：成功调度 future.run() 的线程\n * waiter ：所有等待结果的线程的头节点。\n\n\n# 3. FutureTask.run()\n\n如果让咱们借助上面的变量实现 run方法如何实现？\n\n首先要做判断，可能有多个线程调用了 FutureTask.run()但是只有一个可以成功调用，如何判断？\n\nstate 变量和 runnerOfferset 变量\n\nif (state != NEW ||\n    !UNSAFE.compareAndSwapObject(this, runnerOffset,\n                                 null, Thread.currentThread())) {\n    return;\n}\n\n\n * state != NEW ：callable已经被别的线程运行了，state不再是新创建了。\n * 使用 CAS 将运行 callable 的 runner 从 null 改为此线程，失败了就代表没抢过。\n\n这个判断是为了防止任务多次执行。如果能走出这个判断，也就拿到了执行任务的权利，此时的 runner已经为本线程了。\n\nif (state != NEW ||\n    !UNSAFE.compareAndSwapObject(this, runnerOffset,\n                                 null, Thread.currentThread())) {\n    return;\n}\ntry {\n    Callable<V> c = callable;\n    if (c != null && state == NEW) {\n        V result;\n        boolean ran;\n        try {\n            result = c.call();\n            ran = true;\n        } catch (Throwable ex) {\n            result = null;\n            ran = false;\n            setException(ex);\n        }\n        if (ran)\n            set(result);\n    }\n} finally {\n    runner = null;\n    int s = state;\n    if (s >= INTERRUPTING)\n        handlePossibleCancellationInterrupt(s);\n}\n\n\n其实逻辑也挺简单，拿到 callable 之后调用它，如果没有异常就执行 set(result) 方法，盲猜 set() 方法就是将 result 变量赋值给 outcome 的，但是答案不会在此处揭晓。\n\n整个 run() 的逻辑 ：\n\n 1. 抢 callable.call() 的执行权，没抢到就退出，去执行 future.get()\n 2. 抢到的就执行 callable.call()，然后将结果赋值给 outcome\n\n\n# 4. FutureTask.get()\n\nget() 就是FutureTask 阻塞的核心了，它阻塞的不是 callable 线程，而是调用 FutureTask.get() 的线程，所以还是比较好实现的。\n\n一共有两种实现方式，一种是无限阻塞，一种是限时阻塞。先来看一下无限阻塞。\n\npublic V get() throws InterruptedException, ExecutionException {\n    int s = state;\n    // 如果任务还未执行完毕，线程将会被阻塞在这个if中\n    if (s <= COMPLETING)\n        s = awaitDone(false, 0L);\n    \n    // 走到这里的线程有两种情况 ：\n    // 1. 任务执行的飞快，线程压根没阻塞\n    // 2. 线程if之后进入阻塞状态，然后任务执行完后被唤醒了，自然走到了return，可以将结果返回。\n    return report(s);\n}\n\n\n如果 state > COMPLETING，说明有结果了，结果是正常的还是异常的先不论，反正可以返回一个结果。\n\n如果 state <= COMPLETING，说明未执行或正在执行，那么就可以阻塞当前线程了。\n\n让当前线程阻塞是在 awaitDone 中实现的 ：\n\n// timed : 是否为限时阻塞\n// nanos : 如果是限时阻塞，限时多久\nprivate int awaitDone(boolean timed, long nanos)\n    throws InterruptedException {\n    // 先判断一下是否限时，如果限时，计算出结束限时的时间。\n    final long deadline = timed ? System.nanoTime() + nanos : 0L;\n    WaitNode q = null;\n    boolean queued = false;\n    // 死循环\n    for (;;) {\n        if (Thread.interrupted()) {\n            removeWaiter(q);\n            throw new InterruptedException();\n        }\n\t\t// 由于任务随时可能执行结束，所以每次循环都重新获取当前状态\n        int s = state;\n        // 如果大于 COMPLETING 说明已经执行完了，将状态返回\n        // 由于是死循环遍历，第n次遍历的时候 state总有执行成功那一天\n        if (s > COMPLETING) {\n            if (q != null)\n                q.thread = null;\n            return s;\n        }\n        // 如果正在执行，当前线程让出CPU\n        else if (s == COMPLETING) \n            Thread.yield();\n        // 如果 q == Null，那我们就要将当前线程封装为 节点，下次循环就可以放到阻塞链表中\n        // 该线程第一次循环会被封装为节点，下一次循环才会被放入阻塞链表\n        else if (q == null)\n            q = new WaitNode();\n        // 如果当前线程的节点还没有放入阻塞链表中，现在就放入。\n        else if (!queued)\n            queued = UNSAFE.compareAndSwapObject(this, waitersOffset,\n                                                 q.next = waiters, q);\n        // 如果要限时阻塞，获取一下阻塞时间，调用 LockSupport.parkNanos()\n        // 不用担心这个线程醒不来，run() 中调用的 finishCompletion() 会将所有 park 的线程 unpark\n        else if (timed) {\n            nanos = deadline - System.nanoTime();\n            if (nanos <= 0L) {\n                removeWaiter(q);\n                return state;\n            }\n            LockSupport.parkNanos(this, nanos);\n        }\n        // 否则就直接park\n        else\n            LockSupport.park(this);\n    }\n}\n\n\n所有调用 FutureTask.get() 的线程都会进入阻塞链表其实就是挨个挂在 waiters 的 next 上，如果 FutureTask.run() 中走出了 callable.call() ，在 set(result) 时会将所有 park 的线程唤醒。\n\n\n# 5. FutureTask.set()\n\n任务执行成功后调用 FutureTask.set(result) 方法将结果赋值给 outcome，再将所有线程唤醒。\n\nprotected void set(V v) {\n    // CAS操作将state从 NEW 改为 COMPLETING\n    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {\n        outcome = v;\n        // CAS操作将state从 COMPLETING 改为 NORMAL\n        UNSAFE.putOrderedInt(this, stateOffset, NORMAL); \n        // 唤醒阻塞的线程们\n        finishCompletion();\n    }\n}\n\n\n当任务执行完毕的时候，set() 调用 CAS 将 state 从 NEW 改为 COMPLETING，如果更改成功，就将任务执行的结果赋值给 outcome，再用 CAS 将 state 改为 NORMAL，此时，任务正式执行完成。但是接下来还需要唤醒其他等待结果的线程 ：finishCompletion()\n\nprivate void finishCompletion() {\n\t// 为什么要双重循环，其实这里我不懂。\n    for (WaitNode q; (q = waiters) != null;) {\n        if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) {\n            for (;;) {\n                // 取出此节点的线程，调用 LockSupport.unpatk(t) 唤醒此节点\n                Thread t = q.thread;\n                if (t != null) {\n                    q.thread = null;\n                    LockSupport.unpark(t);\n                }\n                WaitNode next = q.next;\n                // 如果q.next为空，说明 q是最后一个节点，退出循环\n                if (next == null)\n                    break;\n                // 如果 q.next 不为空，继续循环，目的是将所有节点的线程唤醒\n                // 方便gc\n                q.next = null; \n                // 将 q 改为 next\n                q = next;\n            }\n            break;\n        }\n    }\n\t// 钩子函数，交给程序员实现\n    done();\n\t// 任务执行完毕，所有等待线程已经唤醒，可以将 callable 置为空\n    callable = null;        // to reduce footprint\n}\n\n\n刚才我们说 ：state = COMPLETING 代表 callable 已经执行完了，FutureTask 没执行完，现在你知道啥意思了吧。因为任务虽然执行完了，但是还有很多阻塞等待的链表没有 notify 起来，它们还在等待。\n\n好了，再看着源码分析一下执行流程 ：\n\npublic void run() {\n    // 1. 判断callable是否已经被别的线程启动\n    if (state != NEW ||\n        !UNSAFE.compareAndSwapObject(this, runnerOffset,\n                                     null, Thread.currentThread()))\n        return;\n    // 走到这里说明callable没有被别的线程启动，此线程可以启动 callable\n    try {\n        // 拿到 callable\n        Callable<V> c = callable;\n        // 再次判断\n        if (c != null && state == NEW) {\n            V result;\n            boolean ran;\n            try {\n                // 执行任务\n                result = c.call();\n                ran = true;\n            } catch (Throwable ex) {\n                result = null;\n                ran = false;\n                setException(ex);\n            }\n            // 如果ran为true:\n            // 1. 将状态改为 COMPLETING\n            // 2. 将结果赋值给 outcome\n            // 3. 将状态改为 Normal\n            // 4. 唤醒所有阻塞的线程\n            if (ran)\n                set(result);\n        }\n    } finally {\n        // 执行完了将 runner置为空\n        runner = null;\n        int s = state;\n        if (s >= INTERRUPTING)\n            handlePossibleCancellationInterrupt(s);\n    }\n}\n\n// 1. 将状态改为 COMPLETING\n// 2. 将结果赋值给 outcome\n// 3. 将状态改为 Normal\n// 4. 唤醒所有阻塞的线程\nprotected void set(V v) {\n    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {\n        outcome = v;\n        UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state\n        finishCompletion();\n    }\n}\n\n// 唤醒所有阻塞等待的线程\nprivate void finishCompletion() {\n    // assert state > COMPLETING;\n    for (WaitNode q; (q = waiters) != null;) {\n        if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) {\n            for (;;) {\n                Thread t = q.thread;\n                if (t != null) {\n                    q.thread = null;\n                    LockSupport.unpark(t);\n                }\n                WaitNode next = q.next;\n                if (next == null)\n                    break;\n                q.next = null; // unlink to help gc\n                q = next;\n            }\n            break;\n        }\n    }\n    done();\n    callable = null;        // to reduce footprint\n}\n\n\n\n# 6. 总结\n\n到这里就讲完了，跟小伙伴们讨论的时候感觉难的地方就是 FutureTask 对阻塞链表的管理，比如添加节点、删除节点，并没有用 Java 做，也不能这么说，反正就是 debug 的时候确实看的不太清且。其实 FutureTask 算上注释也才480行，去掉注释估计就 300行了，不难阅读',normalizedContent:'# 1. 简述\n\nfuturetask 实现了 runnable、future，可以进行任务的异步执行，但是 futuretask 会阻塞主线程。\n\n它提供了两个功能 ：\n\n 1. 执行任务\n 2. 阻塞等待任务执行完毕\n\npublic static void main(string[] args) throws executionexception, interruptedexception {\n    callable<string> callable = new callable<string>() {\n        @override\n        public string call() throws exception {\n            // 处理业务\n            return "执行结束";\n        }\n    };\n\n    futuretask<string> futuretask = new futuretask<>(callable);\n    // 执行任务\n    futuretask.run();\n    // 阻塞等待结果\n    futuretask.get();\n}\n\n\n从代码中可以猜测 ：\n\n * futuretask 内部有一个 callable 变量\n * futuretask.run() 调用了 callable.call() 去获取结果\n * 此时 futuretask.get() 的结果会是null，故执行 futuretask.get() 的线程会阻塞，callable.call() 方法运行。\n * callable.run() 方法结束，将运行的结果交给 futuretask，futuretask 停止阻塞。\n\n\n\n想要搞懂 futuretask 的源码，必须要搞懂它做了什么，根据上面的阐述可以简单猜测：\n\n 1. futuretask 中的变量不仅有 callable，还有 callable 执行后的结果 result，callable 执行后将结果设置给 result。\n 2. futuretask.get() 方法用 while(true) 循环检查result，如果为空说明没执行完，继续循环；如果不为空说明已经执行结束，退出循环并返回结果。\n\n简单实现一下futuretask\n\npublic class futuretask<t> {\n    // 任务\n    private callable<t> callable;\n    // 结果\n    private t result;\n    \n    public void run() {\n    \tr = callable.call();    \n    \tresult = r;\n    }\n    \n    public t get() {\n        while (true) {\n            if (result == null) {\n                // 当前线程让出执行权，也就是主线程让出执行权。\n                thread.yield();\n            } else {\n            \treturn t;    \n            }\n        }\n    }\n}\n\n\n但是真正的 futuretask 才不会这么简单。接下来进入 futuretask 的源码一探究竟。\n\n\n# 2. futuretask 中的变量\n\n根据之前的分析，futuretask已经有了两个变量 ：\n\npublic class futuretask<t> {\n    // 任务\n    private callable<t> callable;\n    // 结果\n    private t outcome;\n}\n\n\n\n# 2.1 futuretask 中的状态变量\n\n我们刚才使用 result 结果变量充当了判断任务是否结束的标志，其实 futuretask 没有用它，而是定义了几个状态变量 ：\n\n// 当前状态\nprivate volatile int state;\n\n// new 新建状态，表示这个 futuretask还没有开始运行\nprivate static final int new = 0;\n// completing 完成状态， 表示 futuretask 任务已经计算完毕了，但是还有一些后续操作没有完成。\nprivate static final int completing   = 1;\n\n// futuretask 任务完结，正常完成，没有发生异常\nprivate static final int normal       = 2;\n// futuretask 任务完结，因为发生异常。\nprivate static final int exceptional  = 3;\n// futuretask 任务完结，因为取消任务\nprivate static final int cancelled    = 4;\n// futuretask 任务完结，也是取消任务，不过发起了中断运行任务线程的中断请求\nprivate static final int interrupting = 5;\n// futuretask 任务完结，也是取消任务，已经完成了中断运行任务线程的中断请求\nprivate static final int interrupted  = 6;\n\n\n为什么有了 outcome 结果变量还要使用状态变量来表示任务是否结束呢？\n\n因为 futuretask 执行的任务既可以是 callable，又可以是 runnable，runnable 可没有返回值哦，所以使用状态变量来表示任务是否执行结束\n\npublic futuretask(callable<v> callable);\n\npublic futuretask(runnable runnable, void result);\n\n\n这些状态变量大致可以分为两种 ：已执行、未执行。\n\n如果 state > completing 就说明任务已经执行完了，不管是正常执行还是异常执行，反正现在要把结果result返回给主线程。\n\ncompleting 这个状态很特殊，如果 state = completing，那么这个任务算是已经执行完了，但是还有一些变量还没有改变，所以你可以理解为 ：callable 执行完了，但 future 没执行完。\n\n讲到现在，futuretask 中的变量共有 ：\n\npublic class futuretask<t> {\n    // 任务\n    private callable<t> callable;\n    // 结果\n    private object outcome;\n    // 当前状态\n    private volatile int state;\n\n    // new 新建状态，表示这个 futuretask还没有开始运行\n    private static final int new = 0;\n    // completing 完成状态， 表示 futuretask 任务已经计算完毕了\n    // 但是还有一些后续操作，例如唤醒等待线程操作，还没有完成。\n    private static final int completing   = 1;\n\n    // futuretask 任务完结，正常完成，没有发生异常\n    private static final int normal       = 2;\n    // futuretask 任务完结，因为发生异常。\n    private static final int exceptional  = 3;\n    // futuretask 任务完结，因为取消任务\n    private static final int cancelled    = 4;\n    // futuretask 任务完结，也是取消任务，不过发起了中断运行任务线程的中断请求\n    private static final int interrupting = 5;\n    // futuretask 任务完结，也是取消任务，已经完成了中断运行任务线程的中断请求\n    private static final int interrupted  = 6;\n}\n\n\n\n# 2.2 futuretask 中的链表变量\n\nfuturetask 使用的场景是并发环境，大概率是多线程拥有同一个 callable，然后一起执行 future.run、future.get\n\n所以要保证即使在并发环境下，同一个 callable 也只能执行一次。\n\n * 使用 runner 代表成功调用 future.run() 的线程，当多个线程使用 cas 将 runner 设置为自己时，只有一个能成功\n * 其他线程调用 future.run() 失败后并不抛异常，而是继续向下执行 future.get()，如果 callable 执行时间过长，其他线程必须封装为链表的节点，阻塞等待，一直到任务执行完毕时遍历连表将他们唤醒。\n\npublic class futuretask<v> implements runnablefuture<v> {\n\t// 任务的执行状态\n    private volatile int state;\n    // 新建，未执行\n    private static final int new          = 0;\n    // 正在执行，未执行结束\n    private static final int completing   = 1;\n    // 已执行结束，正常执行结束\n    private static final int normal       = 2;\n    // 已执行结束，异常执行结束\n    private static final int exceptional  = 3;\n    // 已执行结束，被停止\n    private static final int cancelled    = 4;\n    // 已执行结束，发起了中断请求\n    private static final int interrupting = 5;\n    // 已执行结束，完成了中断请求\n    private static final int interrupted  = 6;\n\n\t// 需要执行的任务\n    private callable<v> callable;\n\t// 执行结果，如果是正常执行，outcome为结果。如果是异常执行，outcome是异常。\n    private object outcome; \n    // 调用 callable.run() 的线程。\n    private volatile thread runner;\n    \n    // 所有被阻塞的链表节点，内含有线程\n    private volatile waitnode waiters;\n    static final class waitnode {\n        volatile thread thread;\n        volatile waitnode next;\n        waitnode() { thread = thread.currentthread(); }\n    }\n}\n\n\n作为链表节点 waitnode，其实 futuretask 中并没有实现其他内容去维护这个链表，而是粗暴的使用 unsafe 去执行将节点添加到链表中的操作。\n\nprivate static final sun.misc.unsafe unsafe;\n// state变量的地址\nprivate static final long stateoffset;\n// runner线程的地址\nprivate static final long runneroffset;\n// 其他调用 futuretask.get() 进入阻塞的线程的地址\nprivate static final long waitersoffset;\nstatic {\n    try {\n        unsafe = sun.misc.unsafe.getunsafe();\n        class<?> k = futuretask.class;\n        stateoffset = unsafe.objectfieldoffset\n            (k.getdeclaredfield("state"));\n        runneroffset = unsafe.objectfieldoffset\n            (k.getdeclaredfield("runner"));\n        waitersoffset = unsafe.objectfieldoffset\n            (k.getdeclaredfield("waiters"));\n    } catch (exception e) {\n        throw new error(e);\n    }\n}\n\n\n通过 unsafe 得到 state、runner、waiter的地址，以后就可以用 unsafe.cas() 操作这些变量。\n\n到现在，futuretask 的变量全部介绍完成，贴一下代码：\n\npublic class futuretask<v> implements runnablefuture<v> {\n\t// 任务的执行状态\n    private volatile int state;\n    // 新建，未执行\n    private static final int new          = 0;\n    // 正在执行，未执行结束\n    private static final int completing   = 1;\n    // 已执行结束，正常执行结束\n    private static final int normal       = 2;\n    // 已执行结束，异常执行结束\n    private static final int exceptional  = 3;\n    // 已执行结束，被停止\n    private static final int cancelled    = 4;\n    // 已执行结束，发起了中断请求\n    private static final int interrupting = 5;\n    // 已执行结束，完成了中断请求\n    private static final int interrupted  = 6;\n\n\t// 需要执行的任务\n    private callable<v> callable;\n\t// 执行结果，如果是正常执行，outcome为结果。如果是异常执行，outcome是异常。\n    private object outcome; \n    // 调用 callable.run() 的线程。\n    private volatile thread runner;\n    \n    // 所有被阻塞的链表节点，内含有线程\n    private volatile waitnode waiters;\n    static final class waitnode {\n        volatile thread thread;\n        volatile waitnode next;\n        waitnode() { thread = thread.currentthread(); }\n    }\n    \n    private static final sun.misc.unsafe unsafe;\n    // state变量的地址\n    private static final long stateoffset;\n    // runner线程的地址\n    private static final long runneroffset;\n    // 其他调用 futuretask.get() 进入阻塞的线程的地址\n    private static final long waitersoffset;\n    static {\n        try {\n            unsafe = sun.misc.unsafe.getunsafe();\n            class<?> k = futuretask.class;\n            stateoffset = unsafe.objectfieldoffset\n                (k.getdeclaredfield("state"));\n            runneroffset = unsafe.objectfieldoffset\n                (k.getdeclaredfield("runner"));\n            waitersoffset = unsafe.objectfieldoffset\n                (k.getdeclaredfield("waiters"));\n        } catch (exception e) {\n            throw new error(e);\n        }\n    }\n}\n\n\n再介绍一下 ：\n\n * callable ：被执行的任务\n * outcome ：结果变量\n * state ：状态变量\n * runner ：成功调度 future.run() 的线程\n * waiter ：所有等待结果的线程的头节点。\n\n\n# 3. futuretask.run()\n\n如果让咱们借助上面的变量实现 run方法如何实现？\n\n首先要做判断，可能有多个线程调用了 futuretask.run()但是只有一个可以成功调用，如何判断？\n\nstate 变量和 runnerofferset 变量\n\nif (state != new ||\n    !unsafe.compareandswapobject(this, runneroffset,\n                                 null, thread.currentthread())) {\n    return;\n}\n\n\n * state != new ：callable已经被别的线程运行了，state不再是新创建了。\n * 使用 cas 将运行 callable 的 runner 从 null 改为此线程，失败了就代表没抢过。\n\n这个判断是为了防止任务多次执行。如果能走出这个判断，也就拿到了执行任务的权利，此时的 runner已经为本线程了。\n\nif (state != new ||\n    !unsafe.compareandswapobject(this, runneroffset,\n                                 null, thread.currentthread())) {\n    return;\n}\ntry {\n    callable<v> c = callable;\n    if (c != null && state == new) {\n        v result;\n        boolean ran;\n        try {\n            result = c.call();\n            ran = true;\n        } catch (throwable ex) {\n            result = null;\n            ran = false;\n            setexception(ex);\n        }\n        if (ran)\n            set(result);\n    }\n} finally {\n    runner = null;\n    int s = state;\n    if (s >= interrupting)\n        handlepossiblecancellationinterrupt(s);\n}\n\n\n其实逻辑也挺简单，拿到 callable 之后调用它，如果没有异常就执行 set(result) 方法，盲猜 set() 方法就是将 result 变量赋值给 outcome 的，但是答案不会在此处揭晓。\n\n整个 run() 的逻辑 ：\n\n 1. 抢 callable.call() 的执行权，没抢到就退出，去执行 future.get()\n 2. 抢到的就执行 callable.call()，然后将结果赋值给 outcome\n\n\n# 4. futuretask.get()\n\nget() 就是futuretask 阻塞的核心了，它阻塞的不是 callable 线程，而是调用 futuretask.get() 的线程，所以还是比较好实现的。\n\n一共有两种实现方式，一种是无限阻塞，一种是限时阻塞。先来看一下无限阻塞。\n\npublic v get() throws interruptedexception, executionexception {\n    int s = state;\n    // 如果任务还未执行完毕，线程将会被阻塞在这个if中\n    if (s <= completing)\n        s = awaitdone(false, 0l);\n    \n    // 走到这里的线程有两种情况 ：\n    // 1. 任务执行的飞快，线程压根没阻塞\n    // 2. 线程if之后进入阻塞状态，然后任务执行完后被唤醒了，自然走到了return，可以将结果返回。\n    return report(s);\n}\n\n\n如果 state > completing，说明有结果了，结果是正常的还是异常的先不论，反正可以返回一个结果。\n\n如果 state <= completing，说明未执行或正在执行，那么就可以阻塞当前线程了。\n\n让当前线程阻塞是在 awaitdone 中实现的 ：\n\n// timed : 是否为限时阻塞\n// nanos : 如果是限时阻塞，限时多久\nprivate int awaitdone(boolean timed, long nanos)\n    throws interruptedexception {\n    // 先判断一下是否限时，如果限时，计算出结束限时的时间。\n    final long deadline = timed ? system.nanotime() + nanos : 0l;\n    waitnode q = null;\n    boolean queued = false;\n    // 死循环\n    for (;;) {\n        if (thread.interrupted()) {\n            removewaiter(q);\n            throw new interruptedexception();\n        }\n\t\t// 由于任务随时可能执行结束，所以每次循环都重新获取当前状态\n        int s = state;\n        // 如果大于 completing 说明已经执行完了，将状态返回\n        // 由于是死循环遍历，第n次遍历的时候 state总有执行成功那一天\n        if (s > completing) {\n            if (q != null)\n                q.thread = null;\n            return s;\n        }\n        // 如果正在执行，当前线程让出cpu\n        else if (s == completing) \n            thread.yield();\n        // 如果 q == null，那我们就要将当前线程封装为 节点，下次循环就可以放到阻塞链表中\n        // 该线程第一次循环会被封装为节点，下一次循环才会被放入阻塞链表\n        else if (q == null)\n            q = new waitnode();\n        // 如果当前线程的节点还没有放入阻塞链表中，现在就放入。\n        else if (!queued)\n            queued = unsafe.compareandswapobject(this, waitersoffset,\n                                                 q.next = waiters, q);\n        // 如果要限时阻塞，获取一下阻塞时间，调用 locksupport.parknanos()\n        // 不用担心这个线程醒不来，run() 中调用的 finishcompletion() 会将所有 park 的线程 unpark\n        else if (timed) {\n            nanos = deadline - system.nanotime();\n            if (nanos <= 0l) {\n                removewaiter(q);\n                return state;\n            }\n            locksupport.parknanos(this, nanos);\n        }\n        // 否则就直接park\n        else\n            locksupport.park(this);\n    }\n}\n\n\n所有调用 futuretask.get() 的线程都会进入阻塞链表其实就是挨个挂在 waiters 的 next 上，如果 futuretask.run() 中走出了 callable.call() ，在 set(result) 时会将所有 park 的线程唤醒。\n\n\n# 5. futuretask.set()\n\n任务执行成功后调用 futuretask.set(result) 方法将结果赋值给 outcome，再将所有线程唤醒。\n\nprotected void set(v v) {\n    // cas操作将state从 new 改为 completing\n    if (unsafe.compareandswapint(this, stateoffset, new, completing)) {\n        outcome = v;\n        // cas操作将state从 completing 改为 normal\n        unsafe.putorderedint(this, stateoffset, normal); \n        // 唤醒阻塞的线程们\n        finishcompletion();\n    }\n}\n\n\n当任务执行完毕的时候，set() 调用 cas 将 state 从 new 改为 completing，如果更改成功，就将任务执行的结果赋值给 outcome，再用 cas 将 state 改为 normal，此时，任务正式执行完成。但是接下来还需要唤醒其他等待结果的线程 ：finishcompletion()\n\nprivate void finishcompletion() {\n\t// 为什么要双重循环，其实这里我不懂。\n    for (waitnode q; (q = waiters) != null;) {\n        if (unsafe.compareandswapobject(this, waitersoffset, q, null)) {\n            for (;;) {\n                // 取出此节点的线程，调用 locksupport.unpatk(t) 唤醒此节点\n                thread t = q.thread;\n                if (t != null) {\n                    q.thread = null;\n                    locksupport.unpark(t);\n                }\n                waitnode next = q.next;\n                // 如果q.next为空，说明 q是最后一个节点，退出循环\n                if (next == null)\n                    break;\n                // 如果 q.next 不为空，继续循环，目的是将所有节点的线程唤醒\n                // 方便gc\n                q.next = null; \n                // 将 q 改为 next\n                q = next;\n            }\n            break;\n        }\n    }\n\t// 钩子函数，交给程序员实现\n    done();\n\t// 任务执行完毕，所有等待线程已经唤醒，可以将 callable 置为空\n    callable = null;        // to reduce footprint\n}\n\n\n刚才我们说 ：state = completing 代表 callable 已经执行完了，futuretask 没执行完，现在你知道啥意思了吧。因为任务虽然执行完了，但是还有很多阻塞等待的链表没有 notify 起来，它们还在等待。\n\n好了，再看着源码分析一下执行流程 ：\n\npublic void run() {\n    // 1. 判断callable是否已经被别的线程启动\n    if (state != new ||\n        !unsafe.compareandswapobject(this, runneroffset,\n                                     null, thread.currentthread()))\n        return;\n    // 走到这里说明callable没有被别的线程启动，此线程可以启动 callable\n    try {\n        // 拿到 callable\n        callable<v> c = callable;\n        // 再次判断\n        if (c != null && state == new) {\n            v result;\n            boolean ran;\n            try {\n                // 执行任务\n                result = c.call();\n                ran = true;\n            } catch (throwable ex) {\n                result = null;\n                ran = false;\n                setexception(ex);\n            }\n            // 如果ran为true:\n            // 1. 将状态改为 completing\n            // 2. 将结果赋值给 outcome\n            // 3. 将状态改为 normal\n            // 4. 唤醒所有阻塞的线程\n            if (ran)\n                set(result);\n        }\n    } finally {\n        // 执行完了将 runner置为空\n        runner = null;\n        int s = state;\n        if (s >= interrupting)\n            handlepossiblecancellationinterrupt(s);\n    }\n}\n\n// 1. 将状态改为 completing\n// 2. 将结果赋值给 outcome\n// 3. 将状态改为 normal\n// 4. 唤醒所有阻塞的线程\nprotected void set(v v) {\n    if (unsafe.compareandswapint(this, stateoffset, new, completing)) {\n        outcome = v;\n        unsafe.putorderedint(this, stateoffset, normal); // final state\n        finishcompletion();\n    }\n}\n\n// 唤醒所有阻塞等待的线程\nprivate void finishcompletion() {\n    // assert state > completing;\n    for (waitnode q; (q = waiters) != null;) {\n        if (unsafe.compareandswapobject(this, waitersoffset, q, null)) {\n            for (;;) {\n                thread t = q.thread;\n                if (t != null) {\n                    q.thread = null;\n                    locksupport.unpark(t);\n                }\n                waitnode next = q.next;\n                if (next == null)\n                    break;\n                q.next = null; // unlink to help gc\n                q = next;\n            }\n            break;\n        }\n    }\n    done();\n    callable = null;        // to reduce footprint\n}\n\n\n\n# 6. 总结\n\n到这里就讲完了，跟小伙伴们讨论的时候感觉难的地方就是 futuretask 对阻塞链表的管理，比如添加节点、删除节点，并没有用 java 做，也不能这么说，反正就是 debug 的时候确实看的不太清且。其实 futuretask 算上注释也才480行，去掉注释估计就 300行了，不难阅读',charsets:{cjk:!0},lastUpdated:"2024/02/28, 21:50:33",lastUpdatedTimestamp:1709128233e3},{title:"线程池",frontmatter:{title:"线程池",date:"2023-07-16T18:36:54.000Z",permalink:"/pages/671511/"},regularPath:"/02.%E6%96%87%E7%AB%A0/75.Java%E5%B9%B6%E5%8F%91/300.%E7%BA%BF%E7%A8%8B%E6%B1%A0.html",relativePath:"02.文章/75.Java并发/300.线程池.md",key:"v-d0b615f8",path:"/pages/671511/",headers:[{level:2,title:"1. 前言",slug:"_1-前言",normalizedTitle:"1. 前言",charIndex:2},{level:2,title:"2. 概述",slug:"_2-概述",normalizedTitle:"2. 概述",charIndex:12},{level:2,title:"3. Executor、ExecutorService",slug:"_3-executor、executorservice",normalizedTitle:"3. executor、executorservice",charIndex:278},{level:2,title:"4. ThreadPoolExecutor",slug:"_4-threadpoolexecutor",normalizedTitle:"4. threadpoolexecutor",charIndex:1412},{level:3,title:"4.1 七个核心参数",slug:"_4-1-七个核心参数",normalizedTitle:"4.1 七个核心参数",charIndex:1438},{level:3,title:"4.2 生命周期管理",slug:"_4-2-生命周期管理",normalizedTitle:"4.2 生命周期管理",charIndex:2340},{level:3,title:"4.3 任务执行机制",slug:"_4-3-任务执行机制",normalizedTitle:"4.3 任务执行机制",charIndex:3233},{level:2,title:"5. 线程池用到的队列",slug:"_5-线程池用到的队列",normalizedTitle:"5. 线程池用到的队列",charIndex:5489},{level:3,title:"5.0 阻塞队列与非阻塞队列",slug:"_5-0-阻塞队列与非阻塞队列",normalizedTitle:"5.0 阻塞队列与非阻塞队列",charIndex:5593},{level:3,title:"5.1 ArrayBlockingQueue",slug:"_5-1-arrayblockingqueue",normalizedTitle:"5.1 arrayblockingqueue",charIndex:6427},{level:3,title:"5.2 LinkedBlockingQueue",slug:"_5-2-linkedblockingqueue",normalizedTitle:"5.2 linkedblockingqueue",charIndex:8857},{level:3,title:"5.3 SynchronousQueue",slug:"_5-3-synchronousqueue",normalizedTitle:"5.3 synchronousqueue",charIndex:9721},{level:2,title:"6. 线程池用到的拒绝策略",slug:"_6-线程池用到的拒绝策略",normalizedTitle:"6. 线程池用到的拒绝策略",charIndex:10634},{level:2,title:"7. Executors",slug:"_7-executors",normalizedTitle:"7. executors",charIndex:12476},{level:2,title:"8. 线程池参数的配置",slug:"_8-线程池参数的配置",normalizedTitle:"8. 线程池参数的配置",charIndex:14077}],headersStr:"1. 前言 2. 概述 3. Executor、ExecutorService 4. ThreadPoolExecutor 4.1 七个核心参数 4.2 生命周期管理 4.3 任务执行机制 5. 线程池用到的队列 5.0 阻塞队列与非阻塞队列 5.1 ArrayBlockingQueue 5.2 LinkedBlockingQueue 5.3 SynchronousQueue 6. 线程池用到的拒绝策略 7. Executors 8. 线程池参数的配置",content:'# 1. 前言\n\n\n# 2. 概述\n\n至于为什么要有线程池，Java里面有很多池，例如常量池、数据库连接池、线程池.....他们都体现了一种池化思想，什么是池化思想呢？就是通过创建和管理可重复使用的资源来提高资源的利用率，进而提高性能。\n\n> 线程池简而言之，就是一个有许多线程的容器，这些线程并不跟我们平时使用的线程一样随用随丢，而是将它们放在容器也就是线程池中，以便可以重复使用，减少线程重复创建和销毁带来的性能消耗。\n\n首先来看一下ThreadPoolExecutor的UML类图，了解下ThreadPoolExecutor的继承关系。\n\n\n\n\n# 3. Executor、ExecutorService\n\n先来看一下Executor：\n\npublic interface Executor {\n    void execute(Runnable command);\n}\n\n\n可以看到，Executor 这个接口十分简单，只提供了一个 executor 方法，也就是执行方法。实现了这个方法的人要去完成线程的主要逻辑，也就是执行。\n\n接下来看 ExecutorService ，\n\npublic interface ExecutorService extends Executor {\n    void shutdown();  \n    List<Runnable> shutdownNow();\n    boolean isShutdown();\n    boolean isTerminated();\n    boolean awaitTermination(long timeout, TimeUnit unit)\n        throws InterruptedException;\n\n    <T> Future<T> submit(Callable<T> task);\n    <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks)\n        throws InterruptedException;\n    // 还有一些方法不再列举\n}\n\n\nExecutorService提供了对于线程池操作的服务，例如任务的提交submit、判断线程池的状态isShutdown....\n\nExecutorService接口增加了一些能力：\n（1）扩充执行任务的能力，补充可以为一个或一批异步任务生成Future的方法；\n（2）提供了管控线程池的方法，比如停止线程池的运行。AbstractExecutorService则是上层的抽象类，将执行任务的流程串联了起来，保证下层的实现只需关注一个执行任务的方法即可。\n\n> 那么当我们使用 ThreadPoolExecutor 时就可以意识到，\n> \n>  * 主要的执行方法是 实现Executor的。\n>  * 功能方法是 实现ExecutorService 的。\n\nExecutor和ExecutorService提供了一种思想 ：将任务的提交和任务的执行解耦。\n\n用户无需关注如何创建线程、如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。\n\n\n# 4. ThreadPoolExecutor\n\n\n# 4.1 七个核心参数\n\n只要学习 ThreadPoolExector ，绕不开它的七个参数。\n\npublic ThreadPoolExecutor(int corePoolSize,\n                          int maximumPoolSize,\n                          long keepAliveTime,\n                          TimeUnit unit,\n                          BlockingQueue<Runnable> workQueue,\n                          ThreadFactory threadFactory,\n                          RejectedExecutionHandler handler) \n\n\n 1. corePoolSize ：核心线程数，默认情况下，核心线程数会一直存活。\n\n 2. maximumPoolSize ：最大线程数，核心线程数+临时线程数的总和。\n    \n    除了核心线程数之外的线程数称为临时线程（maximumPoolSize - corePoolSize ），临时线程如果一定时间内接收不到任务会死亡。\n\n 3. keepAliveTime ：临时线程接收不到任务时的死亡时间。\n\n 4. unit ：时间的单位\n\n 5. workQueue ：阻塞队列，存放任务的地方。\n\n 6. threadFactory ：线程工厂，所有线程在这里被创建。\n\n 7. handler ：当任务实在太多时执行的拒绝任务的策略。\n\n线程池的工作流程\n\n当核心线程数有空闲数时，所有任务都会被核心线程处理，\n\n当核心线程都忙碌时，任务首先到达阻塞队列中等待，核心线程执行完手上的任务后会去任务队列中取任务。\n\n当任务队列满后会创建临时线程执行任务，临时线程也会从任务队列中取任务执行。\n\n当任务队列满了并且全部线程都在工作中，还是有新的任务到达，就会执行拒绝策略。\n\n\n# 4.2 生命周期管理\n\n线程池运行的状态并不是用户显式设置的，而是伴随着线程池的运行由内部来维护。线程池内部使用一个变量维护两个值：运行状态(runState)和线程数量 (workerCount)。\n在具体实现中，线程池将运行状态(runState)、线程数量 (workerCount)两个关键参数的维护放在了一起，由同一个变量管理：\n\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n\n\nctl这个AtomicInteger类型的变量，是对线程池的运行状态(runState)、线程数量 (workerCount) 两个信息的汇总， 高3位保存runState，低29位保存workerCount，两个变量之间互不干扰。用一个变量去存储两个值，可避免在做相关决策时出现不一致的情况，不必为了维护两者的一致而占用锁资源。\n\n// COUNT_BITS = 32 - 3 = 29\n// CAPACITY = 1 << 29 - 1\nprivate static final int COUNT_BITS = Integer.SIZE - 3;\nprivate static final int CAPACITY   = (1 << COUNT_BITS) - 1;\n\n//计算当前运行状态\nprivate static int runStateOf(int c)     { \n    return c & ~CAPACITY; \n} \n//计算当前线程数量\nprivate static int workerCountOf(int c)  { \n    return c & CAPACITY; \n}  \n//通过状态和线程数生成ctl\nprivate static int ctlOf(int rs, int wc) { \n    return rs | wc; \n}   \n\n\nThreadPoolExecutor的运行状态有5种，分别为：\n\n其生命周期转换如下入所示：\n\n\n# 4.3 任务执行机制\n\n任务调度是线程池的主要入口，当用户提交了一个任务，接下来这个任务将如何执行都是由这个阶段决定的。了解这部分就相当于了解了线程池的核心运行机制。\n\n首先，所有任务的调度都是由execute方法完成的，这部分完成的工作是：检查现在线程池的运行状态、运行线程数、运行策略，决定接下来执行的流程，是直接申请线程执行，或是缓冲到队列中执行，亦或是直接拒绝该任务。其执行过程如下：\n\n 1. 首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。\n 2. 如果workerCount < corePoolSize，则创建并启动一个线程来执行新提交的任务。\n 3. 如果workerCount >= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中。\n 4. 如果workerCount >= corePoolSize && workerCount < maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。\n 5. 如果workerCount >= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。\n\n来看一下它的 execute 源码 ：\n\npublic void execute(Runnable command) {\n    if (command == null)\n        throw new NullPointerException();\n    \n    // 获取ctl，用于检查线程池的线程数以及线程池状态\n    int c = ctl.get();\n    \n    // 如果当前任务数小于核心线程数，直接使用核心线程\n    if (workerCountOf(c) < corePoolSize) {\n        //执行addWorker,会创建一个核心线程，如果创建失败，重新获取ctl\n        if (addWorker(command, true))\n            return;\n        c = ctl.get();\n    }\n    \n    // 如果线程池还活着，那么就可以将它加入阻塞队列, (也仅仅是加入队列，并没有执行)\n    if (isRunning(c) && workQueue.offer(command)) {\n        //再次获取ctl，进行双重检索（也就是对线程池的状态再次检查一遍）\n        int recheck = ctl.get();\n        \n        //如果线程池是不是处于RUNNING的状态，那么就会将任务从队列中移除，\n        if (! isRunning(recheck) && remove(command))\n            reject(command);\n        //如果移除失败，则会判断工作线程是否为0 ，如果过为0 就创建一个非核心线程\n        else if (workerCountOf(recheck) == 0)\n            addWorker(null, false);\n    }\n\t//如果移除成功，就执行拒绝策略，因为线程池已经不可用了；\n    else if (!addWorker(command, false))\n        reject(command);\n}\n\n\n\n可以看到，创建核心线程和非核心线程都是调用addWorker方法\n\n// 如果Runnable不空，且core为true，则证明创建的是核心线程。\n// 如果Runnable为空，且core为false, 则证明创建的是非核心线程。\nprivate boolean addWorker(Runnable firstTask, boolean core)\n\n\naddWorker：把其他步骤都忽略，来看我们提交的一个任务是如何被处理的。\n\nprivate boolean addWorker(Runnable firstTask, boolean core) {\n        w = new Worker(firstTask);\n}\n\n\nnew 了一个Worker，那么这个Worker是什么？\n\nWorker(Runnable firstTask) {\n    setState(-1); // inhibit interrupts until runWorker\n    this.firstTask = firstTask;\n    this.thread = getThreadFactory().newThread(this);\n}\n\n\n从 getThreadFactory().newThread(this) 可以看出，就把当前的Worker对象作为任务传给了新建的线程，这样启动线程时，它也就启动了。\n\n> 那么思考一个问题：如果任务数量小于核心线程数并且再来一个任务，是优先让空闲的核心线程执行任务还是直接创建一个核心线程呢？\n> \n> 刚才的代码不是已经有答案了嘛？当调用addWorker添加一个任务的时候，如果核心线程数还没有创建满，优先创建核心线程。\n\n\n# 5. 线程池用到的队列\n\n为什么要学习阻塞队列？\n线程池可以高效利用线程，也就是说线程可以在某个地方一直拿任务去执行，而且执行完了之后还不死亡，那么去哪里拿任务呢？这时候就需要有一个容器：阻塞队列。\n\n\n# 5.0 阻塞队列与非阻塞队列\n\n 1. 阻塞队列\n    * 入队 ：如果队列满了，一直等待直到有位置就入队。\n    * 出队 ：如果队列中没有值，一直等待直到队列中有值才会出队。\n 2. 非阻塞队列\n    * 入队 ：队列有位置就入队，没位置就返回false或者报错。\n    * 出队 ：队列中有值就出队，没有值就返回NULL或者报错。\n\n非阻塞队列中的几个主要方法：add(T)、remove()、offer(T)、poll()、peek()。\n\n阻塞队列拥有非阻塞队列的全部方法，而且还多了几个方法：put(T)、take()、offer(T, timeout)、poll(T, timeout)。\n\n这几个方法实现了阻塞效果，也是上面介绍的阻塞队列与非阻塞队列的区别，来简单看看put方法是怎么实现 阻塞 功能的：\n\npublic void put(E e) throws InterruptedException {\n    checkNotNull(e);\n    final ReentrantLock lock = this.lock;\n    lock.lockInterruptibly();\n    try {\n        while (count == items.length)\n            notFull.await();\n        enqueue(e);\n    } finally {\n        lock.unlock();\n    }\n}\n\n\nput()方法是向队列中添加元素，一进来先检查元素是否为空，接着就加锁，然后while判断现有元素是否等于队列的最大长度，如果等于，说明需要阻塞，那就调用await方法进行阻塞等待。这就实现了阻塞功能。\n\n> 在JUC中，大多数使用阻塞队列。当然也有使用非阻塞队列。\n> \n> 但是由于本篇是 线程池相关文章，故只介绍线程池相关的这几个阻塞队列。\n\n\n# 5.1 ArrayBlockingQueue\n\n基于数组实现的阻塞队列，支持公平与非公平模式，默认非公平。\n\n因为是基于数组实现的，所以在构建时需要指定初始容量。\n\npublic ArrayBlockingQueue(int capacity) \npublic ArrayBlockingQueue(int capacity, boolean fair)\n// 提供了参数指定该队列是阻塞还是非阻塞。\npublic ArrayBlockingQueue(int capacity, boolean fair, Collection<? extends E> c)\n\n\n一共三个构造器，都要指定初始大小。数据全部存储在数组中。并且这个数组不能扩容，因为没有提供相关扩容方法。\n\n// 存储元素的数组\nfinal Object[] items;\n\n// 下一次 take、poll、peek将要操作的下标\nint takeIndex;\n\n// 下一次 put、offer、add将要操作的下标\nint putIndex;\n\n// 现有元素的数量。\nint count;\n\n\n通过 takeIndex 和 putIndex 确定操作的下标，通过 count 确定操作是否要阻塞。\n\n话又说回来，如何实现的阻塞？如何实现的公平与非公平？\n\n借助Condition实现阻塞，借助ReentrantLock实现公平与非公平。\n\n> 实现阻塞：\n\nArrayBlockingQueue中有两个Condition对象，notEmpty与notFull，一个是用于判空，一个是用于判满。\n\nprivate final Condition notEmpty;\nprivate final Condition notFull;\n\n\nCondition是用来干啥的？\n\n简而言之，Condition提供了await()方法将当前线程阻塞，并提供signal()方法支持另外一个线程将已经阻塞的线程唤醒。\n\n所以如何实现阻塞呢？\n当满的时候使用notFull.await()阻塞当前线程，当空的时候使用notEmpty.await()阻塞当前线程，当弹出一个元素的时候调用signal方法唤醒线程过来抢位置，当放入一个元素的时候通知线程过来取元素。\n源码如下（删除部分冗余代码）：\n\n// 当满的时候使用notFull.await()阻塞当前线程\npublic void put(E e) throws InterruptedException {\n    final ReentrantLock lock = this.lock;\n    lock.lockInterruptibly();\n    try {\n        // 队列满了\n        while (count == items.length)\n            //  notFull.await 将当前线程阻塞\n            notFull.await();\n        enqueue(e);\n    } finally {\n        lock.unlock();\n    }\n}\n// 当出队时，将阻塞的线程唤醒\nprivate E dequeue() {\n    final Object[] items = this.items;\n    @SuppressWarnings("unchecked")\n    E x = (E) items[takeIndex];\n    items[takeIndex] = null;\n    if (++takeIndex == items.length)\n        takeIndex = 0;\n    count--;\n    if (itrs != null)\n        itrs.elementDequeued();\n    // 将阻塞的线程唤醒\n    notFull.signal();\n    return x;\n}\n\n\n// 当空的时候使用notEmpty.await()阻塞当前线程\npublic E poll(long timeout, TimeUnit unit) throws InterruptedException {\n    final ReentrantLock lock = this.lock;\n    lock.lockInterruptibly();\n    try {\n        // 队列为空\n        while (count == 0) {\n            // notEmpty.await 将当前线程阻塞\n            nanos = notEmpty.awaitNanos(nanos);\n        }\n        return dequeue();\n    } finally {\n        lock.unlock();\n    }\n}\n// 当入队时，将对应线程唤醒\nprivate void enqueue(E x) {\n    final Object[] items = this.items;\n    items[putIndex] = x;\n    if (++putIndex == items.length)\n        putIndex = 0;\n    count++;\n    // 将阻塞线程唤醒\n    notEmpty.signal();\n}\n\n\n> 实现公平、非公平\n\n内部有ReentrantLock，由于Condition是借助Lock才能发挥作用的，所以当Lock的实现类ReentrantLock支持公平锁与非公平锁时，阻塞后的唤醒自然也就拥有公平与非公平的能力。\n\n\n# 5.2 LinkedBlockingQueue\n\n基于链表实现的阻塞队列。只支持非公平模式，\n（因为没有参数去指定 ReentrantLock 的公平与非公平模式，所以它只支持非公平模式。）\n\nLinkedBlockingQueue可以指定大小，如果不指定，默认且最大就是Integer.MAX_VALUE。\n\npublic LinkedBlockingQueue() {\n    this(Integer.MAX_VALUE);\n}\npublic LinkedBlockingQueue(int capacity);\npublic LinkedBlockingQueue(Collection<? extends E> c) ;\n\n\n为什么说它是基于链表实现的？因为内部封装了一个静态内部类，也就是链表节点\n\nstatic class Node<E> {\n    E item;\n\n    Node<E> next;\n\n    Node(E x) { item = x; }\n}\n\n\n从Node的成员变量可以看出，这是一个单链表，因为它只有一个next指针。\n\n所以可以说LinkedBlockingQueue其实是一个由单链表组成的、只支持非公平模式的、可以指定大小的阻塞队列。\n\n与ArrayBlockingQueue的区别不止这些，LinkedBlockingQueue内部有两把锁，ArrayBlockingQueue只有一把\n\nprivate final ReentrantLock takeLock = new ReentrantLock();\nprivate final Condition notEmpty = takeLock.newCondition();\n\n\nprivate final ReentrantLock putLock = new ReentrantLock();\nprivate final Condition notFull = putLock.newCondition();\n\n\n\n# 5.3 SynchronousQueue\n\n上面两种队列都是有界的最大也就Integer.MAX_VALUE，这个队列是无界的....错！这个队列不存储数据😁它只是数据的搬运工。\n\nSynchronousQueue 在插入数据时必须等待另一个线程来取走该数据，反之亦然。\n\nSynchronousQueue的实现方式是基于 TransferQueue 接口，它提供了两个主要的方法：put()和take()。put()方法用于插入元素，如果没有另一个线程正在等待接收该元素，则插入操作将一直阻塞，直到有另一个线程调用take()方法来取走该元素。take()方法用于取走元素，如果没有另一个线程正在等待插入元素，则取走操作将一直阻塞，直到有另一个线程调用put()方法来插入元素。\n\n// put放元素时，如果有其他线程正在等待着取元素，就给他，如果没有就阻塞。\npublic void put(E e) throws InterruptedException {\n    if (e == null) throw new NullPointerException();\n    if (transferer.transfer(e, false, 0) == null) {\n        Thread.interrupted();\n        throw new InterruptedException();\n    }\n}\n\n// take取元素时，如果有元素就拿走，如果没元素就阻塞(Thread.interrupted)\npublic E take() throws InterruptedException {\n    E e = transferer.transfer(null, false, 0);\n    if (e != null)\n        return e;\n    Thread.interrupted();\n    throw new InterruptedException();\n}\n\n\n具体的公平与非公平实现方式可以参照这篇文章：SynchronousQueue实现\n\n\n# 6. 线程池用到的拒绝策略\n\n拒绝策略的顶级接口 ：RejectedExecutionHandler\n\npublic interface RejectedExecutionHandler {\n    void rejectedExecution(Runnable r, ThreadPoolExecutor executor);\n}\n\n\n只提供一个方法，rejectedExecution，即定制具体的拒绝策略的执行逻辑。\n\n\n\n 1. AbortPolicy ：抛出异常，终止任务。\n    \n    抛出拒绝执行 RejectedExecutionHandler 的异常信息。这也是线程池默认的拒绝策略。\n    \n    public static class AbortPolicy implements RejectedExecutionHandler {\n    \n        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n            throw new RejectedExecutionException("Task " + r.toString() +\n                                                 " rejected from " +\n                                                 e.toString());\n        }\n    }\n    \n\n 2. CallerRunsPolicy ：使用调用线程执行任务。\n    \n    当触发该拒绝策略时，只要线程池还没有关闭，就使用 调用这个拒绝策略的线程来执行任务。一般并发比较小，性能要求不高，不允许失败。但是是调用者自己执行任务，如果并发比较高会产生阻塞。\n    \n    public static class CallerRunsPolicy implements RejectedExecutionHandler {\n    \n        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n            // 如果线程池还没停止，就使用当前线程执行任务\n            if (!e.isShutdown()) {\n                r.run();\n            }\n        }\n    }\n    \n\n 3. DiscardPolicy ：直接丢弃，连异常都不抛。\n    \n    public static class DiscardPolicy implements RejectedExecutionHandler {\n    \n        // 方法的实现一行都没有...\n        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n        }\n    }\n    \n\n 4. DiscardOldestPolicy ：丢弃队列最老的任务，将该任务添加进去。\n    \n    当触发该拒绝策略时，只要线程池还未关闭，丢弃阻塞队列中最老的一个任务（也就是队头任务），并将新任务加入队列尾部。\n    \n    public static class DiscardOldestPolicy implements RejectedExecutionHandler {\n         \n        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n            if (!e.isShutdown()) {\n                // 由于队列是FIFO，那么poll出来的一定是队头元素，也就是队列中最老的任务。\n                e.getQueue().poll();\n                e.execute(r);\n            }\n        }\n    }\n    \n\n\n# 7. Executors\n\n每次创建线程池都要填7个参数太麻烦了，所以Java为我们提供了工具类 ：Executors。\n\n简单介绍一下使用这个Executors可以创建什么样的线程池：\n\n 1. newSingleThreadExecutor()\n    \n    单线程的线程池，核心线程数为1，最大线程数为1，使用链表实现的阻塞队列，相当于这个线程中只有一个线程在工作。多余的任务全部扔进阻塞队列中。就像单线程在串行执行任务一样，但是也有些区别 ：如果这个唯一的线程出现了异常，线程池会创建一个新的线程来代替它。\n    \n    public static ExecutorService newSingleThreadExecutor() {\n        return new FinalizableDelegatedExecutorService\n            (new ThreadPoolExecutor(1, 1,\n                                    0L, TimeUnit.MILLISECONDS,\n                                    new LinkedBlockingQueue<Runnable>()));\n    }\n    \n\n 2. newFixedThreadPool(nThreads, threadFactory)\n    \n    核心线程数和最大线程数都由开发者指定，全部线程都处于活跃状态（不会死亡），使用链表实现的阻塞队列。一旦某个线程出现异常，线程池会补充一个线程。提交到线程池的任务过多可能会导致内存溢出。\n    \n    public static ExecutorService newFixedThreadPool(int nThreads, \n                                                     ThreadFactory threadFactory) {\n        return new ThreadPoolExecutor(nThreads, nThreads,\n                                      0L, TimeUnit.MILLISECONDS,\n                                      new LinkedBlockingQueue<Runnable>(),\n                                      threadFactory);\n    }\n    \n\n 3. newCachedThreadPool()\n    \n    可缓存的线程池，核心线程数为0，当线程池中的线程数量超过了运行任务所需要的线程数，那么可以回收空闲的线程，默认每60s回收；同时当任务增加的时候，线程池又可以创建新的线程来处理任务。\n    \n    public static ExecutorService newCachedThreadPool() {\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                      60L, TimeUnit.SECONDS,\n                                      new SynchronousQueue<Runnable>());\n    }\n    \n\n> 需要注意的是 ：不建议使用这几个已有的线程池，建议自己根据任务的特点（IO密集、CPU密集）来创建线程池。\n\n\n# 8. 线程池参数的配置\n\n线程池有7个参数，那该如何配置它们使得利益最大化呢？\n这要看线程池需要执行的任务是CPU密集型还是IO密集型。\n\n 1. CPU密集型 ：任务中含有大量的计算，例如三角函数、位运算、圆周率计算.... CPU密集型也叫计算密集型\n 2. IO密集型 ：任务中含有大量的IO操作。例如：读写文件、访问数据库、使用中间件...\n\n业界的一些线程池参数配置方案： 虽然方案很多，但是我们并没有得出通用的线程池计算方式。并发任务的执行情况和任务类型相关，IO密集型和CPU密集型的任务运行起来的情况差异非常大， 但这种占比是较难合理预估的，这导致很难有一个简单有效的通用公式帮我们直接计算出结果。\n\n思考\n\n既然不能够保证一次计算出来合适的参数，那么是否可以将修改线程池参数的成本降下来，这样至少可以发生故障的时候可以快速调整从而缩短故障恢复的时间呢？\n基于这个思考，是否可以将线程池的参数从代码中迁移到分布式配置中心上，实现线程池参数可动态配置和即时生效\n\n这就是动态线程池的由来。什么？如何实现？我不会，参考美团开源项目 DynamicTp ：美团动态线程池实践思路',normalizedContent:'# 1. 前言\n\n\n# 2. 概述\n\n至于为什么要有线程池，java里面有很多池，例如常量池、数据库连接池、线程池.....他们都体现了一种池化思想，什么是池化思想呢？就是通过创建和管理可重复使用的资源来提高资源的利用率，进而提高性能。\n\n> 线程池简而言之，就是一个有许多线程的容器，这些线程并不跟我们平时使用的线程一样随用随丢，而是将它们放在容器也就是线程池中，以便可以重复使用，减少线程重复创建和销毁带来的性能消耗。\n\n首先来看一下threadpoolexecutor的uml类图，了解下threadpoolexecutor的继承关系。\n\n\n\n\n# 3. executor、executorservice\n\n先来看一下executor：\n\npublic interface executor {\n    void execute(runnable command);\n}\n\n\n可以看到，executor 这个接口十分简单，只提供了一个 executor 方法，也就是执行方法。实现了这个方法的人要去完成线程的主要逻辑，也就是执行。\n\n接下来看 executorservice ，\n\npublic interface executorservice extends executor {\n    void shutdown();  \n    list<runnable> shutdownnow();\n    boolean isshutdown();\n    boolean isterminated();\n    boolean awaittermination(long timeout, timeunit unit)\n        throws interruptedexception;\n\n    <t> future<t> submit(callable<t> task);\n    <t> list<future<t>> invokeall(collection<? extends callable<t>> tasks)\n        throws interruptedexception;\n    // 还有一些方法不再列举\n}\n\n\nexecutorservice提供了对于线程池操作的服务，例如任务的提交submit、判断线程池的状态isshutdown....\n\nexecutorservice接口增加了一些能力：\n（1）扩充执行任务的能力，补充可以为一个或一批异步任务生成future的方法；\n（2）提供了管控线程池的方法，比如停止线程池的运行。abstractexecutorservice则是上层的抽象类，将执行任务的流程串联了起来，保证下层的实现只需关注一个执行任务的方法即可。\n\n> 那么当我们使用 threadpoolexecutor 时就可以意识到，\n> \n>  * 主要的执行方法是 实现executor的。\n>  * 功能方法是 实现executorservice 的。\n\nexecutor和executorservice提供了一种思想 ：将任务的提交和任务的执行解耦。\n\n用户无需关注如何创建线程、如何调度线程来执行任务，用户只需提供runnable对象，将任务的运行逻辑提交到执行器(executor)中，由executor框架完成线程的调配和任务的执行部分。\n\n\n# 4. threadpoolexecutor\n\n\n# 4.1 七个核心参数\n\n只要学习 threadpoolexector ，绕不开它的七个参数。\n\npublic threadpoolexecutor(int corepoolsize,\n                          int maximumpoolsize,\n                          long keepalivetime,\n                          timeunit unit,\n                          blockingqueue<runnable> workqueue,\n                          threadfactory threadfactory,\n                          rejectedexecutionhandler handler) \n\n\n 1. corepoolsize ：核心线程数，默认情况下，核心线程数会一直存活。\n\n 2. maximumpoolsize ：最大线程数，核心线程数+临时线程数的总和。\n    \n    除了核心线程数之外的线程数称为临时线程（maximumpoolsize - corepoolsize ），临时线程如果一定时间内接收不到任务会死亡。\n\n 3. keepalivetime ：临时线程接收不到任务时的死亡时间。\n\n 4. unit ：时间的单位\n\n 5. workqueue ：阻塞队列，存放任务的地方。\n\n 6. threadfactory ：线程工厂，所有线程在这里被创建。\n\n 7. handler ：当任务实在太多时执行的拒绝任务的策略。\n\n线程池的工作流程\n\n当核心线程数有空闲数时，所有任务都会被核心线程处理，\n\n当核心线程都忙碌时，任务首先到达阻塞队列中等待，核心线程执行完手上的任务后会去任务队列中取任务。\n\n当任务队列满后会创建临时线程执行任务，临时线程也会从任务队列中取任务执行。\n\n当任务队列满了并且全部线程都在工作中，还是有新的任务到达，就会执行拒绝策略。\n\n\n# 4.2 生命周期管理\n\n线程池运行的状态并不是用户显式设置的，而是伴随着线程池的运行由内部来维护。线程池内部使用一个变量维护两个值：运行状态(runstate)和线程数量 (workercount)。\n在具体实现中，线程池将运行状态(runstate)、线程数量 (workercount)两个关键参数的维护放在了一起，由同一个变量管理：\n\nprivate final atomicinteger ctl = new atomicinteger(ctlof(running, 0));\n\n\nctl这个atomicinteger类型的变量，是对线程池的运行状态(runstate)、线程数量 (workercount) 两个信息的汇总， 高3位保存runstate，低29位保存workercount，两个变量之间互不干扰。用一个变量去存储两个值，可避免在做相关决策时出现不一致的情况，不必为了维护两者的一致而占用锁资源。\n\n// count_bits = 32 - 3 = 29\n// capacity = 1 << 29 - 1\nprivate static final int count_bits = integer.size - 3;\nprivate static final int capacity   = (1 << count_bits) - 1;\n\n//计算当前运行状态\nprivate static int runstateof(int c)     { \n    return c & ~capacity; \n} \n//计算当前线程数量\nprivate static int workercountof(int c)  { \n    return c & capacity; \n}  \n//通过状态和线程数生成ctl\nprivate static int ctlof(int rs, int wc) { \n    return rs | wc; \n}   \n\n\nthreadpoolexecutor的运行状态有5种，分别为：\n\n其生命周期转换如下入所示：\n\n\n# 4.3 任务执行机制\n\n任务调度是线程池的主要入口，当用户提交了一个任务，接下来这个任务将如何执行都是由这个阶段决定的。了解这部分就相当于了解了线程池的核心运行机制。\n\n首先，所有任务的调度都是由execute方法完成的，这部分完成的工作是：检查现在线程池的运行状态、运行线程数、运行策略，决定接下来执行的流程，是直接申请线程执行，或是缓冲到队列中执行，亦或是直接拒绝该任务。其执行过程如下：\n\n 1. 首先检测线程池运行状态，如果不是running，则直接拒绝，线程池要保证在running的状态下执行任务。\n 2. 如果workercount < corepoolsize，则创建并启动一个线程来执行新提交的任务。\n 3. 如果workercount >= corepoolsize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中。\n 4. 如果workercount >= corepoolsize && workercount < maximumpoolsize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。\n 5. 如果workercount >= maximumpoolsize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。\n\n来看一下它的 execute 源码 ：\n\npublic void execute(runnable command) {\n    if (command == null)\n        throw new nullpointerexception();\n    \n    // 获取ctl，用于检查线程池的线程数以及线程池状态\n    int c = ctl.get();\n    \n    // 如果当前任务数小于核心线程数，直接使用核心线程\n    if (workercountof(c) < corepoolsize) {\n        //执行addworker,会创建一个核心线程，如果创建失败，重新获取ctl\n        if (addworker(command, true))\n            return;\n        c = ctl.get();\n    }\n    \n    // 如果线程池还活着，那么就可以将它加入阻塞队列, (也仅仅是加入队列，并没有执行)\n    if (isrunning(c) && workqueue.offer(command)) {\n        //再次获取ctl，进行双重检索（也就是对线程池的状态再次检查一遍）\n        int recheck = ctl.get();\n        \n        //如果线程池是不是处于running的状态，那么就会将任务从队列中移除，\n        if (! isrunning(recheck) && remove(command))\n            reject(command);\n        //如果移除失败，则会判断工作线程是否为0 ，如果过为0 就创建一个非核心线程\n        else if (workercountof(recheck) == 0)\n            addworker(null, false);\n    }\n\t//如果移除成功，就执行拒绝策略，因为线程池已经不可用了；\n    else if (!addworker(command, false))\n        reject(command);\n}\n\n\n\n可以看到，创建核心线程和非核心线程都是调用addworker方法\n\n// 如果runnable不空，且core为true，则证明创建的是核心线程。\n// 如果runnable为空，且core为false, 则证明创建的是非核心线程。\nprivate boolean addworker(runnable firsttask, boolean core)\n\n\naddworker：把其他步骤都忽略，来看我们提交的一个任务是如何被处理的。\n\nprivate boolean addworker(runnable firsttask, boolean core) {\n        w = new worker(firsttask);\n}\n\n\nnew 了一个worker，那么这个worker是什么？\n\nworker(runnable firsttask) {\n    setstate(-1); // inhibit interrupts until runworker\n    this.firsttask = firsttask;\n    this.thread = getthreadfactory().newthread(this);\n}\n\n\n从 getthreadfactory().newthread(this) 可以看出，就把当前的worker对象作为任务传给了新建的线程，这样启动线程时，它也就启动了。\n\n> 那么思考一个问题：如果任务数量小于核心线程数并且再来一个任务，是优先让空闲的核心线程执行任务还是直接创建一个核心线程呢？\n> \n> 刚才的代码不是已经有答案了嘛？当调用addworker添加一个任务的时候，如果核心线程数还没有创建满，优先创建核心线程。\n\n\n# 5. 线程池用到的队列\n\n为什么要学习阻塞队列？\n线程池可以高效利用线程，也就是说线程可以在某个地方一直拿任务去执行，而且执行完了之后还不死亡，那么去哪里拿任务呢？这时候就需要有一个容器：阻塞队列。\n\n\n# 5.0 阻塞队列与非阻塞队列\n\n 1. 阻塞队列\n    * 入队 ：如果队列满了，一直等待直到有位置就入队。\n    * 出队 ：如果队列中没有值，一直等待直到队列中有值才会出队。\n 2. 非阻塞队列\n    * 入队 ：队列有位置就入队，没位置就返回false或者报错。\n    * 出队 ：队列中有值就出队，没有值就返回null或者报错。\n\n非阻塞队列中的几个主要方法：add(t)、remove()、offer(t)、poll()、peek()。\n\n阻塞队列拥有非阻塞队列的全部方法，而且还多了几个方法：put(t)、take()、offer(t, timeout)、poll(t, timeout)。\n\n这几个方法实现了阻塞效果，也是上面介绍的阻塞队列与非阻塞队列的区别，来简单看看put方法是怎么实现 阻塞 功能的：\n\npublic void put(e e) throws interruptedexception {\n    checknotnull(e);\n    final reentrantlock lock = this.lock;\n    lock.lockinterruptibly();\n    try {\n        while (count == items.length)\n            notfull.await();\n        enqueue(e);\n    } finally {\n        lock.unlock();\n    }\n}\n\n\nput()方法是向队列中添加元素，一进来先检查元素是否为空，接着就加锁，然后while判断现有元素是否等于队列的最大长度，如果等于，说明需要阻塞，那就调用await方法进行阻塞等待。这就实现了阻塞功能。\n\n> 在juc中，大多数使用阻塞队列。当然也有使用非阻塞队列。\n> \n> 但是由于本篇是 线程池相关文章，故只介绍线程池相关的这几个阻塞队列。\n\n\n# 5.1 arrayblockingqueue\n\n基于数组实现的阻塞队列，支持公平与非公平模式，默认非公平。\n\n因为是基于数组实现的，所以在构建时需要指定初始容量。\n\npublic arrayblockingqueue(int capacity) \npublic arrayblockingqueue(int capacity, boolean fair)\n// 提供了参数指定该队列是阻塞还是非阻塞。\npublic arrayblockingqueue(int capacity, boolean fair, collection<? extends e> c)\n\n\n一共三个构造器，都要指定初始大小。数据全部存储在数组中。并且这个数组不能扩容，因为没有提供相关扩容方法。\n\n// 存储元素的数组\nfinal object[] items;\n\n// 下一次 take、poll、peek将要操作的下标\nint takeindex;\n\n// 下一次 put、offer、add将要操作的下标\nint putindex;\n\n// 现有元素的数量。\nint count;\n\n\n通过 takeindex 和 putindex 确定操作的下标，通过 count 确定操作是否要阻塞。\n\n话又说回来，如何实现的阻塞？如何实现的公平与非公平？\n\n借助condition实现阻塞，借助reentrantlock实现公平与非公平。\n\n> 实现阻塞：\n\narrayblockingqueue中有两个condition对象，notempty与notfull，一个是用于判空，一个是用于判满。\n\nprivate final condition notempty;\nprivate final condition notfull;\n\n\ncondition是用来干啥的？\n\n简而言之，condition提供了await()方法将当前线程阻塞，并提供signal()方法支持另外一个线程将已经阻塞的线程唤醒。\n\n所以如何实现阻塞呢？\n当满的时候使用notfull.await()阻塞当前线程，当空的时候使用notempty.await()阻塞当前线程，当弹出一个元素的时候调用signal方法唤醒线程过来抢位置，当放入一个元素的时候通知线程过来取元素。\n源码如下（删除部分冗余代码）：\n\n// 当满的时候使用notfull.await()阻塞当前线程\npublic void put(e e) throws interruptedexception {\n    final reentrantlock lock = this.lock;\n    lock.lockinterruptibly();\n    try {\n        // 队列满了\n        while (count == items.length)\n            //  notfull.await 将当前线程阻塞\n            notfull.await();\n        enqueue(e);\n    } finally {\n        lock.unlock();\n    }\n}\n// 当出队时，将阻塞的线程唤醒\nprivate e dequeue() {\n    final object[] items = this.items;\n    @suppresswarnings("unchecked")\n    e x = (e) items[takeindex];\n    items[takeindex] = null;\n    if (++takeindex == items.length)\n        takeindex = 0;\n    count--;\n    if (itrs != null)\n        itrs.elementdequeued();\n    // 将阻塞的线程唤醒\n    notfull.signal();\n    return x;\n}\n\n\n// 当空的时候使用notempty.await()阻塞当前线程\npublic e poll(long timeout, timeunit unit) throws interruptedexception {\n    final reentrantlock lock = this.lock;\n    lock.lockinterruptibly();\n    try {\n        // 队列为空\n        while (count == 0) {\n            // notempty.await 将当前线程阻塞\n            nanos = notempty.awaitnanos(nanos);\n        }\n        return dequeue();\n    } finally {\n        lock.unlock();\n    }\n}\n// 当入队时，将对应线程唤醒\nprivate void enqueue(e x) {\n    final object[] items = this.items;\n    items[putindex] = x;\n    if (++putindex == items.length)\n        putindex = 0;\n    count++;\n    // 将阻塞线程唤醒\n    notempty.signal();\n}\n\n\n> 实现公平、非公平\n\n内部有reentrantlock，由于condition是借助lock才能发挥作用的，所以当lock的实现类reentrantlock支持公平锁与非公平锁时，阻塞后的唤醒自然也就拥有公平与非公平的能力。\n\n\n# 5.2 linkedblockingqueue\n\n基于链表实现的阻塞队列。只支持非公平模式，\n（因为没有参数去指定 reentrantlock 的公平与非公平模式，所以它只支持非公平模式。）\n\nlinkedblockingqueue可以指定大小，如果不指定，默认且最大就是integer.max_value。\n\npublic linkedblockingqueue() {\n    this(integer.max_value);\n}\npublic linkedblockingqueue(int capacity);\npublic linkedblockingqueue(collection<? extends e> c) ;\n\n\n为什么说它是基于链表实现的？因为内部封装了一个静态内部类，也就是链表节点\n\nstatic class node<e> {\n    e item;\n\n    node<e> next;\n\n    node(e x) { item = x; }\n}\n\n\n从node的成员变量可以看出，这是一个单链表，因为它只有一个next指针。\n\n所以可以说linkedblockingqueue其实是一个由单链表组成的、只支持非公平模式的、可以指定大小的阻塞队列。\n\n与arrayblockingqueue的区别不止这些，linkedblockingqueue内部有两把锁，arrayblockingqueue只有一把\n\nprivate final reentrantlock takelock = new reentrantlock();\nprivate final condition notempty = takelock.newcondition();\n\n\nprivate final reentrantlock putlock = new reentrantlock();\nprivate final condition notfull = putlock.newcondition();\n\n\n\n# 5.3 synchronousqueue\n\n上面两种队列都是有界的最大也就integer.max_value，这个队列是无界的....错！这个队列不存储数据😁它只是数据的搬运工。\n\nsynchronousqueue 在插入数据时必须等待另一个线程来取走该数据，反之亦然。\n\nsynchronousqueue的实现方式是基于 transferqueue 接口，它提供了两个主要的方法：put()和take()。put()方法用于插入元素，如果没有另一个线程正在等待接收该元素，则插入操作将一直阻塞，直到有另一个线程调用take()方法来取走该元素。take()方法用于取走元素，如果没有另一个线程正在等待插入元素，则取走操作将一直阻塞，直到有另一个线程调用put()方法来插入元素。\n\n// put放元素时，如果有其他线程正在等待着取元素，就给他，如果没有就阻塞。\npublic void put(e e) throws interruptedexception {\n    if (e == null) throw new nullpointerexception();\n    if (transferer.transfer(e, false, 0) == null) {\n        thread.interrupted();\n        throw new interruptedexception();\n    }\n}\n\n// take取元素时，如果有元素就拿走，如果没元素就阻塞(thread.interrupted)\npublic e take() throws interruptedexception {\n    e e = transferer.transfer(null, false, 0);\n    if (e != null)\n        return e;\n    thread.interrupted();\n    throw new interruptedexception();\n}\n\n\n具体的公平与非公平实现方式可以参照这篇文章：synchronousqueue实现\n\n\n# 6. 线程池用到的拒绝策略\n\n拒绝策略的顶级接口 ：rejectedexecutionhandler\n\npublic interface rejectedexecutionhandler {\n    void rejectedexecution(runnable r, threadpoolexecutor executor);\n}\n\n\n只提供一个方法，rejectedexecution，即定制具体的拒绝策略的执行逻辑。\n\n\n\n 1. abortpolicy ：抛出异常，终止任务。\n    \n    抛出拒绝执行 rejectedexecutionhandler 的异常信息。这也是线程池默认的拒绝策略。\n    \n    public static class abortpolicy implements rejectedexecutionhandler {\n    \n        public void rejectedexecution(runnable r, threadpoolexecutor e) {\n            throw new rejectedexecutionexception("task " + r.tostring() +\n                                                 " rejected from " +\n                                                 e.tostring());\n        }\n    }\n    \n\n 2. callerrunspolicy ：使用调用线程执行任务。\n    \n    当触发该拒绝策略时，只要线程池还没有关闭，就使用 调用这个拒绝策略的线程来执行任务。一般并发比较小，性能要求不高，不允许失败。但是是调用者自己执行任务，如果并发比较高会产生阻塞。\n    \n    public static class callerrunspolicy implements rejectedexecutionhandler {\n    \n        public void rejectedexecution(runnable r, threadpoolexecutor e) {\n            // 如果线程池还没停止，就使用当前线程执行任务\n            if (!e.isshutdown()) {\n                r.run();\n            }\n        }\n    }\n    \n\n 3. discardpolicy ：直接丢弃，连异常都不抛。\n    \n    public static class discardpolicy implements rejectedexecutionhandler {\n    \n        // 方法的实现一行都没有...\n        public void rejectedexecution(runnable r, threadpoolexecutor e) {\n        }\n    }\n    \n\n 4. discardoldestpolicy ：丢弃队列最老的任务，将该任务添加进去。\n    \n    当触发该拒绝策略时，只要线程池还未关闭，丢弃阻塞队列中最老的一个任务（也就是队头任务），并将新任务加入队列尾部。\n    \n    public static class discardoldestpolicy implements rejectedexecutionhandler {\n         \n        public void rejectedexecution(runnable r, threadpoolexecutor e) {\n            if (!e.isshutdown()) {\n                // 由于队列是fifo，那么poll出来的一定是队头元素，也就是队列中最老的任务。\n                e.getqueue().poll();\n                e.execute(r);\n            }\n        }\n    }\n    \n\n\n# 7. executors\n\n每次创建线程池都要填7个参数太麻烦了，所以java为我们提供了工具类 ：executors。\n\n简单介绍一下使用这个executors可以创建什么样的线程池：\n\n 1. newsinglethreadexecutor()\n    \n    单线程的线程池，核心线程数为1，最大线程数为1，使用链表实现的阻塞队列，相当于这个线程中只有一个线程在工作。多余的任务全部扔进阻塞队列中。就像单线程在串行执行任务一样，但是也有些区别 ：如果这个唯一的线程出现了异常，线程池会创建一个新的线程来代替它。\n    \n    public static executorservice newsinglethreadexecutor() {\n        return new finalizabledelegatedexecutorservice\n            (new threadpoolexecutor(1, 1,\n                                    0l, timeunit.milliseconds,\n                                    new linkedblockingqueue<runnable>()));\n    }\n    \n\n 2. newfixedthreadpool(nthreads, threadfactory)\n    \n    核心线程数和最大线程数都由开发者指定，全部线程都处于活跃状态（不会死亡），使用链表实现的阻塞队列。一旦某个线程出现异常，线程池会补充一个线程。提交到线程池的任务过多可能会导致内存溢出。\n    \n    public static executorservice newfixedthreadpool(int nthreads, \n                                                     threadfactory threadfactory) {\n        return new threadpoolexecutor(nthreads, nthreads,\n                                      0l, timeunit.milliseconds,\n                                      new linkedblockingqueue<runnable>(),\n                                      threadfactory);\n    }\n    \n\n 3. newcachedthreadpool()\n    \n    可缓存的线程池，核心线程数为0，当线程池中的线程数量超过了运行任务所需要的线程数，那么可以回收空闲的线程，默认每60s回收；同时当任务增加的时候，线程池又可以创建新的线程来处理任务。\n    \n    public static executorservice newcachedthreadpool() {\n        return new threadpoolexecutor(0, integer.max_value,\n                                      60l, timeunit.seconds,\n                                      new synchronousqueue<runnable>());\n    }\n    \n\n> 需要注意的是 ：不建议使用这几个已有的线程池，建议自己根据任务的特点（io密集、cpu密集）来创建线程池。\n\n\n# 8. 线程池参数的配置\n\n线程池有7个参数，那该如何配置它们使得利益最大化呢？\n这要看线程池需要执行的任务是cpu密集型还是io密集型。\n\n 1. cpu密集型 ：任务中含有大量的计算，例如三角函数、位运算、圆周率计算.... cpu密集型也叫计算密集型\n 2. io密集型 ：任务中含有大量的io操作。例如：读写文件、访问数据库、使用中间件...\n\n业界的一些线程池参数配置方案： 虽然方案很多，但是我们并没有得出通用的线程池计算方式。并发任务的执行情况和任务类型相关，io密集型和cpu密集型的任务运行起来的情况差异非常大， 但这种占比是较难合理预估的，这导致很难有一个简单有效的通用公式帮我们直接计算出结果。\n\n思考\n\n既然不能够保证一次计算出来合适的参数，那么是否可以将修改线程池参数的成本降下来，这样至少可以发生故障的时候可以快速调整从而缩短故障恢复的时间呢？\n基于这个思考，是否可以将线程池的参数从代码中迁移到分布式配置中心上，实现线程池参数可动态配置和即时生效\n\n这就是动态线程池的由来。什么？如何实现？我不会，参考美团开源项目 dynamictp ：美团动态线程池实践思路',charsets:{cjk:!0},lastUpdated:"2024/02/28, 21:50:33",lastUpdatedTimestamp:1709128233e3},{title:"CAS",frontmatter:{title:"CAS",date:"2023-07-17T02:01:44.000Z",permalink:"/pages/56d8fa/"},regularPath:"/02.%E6%96%87%E7%AB%A0/75.Java%E5%B9%B6%E5%8F%91/50.CAS.html",relativePath:"02.文章/75.Java并发/50.CAS.md",key:"v-040c55f4",path:"/pages/56d8fa/",headers:[{level:2,title:"1. 什么是CAS",slug:"_1-什么是cas",normalizedTitle:"1. 什么是cas",charIndex:2},{level:2,title:"2. CAS 如何实现",slug:"_2-cas-如何实现",normalizedTitle:"2. cas 如何实现",charIndex:457},{level:2,title:"3. ABA问题",slug:"_3-aba问题",normalizedTitle:"3. aba问题",charIndex:1002}],headersStr:"1. 什么是CAS 2. CAS 如何实现 3. ABA问题",content:"# 1. 什么是CAS\n\nCAS，全称 Compare and Swap，是实现并发算法时常用到的一种技术。\n\n它包含了三个操作数：\n\n * 内存位置\n * 预期原值\n * 更新值\n\n也就是 ：比较内存中的值跟预期的旧值是否相同，如果相同就交换，不同就不交换。\n\n使用C艹来实现就是这样的：\n\nbool compareAndSwap(int* address, int oldValue, int newValue) {\n    if (*address == oldValue) {\n        *address = newValue;\n    }\n}\n\n\nCAS是乐观锁的其中一种，可以通过 while(true)配合CAS来实现乐观锁：\n\nfor (;;) {\n    bool result = compareAndSwap(&a, oldValue, newValue);\n    // 如果改失败了或者改成功了之后的业务逻辑....\n    if (result) {\n    } \n}\n\n\n\n# 2. CAS 如何实现\n\njava 的 CAS 利用的的是 Unsafe 这个类提供的 CAS 操作；简而言之，是因为硬件予以了支持，软件层面才能做到。\n\n我尝试在Java源码中找到对于compareAndSwap的实现，发现不过是徒劳~ 因为是c艹写的~\n\n如下是在 Unsafe类 中定义的部分方法：\n\n// var1 : 要操作的对象\n// var2 : 要操作的变量的地址\n// var4 : 旧值\n// var5 : 新值\npublic final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);\n\npublic final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);\n\npublic final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);\n\n\n当然了，Unsafe 类不仅可以使用CAS操作，还可以操作内存...\n\n\n# 3. ABA问题\n\nCAS好用，但是会造成ABA问题。什么是ABA问题？\n\n假设存在两个线程 t1 和 t2。 有一个共享变量 num，初始值为 A 接下来， 线程 t1 想使用 CAS 把 num 值改成 Z, 那么就需要\n\n * 先读取 num 的值, 记录到 oldNum 变量中\n * 使用 CAS 判定当前 num 的值是否为 A， 如果为 A，就修改成 Z.\n\n但是， 在 t1 执行这两个操作之间， t2 线程可能把 num 的值从 A 改成了 B， 又从 B 改成了 A 到这一步, t1 线程无法区分当前这个变量始终是 A， 还是经历了一个变化过程。\n\n其实这样的运行过程在代码上没有错，但是线程 t1 肯定想要自己的操作是原子的，在操作时没有其他线程改来改去。这就好比，我们买一个手机，无法判定这个手机是刚出厂的新手机，还是别人用旧了又翻新过的手机。\n\n怎么解决 CAS 问题呢？\n\naba的关键是值会反复横跳~~如果约定数据只能单方向变化，问题就迎刃而解了（只能增加，或者只能减小）\n\n如果需求要求该数值，既能增加也能减小，应该怎么办？可以引入另外一个版本号变量，约定版本号只能增加~~\n\n每次CAS对比的时候，就不是对比数值本身，而是对比版本号！！\n\n在 CAS 比较数据当前值和旧值的同时, 也要比较版本号是否符合预期",normalizedContent:"# 1. 什么是cas\n\ncas，全称 compare and swap，是实现并发算法时常用到的一种技术。\n\n它包含了三个操作数：\n\n * 内存位置\n * 预期原值\n * 更新值\n\n也就是 ：比较内存中的值跟预期的旧值是否相同，如果相同就交换，不同就不交换。\n\n使用c艹来实现就是这样的：\n\nbool compareandswap(int* address, int oldvalue, int newvalue) {\n    if (*address == oldvalue) {\n        *address = newvalue;\n    }\n}\n\n\ncas是乐观锁的其中一种，可以通过 while(true)配合cas来实现乐观锁：\n\nfor (;;) {\n    bool result = compareandswap(&a, oldvalue, newvalue);\n    // 如果改失败了或者改成功了之后的业务逻辑....\n    if (result) {\n    } \n}\n\n\n\n# 2. cas 如何实现\n\njava 的 cas 利用的的是 unsafe 这个类提供的 cas 操作；简而言之，是因为硬件予以了支持，软件层面才能做到。\n\n我尝试在java源码中找到对于compareandswap的实现，发现不过是徒劳~ 因为是c艹写的~\n\n如下是在 unsafe类 中定义的部分方法：\n\n// var1 : 要操作的对象\n// var2 : 要操作的变量的地址\n// var4 : 旧值\n// var5 : 新值\npublic final native boolean compareandswapobject(object var1, long var2, object var4, object var5);\n\npublic final native boolean compareandswapint(object var1, long var2, int var4, int var5);\n\npublic final native boolean compareandswaplong(object var1, long var2, long var4, long var6);\n\n\n当然了，unsafe 类不仅可以使用cas操作，还可以操作内存...\n\n\n# 3. aba问题\n\ncas好用，但是会造成aba问题。什么是aba问题？\n\n假设存在两个线程 t1 和 t2。 有一个共享变量 num，初始值为 a 接下来， 线程 t1 想使用 cas 把 num 值改成 z, 那么就需要\n\n * 先读取 num 的值, 记录到 oldnum 变量中\n * 使用 cas 判定当前 num 的值是否为 a， 如果为 a，就修改成 z.\n\n但是， 在 t1 执行这两个操作之间， t2 线程可能把 num 的值从 a 改成了 b， 又从 b 改成了 a 到这一步, t1 线程无法区分当前这个变量始终是 a， 还是经历了一个变化过程。\n\n其实这样的运行过程在代码上没有错，但是线程 t1 肯定想要自己的操作是原子的，在操作时没有其他线程改来改去。这就好比，我们买一个手机，无法判定这个手机是刚出厂的新手机，还是别人用旧了又翻新过的手机。\n\n怎么解决 cas 问题呢？\n\naba的关键是值会反复横跳~~如果约定数据只能单方向变化，问题就迎刃而解了（只能增加，或者只能减小）\n\n如果需求要求该数值，既能增加也能减小，应该怎么办？可以引入另外一个版本号变量，约定版本号只能增加~~\n\n每次cas对比的时候，就不是对比数值本身，而是对比版本号！！\n\n在 cas 比较数据当前值和旧值的同时, 也要比较版本号是否符合预期",charsets:{cjk:!0},lastUpdated:"2024/02/28, 21:50:33",lastUpdatedTimestamp:1709128233e3},{title:"线程池源码解析",frontmatter:{title:"线程池源码解析",date:"2024-01-21T21:31:55.000Z",permalink:"/pages/79cb1d/"},regularPath:"/02.%E6%96%87%E7%AB%A0/75.Java%E5%B9%B6%E5%8F%91/400.%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90.html",relativePath:"02.文章/75.Java并发/400.线程池源码解析.md",key:"v-9062bd3c",path:"/pages/79cb1d/",headers:[{level:2,title:"1. Worker",slug:"_1-worker",normalizedTitle:"1. worker",charIndex:2},{level:3,title:"1.1 Worker 的不可重入锁",slug:"_1-1-worker-的不可重入锁",normalizedTitle:"1.1 worker 的不可重入锁",charIndex:559},{level:3,title:"1.2 Worker.run()",slug:"_1-2-worker-run",normalizedTitle:"1.2 worker.run()",charIndex:1409},{level:2,title:"2. ThreadPoolExecutor",slug:"_2-threadpoolexecutor",normalizedTitle:"2. threadpoolexecutor",charIndex:5428},{level:3,title:"2.1 线程池变量",slug:"_2-1-线程池变量",normalizedTitle:"2.1 线程池变量",charIndex:5571},{level:3,title:"2.2 execute",slug:"_2-2-execute",normalizedTitle:"2.2 execute",charIndex:8249},{level:3,title:"2.3 shutdown",slug:"_2-3-shutdown",normalizedTitle:"2.3 shutdown",charIndex:11374},{level:3,title:"2.4 shutdownNow",slug:"_2-4-shutdownnow",normalizedTitle:"2.4 shutdownnow",charIndex:12226},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:12570}],headersStr:"1. Worker 1.1 Worker 的不可重入锁 1.2 Worker.run() 2. ThreadPoolExecutor 2.1 线程池变量 2.2 execute 2.3 shutdown 2.4 shutdownNow 3. 总结",content:'# 1. Worker\n\nWorker 是线程在线程池中的表现形式，它并不是一个线程，Worker 继承了 Runnable，可以使用线程工厂根据 Worker 创建一个线程\n\nthreadFactory.newThread(worker);\n\n\n来看看 Worker 中的变量：\n\n// Worker 继承 AQS 实现了不可重入锁\nprivate final class Worker extends AbstractQueuedSynchronizer implements Runnable {\n\t// 这个 Worker 封装的线程\n    final Thread thread;\n    \n\t// 这个 Worker 的任务\n    Runnable firstTask;\n\t\n    // 这个线程执行过的任务数量\n    volatile long completedTasks;\n}\n\n\n可以看到 Worker 不仅继承了 Runnable，还继承了 AQS，它继承 AQS 是为了实现不可重入锁，下面会具体介绍Worker 的不可重入锁。\n\n值得一提的是，虽然我们平时使用线程池时会指定 核心线程数、最大线程数，但是线程被封装为 Worker 时不会区分这个线程是核心线程还是临时线程。\n\n\n# 1.1 Worker 的不可重入锁\n\n如果你对 AQS 不理解或不熟悉，可以阅读一下我的另一篇文章 ：AQS源码解析\n\nWorker 实现的是不可重入锁，不可重入锁实现起来比较简单 ：\n\nprotected boolean tryAcquire(int unused) {\n    if (compareAndSetState(0, 1)) {\n        setExclusiveOwnerThread(Thread.currentThread());\n        return true;\n    }\n    return false;\n}\n\n\n * 可重入锁 ：如果锁已经被占有，还要判断占有锁的线程是否是自己。\n * 不可重入锁 ：如果锁已经被占有，不再判断直接返回加锁失败。\n\nWorker 的加锁逻辑是将 state 值从 0 改为 1，如果成功就返回 true，如果失败就返回 false。\n\n但是 Worker 为什么要加锁功能呢 ？\n\n线程池有一个方法 ：shutdown() ，就是要停止所有的线程，但是如果该线程正在执行任务，则等待它执行结束再关闭它。\n\nWorker 在执行任务时要加锁，执行结束时解锁，线程池停止线程时也加锁，如果加锁成功就着手关闭该线程。\n\n这样就可以避免线程池将正在执行任务的线程给关闭了。\n\n其实线程池还有一个方法 ：shutdownNow()，它可不管线程是否正在执行，直接关闭。\n\n那么 shutdown 和 shutdownNow 方法工作的区别就是 ：\n\n 1. shutdown() ：关闭线程池中的所有线程。如果线程正在执行任务，等待其执行结束。\n    \n    遍历所有 Worker，调用 worker.tryLock() 如果抢锁失败说明这个 Worker 正在执行任务，等待其执行结束后再关闭。\n\n 2. shutdownNow() ：关闭线程池中的所有线程\n    \n    遍历所有 Worker，直接关闭。\n\n\n# 1.2 Worker.run()\n\nWorker 是一个线程，那我们就绕不开它的 run() 方法，在这里可以猜测一下 Worker.run() 的逻辑：\n\n 1. 循环从阻塞队列中取任务\n 2. 如果超时，判断是否终止循环，终止循环实际上这个线程就执行结束了，相当于线程死亡。\n 3. 什么时候终止循环 ？如果当前线程池中的线程数量 < 核心线程数，那我们不能让线程终止。\n\n然后可以看一下源码，看看和我们猜测的是否有差异 ：\n\n// Worker 线程一启动就会调用 runWorker 方法，runWorker 方法在 ThreadPoolExecutor 中\npublic void run() {\n    runWorker(this);\n}\n\n\n由于 Worker 是 ThreadPoolExecutor 的内部类，所以 Worker.run() 的逻辑是由 ThreadPoolExecutor.runWorker() 来实现的。\n\n线程池里面的线程其实做的无非就是两件事 ：获取任务、执行任务。\n\n 1. 获取任务，获取任务有两种途径\n    * 创建 Worker 时指定好的，这个只有第一次循环可能拿到\n    * 从阻塞队列中获取的，但是阻塞队列中不一定有，判断线程能否死亡的逻辑也是在这里做的。\n 2. 执行任务\n\n// 工作线程启动后就会执行这个方法\nfinal void runWorker(Worker w) {\n    // 拿到当前线程，由于现在运行这个方法的是 worker.run()，所以当前线程实际上就是 worker.thread\n    Thread wt = Thread.currentThread();\n    // 拿到该线程的 task\n    Runnable task = w.firstTask;\n    // 已经把任务拿出来了，将其置空\n    w.firstTask = null;\n    // 释放锁--------存疑, 这里我没搞懂为啥要释放锁。\n    w.unlock(); \n    // 运行过程中是否出现了异常\n    boolean completedAbruptly = true;\n    try {\n        // 第一次运行时 task != null，不会执行 task.getTask() 的逻辑\n        // 第二次运行时 task == null，会调用 task.getTask() 从阻塞队列中获取任务\n        // 注意，这里的 getTask 如果获取到了 null，循环就会结束，该线程就会终止\n        while (task != null || (task = getTask()) != null) {\n            // 加锁，表示该线程正在运行任务，不允许打断\n            w.lock();\n            try {\n                // 由程序员实现的逻辑, 钩子函数\n                beforeExecute(wt, task);\n                // 可能会抛出的异常\n                Throwable thrown = null;\n                // 执行该任务\n                task.run();\n                \n            } finally {\n                task = null;\n                w.completedTasks++;\n                w.unlock();\n            }\n        }\n        completedAbruptly = false;\n    } finally {\n        // 线程退出，也就是我们嘴里的"线程死亡"\n        processWorkerExit(w, completedAbruptly);\n    }\n}\n\n\n下面看一下 getTask() 方法，这个方法特别重要，它会判断这个线程是否有资格死亡，结合上面 runWorker 的代码来看，只要 getTask() 返回 null，这个线程就算死了。\n\n我们可以大概想一下线程可以死亡的条件：\n\n 1. 不允许核心线程死亡时 ：\n    \n    当线程数量 > 核心线程数，也就是有临时线程，从阻塞队列中取数据超时了，也就是队列中没有任务，那么此线程可以死亡。\n    \n    注意 ：从阻塞队列中取数据 这个操作的持续时间 == 临时线程的死亡时间。\n\n 2. 允许核心线程死亡时 ：\n    \n    线程数量 < 最大线程数，从队列中取任务超时，并且队列中没有任务。\n\n源码中的判断逻辑比较难懂 ：\n\nprivate Runnable getTask() {\n    // 阻塞获取任务是否超时\n    boolean timedOut = false; \n    for (;;) {\n        int c = ctl.get();\n        // 获取线程池的状态\n        int rs = runStateOf(c);\n        // rs >= SHUTDOWN都不正常。\n        // 如果线程池已经调用了 threadPool.shutdown()，符合下列条件中的任何一个都会返回null\n        // 1. 线程池的状态 >= STOP，不再处理或接收任务\n        // 2. 任务队列为空，已经处理完了\n        if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {\n            decrementWorkerCount();\n            return null;\n        }\n        \n\t\t// 获取线程池中的线程数量\n        int wc = workerCountOf(c);\n\n\t\t// 以下的判断是决定此线程是否要死亡\n        // 线程死亡的条件:\n        // 1. 不允许核心线程死亡 : \n        //     核心线程数 < 线程数量 < 最大线程数，并且从队列中取任务超时，并且队列中没有任务\n        // 2. 允许核心线程死亡 : 线程数量 < 最大线程数，从队列中取任务超时，并且队列中没有任务\n        // 3. 线程数量 > 最大线程数\n        boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;\n\n        if ((wc > maximumPoolSize || (timed && timedOut))\n            && (wc > 1 || workQueue.isEmpty())) {\n            if (compareAndDecrementWorkerCount(c))\n                return null;\n            continue;\n        }\n\n        try {\n            // 如果在这里出现中断异常，可能是线程池调用了 shutdown，\n            // 该线程会进入下一个循环并在第一个if中返回 null，达到停止线程/杀死线程的目标。\n            Runnable r = timed ?\n                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :\n            workQueue.take();\n            if (r != null)\n                return r;\n            timedOut = true;\n        } catch (InterruptedException retry) {\n            timedOut = false;\n        }\n    }\n}\n\n\n这里面有个有意思的判断逻辑 ：\n\nboolean timed = allowCoreThreadTimeOut || wc > corePoolSize;\n\nRunnable r = timed ?\n    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :\nworkQueue.take();\n\n\n一般情况下我们不会允许核心线程死亡，那么 timed 这个变量就取决于当前线程的数量是否大于核心线程的数量。\n\n 1. 如果大于，说明此时有临时线程，那么此线程的身份就是临时线程，取任务时阻塞 keepAliveTime 这么长时间。如果阻塞了 keepAliveTime 还没有拿到任务，就会进入下一个循环，判断此线程是否要死亡。\n\n 2. 如果小于，说明此时没有临时线程，那么此线程的身份就是核心线程，取任务时永久阻塞。\n\n至此，Worker 的源码就说完了，线程池中的线程并不会区分核心线程与临时线程，它只会保证线程池中始终有 corePoolSize 个线程保持活跃。\n\n\n# 2. ThreadPoolExecutor\n\n源码大概有 1000 多行，根本不需要看完，重要有两个方法 ：\n\n 1. 提交任务 execute ：在这里可以看到线程池的工作流程以及线程的创建过程。\n 2. 关闭线程池 shutdown ：在这里可以看到线程池的不同关闭逻辑。\n\n\n# 2.1 线程池变量\n\npublic class ThreadPoolExecutor extends AbstractExecutorService {\n    // 线程池的状态和线程数量\n    // 高三位表示线程池的状态\n    // 低29位表示线程池中的线程数量\n    private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n\n    private static final int COUNT_BITS = Integer.SIZE - 3;\n    // 1 << 29 = 00010000 00000000 00000000 00000000\n    // 再减1 = 00001111 11111111 11111111 11111111\n    // ctl & CAPACITY 可以得到线程数量 \n    private static final int CAPACITY   = (1 << COUNT_BITS) - 1;\n\n\t// 线程池的五种状态，在 ctl 的高三位表示\n    // 111 00000 00000000 00000000 00000000\n    // 正在运行\t\t\n    private static final int RUNNING    = -1 << COUNT_BITS;\n    \n    // 000 00000 00000000 00000000 00000000\n    // 已经调用了 shutdown，但是里面的线程还没有停止\n    private static final int SHUTDOWN   =  0 << COUNT_BITS;\n    \n    // 001 00000 00000000 00000000 00000000\n    private static final int STOP       =  1 << COUNT_BITS;\n    // 010 00000 00000000 00000000 00000000\n    private static final int TIDYING    =  2 << COUNT_BITS;\n    // 011 00000 00000000 00000000 00000000\n    private static final int TERMINATED =  3 << COUNT_BITS;\n\n\t// 传入 ctl，返回线程池的状态\n    private static int runStateOf(int c)     { return c & ~CAPACITY; }\n    // 传入 ctl，返回线程数量\n    private static int workerCountOf(int c)  { return c & CAPACITY; }\n    // 传入线程池的状态和线程数量，返回ctl\n    private static int ctlOf(int rs, int wc) { return rs | wc; }\n\n\n\n\t// CAS的方式增加工作线程的数量，增加一个\n    private boolean compareAndIncrementWorkerCount(int expect) {\n        return ctl.compareAndSet(expect, expect + 1);\n    }\n\n\t// CAS的方式减少工作线程的数量，减少一个\n    private boolean compareAndDecrementWorkerCount(int expect) {\n        return ctl.compareAndSet(expect, expect - 1);\n    }\n\n\n    // 保存工作线程的集合\n    private final HashSet<Worker> workers = new HashSet<Worker>();\n\n    \n   \t// 线程池的状态锁，改变线程池状态时要加这个锁\n    private final ReentrantLock mainLock = new ReentrantLock();\n\n    // 线程池的条件锁，在线程池的状态发生改变时，使用这个条件锁通知所有等待的线程阻塞或者唤醒\n    private final Condition termination = mainLock.newCondition();\n\n    // 线程池中曾经出现过的最大的线程数量\n    private int largestPoolSize;\n\n    // 已经完成的任务数量\n    private long completedTaskCount;\n\n    \n\t// 下面是核心参数，也就是需要我们指定的7个参数\n    // 线程池的阻塞队列\n    private final BlockingQueue<Runnable> workQueue;\n\t// 线程工厂\n    private volatile ThreadFactory threadFactory;\n\t// 拒绝策略\n    private volatile RejectedExecutionHandler handler;\n\t// 临时线程存活时间\n    private volatile long keepAliveTime;\n    // 是否允许核心线程死亡\n    private volatile boolean allowCoreThreadTimeOut;\n    // 核心线程数\n    private volatile int corePoolSize;\n    // 最大线程数 = 核心线程数 + 临时线程数\n    private volatile int maximumPoolSize;\n\n    // 默认的拒绝策略，拒绝执行并抛出异常\n    private static final RejectedExecutionHandler defaultHandler =\n        new AbortPolicy();\n\n}\n\n\n\n# 2.2 execute\n\n线程池的工作流程是老八股了 ：\n\n\n\n这个步骤是正确的，我们也可以按照这个步骤来阅读源码 ：\n\n// 提交任务\npublic void execute(Runnable command) {\n    if (command == null)\n        throw new NullPointerException();\n    // 获取 ctl\n    int c = ctl.get();\n    // 如果线程数量 < 核心线程\n    if (workerCountOf(c) < corePoolSize) {\n        // 添加核心线程\n        // addWorker: 判断能否创建线程，然后再创建线程\n        // 如果返回 true，说明创建成功，直接结束，这个任务会交给新建的线程去执行\n        // 如果返回 false，说明线程池状态异常，或者线程数量超了\n        if (addWorker(command, true))\n            return;\n        c = ctl.get();\n    }\n    // 将任务放入阻塞队列中\n    if (isRunning(c) && workQueue.offer(command)) {\n        int recheck = ctl.get();\n        if (!isRunning(recheck) && remove(command))\n            reject(command);\n        // 如果现在没有正在运行的线程，就创建一个线程处理任务\n        else if (workerCountOf(recheck) == 0)\n            addWorker(null, false);\n    }\n    // 如果放入队列失败，新建临时线程处理任务\n    // 如果新建临时线程失败，就执行拒绝策略\n    else if (!addWorker(command, false))\n        reject(command);\n}\n\n\n有一个细节 ：当指定核心线程数量为 0 时，也会创建一个线程，并且在阻塞队列满之前都只有这一个线程处理任务。\n\n接下来重要的就是 addWorker() ，它是具体创建线程的地方 ：\n\n// 添加线程 \nprivate boolean addWorker(Runnable firstTask, boolean core) {\n    retry:\n    for (;;) {\n        int c = ctl.get();\n        int rs = runStateOf(c);\n\n        // 判断线程池的状态，如果是已经关闭，那就不能再创建线程\n        if (rs >= SHUTDOWN &&\n            !(rs == SHUTDOWN && firstTask == null && !workQueue.isEmpty()))\n            return false;\n\n        for (;;) {\n            int wc = workerCountOf(c);\n            // 如果线程数量大于最大数量，肯定没法继续创建\n            // 如果现在要创建的是核心线程，wc就跟核心线程数判断\n            // 如果线程要创建的是临时线程，wc就跟最大线程数判断\n            // 如果大于了，就没法创建线程了，返回false\n            if (wc >= CAPACITY ||\n                wc >= (core ? corePoolSize : maximumPoolSize))\n                return false;\n\n            // 可以创建，修改一下线程数量\n            if (compareAndIncrementWorkerCount(c))\n                break retry;\n            c = ctl.get();  \n            if (runStateOf(c) != rs)\n                continue retry;\n\n        }\n    }\n    // 上面是检查能否创建线程\n    // 下面开始创建线程\n    boolean workerStarted = false;\n    boolean workerAdded = false;\n    Worker w = null;\n    try {\n        w = new Worker(firstTask);\n        final Thread t = w.thread;\n        if (t != null) {\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n\n                int rs = runStateOf(ctl.get());\n\n                if (rs < SHUTDOWN ||\n                    (rs == SHUTDOWN && firstTask == null)) {\n                    if (t.isAlive()) // precheck that t is startable\n                        throw new IllegalThreadStateException();\n                    // 将新建的 Worker 放入集合中\n                    workers.add(w);\n                    int s = workers.size();\n                    if (s > largestPoolSize)\n                        largestPoolSize = s;\n                    workerAdded = true;\n                }\n            } finally {\n                mainLock.unlock();\n            }\n            if (workerAdded) {\n                t.start();\n                workerStarted = true;\n            }\n        }\n    } finally {\n        if (! workerStarted)\n            addWorkerFailed(w);\n    }\n    return workerStarted;\n}\n\n\n\n# 2.3 shutdown\n\n前面说过，shutdown()方法关闭线程池中的所有线程。如果线程正在执行任务，等待其执行结束。\n\n具体的过程 ：遍历所有 Worker，调用 worker.tryLock() 如果抢锁失败说明这个 Worker 正在执行任务，等待其执行结束后再关闭。\n\n// 遍历线程池中的所有线程，如果该线程正在运行，等待其运行结束再终止它\nprivate void interruptIdleWorkers(boolean onlyOne) {\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n        // 遍历所有 worker\n        for (Worker w : workers) {\n            Thread t = w.thread;\n            // 这里会抢锁，如果没抢到就会阻塞在这里\n            // 同时也就说明这个线程正在处理任务，那就等它处理完了再关闭它\n            if (!t.isInterrupted() && w.tryLock()) {\n                try {\n                    t.interrupt();\n                } catch (SecurityException ignore) {\n                } finally {\n                    w.unlock();\n                }\n            }\n            if (onlyOne)\n                break;\n        }\n    } finally {\n        mainLock.unlock();\n    }\n}\n\n\n\n# 2.4 shutdownNow\n\n关闭线程池中的所有线程。遍历所有 Worker，直接关闭。\n\n// 遍历线程池中的所有线程，调用该线程的 interruptIfStarted方法停止该线程\n// 强行停止\nprivate void interruptWorkers() {\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n        for (Worker w : workers)\n            w.interruptIfStarted();\n    } finally {\n        mainLock.unlock();\n    }\n}\n\n\n\n# 3. 总结\n\n这次看源码对我来说最有用的是两点 ：\n\n 1. 我知道了线程池中的线程并不会严格区分核心线程和非核心线程，它只会保证池子中有这么多线程一直活着。\n 2. 我知道了当核心线程数指定为 0 时，线程池也会创建一个线程去处理任务，由于核心线程数为0，这个线程是会死的。',normalizedContent:'# 1. worker\n\nworker 是线程在线程池中的表现形式，它并不是一个线程，worker 继承了 runnable，可以使用线程工厂根据 worker 创建一个线程\n\nthreadfactory.newthread(worker);\n\n\n来看看 worker 中的变量：\n\n// worker 继承 aqs 实现了不可重入锁\nprivate final class worker extends abstractqueuedsynchronizer implements runnable {\n\t// 这个 worker 封装的线程\n    final thread thread;\n    \n\t// 这个 worker 的任务\n    runnable firsttask;\n\t\n    // 这个线程执行过的任务数量\n    volatile long completedtasks;\n}\n\n\n可以看到 worker 不仅继承了 runnable，还继承了 aqs，它继承 aqs 是为了实现不可重入锁，下面会具体介绍worker 的不可重入锁。\n\n值得一提的是，虽然我们平时使用线程池时会指定 核心线程数、最大线程数，但是线程被封装为 worker 时不会区分这个线程是核心线程还是临时线程。\n\n\n# 1.1 worker 的不可重入锁\n\n如果你对 aqs 不理解或不熟悉，可以阅读一下我的另一篇文章 ：aqs源码解析\n\nworker 实现的是不可重入锁，不可重入锁实现起来比较简单 ：\n\nprotected boolean tryacquire(int unused) {\n    if (compareandsetstate(0, 1)) {\n        setexclusiveownerthread(thread.currentthread());\n        return true;\n    }\n    return false;\n}\n\n\n * 可重入锁 ：如果锁已经被占有，还要判断占有锁的线程是否是自己。\n * 不可重入锁 ：如果锁已经被占有，不再判断直接返回加锁失败。\n\nworker 的加锁逻辑是将 state 值从 0 改为 1，如果成功就返回 true，如果失败就返回 false。\n\n但是 worker 为什么要加锁功能呢 ？\n\n线程池有一个方法 ：shutdown() ，就是要停止所有的线程，但是如果该线程正在执行任务，则等待它执行结束再关闭它。\n\nworker 在执行任务时要加锁，执行结束时解锁，线程池停止线程时也加锁，如果加锁成功就着手关闭该线程。\n\n这样就可以避免线程池将正在执行任务的线程给关闭了。\n\n其实线程池还有一个方法 ：shutdownnow()，它可不管线程是否正在执行，直接关闭。\n\n那么 shutdown 和 shutdownnow 方法工作的区别就是 ：\n\n 1. shutdown() ：关闭线程池中的所有线程。如果线程正在执行任务，等待其执行结束。\n    \n    遍历所有 worker，调用 worker.trylock() 如果抢锁失败说明这个 worker 正在执行任务，等待其执行结束后再关闭。\n\n 2. shutdownnow() ：关闭线程池中的所有线程\n    \n    遍历所有 worker，直接关闭。\n\n\n# 1.2 worker.run()\n\nworker 是一个线程，那我们就绕不开它的 run() 方法，在这里可以猜测一下 worker.run() 的逻辑：\n\n 1. 循环从阻塞队列中取任务\n 2. 如果超时，判断是否终止循环，终止循环实际上这个线程就执行结束了，相当于线程死亡。\n 3. 什么时候终止循环 ？如果当前线程池中的线程数量 < 核心线程数，那我们不能让线程终止。\n\n然后可以看一下源码，看看和我们猜测的是否有差异 ：\n\n// worker 线程一启动就会调用 runworker 方法，runworker 方法在 threadpoolexecutor 中\npublic void run() {\n    runworker(this);\n}\n\n\n由于 worker 是 threadpoolexecutor 的内部类，所以 worker.run() 的逻辑是由 threadpoolexecutor.runworker() 来实现的。\n\n线程池里面的线程其实做的无非就是两件事 ：获取任务、执行任务。\n\n 1. 获取任务，获取任务有两种途径\n    * 创建 worker 时指定好的，这个只有第一次循环可能拿到\n    * 从阻塞队列中获取的，但是阻塞队列中不一定有，判断线程能否死亡的逻辑也是在这里做的。\n 2. 执行任务\n\n// 工作线程启动后就会执行这个方法\nfinal void runworker(worker w) {\n    // 拿到当前线程，由于现在运行这个方法的是 worker.run()，所以当前线程实际上就是 worker.thread\n    thread wt = thread.currentthread();\n    // 拿到该线程的 task\n    runnable task = w.firsttask;\n    // 已经把任务拿出来了，将其置空\n    w.firsttask = null;\n    // 释放锁--------存疑, 这里我没搞懂为啥要释放锁。\n    w.unlock(); \n    // 运行过程中是否出现了异常\n    boolean completedabruptly = true;\n    try {\n        // 第一次运行时 task != null，不会执行 task.gettask() 的逻辑\n        // 第二次运行时 task == null，会调用 task.gettask() 从阻塞队列中获取任务\n        // 注意，这里的 gettask 如果获取到了 null，循环就会结束，该线程就会终止\n        while (task != null || (task = gettask()) != null) {\n            // 加锁，表示该线程正在运行任务，不允许打断\n            w.lock();\n            try {\n                // 由程序员实现的逻辑, 钩子函数\n                beforeexecute(wt, task);\n                // 可能会抛出的异常\n                throwable thrown = null;\n                // 执行该任务\n                task.run();\n                \n            } finally {\n                task = null;\n                w.completedtasks++;\n                w.unlock();\n            }\n        }\n        completedabruptly = false;\n    } finally {\n        // 线程退出，也就是我们嘴里的"线程死亡"\n        processworkerexit(w, completedabruptly);\n    }\n}\n\n\n下面看一下 gettask() 方法，这个方法特别重要，它会判断这个线程是否有资格死亡，结合上面 runworker 的代码来看，只要 gettask() 返回 null，这个线程就算死了。\n\n我们可以大概想一下线程可以死亡的条件：\n\n 1. 不允许核心线程死亡时 ：\n    \n    当线程数量 > 核心线程数，也就是有临时线程，从阻塞队列中取数据超时了，也就是队列中没有任务，那么此线程可以死亡。\n    \n    注意 ：从阻塞队列中取数据 这个操作的持续时间 == 临时线程的死亡时间。\n\n 2. 允许核心线程死亡时 ：\n    \n    线程数量 < 最大线程数，从队列中取任务超时，并且队列中没有任务。\n\n源码中的判断逻辑比较难懂 ：\n\nprivate runnable gettask() {\n    // 阻塞获取任务是否超时\n    boolean timedout = false; \n    for (;;) {\n        int c = ctl.get();\n        // 获取线程池的状态\n        int rs = runstateof(c);\n        // rs >= shutdown都不正常。\n        // 如果线程池已经调用了 threadpool.shutdown()，符合下列条件中的任何一个都会返回null\n        // 1. 线程池的状态 >= stop，不再处理或接收任务\n        // 2. 任务队列为空，已经处理完了\n        if (rs >= shutdown && (rs >= stop || workqueue.isempty())) {\n            decrementworkercount();\n            return null;\n        }\n        \n\t\t// 获取线程池中的线程数量\n        int wc = workercountof(c);\n\n\t\t// 以下的判断是决定此线程是否要死亡\n        // 线程死亡的条件:\n        // 1. 不允许核心线程死亡 : \n        //     核心线程数 < 线程数量 < 最大线程数，并且从队列中取任务超时，并且队列中没有任务\n        // 2. 允许核心线程死亡 : 线程数量 < 最大线程数，从队列中取任务超时，并且队列中没有任务\n        // 3. 线程数量 > 最大线程数\n        boolean timed = allowcorethreadtimeout || wc > corepoolsize;\n\n        if ((wc > maximumpoolsize || (timed && timedout))\n            && (wc > 1 || workqueue.isempty())) {\n            if (compareanddecrementworkercount(c))\n                return null;\n            continue;\n        }\n\n        try {\n            // 如果在这里出现中断异常，可能是线程池调用了 shutdown，\n            // 该线程会进入下一个循环并在第一个if中返回 null，达到停止线程/杀死线程的目标。\n            runnable r = timed ?\n                workqueue.poll(keepalivetime, timeunit.nanoseconds) :\n            workqueue.take();\n            if (r != null)\n                return r;\n            timedout = true;\n        } catch (interruptedexception retry) {\n            timedout = false;\n        }\n    }\n}\n\n\n这里面有个有意思的判断逻辑 ：\n\nboolean timed = allowcorethreadtimeout || wc > corepoolsize;\n\nrunnable r = timed ?\n    workqueue.poll(keepalivetime, timeunit.nanoseconds) :\nworkqueue.take();\n\n\n一般情况下我们不会允许核心线程死亡，那么 timed 这个变量就取决于当前线程的数量是否大于核心线程的数量。\n\n 1. 如果大于，说明此时有临时线程，那么此线程的身份就是临时线程，取任务时阻塞 keepalivetime 这么长时间。如果阻塞了 keepalivetime 还没有拿到任务，就会进入下一个循环，判断此线程是否要死亡。\n\n 2. 如果小于，说明此时没有临时线程，那么此线程的身份就是核心线程，取任务时永久阻塞。\n\n至此，worker 的源码就说完了，线程池中的线程并不会区分核心线程与临时线程，它只会保证线程池中始终有 corepoolsize 个线程保持活跃。\n\n\n# 2. threadpoolexecutor\n\n源码大概有 1000 多行，根本不需要看完，重要有两个方法 ：\n\n 1. 提交任务 execute ：在这里可以看到线程池的工作流程以及线程的创建过程。\n 2. 关闭线程池 shutdown ：在这里可以看到线程池的不同关闭逻辑。\n\n\n# 2.1 线程池变量\n\npublic class threadpoolexecutor extends abstractexecutorservice {\n    // 线程池的状态和线程数量\n    // 高三位表示线程池的状态\n    // 低29位表示线程池中的线程数量\n    private final atomicinteger ctl = new atomicinteger(ctlof(running, 0));\n\n    private static final int count_bits = integer.size - 3;\n    // 1 << 29 = 00010000 00000000 00000000 00000000\n    // 再减1 = 00001111 11111111 11111111 11111111\n    // ctl & capacity 可以得到线程数量 \n    private static final int capacity   = (1 << count_bits) - 1;\n\n\t// 线程池的五种状态，在 ctl 的高三位表示\n    // 111 00000 00000000 00000000 00000000\n    // 正在运行\t\t\n    private static final int running    = -1 << count_bits;\n    \n    // 000 00000 00000000 00000000 00000000\n    // 已经调用了 shutdown，但是里面的线程还没有停止\n    private static final int shutdown   =  0 << count_bits;\n    \n    // 001 00000 00000000 00000000 00000000\n    private static final int stop       =  1 << count_bits;\n    // 010 00000 00000000 00000000 00000000\n    private static final int tidying    =  2 << count_bits;\n    // 011 00000 00000000 00000000 00000000\n    private static final int terminated =  3 << count_bits;\n\n\t// 传入 ctl，返回线程池的状态\n    private static int runstateof(int c)     { return c & ~capacity; }\n    // 传入 ctl，返回线程数量\n    private static int workercountof(int c)  { return c & capacity; }\n    // 传入线程池的状态和线程数量，返回ctl\n    private static int ctlof(int rs, int wc) { return rs | wc; }\n\n\n\n\t// cas的方式增加工作线程的数量，增加一个\n    private boolean compareandincrementworkercount(int expect) {\n        return ctl.compareandset(expect, expect + 1);\n    }\n\n\t// cas的方式减少工作线程的数量，减少一个\n    private boolean compareanddecrementworkercount(int expect) {\n        return ctl.compareandset(expect, expect - 1);\n    }\n\n\n    // 保存工作线程的集合\n    private final hashset<worker> workers = new hashset<worker>();\n\n    \n   \t// 线程池的状态锁，改变线程池状态时要加这个锁\n    private final reentrantlock mainlock = new reentrantlock();\n\n    // 线程池的条件锁，在线程池的状态发生改变时，使用这个条件锁通知所有等待的线程阻塞或者唤醒\n    private final condition termination = mainlock.newcondition();\n\n    // 线程池中曾经出现过的最大的线程数量\n    private int largestpoolsize;\n\n    // 已经完成的任务数量\n    private long completedtaskcount;\n\n    \n\t// 下面是核心参数，也就是需要我们指定的7个参数\n    // 线程池的阻塞队列\n    private final blockingqueue<runnable> workqueue;\n\t// 线程工厂\n    private volatile threadfactory threadfactory;\n\t// 拒绝策略\n    private volatile rejectedexecutionhandler handler;\n\t// 临时线程存活时间\n    private volatile long keepalivetime;\n    // 是否允许核心线程死亡\n    private volatile boolean allowcorethreadtimeout;\n    // 核心线程数\n    private volatile int corepoolsize;\n    // 最大线程数 = 核心线程数 + 临时线程数\n    private volatile int maximumpoolsize;\n\n    // 默认的拒绝策略，拒绝执行并抛出异常\n    private static final rejectedexecutionhandler defaulthandler =\n        new abortpolicy();\n\n}\n\n\n\n# 2.2 execute\n\n线程池的工作流程是老八股了 ：\n\n\n\n这个步骤是正确的，我们也可以按照这个步骤来阅读源码 ：\n\n// 提交任务\npublic void execute(runnable command) {\n    if (command == null)\n        throw new nullpointerexception();\n    // 获取 ctl\n    int c = ctl.get();\n    // 如果线程数量 < 核心线程\n    if (workercountof(c) < corepoolsize) {\n        // 添加核心线程\n        // addworker: 判断能否创建线程，然后再创建线程\n        // 如果返回 true，说明创建成功，直接结束，这个任务会交给新建的线程去执行\n        // 如果返回 false，说明线程池状态异常，或者线程数量超了\n        if (addworker(command, true))\n            return;\n        c = ctl.get();\n    }\n    // 将任务放入阻塞队列中\n    if (isrunning(c) && workqueue.offer(command)) {\n        int recheck = ctl.get();\n        if (!isrunning(recheck) && remove(command))\n            reject(command);\n        // 如果现在没有正在运行的线程，就创建一个线程处理任务\n        else if (workercountof(recheck) == 0)\n            addworker(null, false);\n    }\n    // 如果放入队列失败，新建临时线程处理任务\n    // 如果新建临时线程失败，就执行拒绝策略\n    else if (!addworker(command, false))\n        reject(command);\n}\n\n\n有一个细节 ：当指定核心线程数量为 0 时，也会创建一个线程，并且在阻塞队列满之前都只有这一个线程处理任务。\n\n接下来重要的就是 addworker() ，它是具体创建线程的地方 ：\n\n// 添加线程 \nprivate boolean addworker(runnable firsttask, boolean core) {\n    retry:\n    for (;;) {\n        int c = ctl.get();\n        int rs = runstateof(c);\n\n        // 判断线程池的状态，如果是已经关闭，那就不能再创建线程\n        if (rs >= shutdown &&\n            !(rs == shutdown && firsttask == null && !workqueue.isempty()))\n            return false;\n\n        for (;;) {\n            int wc = workercountof(c);\n            // 如果线程数量大于最大数量，肯定没法继续创建\n            // 如果现在要创建的是核心线程，wc就跟核心线程数判断\n            // 如果线程要创建的是临时线程，wc就跟最大线程数判断\n            // 如果大于了，就没法创建线程了，返回false\n            if (wc >= capacity ||\n                wc >= (core ? corepoolsize : maximumpoolsize))\n                return false;\n\n            // 可以创建，修改一下线程数量\n            if (compareandincrementworkercount(c))\n                break retry;\n            c = ctl.get();  \n            if (runstateof(c) != rs)\n                continue retry;\n\n        }\n    }\n    // 上面是检查能否创建线程\n    // 下面开始创建线程\n    boolean workerstarted = false;\n    boolean workeradded = false;\n    worker w = null;\n    try {\n        w = new worker(firsttask);\n        final thread t = w.thread;\n        if (t != null) {\n            final reentrantlock mainlock = this.mainlock;\n            mainlock.lock();\n            try {\n\n                int rs = runstateof(ctl.get());\n\n                if (rs < shutdown ||\n                    (rs == shutdown && firsttask == null)) {\n                    if (t.isalive()) // precheck that t is startable\n                        throw new illegalthreadstateexception();\n                    // 将新建的 worker 放入集合中\n                    workers.add(w);\n                    int s = workers.size();\n                    if (s > largestpoolsize)\n                        largestpoolsize = s;\n                    workeradded = true;\n                }\n            } finally {\n                mainlock.unlock();\n            }\n            if (workeradded) {\n                t.start();\n                workerstarted = true;\n            }\n        }\n    } finally {\n        if (! workerstarted)\n            addworkerfailed(w);\n    }\n    return workerstarted;\n}\n\n\n\n# 2.3 shutdown\n\n前面说过，shutdown()方法关闭线程池中的所有线程。如果线程正在执行任务，等待其执行结束。\n\n具体的过程 ：遍历所有 worker，调用 worker.trylock() 如果抢锁失败说明这个 worker 正在执行任务，等待其执行结束后再关闭。\n\n// 遍历线程池中的所有线程，如果该线程正在运行，等待其运行结束再终止它\nprivate void interruptidleworkers(boolean onlyone) {\n    final reentrantlock mainlock = this.mainlock;\n    mainlock.lock();\n    try {\n        // 遍历所有 worker\n        for (worker w : workers) {\n            thread t = w.thread;\n            // 这里会抢锁，如果没抢到就会阻塞在这里\n            // 同时也就说明这个线程正在处理任务，那就等它处理完了再关闭它\n            if (!t.isinterrupted() && w.trylock()) {\n                try {\n                    t.interrupt();\n                } catch (securityexception ignore) {\n                } finally {\n                    w.unlock();\n                }\n            }\n            if (onlyone)\n                break;\n        }\n    } finally {\n        mainlock.unlock();\n    }\n}\n\n\n\n# 2.4 shutdownnow\n\n关闭线程池中的所有线程。遍历所有 worker，直接关闭。\n\n// 遍历线程池中的所有线程，调用该线程的 interruptifstarted方法停止该线程\n// 强行停止\nprivate void interruptworkers() {\n    final reentrantlock mainlock = this.mainlock;\n    mainlock.lock();\n    try {\n        for (worker w : workers)\n            w.interruptifstarted();\n    } finally {\n        mainlock.unlock();\n    }\n}\n\n\n\n# 3. 总结\n\n这次看源码对我来说最有用的是两点 ：\n\n 1. 我知道了线程池中的线程并不会严格区分核心线程和非核心线程，它只会保证池子中有这么多线程一直活着。\n 2. 我知道了当核心线程数指定为 0 时，线程池也会创建一个线程去处理任务，由于核心线程数为0，这个线程是会死的。',charsets:{cjk:!0},lastUpdated:"2024/02/28, 21:50:33",lastUpdatedTimestamp:1709128233e3},{title:"AQS源码解析",frontmatter:{title:"AQS源码解析",date:"2023-12-21T23:27:11.000Z",permalink:"/pages/6c8c00/"},regularPath:"/02.%E6%96%87%E7%AB%A0/75.Java%E5%B9%B6%E5%8F%91/60.AQS%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90.html",relativePath:"02.文章/75.Java并发/60.AQS源码解析.md",key:"v-230aad5c",path:"/pages/6c8c00/",headers:[{level:2,title:"1. 简述",slug:"_1-简述",normalizedTitle:"1. 简述",charIndex:2},{level:2,title:"2. AQS 的一些重要属性",slug:"_2-aqs-的一些重要属性",normalizedTitle:"2. aqs 的一些重要属性",charIndex:609},{level:3,title:"2.1 Node",slug:"_2-1-node",normalizedTitle:"2.1 node",charIndex:628},{level:3,title:"2.2 同步队列",slug:"_2-2-同步队列",normalizedTitle:"2.2 同步队列",charIndex:1913},{level:3,title:"2.3 等待队列",slug:"_2-3-等待队列",normalizedTitle:"2.3 等待队列",charIndex:2166},{level:3,title:"2.4 state状态值",slug:"_2-4-state状态值",normalizedTitle:"2.4 state状态值",charIndex:2619},{level:3,title:"2.5 小结",slug:"_2-5-小结",normalizedTitle:"2.5 小结",charIndex:2972},{level:2,title:"3. 线程加锁失败后",slug:"_3-线程加锁失败后",normalizedTitle:"3. 线程加锁失败后",charIndex:3376},{level:3,title:"3.1 将当前线程加入同步队列",slug:"_3-1-将当前线程加入同步队列",normalizedTitle:"3.1 将当前线程加入同步队列",charIndex:4229},{level:3,title:"3.2 将当前线程阻塞",slug:"_3-2-将当前线程阻塞",normalizedTitle:"3.2 将当前线程阻塞",charIndex:5591},{level:2,title:"4. 释放锁后",slug:"_4-释放锁后",normalizedTitle:"4. 释放锁后",charIndex:7283},{level:2,title:"5. Condition",slug:"_5-condition",normalizedTitle:"5. condition",charIndex:8626},{level:3,title:"5.1 Condition.await()",slug:"_5-1-condition-await",normalizedTitle:"5.1 condition.await()",charIndex:9279},{level:3,title:"5.2 Condition.signal()",slug:"_5-2-condition-signal",normalizedTitle:"5.2 condition.signal()",charIndex:10459},{level:2,title:"5. 总结",slug:"_5-总结",normalizedTitle:"5. 总结",charIndex:11649}],headersStr:"1. 简述 2. AQS 的一些重要属性 2.1 Node 2.2 同步队列 2.3 等待队列 2.4 state状态值 2.5 小结 3. 线程加锁失败后 3.1 将当前线程加入同步队列 3.2 将当前线程阻塞 4. 释放锁后 5. Condition 5.1 Condition.await() 5.2 Condition.signal() 5. 总结",content:"# 1. 简述\n\nJUC 包下的很多类都依靠 AQS，在知道 AQS 是一个抽象类之后，我一度以为 AQS是JUC的基石 这句话的意思是：JUC包下很多类都实现/继承了 AQS，比如 ReentrantLock 实现了 AQS... 但是我错了。\n\n\n\n可以看到，AQS 有很多名为 Sync的实现类，这些 Sync 分布在不同的类中，那么 AQS是JUC的基石 的意思就应该是：当一个工具类想要使用 AQS 提供的基本功能时，会写一个内部类 Sync 继承 AQS。\n\n再次强调 ：AQS 是一个工具，它没有加锁功能。它的许多实现类（大多叫做 Sync）实现了加锁功能，比如公平加锁、非公平加锁、加读写锁、加公平锁.....\n\nAQS 提供了什么功能呢？如果没有抢到锁就会让线程阻塞等待。\n\n当某个类想要使用 AQS 提供的基本功能时，只需要继承它并实现那些还没有实现的方法就可以，这是典型的模板方法设计模式。\n\nAQS 本身没有抢锁功能，大多数文章会从 ReentrantLock 入手，但是这会让读者乱套，初学者很容易对 ReentrantLock 与 AQS 迷迷糊糊分不清，所以本篇文章会抽象表达 “加锁” 这个概念，也就是不讲解加锁功能，而是简略的以 “某线程抢锁失败” 来表达。\n\n等把 AQS 提供的功能介绍清楚了再介绍 ReentrantLock、CountDownLatch 对它的实现。\n\n\n# 2. AQS 的一些重要属性\n\n\n# 2.1 Node\n\n现在可以抽空看一下目录，是不是有同步队列和等待队列这两个小标题？这个Node类就是组成同步队列和阻塞队列的节点。原本想要在同步队列中直接将 Node 引出，但是会因此让文章变得混乱，所以我决定先介绍Node。\n\nAQS中有一个静态内部类：Node。这个Node可以抽象为线程，也许说它就代表着线程更加妥当。\n\nstatic final class Node {\n    // 此Node代表的线程\n    volatile Thread thread;\n    // pre 和 next 构成了双向链表，组成AQS的同步队列\n    // 此Node的前一个结点\n    volatile Node prev;\n\t// 此Node的后一个节点\n    volatile Node next;\n    // nextWaiter 构成了单向链表，组成了AQS的等待队列\n    Node nextWaiter;\n    // 节点的状态\n    volatile int waitStatus;\n}\n\n\n * next 和 prev 用于实现同步队列（基于双向链表）\n * nextWaiter 用于实现等待队列（基于单链表），这个 nextWaiter 用于 Condition.await()\n\n因为 Node 代表着线程，所以它提供了几个状态值来代表线程在队列中的状态 ：\n\n// Node的状态默认为 0\n\n// 此任务已取消\nstatic final int CANCELLED =  1;\n\n// 当前节点的下一个节点挂起了\nstatic final int SIGNAL    = -1;\n\n// 当前节点在等待队列中\nstatic final int CONDITION = -2;\n\n// 与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态。\nstatic final int PROPAGATE = -3;\n\n\n谁拥有这些状态值呢？waitStatus\n\n线程都是以 Node 形式保存在 AQS 中的，Node中提供了几种状态供线程使用，例如 已取消（1）、默认（0）、挂起（-1）、等待（-2）....\n\n同时，如果你正在看源码，还会看到两个属性 :\n\n// 共享模式\nstatic final Node SHARED = new Node();\n// 独占模式\nstatic final Node EXCLUSIVE = null;\n\n\nSHARED 和 EXCLUSIVE 两个单词的意思很明显 ：共享和独占。\n\n 1. 独占模式即当锁被某个线程成功获取时，其他线程无法获取到该锁，同一时间只有一个线程能拿到锁执行，锁的状态只有0和1两种情况。例如 ReentrantLock，一次只有一个线程可以工作。\n 2. 共享模式即当锁被某个线程成功获取时，其他线程仍然可能获取到该锁，同一时间有多个线程可以拿到锁协同工作，锁的状态大于或等于0。例如 CountDownLatch，一次可以有多个线程工作。\n\n\n# 2.2 同步队列\n\n这个同步队列是由双向链表实现的。从上面所说的可以知道，AQS中的同步队列是由Node组成、Node中的prev和next连接。\n\n只有节点肯定不行，AQS中有两个属性控制这个双向链表，head 和 tail 。即头和尾。头是一个虚拟节点，它里面的 thread变量 一直是NULL并不会代表哪个线程；尾是有具体意义的，会代表某一个线程。即：头节点无意义，其他节点都代表一个线程。\n\n\n\n注意喽，同步队列的头节点是无意义的，线程封装的节点不能成为头节点，只能成为头节点后的节点。\n\n\n# 2.3 等待队列\n\nNode组成等待队列，Node中的nextWaiter连接成为等待队列。\n\n\n\n奇怪的是，当我在AQS中寻找与管理同步队列的head和tail类似的属性时并没有找到，但我还是找到了管理等待队列的属性：firstWaiter、lastWaiter\n\n它在AQS另一个内部类中 ：ConditionObject。\n\n说来也是，就 “等待队列” 这个词而言，等待肯定是它的一大特点。那么如何实现等待？一个是Object类中的wait方法，另一个就是 Condition 的 await 方法。那么就好解释了：\n\n> ConditionObject 提供了让 Node 等待的方法，例如 await、signal...通过 Node.nextWaiter 将线程串为一个等待队列，并且使用 firstWaiter 和 lastWaiter 控制/管理 等待队列。\n\n注意喽，等待队列的 firstWaiter 可不是无意义的哦，线程封装为 Node 后可以成为 firstWaiter\n\n\n# 2.4 state状态值\n\n这是一个非常重要的属性。\n\nprivate volatile int state;\n\n\n毕竟AQS提供的是并发支持，有并发就要有锁，那么一个线程怎样才算拿到锁呢？\n\nstate 不为 0 的时候证明这个锁被占有了。\n\n同时，由于 AQS 并没有要求实现类必须怎样怎样，所以实现类们也把 state 用的花里胡哨，例如：\n\n 1. 在 ReentrantLock 中，state 为 0 代表锁还未被占有，如果为 1 代表被占有，如果大于 1 代表重入。\n 2. 在 CountDownLatch 中，state 代表着任务数量。\n 3. 在 ReentrantReadWriteLock 中，将 state 的 32 个字节均分为两部分，一部分表示读锁，一部表示写锁。\n\n\n# 2.5 小结\n\n 1. AQS有两个重要的属性：Node和state。\n\n 2. state 是状态值，一般来说代表锁是否被持有，不过具体含义要看实现类如何操作。\n\n 3. 共享和独占 ：共享是允许多个线程共同执行任务，独占是同一时间只允许一个线程执行\n\n 4. Node：是线程的代表，线程会被封装为Node在AQS中存在。\n    \n    Node中有三个属性：next、prev、nextWaiter。\n    \n    * next和prev连接Node成为同步队列。控制同步队列的属性 head 和 tail 在AQS中。\n    * nextWaiter连接Node成为等待队列。控制等待队列的属性 firstWaiter 和 lastWaiter 在 ConditionObject 中（AQS的内部类）\n    * （至于同步队列和等待队列到底有什么用，我想在后续慢慢展开。）\n\n\n\n\n# 3. 线程加锁失败后\n\n在上面说过，AQS 自身并不提供加锁功能，而是实现了加锁失败后的逻辑。这么做有什么好处呢？\n\n程序员可以根据需要进行加锁，比如以下各种锁实现时，想要加锁要满足什么条件：\n\n 1. 不可重入锁 ：锁不被任何线程持有时才能加锁成功\n 2. 可重入锁 ：锁不被任何线程持有，但是如果是自己持有，还可以加锁\n 3. 公平锁 ：线程抢锁之前先看看有没有其他线程正在等待，没有再抢锁，有就跟在他们后面\n 4. 非公平锁 ：管它呢直接抢，抢不到再说\n 5. 读写锁 ：读锁可共享，写锁需排斥。\n\n如果没有 AQS，这些锁在实现的时候都要写一遍 “线程抢锁失败后需要阻塞等待” 的逻辑，代码太冗余了！AQS 大手一挥，我帮你们实现，程序员只要根据现在的情况判断是否抢锁成功就行了，抢锁失败的线程交给我。\n\n那么现在就来看看 AQS 如何对待抢锁失败的线程的吧。\n\nAQS 需要它的子类实现的方法是 ：tryAcquire()，也就是尝试获取锁，如果获取成功了就没 AQS 要干的事了，但是如果失败，那么就要处理当前线程了：\n\npublic final void acquire(int arg) {\n    // tryAcquire让子类去实现\n    // 如果获取锁失败，执行后面的逻辑\n    if (!tryAcquire(arg) &&\n        // 将当前线程加入到同步队列中，并且将线程阻塞\n        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n        // 阻塞停止后，调用该线程的 interrupt方法\n        selfInterrupt();\n}\n\n\ntryAcquire 方法由子类实现，那么现在来看看 addWaiter 与 acquireQueued 这两个方法\n\n 1. addWaiter ：将当前线程封装为 Node 并放入同步队列\n 2. acquireQueued ：\n\n\n# 3.1 将当前线程加入同步队列\n\n步骤分为两大步：构建一个 Node、放到队列尾部。\n\n你想把一个 Node 放到双向链表的尾部，大抵是这三步：\n\ntail.next = node;\nnode.pre = tail;\nnode = tail\n\n\n也就是将链表尾节点的 next 指针指向自己，自己的 pre 指针指向尾节点，最后自己变成了尾节点。\n\n但是放入队列尾部这个动作说得轻巧，问题就出在这里，当多个 Node 想要挂在同一个尾节点上时，会出现并发情况。但是我懒得画图了😜\n\nAQS 解决并发情况是这样做的 ：先将 node.pre = tail，再使用 CAS 将 node 成为尾节点，最后将 node.pre.next = node，如果 CAS 失败，说明现在出现并发情况了，别的线程抢先一步将 Node 变成了尾节点，此线程的 node 只能挂在那个 node 后面了。\n\n// 调用来源 : addWaiter(Node.EXCLUSIVE)\n// 使用 Node.EXCLUSIVE 作为 mode 的入参，mode为空。\nprivate Node addWaiter(Node mode) {\n    // 将此线程封装为独占模式的 Node\n    Node node = new Node(Thread.currentThread(), mode);\n    // 获取阻塞队列的尾节点\n    Node pred = tail;\n   \n    if (pred != null) {\n        // 如果尾节点不为空，把此节点挂在尾节点后面\n        // 首先执行 node.pre = pred\n        node.prev = pred;\n        // 然后使用CAS的方式将node设置为尾节点\n        // 如果设置成功，就可以将之前尾节点的next指向现在的尾节点: pred.next = node\n        if (compareAndSetTail(pred, node)) {\n            pred.next = node;\n            // 一般情况下会在这里return\n            return node;\n        }\n    }\n    // 如果前面没有return，说明什么？\n    // 说明CAS失败了，也就是出现了并发设置尾节点的情况，即: 多个线程设置尾节点，这个线程设置失败了。\n    // 虽然失败了，那这个节点可以挂在新来的尾节点上啊~ \n    // 所以这个方法的逻辑就是将此节点挂在新来的尾节点上，就不再详细解释了\n    enq(node);\n    return node;\n}\n\n// 用 CAS 将尾节点的值从 expect 换成 update\nprivate final boolean compareAndSetTail(Node expect, Node update) {\n    return unsafe.compareAndSwapObject(this, tailOffset, expect, update);\n}\n\n\n\n# 3.2 将当前线程阻塞\n\n此时，node 已经成为同步队列中的尾节点了，但是线程还没有阻塞，AQS 要做的就是让抢锁失败的线程阻塞，所以这个方法至关重要。\n\n一上来就是死循环，当前节点虽然是尾节点，但是如果它的 pre 是头节点代表啥？代表同步队列中只有它一个线程，那我就得重新抢一下锁了，如果抢失败了我再阻塞。\n\nfinal boolean acquireQueued(final Node node, int arg) {\n    boolean failed = true;\n    try {\n        boolean interrupted = false;\n        for (;;) {\n            // 拿到当前节点的前一个节点，\n            // 如果是head节点，可以尝试抢一下锁\n            final Node p = node.predecessor();\n            // 如果当前节点的前一个节点是head节点，尝试抢锁\n            if (p == head && tryAcquire(arg)) {\n                // 如果抢锁成功，将此节点变成head傀儡节点\n                // setHead() 方法首先会将 Node内部的线程置为空，为啥置为空？\n                // 都抢到锁了，这个线程肯定不需要存在于AQS中了。\n                setHead(node);\n                // 之前的head节点置为空，方便GC\n                p.next = null; \n                failed = false;\n                return interrupted;\n            }\n            // 此节点的上一个节点不是头节点，或者抢锁失败，将当前线程 park 起来\n            if (\n                // 检查一下节点的状态，如果已取消就没必要阻塞等待\n                shouldParkAfterFailedAcquire(p, node) &&\n                // 这个方法将当前线程park起来\n                parkAndCheckInterrupt()\n               )\n                interrupted = true;\n        }\n    } finally {\n        if (failed)\n            cancelAcquire(node);\n    }\n}\n\n// 将node内部的线程置为空，变成无意义的 head 节点\nprivate void setHead(Node node) {\n    head = node;\n    node.thread = null;\n    node.prev = null;\n}\n\n// 将当前线程park起来\nprivate final boolean parkAndCheckInterrupt() {\n    // ★ 线程阻塞在此处等待唤醒 \n    LockSupport.park(this);\n    // 返回对应线程的中断标志位，并且将中断标志位重置变为false\n    return Thread.interrupted();\n}\n\n\n注意 ：当锁被释放时，只会唤醒同步队列中第一个节点，也就是 head.next。（这个会在释放锁的逻辑中说）\n\n当阻塞的线程被唤醒，也就代表此节点是 head.next，那么死循环中的 if 条件就可以走通了，于是此节点会使用 tryAcquire 尝试获取锁，如果获取成功就退出循环，如果获取失败就还要阻塞。\n\n\n# 4. 释放锁后\n\nAQS当然不会管怎么释放锁，释放锁的逻辑让子类去实现，比如不可重入锁直接释放，可重入锁还要判断一下是否重入。\n\nAQS 实现的是之前被阻塞的线程怎么办的逻辑。\n\npublic final boolean release(int arg) {\n    // 释放锁的逻辑让子类实现\n    // 一旦释放成功，AQS就开始唤醒同步队列中的第一个节点\n    if (tryRelease(arg)) {\n        // 拿到头节点\n        Node h = head;\n        if (h != null && h.waitStatus != 0)\n            // 唤醒头节点后面那个节点\n            unparkSuccessor(h);\n        return true;\n    }\n    return false;\n}\n\n\n不出意外的情况下是直接唤醒 head.next 那个线程，但是不出意外的情况下要出意外了 ：\n\nhead 后的第一个节点为空！或者说它的状态为取消！那么就从同步队列的尾部向前寻找一个有意义的节点将它唤醒，注意只找一个哦。\n\n并且有一个小细节 ：如果Node的状态为取消，它不会从同步队列中移除，这个细节在 Condition 中会涉及\n\n// 此时传入的Node为头节点\nprivate void unparkSuccessor(Node node) {\n    int ws = node.waitStatus;\n    if (ws < 0)\n        compareAndSetWaitStatus(node, ws, 0);\n\t// 拿到头节点后面的第一个节点\n    Node s = node.next;\n    // 一般来说不会走这里，而是下面那个if，直接将线程唤醒。\n    // 但是走这里的逻辑是因为啥呢？\n    // waitStatus在上面有讲解，节点的 waitStatus > 0代表此节点已经取消\n    // 所以逻辑就是：如果 head.next 为空或者已经取消，就从同步队列的尾部开始往前寻找，\n    // 直到找到一个没有取消的节点\n    if (s == null || s.waitStatus > 0) {\n        s = null;\n        for (Node t = tail; t != null && t != node; t = t.prev)\n            if (t.waitStatus <= 0)\n                s = t;\n    }\n    // 直接将这个线程唤醒了\n    if (s != null)\n        LockSupport.unpark(s.thread);\n}\n\n\n步骤 ：拿到头节点后的第一个有意义的节点，如果这个节点的状态为取消，说明这个节点刚从等待队列放到同步队列，跳过它从队列的尾部开始找状态正常的，找到之后将它唤醒\n\n所有线程的执行都阻塞在 acquireQueued 方法内部，这个你可以向上翻，我有说。\n\n\n# 5. Condition\n\n可能刚说完 AQS 就说 Condition 会有些割裂感，因为很难想象 Condition 与 AQS 有啥关系，对，有关系，还记得 AQS 的 Node 中有一个成员变量 ：nextWaiter\n\n我在之前说过，AQS 本身的逻辑并没有用到这个变量，而是在 ConditionObject 中使用到了，所以 AQS 中第二个队列出现了 ：等待队列\n\n笔记\n\n请你注意等待队列与同步队列的区别。不要将二者混为一谈\n\nstatic final class Node {\n    // 此Node代表的线程\n    volatile Thread thread;\n    // 用于同步队列，此Node的前一个结点\n    volatile Node prev;\n\t// 用于同步队列，此Node的后一个节点\n    volatile Node next;\n    // 用于等待队列，等待队列是一个单向链表组成的队列\n    Node nextWaiter;\n    // 节点的状态\n    volatile int waitStatus;\n    // 省略其他变量\n}\n\n\n常用的让线程等待的方法有两种 ：\n\n 1. Object.wait()\n 2. Condition.await()\n\n虽然实现不一样，但是原理是一样的，线程等待的前提肯定是已经拥有锁了，调用 wait 后会释放锁然后阻塞。调用 signal 将线程从等待状态唤醒，进入阻塞状态，可以抢锁。\n\n\n# 5.1 Condition.await()\n\n如果是你，你会如何借助 AQS 来实现 Condition.await() 呢？不就是释放锁之后阻塞嘛~\n\n 1. 将此线程封装为 Node 并放入等待队列\n 2. 调用 AQS 的 release 释放锁\n 3. 将当前线程阻塞\n\n对，就是这三步，来看看 AQS 中的 ConditionObject 如何实现这三步的 ：\n\npublic final void await() throws InterruptedException {\n    if (Thread.interrupted())\n        throw new InterruptedException();\n    // 将当前线程封装为Node，Node的状态为-2，也就是等待，然后放入等待队列\n    // 这时会将 node.waitStatus 改为 CONDITION\n    Node node = addConditionWaiter();\n    // 调用 release 方法释放锁\n    // 这时会将 node.waitStatus 改为 CANCELLED ★ 这里特别重要！！！！！\n    // 再次强调，这里会将 node.waitStatus 改为 CANCELLED \n    int savedState = fullyRelease(node);\n    int interruptMode = 0;\n    // 判断 Node 节点的状态\n    // 第一次进入时都会返回false，取反后会进入方法将线程阻塞\n    while (!isOnSyncQueue(node)) {\n        LockSupport.park(this);\n        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n            break;\n    }\n    // 线程从等待状态恢复后，进入同步队列等待抢锁，这里的逻辑就是上面说过了的。\n    if (acquireQueued(node, savedState) && interruptMode != THROW_IE)\n        interruptMode = REINTERRUPT;\n    if (node.nextWaiter != null) // clean up if cancelled\n        unlinkCancelledWaiters();\n    if (interruptMode != 0)\n        reportInterruptAfterWait(interruptMode);\n}\n\n\n\n# 5.2 Condition.signal()\n\n如果是你，你会如何借助 AQS 来实现 Condition.signal() 呢？不就是唤醒锁、把它加入同步队列嘛~\n\nCondition.signal() 会唤醒在等待队列中等待时间最长的节点（首节点）\n\n// 传入的是等待队列的头节点（线程是可以成为头节点的）\nprivate void doSignal(Node first) {\n    do {\n        // 一般不会走这里\n        if ( (firstWaiter = first.nextWaiter) == null)\n            lastWaiter = null;\n        // 将头节点的next指针置为空\n        first.nextWaiter = null;\n    } while (!transferForSignal(first) &&\n             (first = firstWaiter) != null);\n}\n\n\nfinal boolean transferForSignal(Node node) {\n    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))\n        return false;\n    // 将该节点加入同步队列尾部\n    Node p = enq(node);\n    // 刚刚在 await方法中，我特别强调了，fullyRelease 方法会将节点的状态改为取消\n    // 也就是 node.waitStatus = 1, 即 ws = 1\n    int ws = p.waitStatus;\n    if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))\n        LockSupport.unpark(node.thread);\n    return true;\n}\n\n\n思考 ：为啥调用 await() 方法让线程释放锁后，线程 Node 的状态会变成取消（node.waitStatus = 1）呢？\n\n因为 signal 方法的步骤为 ：\n\n 1. 将 node 放入同步队列\n 2. 将线程唤醒\n\n将 node 放入同步队列后，万一被唤醒了怎么办？那就要通过一些手段防止这种概率特别小的情况出现，也就是线程调用 await() 进入等待之前先将 Node 的状态变成 取消，那么就不会被误唤醒！真叼啊。\n\nCondition 的 singalAll 方法，相当于对等待队列的每个节点均执行一次 singal 方法，效果就是将等待队列中所有节点全部移动到同步队列，并唤醒每个节点的线程。\n\n\n# 5. 总结\n\n至此，AQS 的核心功能已经说完了，没有讲加锁、释放锁？因为加锁、释放锁的逻辑本来就不是 AQS 要完成的呀。\n\n所以加锁与释放锁我会在 ReentrantLock、CountDownLatch、ReadWriteLock 中讲。",normalizedContent:"# 1. 简述\n\njuc 包下的很多类都依靠 aqs，在知道 aqs 是一个抽象类之后，我一度以为 aqs是juc的基石 这句话的意思是：juc包下很多类都实现/继承了 aqs，比如 reentrantlock 实现了 aqs... 但是我错了。\n\n\n\n可以看到，aqs 有很多名为 sync的实现类，这些 sync 分布在不同的类中，那么 aqs是juc的基石 的意思就应该是：当一个工具类想要使用 aqs 提供的基本功能时，会写一个内部类 sync 继承 aqs。\n\n再次强调 ：aqs 是一个工具，它没有加锁功能。它的许多实现类（大多叫做 sync）实现了加锁功能，比如公平加锁、非公平加锁、加读写锁、加公平锁.....\n\naqs 提供了什么功能呢？如果没有抢到锁就会让线程阻塞等待。\n\n当某个类想要使用 aqs 提供的基本功能时，只需要继承它并实现那些还没有实现的方法就可以，这是典型的模板方法设计模式。\n\naqs 本身没有抢锁功能，大多数文章会从 reentrantlock 入手，但是这会让读者乱套，初学者很容易对 reentrantlock 与 aqs 迷迷糊糊分不清，所以本篇文章会抽象表达 “加锁” 这个概念，也就是不讲解加锁功能，而是简略的以 “某线程抢锁失败” 来表达。\n\n等把 aqs 提供的功能介绍清楚了再介绍 reentrantlock、countdownlatch 对它的实现。\n\n\n# 2. aqs 的一些重要属性\n\n\n# 2.1 node\n\n现在可以抽空看一下目录，是不是有同步队列和等待队列这两个小标题？这个node类就是组成同步队列和阻塞队列的节点。原本想要在同步队列中直接将 node 引出，但是会因此让文章变得混乱，所以我决定先介绍node。\n\naqs中有一个静态内部类：node。这个node可以抽象为线程，也许说它就代表着线程更加妥当。\n\nstatic final class node {\n    // 此node代表的线程\n    volatile thread thread;\n    // pre 和 next 构成了双向链表，组成aqs的同步队列\n    // 此node的前一个结点\n    volatile node prev;\n\t// 此node的后一个节点\n    volatile node next;\n    // nextwaiter 构成了单向链表，组成了aqs的等待队列\n    node nextwaiter;\n    // 节点的状态\n    volatile int waitstatus;\n}\n\n\n * next 和 prev 用于实现同步队列（基于双向链表）\n * nextwaiter 用于实现等待队列（基于单链表），这个 nextwaiter 用于 condition.await()\n\n因为 node 代表着线程，所以它提供了几个状态值来代表线程在队列中的状态 ：\n\n// node的状态默认为 0\n\n// 此任务已取消\nstatic final int cancelled =  1;\n\n// 当前节点的下一个节点挂起了\nstatic final int signal    = -1;\n\n// 当前节点在等待队列中\nstatic final int condition = -2;\n\n// 与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态。\nstatic final int propagate = -3;\n\n\n谁拥有这些状态值呢？waitstatus\n\n线程都是以 node 形式保存在 aqs 中的，node中提供了几种状态供线程使用，例如 已取消（1）、默认（0）、挂起（-1）、等待（-2）....\n\n同时，如果你正在看源码，还会看到两个属性 :\n\n// 共享模式\nstatic final node shared = new node();\n// 独占模式\nstatic final node exclusive = null;\n\n\nshared 和 exclusive 两个单词的意思很明显 ：共享和独占。\n\n 1. 独占模式即当锁被某个线程成功获取时，其他线程无法获取到该锁，同一时间只有一个线程能拿到锁执行，锁的状态只有0和1两种情况。例如 reentrantlock，一次只有一个线程可以工作。\n 2. 共享模式即当锁被某个线程成功获取时，其他线程仍然可能获取到该锁，同一时间有多个线程可以拿到锁协同工作，锁的状态大于或等于0。例如 countdownlatch，一次可以有多个线程工作。\n\n\n# 2.2 同步队列\n\n这个同步队列是由双向链表实现的。从上面所说的可以知道，aqs中的同步队列是由node组成、node中的prev和next连接。\n\n只有节点肯定不行，aqs中有两个属性控制这个双向链表，head 和 tail 。即头和尾。头是一个虚拟节点，它里面的 thread变量 一直是null并不会代表哪个线程；尾是有具体意义的，会代表某一个线程。即：头节点无意义，其他节点都代表一个线程。\n\n\n\n注意喽，同步队列的头节点是无意义的，线程封装的节点不能成为头节点，只能成为头节点后的节点。\n\n\n# 2.3 等待队列\n\nnode组成等待队列，node中的nextwaiter连接成为等待队列。\n\n\n\n奇怪的是，当我在aqs中寻找与管理同步队列的head和tail类似的属性时并没有找到，但我还是找到了管理等待队列的属性：firstwaiter、lastwaiter\n\n它在aqs另一个内部类中 ：conditionobject。\n\n说来也是，就 “等待队列” 这个词而言，等待肯定是它的一大特点。那么如何实现等待？一个是object类中的wait方法，另一个就是 condition 的 await 方法。那么就好解释了：\n\n> conditionobject 提供了让 node 等待的方法，例如 await、signal...通过 node.nextwaiter 将线程串为一个等待队列，并且使用 firstwaiter 和 lastwaiter 控制/管理 等待队列。\n\n注意喽，等待队列的 firstwaiter 可不是无意义的哦，线程封装为 node 后可以成为 firstwaiter\n\n\n# 2.4 state状态值\n\n这是一个非常重要的属性。\n\nprivate volatile int state;\n\n\n毕竟aqs提供的是并发支持，有并发就要有锁，那么一个线程怎样才算拿到锁呢？\n\nstate 不为 0 的时候证明这个锁被占有了。\n\n同时，由于 aqs 并没有要求实现类必须怎样怎样，所以实现类们也把 state 用的花里胡哨，例如：\n\n 1. 在 reentrantlock 中，state 为 0 代表锁还未被占有，如果为 1 代表被占有，如果大于 1 代表重入。\n 2. 在 countdownlatch 中，state 代表着任务数量。\n 3. 在 reentrantreadwritelock 中，将 state 的 32 个字节均分为两部分，一部分表示读锁，一部表示写锁。\n\n\n# 2.5 小结\n\n 1. aqs有两个重要的属性：node和state。\n\n 2. state 是状态值，一般来说代表锁是否被持有，不过具体含义要看实现类如何操作。\n\n 3. 共享和独占 ：共享是允许多个线程共同执行任务，独占是同一时间只允许一个线程执行\n\n 4. node：是线程的代表，线程会被封装为node在aqs中存在。\n    \n    node中有三个属性：next、prev、nextwaiter。\n    \n    * next和prev连接node成为同步队列。控制同步队列的属性 head 和 tail 在aqs中。\n    * nextwaiter连接node成为等待队列。控制等待队列的属性 firstwaiter 和 lastwaiter 在 conditionobject 中（aqs的内部类）\n    * （至于同步队列和等待队列到底有什么用，我想在后续慢慢展开。）\n\n\n\n\n# 3. 线程加锁失败后\n\n在上面说过，aqs 自身并不提供加锁功能，而是实现了加锁失败后的逻辑。这么做有什么好处呢？\n\n程序员可以根据需要进行加锁，比如以下各种锁实现时，想要加锁要满足什么条件：\n\n 1. 不可重入锁 ：锁不被任何线程持有时才能加锁成功\n 2. 可重入锁 ：锁不被任何线程持有，但是如果是自己持有，还可以加锁\n 3. 公平锁 ：线程抢锁之前先看看有没有其他线程正在等待，没有再抢锁，有就跟在他们后面\n 4. 非公平锁 ：管它呢直接抢，抢不到再说\n 5. 读写锁 ：读锁可共享，写锁需排斥。\n\n如果没有 aqs，这些锁在实现的时候都要写一遍 “线程抢锁失败后需要阻塞等待” 的逻辑，代码太冗余了！aqs 大手一挥，我帮你们实现，程序员只要根据现在的情况判断是否抢锁成功就行了，抢锁失败的线程交给我。\n\n那么现在就来看看 aqs 如何对待抢锁失败的线程的吧。\n\naqs 需要它的子类实现的方法是 ：tryacquire()，也就是尝试获取锁，如果获取成功了就没 aqs 要干的事了，但是如果失败，那么就要处理当前线程了：\n\npublic final void acquire(int arg) {\n    // tryacquire让子类去实现\n    // 如果获取锁失败，执行后面的逻辑\n    if (!tryacquire(arg) &&\n        // 将当前线程加入到同步队列中，并且将线程阻塞\n        acquirequeued(addwaiter(node.exclusive), arg))\n        // 阻塞停止后，调用该线程的 interrupt方法\n        selfinterrupt();\n}\n\n\ntryacquire 方法由子类实现，那么现在来看看 addwaiter 与 acquirequeued 这两个方法\n\n 1. addwaiter ：将当前线程封装为 node 并放入同步队列\n 2. acquirequeued ：\n\n\n# 3.1 将当前线程加入同步队列\n\n步骤分为两大步：构建一个 node、放到队列尾部。\n\n你想把一个 node 放到双向链表的尾部，大抵是这三步：\n\ntail.next = node;\nnode.pre = tail;\nnode = tail\n\n\n也就是将链表尾节点的 next 指针指向自己，自己的 pre 指针指向尾节点，最后自己变成了尾节点。\n\n但是放入队列尾部这个动作说得轻巧，问题就出在这里，当多个 node 想要挂在同一个尾节点上时，会出现并发情况。但是我懒得画图了😜\n\naqs 解决并发情况是这样做的 ：先将 node.pre = tail，再使用 cas 将 node 成为尾节点，最后将 node.pre.next = node，如果 cas 失败，说明现在出现并发情况了，别的线程抢先一步将 node 变成了尾节点，此线程的 node 只能挂在那个 node 后面了。\n\n// 调用来源 : addwaiter(node.exclusive)\n// 使用 node.exclusive 作为 mode 的入参，mode为空。\nprivate node addwaiter(node mode) {\n    // 将此线程封装为独占模式的 node\n    node node = new node(thread.currentthread(), mode);\n    // 获取阻塞队列的尾节点\n    node pred = tail;\n   \n    if (pred != null) {\n        // 如果尾节点不为空，把此节点挂在尾节点后面\n        // 首先执行 node.pre = pred\n        node.prev = pred;\n        // 然后使用cas的方式将node设置为尾节点\n        // 如果设置成功，就可以将之前尾节点的next指向现在的尾节点: pred.next = node\n        if (compareandsettail(pred, node)) {\n            pred.next = node;\n            // 一般情况下会在这里return\n            return node;\n        }\n    }\n    // 如果前面没有return，说明什么？\n    // 说明cas失败了，也就是出现了并发设置尾节点的情况，即: 多个线程设置尾节点，这个线程设置失败了。\n    // 虽然失败了，那这个节点可以挂在新来的尾节点上啊~ \n    // 所以这个方法的逻辑就是将此节点挂在新来的尾节点上，就不再详细解释了\n    enq(node);\n    return node;\n}\n\n// 用 cas 将尾节点的值从 expect 换成 update\nprivate final boolean compareandsettail(node expect, node update) {\n    return unsafe.compareandswapobject(this, tailoffset, expect, update);\n}\n\n\n\n# 3.2 将当前线程阻塞\n\n此时，node 已经成为同步队列中的尾节点了，但是线程还没有阻塞，aqs 要做的就是让抢锁失败的线程阻塞，所以这个方法至关重要。\n\n一上来就是死循环，当前节点虽然是尾节点，但是如果它的 pre 是头节点代表啥？代表同步队列中只有它一个线程，那我就得重新抢一下锁了，如果抢失败了我再阻塞。\n\nfinal boolean acquirequeued(final node node, int arg) {\n    boolean failed = true;\n    try {\n        boolean interrupted = false;\n        for (;;) {\n            // 拿到当前节点的前一个节点，\n            // 如果是head节点，可以尝试抢一下锁\n            final node p = node.predecessor();\n            // 如果当前节点的前一个节点是head节点，尝试抢锁\n            if (p == head && tryacquire(arg)) {\n                // 如果抢锁成功，将此节点变成head傀儡节点\n                // sethead() 方法首先会将 node内部的线程置为空，为啥置为空？\n                // 都抢到锁了，这个线程肯定不需要存在于aqs中了。\n                sethead(node);\n                // 之前的head节点置为空，方便gc\n                p.next = null; \n                failed = false;\n                return interrupted;\n            }\n            // 此节点的上一个节点不是头节点，或者抢锁失败，将当前线程 park 起来\n            if (\n                // 检查一下节点的状态，如果已取消就没必要阻塞等待\n                shouldparkafterfailedacquire(p, node) &&\n                // 这个方法将当前线程park起来\n                parkandcheckinterrupt()\n               )\n                interrupted = true;\n        }\n    } finally {\n        if (failed)\n            cancelacquire(node);\n    }\n}\n\n// 将node内部的线程置为空，变成无意义的 head 节点\nprivate void sethead(node node) {\n    head = node;\n    node.thread = null;\n    node.prev = null;\n}\n\n// 将当前线程park起来\nprivate final boolean parkandcheckinterrupt() {\n    // ★ 线程阻塞在此处等待唤醒 \n    locksupport.park(this);\n    // 返回对应线程的中断标志位，并且将中断标志位重置变为false\n    return thread.interrupted();\n}\n\n\n注意 ：当锁被释放时，只会唤醒同步队列中第一个节点，也就是 head.next。（这个会在释放锁的逻辑中说）\n\n当阻塞的线程被唤醒，也就代表此节点是 head.next，那么死循环中的 if 条件就可以走通了，于是此节点会使用 tryacquire 尝试获取锁，如果获取成功就退出循环，如果获取失败就还要阻塞。\n\n\n# 4. 释放锁后\n\naqs当然不会管怎么释放锁，释放锁的逻辑让子类去实现，比如不可重入锁直接释放，可重入锁还要判断一下是否重入。\n\naqs 实现的是之前被阻塞的线程怎么办的逻辑。\n\npublic final boolean release(int arg) {\n    // 释放锁的逻辑让子类实现\n    // 一旦释放成功，aqs就开始唤醒同步队列中的第一个节点\n    if (tryrelease(arg)) {\n        // 拿到头节点\n        node h = head;\n        if (h != null && h.waitstatus != 0)\n            // 唤醒头节点后面那个节点\n            unparksuccessor(h);\n        return true;\n    }\n    return false;\n}\n\n\n不出意外的情况下是直接唤醒 head.next 那个线程，但是不出意外的情况下要出意外了 ：\n\nhead 后的第一个节点为空！或者说它的状态为取消！那么就从同步队列的尾部向前寻找一个有意义的节点将它唤醒，注意只找一个哦。\n\n并且有一个小细节 ：如果node的状态为取消，它不会从同步队列中移除，这个细节在 condition 中会涉及\n\n// 此时传入的node为头节点\nprivate void unparksuccessor(node node) {\n    int ws = node.waitstatus;\n    if (ws < 0)\n        compareandsetwaitstatus(node, ws, 0);\n\t// 拿到头节点后面的第一个节点\n    node s = node.next;\n    // 一般来说不会走这里，而是下面那个if，直接将线程唤醒。\n    // 但是走这里的逻辑是因为啥呢？\n    // waitstatus在上面有讲解，节点的 waitstatus > 0代表此节点已经取消\n    // 所以逻辑就是：如果 head.next 为空或者已经取消，就从同步队列的尾部开始往前寻找，\n    // 直到找到一个没有取消的节点\n    if (s == null || s.waitstatus > 0) {\n        s = null;\n        for (node t = tail; t != null && t != node; t = t.prev)\n            if (t.waitstatus <= 0)\n                s = t;\n    }\n    // 直接将这个线程唤醒了\n    if (s != null)\n        locksupport.unpark(s.thread);\n}\n\n\n步骤 ：拿到头节点后的第一个有意义的节点，如果这个节点的状态为取消，说明这个节点刚从等待队列放到同步队列，跳过它从队列的尾部开始找状态正常的，找到之后将它唤醒\n\n所有线程的执行都阻塞在 acquirequeued 方法内部，这个你可以向上翻，我有说。\n\n\n# 5. condition\n\n可能刚说完 aqs 就说 condition 会有些割裂感，因为很难想象 condition 与 aqs 有啥关系，对，有关系，还记得 aqs 的 node 中有一个成员变量 ：nextwaiter\n\n我在之前说过，aqs 本身的逻辑并没有用到这个变量，而是在 conditionobject 中使用到了，所以 aqs 中第二个队列出现了 ：等待队列\n\n笔记\n\n请你注意等待队列与同步队列的区别。不要将二者混为一谈\n\nstatic final class node {\n    // 此node代表的线程\n    volatile thread thread;\n    // 用于同步队列，此node的前一个结点\n    volatile node prev;\n\t// 用于同步队列，此node的后一个节点\n    volatile node next;\n    // 用于等待队列，等待队列是一个单向链表组成的队列\n    node nextwaiter;\n    // 节点的状态\n    volatile int waitstatus;\n    // 省略其他变量\n}\n\n\n常用的让线程等待的方法有两种 ：\n\n 1. object.wait()\n 2. condition.await()\n\n虽然实现不一样，但是原理是一样的，线程等待的前提肯定是已经拥有锁了，调用 wait 后会释放锁然后阻塞。调用 signal 将线程从等待状态唤醒，进入阻塞状态，可以抢锁。\n\n\n# 5.1 condition.await()\n\n如果是你，你会如何借助 aqs 来实现 condition.await() 呢？不就是释放锁之后阻塞嘛~\n\n 1. 将此线程封装为 node 并放入等待队列\n 2. 调用 aqs 的 release 释放锁\n 3. 将当前线程阻塞\n\n对，就是这三步，来看看 aqs 中的 conditionobject 如何实现这三步的 ：\n\npublic final void await() throws interruptedexception {\n    if (thread.interrupted())\n        throw new interruptedexception();\n    // 将当前线程封装为node，node的状态为-2，也就是等待，然后放入等待队列\n    // 这时会将 node.waitstatus 改为 condition\n    node node = addconditionwaiter();\n    // 调用 release 方法释放锁\n    // 这时会将 node.waitstatus 改为 cancelled ★ 这里特别重要！！！！！\n    // 再次强调，这里会将 node.waitstatus 改为 cancelled \n    int savedstate = fullyrelease(node);\n    int interruptmode = 0;\n    // 判断 node 节点的状态\n    // 第一次进入时都会返回false，取反后会进入方法将线程阻塞\n    while (!isonsyncqueue(node)) {\n        locksupport.park(this);\n        if ((interruptmode = checkinterruptwhilewaiting(node)) != 0)\n            break;\n    }\n    // 线程从等待状态恢复后，进入同步队列等待抢锁，这里的逻辑就是上面说过了的。\n    if (acquirequeued(node, savedstate) && interruptmode != throw_ie)\n        interruptmode = reinterrupt;\n    if (node.nextwaiter != null) // clean up if cancelled\n        unlinkcancelledwaiters();\n    if (interruptmode != 0)\n        reportinterruptafterwait(interruptmode);\n}\n\n\n\n# 5.2 condition.signal()\n\n如果是你，你会如何借助 aqs 来实现 condition.signal() 呢？不就是唤醒锁、把它加入同步队列嘛~\n\ncondition.signal() 会唤醒在等待队列中等待时间最长的节点（首节点）\n\n// 传入的是等待队列的头节点（线程是可以成为头节点的）\nprivate void dosignal(node first) {\n    do {\n        // 一般不会走这里\n        if ( (firstwaiter = first.nextwaiter) == null)\n            lastwaiter = null;\n        // 将头节点的next指针置为空\n        first.nextwaiter = null;\n    } while (!transferforsignal(first) &&\n             (first = firstwaiter) != null);\n}\n\n\nfinal boolean transferforsignal(node node) {\n    if (!compareandsetwaitstatus(node, node.condition, 0))\n        return false;\n    // 将该节点加入同步队列尾部\n    node p = enq(node);\n    // 刚刚在 await方法中，我特别强调了，fullyrelease 方法会将节点的状态改为取消\n    // 也就是 node.waitstatus = 1, 即 ws = 1\n    int ws = p.waitstatus;\n    if (ws > 0 || !compareandsetwaitstatus(p, ws, node.signal))\n        locksupport.unpark(node.thread);\n    return true;\n}\n\n\n思考 ：为啥调用 await() 方法让线程释放锁后，线程 node 的状态会变成取消（node.waitstatus = 1）呢？\n\n因为 signal 方法的步骤为 ：\n\n 1. 将 node 放入同步队列\n 2. 将线程唤醒\n\n将 node 放入同步队列后，万一被唤醒了怎么办？那就要通过一些手段防止这种概率特别小的情况出现，也就是线程调用 await() 进入等待之前先将 node 的状态变成 取消，那么就不会被误唤醒！真叼啊。\n\ncondition 的 singalall 方法，相当于对等待队列的每个节点均执行一次 singal 方法，效果就是将等待队列中所有节点全部移动到同步队列，并唤醒每个节点的线程。\n\n\n# 5. 总结\n\n至此，aqs 的核心功能已经说完了，没有讲加锁、释放锁？因为加锁、释放锁的逻辑本来就不是 aqs 要完成的呀。\n\n所以加锁与释放锁我会在 reentrantlock、countdownlatch、readwritelock 中讲。",charsets:{cjk:!0},lastUpdated:"2024/02/28, 21:50:33",lastUpdatedTimestamp:1709128233e3},{title:"ReentrantReadWriteLock 源码解析",frontmatter:{title:"ReentrantReadWriteLock 源码解析",date:"2023-12-22T16:33:45.000Z",permalink:"/pages/6cfda5/"},regularPath:"/02.%E6%96%87%E7%AB%A0/75.Java%E5%B9%B6%E5%8F%91/70.ReentrantReadWriteLock.html",relativePath:"02.文章/75.Java并发/70.ReentrantReadWriteLock.md",key:"v-b5de3650",path:"/pages/6cfda5/",headers:[{level:2,title:"1. 简述",slug:"_1-简述",normalizedTitle:"1. 简述",charIndex:2},{level:2,title:"2. 类结构",slug:"_2-类结构",normalizedTitle:"2. 类结构",charIndex:971},{level:2,title:"3. 读写锁需要的变量",slug:"_3-读写锁需要的变量",normalizedTitle:"3. 读写锁需要的变量",charIndex:1158},{level:2,title:"4. 加写锁",slug:"_4-加写锁",normalizedTitle:"4. 加写锁",charIndex:2271},{level:2,title:"5. 加读锁",slug:"_5-加读锁",normalizedTitle:"5. 加读锁",charIndex:3348}],headersStr:"1. 简述 2. 类结构 3. 读写锁需要的变量 4. 加写锁 5. 加读锁",content:'# 1. 简述\n\n前面已经介绍了 AQS、ReentrantLock 的实现 ：\n\n * AQS ：\n * ReentrantLock\n\n本篇文章会介绍 ReentrantReadWriteLock（可重入读写锁），从名字可以看出来，这个锁实现了 ReentrantLock + ReadWriteLock 的功能，也就是不仅可以重入、公平、非公平，还提供了读锁、写锁。\n\n在一般情况下，ReentrantReadWriteLock 跟 ReentrantLock 的功能一样，都只提供 可重入、公平锁、非公平锁。、\n\n但是 ReentrantReadWriteLock 也提供了 读锁、写锁，不过需要显式获取读、写锁。\n\n// 创建读写锁，这个锁的功能跟 ReentrantLock 一样\nfinal ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();\n// 获得读锁\nfinal ReentrantReadWriteLock.ReadLock readLock = readWriteLock.readLock();\n// 获得写锁\nfinal ReentrantReadWriteLock.WriteLock writeLock = readWriteLock.writeLock();\n\n// 读锁使用\nreadLock.lock();\ntry {\n    // 业务代码...\n} finally {\n    readLock.unlock();\n}\n\n// 写锁使用\nwriteLock.lock();\ntry {\n    // 业务代码...\n} finally {\n    writeLock.unlock();\n}\n\n\n什么叫做读写锁？\n\n * 读锁 ：多给线程可以共享读锁，加了读锁不能再加写锁，但是还可以加读锁\n * 写锁 ：写锁独占，只要有一个写锁，就不能存在其他任何锁。\n\n也就是 读共享，写独占。并且 ReentrantReadWriteLock 实现了锁降级 ：获取写锁后，可以在释放写锁前获取读锁，实现了无缝衔接。\n\n实现锁降级有啥好处呢？锁降级是释放写锁前加读锁，也就是此线程想要获取本线程修改之后的最新的数据。\n\n\n# 2. 类结构\n\n按照惯例，加锁逻辑仍然是锁内部的各个 Sync 实现的。公平于非公平锁就不说了，这里只介绍读锁与写锁。\n\n * Sync ：内部包含读写锁的实现以及实现读写锁需要的变量\n * ReadLock ：调用 Sync 内的 tryReadLock 尝试获取读锁。\n * WriteLock ：调用 Sync 内的 tryWriteLock 尝试获取写锁。\n\n\n# 3. 读写锁需要的变量\n\n实现读写锁需要的便令都在 Sync 类中，当然了，最重要的还得是 AQS 中的 state。\n\n在 ReentrantLock 中，state 表示重入了几次，在读写锁中也用这个变量，不过将它分成两半，因为 state 有 32 个二进制位，所以读锁、写锁每人一半 ：\n\n * state 的高16位 ：表示读锁 ，表示有 1 ~ n 个读锁\n * state 的低16位 ：表示写锁，只能由一个线程占有，可以重入\n\n//读 写 锁分界点\nstatic final int SHARED_SHIFT   = 16;\n//读锁最小单位，刚好表示当前拥有一个读锁线程\n// 00000000 00000001 00000000 00000000\nstatic final int SHARED_UNIT    = (1 << SHARED_SHIFT);\n\n// 支持最大读取次数\nstatic final int MAX_COUNT      = (1 << SHARED_SHIFT) - 1;\n\n// 写锁掩码\n// 00000000 00000000 11111111 11111111\n// 计算时很方便，state &  EXCLUSIVE_MASK 就可以得到写锁数量\nstatic final int EXCLUSIVE_MASK = (1 << SHARED_SHIFT) - 1;\n\n\nstate 的高十六位表示读线程数量，那么怎么表示每一个线程重入了多少次呢？那就只能存储在各个线程里面，哪个工具可以实现线程私有变量呢？ThreadLocal\n\nstatic final class ThreadLocalHoldCounter\n    extends ThreadLocal<HoldCounter> {\n    public HoldCounter initialValue() {\n        return new HoldCounter();\n    }\n}\n\nstatic final class HoldCounter {\n    int count = 0;\n    final long tid = getThreadId(Thread.currentThread());\n}\n\n\n每一个线程都有一个 HoldCounter，每一个 HoldCounter 中都记录着线程 id 与 该线程获取了多少次读锁。\n\n写锁重入怎么表示呢？正常用 state 表示呀，写锁只能有一个线程占有，那么 state 的低16位就可以表示当前抢占写锁线程的重入次数了。\n\n\n# 4. 加写锁\n\n加写锁的逻辑相对简单，由于写锁与读锁不能共存，先判断有没有其他线程占据 读/写锁，没有就加，有就等待。\n\n * state != 0 && 读锁 == 0 ：说明有线程占据了写锁，看看是不是自己，如果是自己可以重入\n * state != 0 && 写锁 == 0 ：说明有线程占据了读锁，读锁与写锁不能共存，并且不支持读锁升级为写锁。\n\nfinal boolean tryWriteLock() {\n    // 获取当前线程\n    Thread current = Thread.currentThread();\n    // 获取 AQS 中的状态\n    int c = getState();\n    // 如果c != 0，说明要么写锁被占据，要么读锁被占据\n    // 如果是自己占据了写锁，那就可以重入\n    if (c != 0) {\n        // 获取写锁是否被重入，如果w == 0，说明写锁没有被占据\n        // c != 0 并且 w == 0 说明没有别的线程占据写锁，只占据了读锁\n        // 如果 w != 0，说明写锁被占据了，那就看看是不是自己，如果是自己就可以重入\n        int w = exclusiveCount(c);\n        if (w == 0 || current != getExclusiveOwnerThread())\n            return false;\n        if (w == MAX_COUNT)\n            throw new Error("Maximum lock count exceeded");\n    }\n    // 如果 c == 0，说明锁没有被抢，可以尝试抢锁\n    if (!compareAndSetState(c, c + 1))\n        // 抢锁失败返回false\n        return false;\n    // 抢锁成功，将独占线程变成自己，返回 true\n    setExclusiveOwnerThread(current);\n    return true;\n}\n\nstatic int exclusiveCount(int c) { \n    return c & EXCLUSIVE_MASK; \n}\n\n\nReentrantReadWriteLock 不支持读锁升级为写锁，所以在加写锁时不需要判断之前有没有读锁。\n\n\n# 5. 加读锁\n\nReentrantReadWriteLock 加读锁的过程比较复杂，因为支持锁的降级，即支持已经拥有写锁的情况下再去获取读锁。所以在加读锁的时候，判断条件就多一点。\n\nfinal boolean tryReadLock() {\n    // 获取当前线程\n    Thread current = Thread.currentThread();\n    // 死循环\n    for (;;) {\n        // 获取 AQS 的当前状态\n        int c = getState();\n        // 如果现在已经有写锁，并且拿到写锁的不是自己，那就不能加读锁\n        // 如果是自己，说明要进行锁降级\n        if (exclusiveCount(c) != 0 &&\n            getExclusiveOwnerThread() != current)\n            return false;\n        // 获取读锁的线程的数量，太多了就不让获取了\n        int r = sharedCount(c);\n        if (r == MAX_COUNT)\n            throw new Error("Maximum lock count exceeded");\n        // 到这里就是获取共享读锁的过程\n        if (compareAndSetState(c, c + SHARED_UNIT)) {\n            // 记录第一个拥有读锁的线程\n            if (r == 0) {\n                firstReader = current;\n                firstReaderHoldCount = 1;\n            } else if (firstReader == current) {\n                firstReaderHoldCount++;\n            } else {\n                // 当前线程的 HoldCounter.count ++ \n                HoldCounter rh = cachedHoldCounter;\n                if (rh == null || rh.tid != getThreadId(current))\n                    cachedHoldCounter = rh = readHolds.get();\n                else if (rh.count == 0)\n                    readHolds.set(rh);\n                rh.count++;\n            }\n            return true;\n        }\n    }\n}\n',normalizedContent:'# 1. 简述\n\n前面已经介绍了 aqs、reentrantlock 的实现 ：\n\n * aqs ：\n * reentrantlock\n\n本篇文章会介绍 reentrantreadwritelock（可重入读写锁），从名字可以看出来，这个锁实现了 reentrantlock + readwritelock 的功能，也就是不仅可以重入、公平、非公平，还提供了读锁、写锁。\n\n在一般情况下，reentrantreadwritelock 跟 reentrantlock 的功能一样，都只提供 可重入、公平锁、非公平锁。、\n\n但是 reentrantreadwritelock 也提供了 读锁、写锁，不过需要显式获取读、写锁。\n\n// 创建读写锁，这个锁的功能跟 reentrantlock 一样\nfinal reentrantreadwritelock readwritelock = new reentrantreadwritelock();\n// 获得读锁\nfinal reentrantreadwritelock.readlock readlock = readwritelock.readlock();\n// 获得写锁\nfinal reentrantreadwritelock.writelock writelock = readwritelock.writelock();\n\n// 读锁使用\nreadlock.lock();\ntry {\n    // 业务代码...\n} finally {\n    readlock.unlock();\n}\n\n// 写锁使用\nwritelock.lock();\ntry {\n    // 业务代码...\n} finally {\n    writelock.unlock();\n}\n\n\n什么叫做读写锁？\n\n * 读锁 ：多给线程可以共享读锁，加了读锁不能再加写锁，但是还可以加读锁\n * 写锁 ：写锁独占，只要有一个写锁，就不能存在其他任何锁。\n\n也就是 读共享，写独占。并且 reentrantreadwritelock 实现了锁降级 ：获取写锁后，可以在释放写锁前获取读锁，实现了无缝衔接。\n\n实现锁降级有啥好处呢？锁降级是释放写锁前加读锁，也就是此线程想要获取本线程修改之后的最新的数据。\n\n\n# 2. 类结构\n\n按照惯例，加锁逻辑仍然是锁内部的各个 sync 实现的。公平于非公平锁就不说了，这里只介绍读锁与写锁。\n\n * sync ：内部包含读写锁的实现以及实现读写锁需要的变量\n * readlock ：调用 sync 内的 tryreadlock 尝试获取读锁。\n * writelock ：调用 sync 内的 trywritelock 尝试获取写锁。\n\n\n# 3. 读写锁需要的变量\n\n实现读写锁需要的便令都在 sync 类中，当然了，最重要的还得是 aqs 中的 state。\n\n在 reentrantlock 中，state 表示重入了几次，在读写锁中也用这个变量，不过将它分成两半，因为 state 有 32 个二进制位，所以读锁、写锁每人一半 ：\n\n * state 的高16位 ：表示读锁 ，表示有 1 ~ n 个读锁\n * state 的低16位 ：表示写锁，只能由一个线程占有，可以重入\n\n//读 写 锁分界点\nstatic final int shared_shift   = 16;\n//读锁最小单位，刚好表示当前拥有一个读锁线程\n// 00000000 00000001 00000000 00000000\nstatic final int shared_unit    = (1 << shared_shift);\n\n// 支持最大读取次数\nstatic final int max_count      = (1 << shared_shift) - 1;\n\n// 写锁掩码\n// 00000000 00000000 11111111 11111111\n// 计算时很方便，state &  exclusive_mask 就可以得到写锁数量\nstatic final int exclusive_mask = (1 << shared_shift) - 1;\n\n\nstate 的高十六位表示读线程数量，那么怎么表示每一个线程重入了多少次呢？那就只能存储在各个线程里面，哪个工具可以实现线程私有变量呢？threadlocal\n\nstatic final class threadlocalholdcounter\n    extends threadlocal<holdcounter> {\n    public holdcounter initialvalue() {\n        return new holdcounter();\n    }\n}\n\nstatic final class holdcounter {\n    int count = 0;\n    final long tid = getthreadid(thread.currentthread());\n}\n\n\n每一个线程都有一个 holdcounter，每一个 holdcounter 中都记录着线程 id 与 该线程获取了多少次读锁。\n\n写锁重入怎么表示呢？正常用 state 表示呀，写锁只能有一个线程占有，那么 state 的低16位就可以表示当前抢占写锁线程的重入次数了。\n\n\n# 4. 加写锁\n\n加写锁的逻辑相对简单，由于写锁与读锁不能共存，先判断有没有其他线程占据 读/写锁，没有就加，有就等待。\n\n * state != 0 && 读锁 == 0 ：说明有线程占据了写锁，看看是不是自己，如果是自己可以重入\n * state != 0 && 写锁 == 0 ：说明有线程占据了读锁，读锁与写锁不能共存，并且不支持读锁升级为写锁。\n\nfinal boolean trywritelock() {\n    // 获取当前线程\n    thread current = thread.currentthread();\n    // 获取 aqs 中的状态\n    int c = getstate();\n    // 如果c != 0，说明要么写锁被占据，要么读锁被占据\n    // 如果是自己占据了写锁，那就可以重入\n    if (c != 0) {\n        // 获取写锁是否被重入，如果w == 0，说明写锁没有被占据\n        // c != 0 并且 w == 0 说明没有别的线程占据写锁，只占据了读锁\n        // 如果 w != 0，说明写锁被占据了，那就看看是不是自己，如果是自己就可以重入\n        int w = exclusivecount(c);\n        if (w == 0 || current != getexclusiveownerthread())\n            return false;\n        if (w == max_count)\n            throw new error("maximum lock count exceeded");\n    }\n    // 如果 c == 0，说明锁没有被抢，可以尝试抢锁\n    if (!compareandsetstate(c, c + 1))\n        // 抢锁失败返回false\n        return false;\n    // 抢锁成功，将独占线程变成自己，返回 true\n    setexclusiveownerthread(current);\n    return true;\n}\n\nstatic int exclusivecount(int c) { \n    return c & exclusive_mask; \n}\n\n\nreentrantreadwritelock 不支持读锁升级为写锁，所以在加写锁时不需要判断之前有没有读锁。\n\n\n# 5. 加读锁\n\nreentrantreadwritelock 加读锁的过程比较复杂，因为支持锁的降级，即支持已经拥有写锁的情况下再去获取读锁。所以在加读锁的时候，判断条件就多一点。\n\nfinal boolean tryreadlock() {\n    // 获取当前线程\n    thread current = thread.currentthread();\n    // 死循环\n    for (;;) {\n        // 获取 aqs 的当前状态\n        int c = getstate();\n        // 如果现在已经有写锁，并且拿到写锁的不是自己，那就不能加读锁\n        // 如果是自己，说明要进行锁降级\n        if (exclusivecount(c) != 0 &&\n            getexclusiveownerthread() != current)\n            return false;\n        // 获取读锁的线程的数量，太多了就不让获取了\n        int r = sharedcount(c);\n        if (r == max_count)\n            throw new error("maximum lock count exceeded");\n        // 到这里就是获取共享读锁的过程\n        if (compareandsetstate(c, c + shared_unit)) {\n            // 记录第一个拥有读锁的线程\n            if (r == 0) {\n                firstreader = current;\n                firstreaderholdcount = 1;\n            } else if (firstreader == current) {\n                firstreaderholdcount++;\n            } else {\n                // 当前线程的 holdcounter.count ++ \n                holdcounter rh = cachedholdcounter;\n                if (rh == null || rh.tid != getthreadid(current))\n                    cachedholdcounter = rh = readholds.get();\n                else if (rh.count == 0)\n                    readholds.set(rh);\n                rh.count++;\n            }\n            return true;\n        }\n    }\n}\n',charsets:{cjk:!0},lastUpdated:"2024/02/28, 21:50:33",lastUpdatedTimestamp:1709128233e3},{title:"ReentrantLock 源码解析",frontmatter:{title:"ReentrantLock 源码解析",date:"2023-12-22T13:21:37.000Z",permalink:"/pages/5031c2/"},regularPath:"/02.%E6%96%87%E7%AB%A0/75.Java%E5%B9%B6%E5%8F%91/65.ReentrantLock.html",relativePath:"02.文章/75.Java并发/65.ReentrantLock.md",key:"v-ff4b2134",path:"/pages/5031c2/",headers:[{level:2,title:"1. 前言",slug:"_1-前言",normalizedTitle:"1. 前言",charIndex:2},{level:2,title:"2. 类结构",slug:"_2-类结构",normalizedTitle:"2. 类结构",charIndex:309},{level:2,title:"3. 非公平锁",slug:"_3-非公平锁",normalizedTitle:"3. 非公平锁",charIndex:666},{level:2,title:"4. 公平锁",slug:"_4-公平锁",normalizedTitle:"4. 公平锁",charIndex:1727},{level:2,title:"5. 释放锁",slug:"_5-释放锁",normalizedTitle:"5. 释放锁",charIndex:2635},{level:2,title:"6. 总结",slug:"_6-总结",normalizedTitle:"6. 总结",charIndex:3246}],headersStr:"1. 前言 2. 类结构 3. 非公平锁 4. 公平锁 5. 释放锁 6. 总结",content:'# 1. 前言\n\n阅读前请先阅读 ：AQS源码解析\n\n在上篇文章中介绍了 AQS 提供的功能 ：\n\n 1. 加锁失败后，线程被封装为 Node 放入同步队列，然后阻塞\n 2. 释放锁后，优先唤醒同步队列中的第一个线程，如果该线程的状态为已取消，从同步队列的尾部向前找到正常节点并唤醒它。\n\n同时，为了讲解上述功能的实现方式，文章中还介绍了 AQS 的变量，如果只是想实现不同种类的锁，那么只需要这些变量 ：\n\n 1. state\n 2. 同步队列\n\nReentrantLock 是非常常用的可重入锁，并且实现了公平、非公平的加锁方式，接下来看看它是如何根据 AQS 提供的功能实现的 可重入、公平、非公平吧。\n\n\n# 2. 类结构\n\n在上文中介绍过，不同的锁在实现 “加锁” 这个功能时，它并不会自己实现，而是在内部类 Sync 中实现加锁逻辑。\n\nReentrantLock 一共有三个 Sync 类型的内部类 ：\n\n * Sync ：内部包含非公平锁的实现 nonfairTryAcquire，提供抽象方法 lock 进行加锁\n * NonfairSync ：非公平锁，继承于 Sync。自己内部没有实现非公平的加锁逻辑，而是直接调用父类 Sync 的非公平加锁逻辑。\n * FairSync ：公平锁，继承于 Sync\n\n看名字就知道是啥意思了，继承关系如下 ：\n\n           Sync\n         /     \\\n       /        \\\nNonfairSync    FairSync\n\n\n\n# 3. 非公平锁\n\n如刚才所述，非公平锁作为 ReentrantLock 的默认功能，由 Sync 实现，NonfairSync 继承后可以直接调用。\n\n在 Sync 中，非公平方法的名字为 nonfairTryAcquire ：\n\nfinal boolean nonfairTryAcquire(int acquires) {\n    // 获取当前线程\n    final Thread current = Thread.currentThread();\n    // 获取 AQS 中的 state 状态变量\n    int c = getState();\n    // 如果状态变量为0，说明没有线程拥有锁，直接尝试加锁\n    if (c == 0) {\n        if (compareAndSetState(0, acquires)) {\n            // 如果加锁成功，将锁当前的拥有者改为自己\n            setExclusiveOwnerThread(current);\n            // 返回加锁成功\n            return true;\n        }\n    }\n    // 如果 c != 0，说明锁已经被人占有了。\n    // 但是如果占有这个锁的是自己，那么可以进行重入\n    else if (current == getExclusiveOwnerThread()) {\n        // 重入次数+1\n        int nextc = c + acquires;\n        if (nextc < 0) // overflow\n            throw new Error("Maximum lock count exceeded");\n        // state = nextc\n        setState(nextc);\n        // 返回加锁成功\n        return true;\n    }\n    // 否则返回加锁失败，返回false后，开始执行 AQS 提供的将锁阻塞的步骤\n    return false;\n}\n\n\n在并发情况下，AQS 中的同步队列可能还有很多等待抢锁的线程，但是非公平之所以叫做非公平，是因为它一上来先抢锁，我可不管你有多少线程在等待。\n\n别人都在排队，我上去直接尝试服务员会不会先服务我。如果人家不服务我，我再排队嘛~\n\n\n# 4. 公平锁\n\n公平锁的逻辑在 ReentrantLock.FairSync 中实现 ：\n\n非公平锁是直接抢锁，公平锁就比较有素质了，它先看现在有没有人正在排队，如果有排队的，那我也去排队。\n\nprotected final boolean tryAcquire(int acquires) {\n    // 获取当前线程\n    final Thread current = Thread.currentThread();\n    // 获取 AQS 中的 state 状态变量\n    int c = getState();\n    // state == 0，说明能抢锁，但是公平锁是有素质的\n    if (c == 0) {\n        // 先查看 AQS 的同步队列中是否有其他线程正在排队\n        // 如果有，直接退出，我也去排队\n        // 如果没有，CAS 获取锁，获取锁成功就将独占线程设置为自己，然后返回true\n        if (!hasQueuedPredecessors() &&\n            compareAndSetState(0, acquires)) {\n            setExclusiveOwnerThread(current);\n            return true;\n        }\n    }\n    // 这个跟刚才的步骤是一样的，不再赘述\n    else if (current == getExclusiveOwnerThread()) {\n        int nextc = c + acquires;\n        if (nextc < 0)\n            throw new Error("Maximum lock count exceeded");\n        setState(nextc);\n        return true;\n    }\n    // 抢锁失败返回 false，执行 AQS 的逻辑\n    return false;\n}\n\n\n\n# 5. 释放锁\n\n再来看看 Sync、NonfairSync、FairSync 的结构图：\n\n你能在 NonfairSync、FairSync 中找到释放锁的代码吗？\n\n没有，它们都用 Sync 的释放锁逻辑 ：tryRelease\n\n所以公平锁于非公平锁的释放锁逻辑是一样的，都是可重入锁的步骤，如果没有重入，直接释放，如果重入了，将 state - 1\n\nprotected final boolean tryRelease(int releases) {\n    int c = getState() - releases;\n    if (Thread.currentThread() != getExclusiveOwnerThread())\n        throw new IllegalMonitorStateException();\n    boolean free = false;\n    // state - 1 之后如果是0，证明没有重入，直接释放\n    // 如果不为0，不能释放锁\n    if (c == 0) {\n        free = true;\n        setExclusiveOwnerThread(null);\n    }\n    setState(c);\n    // 释放锁成功/失败。如果重入就是释放锁失败。\n    return free;\n}\n\n\n\n# 6. 总结\n\n本篇文章虽然介绍了可重入、公平、非公平的实现，但是并没有举例子、画图啥的，因为画图太麻烦了。如果你想看举例子，我推荐一个博客 ：https://github.com/crisxuan/bestJavaer/blob/master/java-concurrent/java-aqs.md',normalizedContent:'# 1. 前言\n\n阅读前请先阅读 ：aqs源码解析\n\n在上篇文章中介绍了 aqs 提供的功能 ：\n\n 1. 加锁失败后，线程被封装为 node 放入同步队列，然后阻塞\n 2. 释放锁后，优先唤醒同步队列中的第一个线程，如果该线程的状态为已取消，从同步队列的尾部向前找到正常节点并唤醒它。\n\n同时，为了讲解上述功能的实现方式，文章中还介绍了 aqs 的变量，如果只是想实现不同种类的锁，那么只需要这些变量 ：\n\n 1. state\n 2. 同步队列\n\nreentrantlock 是非常常用的可重入锁，并且实现了公平、非公平的加锁方式，接下来看看它是如何根据 aqs 提供的功能实现的 可重入、公平、非公平吧。\n\n\n# 2. 类结构\n\n在上文中介绍过，不同的锁在实现 “加锁” 这个功能时，它并不会自己实现，而是在内部类 sync 中实现加锁逻辑。\n\nreentrantlock 一共有三个 sync 类型的内部类 ：\n\n * sync ：内部包含非公平锁的实现 nonfairtryacquire，提供抽象方法 lock 进行加锁\n * nonfairsync ：非公平锁，继承于 sync。自己内部没有实现非公平的加锁逻辑，而是直接调用父类 sync 的非公平加锁逻辑。\n * fairsync ：公平锁，继承于 sync\n\n看名字就知道是啥意思了，继承关系如下 ：\n\n           sync\n         /     \\\n       /        \\\nnonfairsync    fairsync\n\n\n\n# 3. 非公平锁\n\n如刚才所述，非公平锁作为 reentrantlock 的默认功能，由 sync 实现，nonfairsync 继承后可以直接调用。\n\n在 sync 中，非公平方法的名字为 nonfairtryacquire ：\n\nfinal boolean nonfairtryacquire(int acquires) {\n    // 获取当前线程\n    final thread current = thread.currentthread();\n    // 获取 aqs 中的 state 状态变量\n    int c = getstate();\n    // 如果状态变量为0，说明没有线程拥有锁，直接尝试加锁\n    if (c == 0) {\n        if (compareandsetstate(0, acquires)) {\n            // 如果加锁成功，将锁当前的拥有者改为自己\n            setexclusiveownerthread(current);\n            // 返回加锁成功\n            return true;\n        }\n    }\n    // 如果 c != 0，说明锁已经被人占有了。\n    // 但是如果占有这个锁的是自己，那么可以进行重入\n    else if (current == getexclusiveownerthread()) {\n        // 重入次数+1\n        int nextc = c + acquires;\n        if (nextc < 0) // overflow\n            throw new error("maximum lock count exceeded");\n        // state = nextc\n        setstate(nextc);\n        // 返回加锁成功\n        return true;\n    }\n    // 否则返回加锁失败，返回false后，开始执行 aqs 提供的将锁阻塞的步骤\n    return false;\n}\n\n\n在并发情况下，aqs 中的同步队列可能还有很多等待抢锁的线程，但是非公平之所以叫做非公平，是因为它一上来先抢锁，我可不管你有多少线程在等待。\n\n别人都在排队，我上去直接尝试服务员会不会先服务我。如果人家不服务我，我再排队嘛~\n\n\n# 4. 公平锁\n\n公平锁的逻辑在 reentrantlock.fairsync 中实现 ：\n\n非公平锁是直接抢锁，公平锁就比较有素质了，它先看现在有没有人正在排队，如果有排队的，那我也去排队。\n\nprotected final boolean tryacquire(int acquires) {\n    // 获取当前线程\n    final thread current = thread.currentthread();\n    // 获取 aqs 中的 state 状态变量\n    int c = getstate();\n    // state == 0，说明能抢锁，但是公平锁是有素质的\n    if (c == 0) {\n        // 先查看 aqs 的同步队列中是否有其他线程正在排队\n        // 如果有，直接退出，我也去排队\n        // 如果没有，cas 获取锁，获取锁成功就将独占线程设置为自己，然后返回true\n        if (!hasqueuedpredecessors() &&\n            compareandsetstate(0, acquires)) {\n            setexclusiveownerthread(current);\n            return true;\n        }\n    }\n    // 这个跟刚才的步骤是一样的，不再赘述\n    else if (current == getexclusiveownerthread()) {\n        int nextc = c + acquires;\n        if (nextc < 0)\n            throw new error("maximum lock count exceeded");\n        setstate(nextc);\n        return true;\n    }\n    // 抢锁失败返回 false，执行 aqs 的逻辑\n    return false;\n}\n\n\n\n# 5. 释放锁\n\n再来看看 sync、nonfairsync、fairsync 的结构图：\n\n你能在 nonfairsync、fairsync 中找到释放锁的代码吗？\n\n没有，它们都用 sync 的释放锁逻辑 ：tryrelease\n\n所以公平锁于非公平锁的释放锁逻辑是一样的，都是可重入锁的步骤，如果没有重入，直接释放，如果重入了，将 state - 1\n\nprotected final boolean tryrelease(int releases) {\n    int c = getstate() - releases;\n    if (thread.currentthread() != getexclusiveownerthread())\n        throw new illegalmonitorstateexception();\n    boolean free = false;\n    // state - 1 之后如果是0，证明没有重入，直接释放\n    // 如果不为0，不能释放锁\n    if (c == 0) {\n        free = true;\n        setexclusiveownerthread(null);\n    }\n    setstate(c);\n    // 释放锁成功/失败。如果重入就是释放锁失败。\n    return free;\n}\n\n\n\n# 6. 总结\n\n本篇文章虽然介绍了可重入、公平、非公平的实现，但是并没有举例子、画图啥的，因为画图太麻烦了。如果你想看举例子，我推荐一个博客 ：https://github.com/crisxuan/bestjavaer/blob/master/java-concurrent/java-aqs.md',charsets:{cjk:!0},lastUpdated:"2024/02/28, 21:50:33",lastUpdatedTimestamp:1709128233e3},{title:"负载均衡算法",frontmatter:{title:"负载均衡算法",date:"2023-07-28T15:52:31.000Z",permalink:"/pages/97a05f/"},regularPath:"/02.%E6%96%87%E7%AB%A0/85.%E7%AE%97%E6%B3%95/1.%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95.html",relativePath:"02.文章/85.算法/1.负载均衡算法.md",key:"v-68f17928",path:"/pages/97a05f/",headers:[{level:2,title:"0. 简述",slug:"_0-简述",normalizedTitle:"0. 简述",charIndex:2},{level:2,title:"1. 轮询法",slug:"_1-轮询法",normalizedTitle:"1. 轮询法",charIndex:113},{level:2,title:"2. 加权轮询法",slug:"_2-加权轮询法",normalizedTitle:"2. 加权轮询法",charIndex:1478},{level:2,title:"3. 随机法",slug:"_3-随机法",normalizedTitle:"3. 随机法",charIndex:3144},{level:2,title:"4. 加权随机法",slug:"_4-加权随机法",normalizedTitle:"4. 加权随机法",charIndex:4414},{level:2,title:"5. 源地址哈希法",slug:"_5-源地址哈希法",normalizedTitle:"5. 源地址哈希法",charIndex:6016}],headersStr:"0. 简述 1. 轮询法 2. 加权轮询法 3. 随机法 4. 加权随机法 5. 源地址哈希法",content:'# 0. 简述\n\n什么是负载均衡算法？\n\n在分布式系统下，我们可能会将同一个服务启动多次形成集群，那么这个集群中的多台机器将会如何分配海量请求时？\n\n负载均衡算法就是以某种算法的形式将这些请求分配给不同的机器/实例。\n\n\n# 1. 轮询法\n\n将请求顺序轮流地分配到不同的实例上。 如果将服务器实例放到一个 List 中，轮询法的作用就是按照顺序遍历 List。\n\nimport java.util.*; \nimport java.util.concurrent.ConcurrentHashMap; \n\npublic  class TestRoundRobin {  \n    // 假设这些IP就是服务地址，那么要做的就是将请求分配到IP上。\n    static Map<String,Integer> ipMap= new HashMap<>(); \n    static { \n        ipMap.put("192.168.13.1",1); \n        ipMap.put("192.168.13.2",1); \n        ipMap.put("192.168.13.3",1); \n    } \n\n    Integer  pos = 0; \n    public String RoundRobin(){ \n        Map<String,Integer> ipServerMap = new ConcurrentHashMap<>(); \n        ipServerMap.putAll(ipMap); \n        \n        // 2.取出来key,也就是IP地址，放到set中 \n        Set<String> ipset = ipServerMap.keySet(); \n        // 3.set放到list，要循环list取出 \n        ArrayList<String> iplist = new ArrayList<String>(); \n        iplist.addAll(ipset); \n        String serverName = null; \n        // 4.定义一个循环的值，如果大于set就从0开始 \n        synchronized(pos){ \n            if (pos >= ipset.size()){ \n                pos=0; \n            } \n            serverName = iplist.get(pos); \n            //轮询+1 \n            pos ++; \n        } \n        return serverName; \n    } \n    public  static  void main(String[] args) { \n        TestRoundRobin testRoundRobin=new TestRoundRobin(); \n        for ( int i=0;i<10;i++){ \n            String serverIp = testRoundRobin.RoundRobin(); \n            System.out.println(serverIp); \n        } \n    } \n} \n\n\n\n# 2. 加权轮询法\n\n不同服务器的配置可能有区别，2核4G的服务器跟1核2G的服务器能处理的请求数量肯定不同。我们要尽量将请求多分配到配置好的服务器上。\n\n简单实现一下加权轮询 ：假如权重是 n ，那么一次循环就分给这个机器 n 次请求。\n\nimport java.util.*; \nimport java.util.concurrent.ConcurrentHashMap; \npublic  class TestWeightRobin { \n    // 1.map, key-ip, value-weight \n    static Map<String,Integer> ipMap = new HashMap<>(); \n    static { \n        ipMap.put("192.168.13.1",1); \n        ipMap.put("192.168.13.2",2); \n        ipMap.put("192.168.13.3",4); \n    } \n    Integer pos = 0; \n    public String WeightRobin() { \n        Map<String,Integer> ipServerMap = new ConcurrentHashMap<>(); \n        ipServerMap.putAll(ipMap); \n        // 取出所有IP\n        Set<String> ipSet = ipServerMap.keySet(); \n        Iterator<String> ipIterator = ipSet.iterator(); \n        //定义一个list放所有server ip\n        ArrayList<String> ipArrayList=new ArrayList<String>(); \n        \n        //循环set，根据set中的可以去得知map中的value，给list中添加对应数字的server数量 \n        while (ipIterator.hasNext()){ \n            String serverName = ipIterator.next(); \n            Integer weight=ipServerMap.get(serverName); \n            for ( int i = 0;i < weight ;i++){ \n                ipArrayList.add(serverName); \n            } \n        } \n        String serverName=null; \n        if (pos>=ipArrayList.size()){ \n            pos=0; \n        } \n        serverName = ipArrayList.get(pos); \n        //轮询+1 \n        pos ++; \n        return  serverName; \n    } \n    public  static  void main(String[] args) { \n        TestWeightRobin testWeightRobin=new TestWeightRobin(); \n        for ( int i = 0; i < 10; i++){ \n            String server = testWeightRobin.WeightRobin(); \n            System.out.println(server); \n        } \n    } \n}\n\n\n\n# 3. 随机法\n\n通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。\n\n由概率统计理论可以得知，随着客户端调用服务端的次数增多， 其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。\n\nimport java.util.*; \nimport java.util.concurrent.ConcurrentHashMap; \n\npublic  class TestRandom { \n    //    1.定义map, key-ip,value-weight \n    static Map<String,Integer> ipMap= new HashMap<>(); \n    static { \n        ipMap.put("192.168.13.1",1); \n        ipMap.put("192.168.13.2",2); \n        ipMap.put("192.168.13.3",4); \n    } \n    public String Random() { \n        Map<String,Integer> ipServerMap = new ConcurrentHashMap<>(); \n        ipServerMap.putAll(ipMap); \n        Set<String> ipSet = ipServerMap.keySet(); \n        //定义一个list放所有server \n        ArrayList<String> ipArrayList = new ArrayList<String>(); \n        ipArrayList.addAll(ipSet); \n        //循环随机数 \n        Random random = new Random(); \n        \n        //随机数在list数量中取（1-list.size） \n        int pos = random.nextInt(ipArrayList.size()); \n        String serverNameReturn = ipArrayList.get(pos); \n        return  serverNameReturn; \n    } \n    public  static  void main(String[] args) { \n        TestRandom testRandom=new TestRandom(); \n        for ( int i =0;i<10;i++){ \n            String server=testRandom.Random(); \n            System.out.println(server); \n        } \n    } \n} \n\n\n\n# 4. 加权随机法\n\n与加权轮询法一样，加权随机法也根据后端机器的配置、系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。\n\nimport java.util.*; \nimport java.util.concurrent.ConcurrentHashMap; \npublic  class TestRobinRandom { \n    //    1.定义map, key-ip,value-weight \n    static Map<String,Integer> ipMap= new HashMap<>(); \n    static { \n        ipMap.put("192.168.13.1",1); \n        ipMap.put("192.168.13.2",2); \n        ipMap.put("192.168.13.3",4); \n    } \n    public String RobinRandom(){ \n        Map<String,Integer> ipServerMap = new ConcurrentHashMap<>(); \n        ipServerMap.putAll(ipMap); \n        Set<String> ipSet = ipServerMap.keySet(); \n        Iterator<String> ipIterator = ipSet.iterator(); \n        //定义一个list放所有server \n        ArrayList<String> ipArrayList = new ArrayList<String>(); \n        //循环set，根据set中的可以去得知map中的value，给list中添加对应数字的server数量 \n        while (ipIterator.hasNext()){ \n            String serverName=ipIterator.next(); \n            Integer weight = ipServerMap.get(serverName); \n            for (int i = 0; i < weight; i++){ \n                ipArrayList.add(serverName); \n            } \n        } \n        //循环随机数 \n        Random random = new Random(); \n        //随机数在list数量中取（1-list.size） \n        int pos=random.nextInt(ipArrayList.size()); \n        String serverNameReturn = ipArrayList.get(pos); \n        return  serverNameReturn; \n    } \n    public  static  void main(String[] args) { \n        TestRobinRandom testRobinRandom = new TestRobinRandom(); \n        for ( int i =0;i<10;i++){ \n            String server = testRobinRandom.RobinRandom(); \n            System.out.println(server); \n        } \n    } \n} \n\n\n\n# 5. 源地址哈希法\n\n源地址哈希的思想是 根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问；\n\nimport java.util.ArrayList; \nimport java.util.HashMap; \nimport java.util.Map; \nimport java.util.Set; \nimport java.util.concurrent.ConcurrentHashMap; \n\npublic  class ipHash { \n    //    1.定义map, key-ip,value-weight \n    static Map<String,Integer> ipMap= new HashMap<>(); \n    static { \n        ipMap.put("192.168.13.1",1); \n        ipMap.put("192.168.13.2",2); \n        ipMap.put("192.168.13.3",4); \n    } \n    // clientIP: 用户IP地址\n    public String ipHash(String clientIP){ \n        Map<String,Integer> ipServerMap = new ConcurrentHashMap<>(); \n        ipServerMap.putAll(ipMap); \n        //    2.取出来key,放到set中 \n        Set<String> ipset = ipServerMap.keySet(); \n        //    3.set放到list，要循环list取出 \n        ArrayList<String> iplist = new ArrayList<String>(); \n        iplist.addAll(ipset); \n        //对ip的hashcode值取余数，每次都一样的 \n        int hashCode = clientIP.hashCode(); \n        int serverListsize = iplist.size(); \n        int pos = hashCode % serverListsize; \n        return iplist.get(pos); \n    } \n    public  static  void main(String[] args) { \n        ipHash iphash=new ipHash(); \n        String servername= iphash.ipHash("192.168.21.2"); \n        System.out.println(servername); \n    } \n} \n\n\n但是呢，这种hash算法是非常普通的，你可以了解一下一致性哈希算法 : 一致性哈希算法',normalizedContent:'# 0. 简述\n\n什么是负载均衡算法？\n\n在分布式系统下，我们可能会将同一个服务启动多次形成集群，那么这个集群中的多台机器将会如何分配海量请求时？\n\n负载均衡算法就是以某种算法的形式将这些请求分配给不同的机器/实例。\n\n\n# 1. 轮询法\n\n将请求顺序轮流地分配到不同的实例上。 如果将服务器实例放到一个 list 中，轮询法的作用就是按照顺序遍历 list。\n\nimport java.util.*; \nimport java.util.concurrent.concurrenthashmap; \n\npublic  class testroundrobin {  \n    // 假设这些ip就是服务地址，那么要做的就是将请求分配到ip上。\n    static map<string,integer> ipmap= new hashmap<>(); \n    static { \n        ipmap.put("192.168.13.1",1); \n        ipmap.put("192.168.13.2",1); \n        ipmap.put("192.168.13.3",1); \n    } \n\n    integer  pos = 0; \n    public string roundrobin(){ \n        map<string,integer> ipservermap = new concurrenthashmap<>(); \n        ipservermap.putall(ipmap); \n        \n        // 2.取出来key,也就是ip地址，放到set中 \n        set<string> ipset = ipservermap.keyset(); \n        // 3.set放到list，要循环list取出 \n        arraylist<string> iplist = new arraylist<string>(); \n        iplist.addall(ipset); \n        string servername = null; \n        // 4.定义一个循环的值，如果大于set就从0开始 \n        synchronized(pos){ \n            if (pos >= ipset.size()){ \n                pos=0; \n            } \n            servername = iplist.get(pos); \n            //轮询+1 \n            pos ++; \n        } \n        return servername; \n    } \n    public  static  void main(string[] args) { \n        testroundrobin testroundrobin=new testroundrobin(); \n        for ( int i=0;i<10;i++){ \n            string serverip = testroundrobin.roundrobin(); \n            system.out.println(serverip); \n        } \n    } \n} \n\n\n\n# 2. 加权轮询法\n\n不同服务器的配置可能有区别，2核4g的服务器跟1核2g的服务器能处理的请求数量肯定不同。我们要尽量将请求多分配到配置好的服务器上。\n\n简单实现一下加权轮询 ：假如权重是 n ，那么一次循环就分给这个机器 n 次请求。\n\nimport java.util.*; \nimport java.util.concurrent.concurrenthashmap; \npublic  class testweightrobin { \n    // 1.map, key-ip, value-weight \n    static map<string,integer> ipmap = new hashmap<>(); \n    static { \n        ipmap.put("192.168.13.1",1); \n        ipmap.put("192.168.13.2",2); \n        ipmap.put("192.168.13.3",4); \n    } \n    integer pos = 0; \n    public string weightrobin() { \n        map<string,integer> ipservermap = new concurrenthashmap<>(); \n        ipservermap.putall(ipmap); \n        // 取出所有ip\n        set<string> ipset = ipservermap.keyset(); \n        iterator<string> ipiterator = ipset.iterator(); \n        //定义一个list放所有server ip\n        arraylist<string> iparraylist=new arraylist<string>(); \n        \n        //循环set，根据set中的可以去得知map中的value，给list中添加对应数字的server数量 \n        while (ipiterator.hasnext()){ \n            string servername = ipiterator.next(); \n            integer weight=ipservermap.get(servername); \n            for ( int i = 0;i < weight ;i++){ \n                iparraylist.add(servername); \n            } \n        } \n        string servername=null; \n        if (pos>=iparraylist.size()){ \n            pos=0; \n        } \n        servername = iparraylist.get(pos); \n        //轮询+1 \n        pos ++; \n        return  servername; \n    } \n    public  static  void main(string[] args) { \n        testweightrobin testweightrobin=new testweightrobin(); \n        for ( int i = 0; i < 10; i++){ \n            string server = testweightrobin.weightrobin(); \n            system.out.println(server); \n        } \n    } \n}\n\n\n\n# 3. 随机法\n\n通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。\n\n由概率统计理论可以得知，随着客户端调用服务端的次数增多， 其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。\n\nimport java.util.*; \nimport java.util.concurrent.concurrenthashmap; \n\npublic  class testrandom { \n    //    1.定义map, key-ip,value-weight \n    static map<string,integer> ipmap= new hashmap<>(); \n    static { \n        ipmap.put("192.168.13.1",1); \n        ipmap.put("192.168.13.2",2); \n        ipmap.put("192.168.13.3",4); \n    } \n    public string random() { \n        map<string,integer> ipservermap = new concurrenthashmap<>(); \n        ipservermap.putall(ipmap); \n        set<string> ipset = ipservermap.keyset(); \n        //定义一个list放所有server \n        arraylist<string> iparraylist = new arraylist<string>(); \n        iparraylist.addall(ipset); \n        //循环随机数 \n        random random = new random(); \n        \n        //随机数在list数量中取（1-list.size） \n        int pos = random.nextint(iparraylist.size()); \n        string servernamereturn = iparraylist.get(pos); \n        return  servernamereturn; \n    } \n    public  static  void main(string[] args) { \n        testrandom testrandom=new testrandom(); \n        for ( int i =0;i<10;i++){ \n            string server=testrandom.random(); \n            system.out.println(server); \n        } \n    } \n} \n\n\n\n# 4. 加权随机法\n\n与加权轮询法一样，加权随机法也根据后端机器的配置、系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。\n\nimport java.util.*; \nimport java.util.concurrent.concurrenthashmap; \npublic  class testrobinrandom { \n    //    1.定义map, key-ip,value-weight \n    static map<string,integer> ipmap= new hashmap<>(); \n    static { \n        ipmap.put("192.168.13.1",1); \n        ipmap.put("192.168.13.2",2); \n        ipmap.put("192.168.13.3",4); \n    } \n    public string robinrandom(){ \n        map<string,integer> ipservermap = new concurrenthashmap<>(); \n        ipservermap.putall(ipmap); \n        set<string> ipset = ipservermap.keyset(); \n        iterator<string> ipiterator = ipset.iterator(); \n        //定义一个list放所有server \n        arraylist<string> iparraylist = new arraylist<string>(); \n        //循环set，根据set中的可以去得知map中的value，给list中添加对应数字的server数量 \n        while (ipiterator.hasnext()){ \n            string servername=ipiterator.next(); \n            integer weight = ipservermap.get(servername); \n            for (int i = 0; i < weight; i++){ \n                iparraylist.add(servername); \n            } \n        } \n        //循环随机数 \n        random random = new random(); \n        //随机数在list数量中取（1-list.size） \n        int pos=random.nextint(iparraylist.size()); \n        string servernamereturn = iparraylist.get(pos); \n        return  servernamereturn; \n    } \n    public  static  void main(string[] args) { \n        testrobinrandom testrobinrandom = new testrobinrandom(); \n        for ( int i =0;i<10;i++){ \n            string server = testrobinrandom.robinrandom(); \n            system.out.println(server); \n        } \n    } \n} \n\n\n\n# 5. 源地址哈希法\n\n源地址哈希的思想是 根据获取客户端的ip地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一ip地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问；\n\nimport java.util.arraylist; \nimport java.util.hashmap; \nimport java.util.map; \nimport java.util.set; \nimport java.util.concurrent.concurrenthashmap; \n\npublic  class iphash { \n    //    1.定义map, key-ip,value-weight \n    static map<string,integer> ipmap= new hashmap<>(); \n    static { \n        ipmap.put("192.168.13.1",1); \n        ipmap.put("192.168.13.2",2); \n        ipmap.put("192.168.13.3",4); \n    } \n    // clientip: 用户ip地址\n    public string iphash(string clientip){ \n        map<string,integer> ipservermap = new concurrenthashmap<>(); \n        ipservermap.putall(ipmap); \n        //    2.取出来key,放到set中 \n        set<string> ipset = ipservermap.keyset(); \n        //    3.set放到list，要循环list取出 \n        arraylist<string> iplist = new arraylist<string>(); \n        iplist.addall(ipset); \n        //对ip的hashcode值取余数，每次都一样的 \n        int hashcode = clientip.hashcode(); \n        int serverlistsize = iplist.size(); \n        int pos = hashcode % serverlistsize; \n        return iplist.get(pos); \n    } \n    public  static  void main(string[] args) { \n        iphash iphash=new iphash(); \n        string servername= iphash.iphash("192.168.21.2"); \n        system.out.println(servername); \n    } \n} \n\n\n但是呢，这种hash算法是非常普通的，你可以了解一下一致性哈希算法 : 一致性哈希算法',charsets:{cjk:!0},lastUpdated:"2023/11/09, 12:26:33",lastUpdatedTimestamp:1699503993e3},{title:"限流算法",frontmatter:{title:"限流算法",date:"2023-06-09T14:23:53.000Z",permalink:"/pages/5dba8e/"},regularPath:"/02.%E6%96%87%E7%AB%A0/85.%E7%AE%97%E6%B3%95/20.%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95.html",relativePath:"02.文章/85.算法/20.限流算法.md",key:"v-20c514cb",path:"/pages/5dba8e/",headers:[{level:2,title:"1. 什么是限流",slug:"_1-什么是限流",normalizedTitle:"1. 什么是限流",charIndex:11},{level:2,title:"2. 常见的限流算法",slug:"_2-常见的限流算法",normalizedTitle:"2. 常见的限流算法",charIndex:178},{level:3,title:"2.1 计算器算法",slug:"_2-1-计算器算法",normalizedTitle:"2.1 计算器算法",charIndex:250},{level:3,title:"2.2 滑动窗口算法",slug:"_2-2-滑动窗口算法",normalizedTitle:"2.2 滑动窗口算法",charIndex:1595},{level:3,title:"2.3 令牌桶算法",slug:"_2-3-令牌桶算法",normalizedTitle:"2.3 令牌桶算法",charIndex:4995},{level:3,title:"2.4 漏桶算法",slug:"_2-4-漏桶算法",normalizedTitle:"2.4 漏桶算法",charIndex:6553},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:7931}],headersStr:"1. 什么是限流 2. 常见的限流算法 2.1 计算器算法 2.2 滑动窗口算法 2.3 令牌桶算法 2.4 漏桶算法 3. 总结",content:'# 限流算法\n\n\n# 1. 什么是限流\n\n什么是限流\n\n限流，也称流量控制。\n是指在系统面临高并发情况下，限制新的请求对系统的访问，从而保证系统的稳定性。\n\n举一些例子，\n\n * 景区会对人流量进行控制，例如每天固定卖多少门票。\n * 这段时间某地的烧烤很火，但是哪怕排队的人再多，烧烤的速度就这么快，就需要采取一些措施减小人流量激增带来的危害。\n\n\n# 2. 常见的限流算法\n\n常见的限流算法有：\n\n常见的限流算法\n\n * 计数器算法\n * 滑动窗口算法\n * 令牌桶算法\n * 漏桶算法\n\n\n# 2.1 计算器算法\n\n计数器算法(又称固定窗口算法)是最简单的限流算法，通过在单位时间内维护一个计数器来控制该时间内的最大访问量。\n例如，定义一个counter, 在1s内多一个请求就把它加1，当超过100时就不处理此请求，可以做到100次/1s的限流。\n又或者，使用Redis的expire命令给一个key设置为1s的生命周期，在1s内多一次请求就加一，到了100就不处理后续请求。1s结束后这个key就消失了， 于是就可以重新接收其他请求。\n(下面只列举出简单的实现)\n\npublic class CounterRateLimiter extends MyRateLimiter {\n    /**\n     * 每秒限制请求数\n     */\n    private final long permitsPerSecond;\n    /**\n     * 上一个窗口的开始时间\n     */\n    public long timestamp = System.currentTimeMillis();\n    /**\n     * 计数器\n     */\n    private int counter;\n\n    public CounterRateLimiter(long permitsPerSecond) {\n        this.permitsPerSecond = permitsPerSecond;\n    }\n\n    @Override\n    public synchronized boolean tryAcquire() {\n        long now = System.currentTimeMillis();\n        // 窗口内请求数量小于阈值，更新计数放行，否则拒绝请求\n        if (now - timestamp < 1000) {\n            if (counter < permitsPerSecond) {\n                counter++;\n                return true;\n            } else {\n                return false;\n            }\n        }\n        // 时间窗口过期，重置计数器和时间戳\n        counter = 0;\n        timestamp = now;\n        return true;\n    }\n}\n\n\n计数器的优点很明显：易于实现、占用内存少，毕竟人家只是用到了一个Key。\n但是缺点也很明显：假如我们要实现1s限流100次，此时有一个恶意人员在0.99s和1.1s各发起100次请求，在算法眼里这是允许的，但是换一个角度，虽然他在0s-1s的流量正确，在1s-2s的流量也正确，但是在0.5s-1.5s他发了200次请求啊\n这个就是计数器算法的临界效应。 临界效应是无法消除的，毕竟1s和2s之间有间隔，0.1ms和0.2ms之间还是有间隔的。所以我们只能尽量减小临界效应的影响，此时就可以使用滑动窗口算法。\n\n\n# 2.2 滑动窗口算法\n\n为什么称计数器算法为固定窗口算法？因为它的时间窗口是不变的，第1s和第2s永远都是分开的，但是我们通过刚才的学习也了解到时间之间是有临界效应的，我们只有把窗口动起来，才可以减小临界效应带来的损失。\n怎么动呢？ 我们可以将1s分为10个100ms，当时间走到0.5s时，我们记录的将是0.5s - 1.5s 的流量，时间再往后走到0.6s，我们记录的就是0.6s - 1.6s，每次丢失之前的100ms，每次录入现在的100ms， 这样就可以减小临界效应带来的损失。\n看图：\n如图所示，滑动窗口一共有10个，每个100ms，一共就是1s。此时滑动窗口滑到了1.1s - 2.1s\n第1.1s到1.2s内接受了3个请求，1.2s到1.3s接收到10个请求....\n这1s内共接收到48个请求，所以并没有任何流量被丢弃。\n现在时间向后移动0.1s:\n向后移动0.1s后，此时的窗口记录的是 1.2s - 2.2s 之间的请求数。之前的记录被丢弃，新增的2.1s-2.2s被纳入窗口。\n这样的好处是不断的更新时间窗口，减小了临界效应的不合理。\n\n但是\n\n滑动窗口也只是减小了临界效应的影响，无法彻底消除。\n\n使用Java代码实现一个简单的滑动窗口限流：\n\npublic class SlidingWindowRateLimiter extends MyRateLimiter {\n    /**\n     * 每分钟限制请求数\n     */\n    private final long permitsPerMinute;\n    /**\n     * 计数器, k-为当前窗口的开始时间值秒，value为当前窗口的计数\n     */\n    private final TreeMap<Long, Integer> counters;\n\n    public SlidingWindowRateLimiter(long permitsPerMinute) {\n        this.permitsPerMinute = permitsPerMinute;\n        this.counters = new TreeMap<>();\n    }\n\n    @Override\n    public synchronized boolean tryAcquire() {\n        // 获取当前时间的所在的子窗口值； 10s一个窗口\n        long currentWindowTime = LocalDateTime.now().toEpochSecond(ZoneOffset.UTC) / 10 * 10;\n        // 获取当前窗口的请求总量\n        int currentWindowCount = getCurrentWindowCount(currentWindowTime);\n        if (currentWindowCount >= permitsPerMinute) {\n            return false;\n        }\n        // 计数器 + 1\n        counters.merge(currentWindowTime, 1, Integer::sum);\n        return true;\n    }\n    /**\n     * 获取当前窗口中的所有请求数（并删除所有无效的子窗口计数器）\n     *\n     * @param currentWindowTime 当前子窗口时间\n     * @return 当前窗口中的计数\n     */\n    private int getCurrentWindowCount(long currentWindowTime) {\n        // 计算出窗口的开始位置时间\n        long startTime = currentWindowTime - 50;\n        int result = 0;\n\n        // 遍历当前存储的计数器，删除无效的子窗口计数器，并累加当前窗口中的所有计数器之和\n        Iterator<Map.Entry<Long, Integer>> iterator = counters.entrySet().iterator();\n        while (iterator.hasNext()) {\n            Map.Entry<Long, Integer> entry = iterator.next();\n            if (entry.getKey() < startTime) {\n                iterator.remove();\n            } else {\n                result += entry.getValue();\n            }\n        }\n        return result;\n    }\n}\n\n\n同样，也可以借助Redis实现滑动窗口限流，使用Redis的zset结构来实现真的很舒服~\nzset的名称可以使用唯一标识确定，例如userId、ip、请求方法...\nzset里面的每一个值可以设置为当前时间。\n每一个值对应的score可以设置为当前时间。 这样，Redis可以给zset中的所有值排序，因为是时间戳，所以它会从小到大排序，后面我们删除的时候直接将最上面的数据删除，删多少？小于当前时间 - 1000的全部删除就行了。\n（现在想想，下面这个例子举的很烂，大家可以直接看代码）\n举个例子（由于时间戳的精度太细，会对画图造成很大的困扰，这里我们假设每一个时间戳是0.01s）\n现在是第10s，zset中已经记录了 9-10 秒中的所有请求。\n\n想删除的时候，只需要删除小于 1000 - 0.01 * 1000 = 910 的数据，就可以向下统计 910 ~ 1010的数据了。\n\n如果一个zset中的元素超过了某个阈值，直接将以后的请求不处理即可。\n\npublic boolean isActionAllowed(String userId, String actionKey, int period, int maxCount) {\n    // 生成唯一的key\n    String key = String.format("hist:%s:%s", userId, actionKey);\n    long nowTs = System.currentTimeMillis();\n    // 使用管道\n    Pipeline pipe = jedis.pipelined();\n    pipe.multi();\n    // 添加当前操作当zset中\n    pipe.zadd(key, nowTs, "" + nowTs);\n    // 整理zset，删除时间窗口外的数据\n    pipe.zremrangeByScore(key, 0, nowTs - period * 1000);\n    Response<Long> count = pipe.zcard(key);\n    pipe.expire(key, period + 1);\n    pipe.exec();\n    pipe.close();\n    \n    return count.get() <= maxCount;\n}\n\n\n你可能忘记了pipeline的操作，来看这个方法的作用：\n\n> pipeline.zremrangeByScore(para1, para2, para3)\n> 第一个参数 ：zset的名称\n> 第二个参数 ：要删除的分数范围的下限\n> 第三个参数 ：要删除的分数范围的上限\n\n使用pipeline还有一个好处：它是批量操作，操作提交后并不会马上执行，而是等其他操作一起批量执行。\n滑动窗口的优点是减小了临界效应的影响，但缺点也很明显，不好实现、维护难。\n\n\n# 2.3 令牌桶算法\n\n令牌桶算法：定期生成令牌放入桶中，请求先去桶中拿令牌，如果拿到令牌就可以执行；如果没拿到令牌就不执行。\n桶中的令牌可以堆积，取决于桶的大小。 令牌桶的处理过程是这样的：\n\n * 生产令牌\n   假设我们设置的发送速率为r,那么每隔1/r秒，就生产一个令牌放入桶中。\n * 令牌上限\n   假设令牌桶的上限为N，如果令牌桶已经满了，那么放进来的令牌就会被丢弃\n * 消耗令牌\n   每当收到一个请求，就消耗掉1个令牌\n * 突发流量\n   因为桶的上限为N，那么最多就允许N个请求的突发流量\n * 限流处理\n   因为生产令牌的速率是固定的，所以请求的处理也是限定的\n\npublic class TokenBucketLimiter {\n\n    private int capaticy; //令牌桶容量\n    private int rate; //令牌产生速率\n    private int tokenAmount; //令牌数量\n\n    public TokenBucketLimiter(int capaticy, int rate) {\n        this.capaticy = capaticy;\n        this.rate = rate;\n        tokenAmount = capaticy;\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                //以恒定速率放令牌\n                while (true){\n                    synchronized (this){\n                        tokenAmount ++;\n                        if(tokenAmount > capaticy){\n                            tokenAmount = capaticy;\n                        }\n                    }\n                    try {\n                        Thread.sleep(1000 / rate);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n            }\n        }).start();\n    }\n\n    public synchronized boolean tryAcquire(Request request){\n        // 如果桶中还有令牌，拿走一个 \n        if(tokenAmount > 0){\n            tokenAmount --;\n            // 这里省略处理请求的代码....\n            return true;\n        }else{\n        \n            return false;\n        }\n\n    }\n    \n}\n \n\n\n令牌桶算法一般用于保护自身的系统，对客户的请求进行限流，保护自己不被突发流量打垮。但是它的缺点就是会丢弃很多请求。\n\n\n# 2.4 漏桶算法\n\n跟令牌桶算法有点类似，不过令牌桶算法是将令牌放入桶中，而漏桶算法是将请求放入桶中，以一定速度将请求"漏出来"处理。\n这跟消息队列的思想就很像了。这种算法适用于保护客户的系统，尽量不让客户的操作丢弃，即使没办法第一时间处理，也要存起来慢慢来。\n\npublic class LeakyBucketLimiter {\n\n    private int capaticy;//漏斗容量\n    private int rate;//漏斗速率\n    private int left;//剩余容量\n    private LinkedList<Request> requestList;\n\n    public LeakyBucketLimiter(int capaticy, int rate) {\n        this.capaticy = capaticy;\n        this.rate = rate;\n        this.left = capaticy;\n        requestList = new LinkedList<>();\n\n        //开启一个定时线程，以固定的速率将漏斗中的请求流出，进行处理\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                while(true){\n                    if(!requestList.isEmpty()){\n                        Request request = requestList.removeFirst();\n                        // 此方法是执行请求的方法\n                        handleRequest(request);\n                    }\n                    try {\n                        Thread.sleep(1000 / rate); //睡眠\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n            }\n        }).start();\n    }\n\n    public synchronized boolean tryAcquire(Request request){\n        if(left <= 0){\n            return false;\n        }else{\n            left --;\n            requestList.addLast(request);\n            return true;\n        }\n    }\n\n}\n\n \n\n\n\n# 3. 总结\n\n以上就是四种常见的限流算法的思想及实现。算法没有优劣，只有是否合适~',normalizedContent:'# 限流算法\n\n\n# 1. 什么是限流\n\n什么是限流\n\n限流，也称流量控制。\n是指在系统面临高并发情况下，限制新的请求对系统的访问，从而保证系统的稳定性。\n\n举一些例子，\n\n * 景区会对人流量进行控制，例如每天固定卖多少门票。\n * 这段时间某地的烧烤很火，但是哪怕排队的人再多，烧烤的速度就这么快，就需要采取一些措施减小人流量激增带来的危害。\n\n\n# 2. 常见的限流算法\n\n常见的限流算法有：\n\n常见的限流算法\n\n * 计数器算法\n * 滑动窗口算法\n * 令牌桶算法\n * 漏桶算法\n\n\n# 2.1 计算器算法\n\n计数器算法(又称固定窗口算法)是最简单的限流算法，通过在单位时间内维护一个计数器来控制该时间内的最大访问量。\n例如，定义一个counter, 在1s内多一个请求就把它加1，当超过100时就不处理此请求，可以做到100次/1s的限流。\n又或者，使用redis的expire命令给一个key设置为1s的生命周期，在1s内多一次请求就加一，到了100就不处理后续请求。1s结束后这个key就消失了， 于是就可以重新接收其他请求。\n(下面只列举出简单的实现)\n\npublic class counterratelimiter extends myratelimiter {\n    /**\n     * 每秒限制请求数\n     */\n    private final long permitspersecond;\n    /**\n     * 上一个窗口的开始时间\n     */\n    public long timestamp = system.currenttimemillis();\n    /**\n     * 计数器\n     */\n    private int counter;\n\n    public counterratelimiter(long permitspersecond) {\n        this.permitspersecond = permitspersecond;\n    }\n\n    @override\n    public synchronized boolean tryacquire() {\n        long now = system.currenttimemillis();\n        // 窗口内请求数量小于阈值，更新计数放行，否则拒绝请求\n        if (now - timestamp < 1000) {\n            if (counter < permitspersecond) {\n                counter++;\n                return true;\n            } else {\n                return false;\n            }\n        }\n        // 时间窗口过期，重置计数器和时间戳\n        counter = 0;\n        timestamp = now;\n        return true;\n    }\n}\n\n\n计数器的优点很明显：易于实现、占用内存少，毕竟人家只是用到了一个key。\n但是缺点也很明显：假如我们要实现1s限流100次，此时有一个恶意人员在0.99s和1.1s各发起100次请求，在算法眼里这是允许的，但是换一个角度，虽然他在0s-1s的流量正确，在1s-2s的流量也正确，但是在0.5s-1.5s他发了200次请求啊\n这个就是计数器算法的临界效应。 临界效应是无法消除的，毕竟1s和2s之间有间隔，0.1ms和0.2ms之间还是有间隔的。所以我们只能尽量减小临界效应的影响，此时就可以使用滑动窗口算法。\n\n\n# 2.2 滑动窗口算法\n\n为什么称计数器算法为固定窗口算法？因为它的时间窗口是不变的，第1s和第2s永远都是分开的，但是我们通过刚才的学习也了解到时间之间是有临界效应的，我们只有把窗口动起来，才可以减小临界效应带来的损失。\n怎么动呢？ 我们可以将1s分为10个100ms，当时间走到0.5s时，我们记录的将是0.5s - 1.5s 的流量，时间再往后走到0.6s，我们记录的就是0.6s - 1.6s，每次丢失之前的100ms，每次录入现在的100ms， 这样就可以减小临界效应带来的损失。\n看图：\n如图所示，滑动窗口一共有10个，每个100ms，一共就是1s。此时滑动窗口滑到了1.1s - 2.1s\n第1.1s到1.2s内接受了3个请求，1.2s到1.3s接收到10个请求....\n这1s内共接收到48个请求，所以并没有任何流量被丢弃。\n现在时间向后移动0.1s:\n向后移动0.1s后，此时的窗口记录的是 1.2s - 2.2s 之间的请求数。之前的记录被丢弃，新增的2.1s-2.2s被纳入窗口。\n这样的好处是不断的更新时间窗口，减小了临界效应的不合理。\n\n但是\n\n滑动窗口也只是减小了临界效应的影响，无法彻底消除。\n\n使用java代码实现一个简单的滑动窗口限流：\n\npublic class slidingwindowratelimiter extends myratelimiter {\n    /**\n     * 每分钟限制请求数\n     */\n    private final long permitsperminute;\n    /**\n     * 计数器, k-为当前窗口的开始时间值秒，value为当前窗口的计数\n     */\n    private final treemap<long, integer> counters;\n\n    public slidingwindowratelimiter(long permitsperminute) {\n        this.permitsperminute = permitsperminute;\n        this.counters = new treemap<>();\n    }\n\n    @override\n    public synchronized boolean tryacquire() {\n        // 获取当前时间的所在的子窗口值； 10s一个窗口\n        long currentwindowtime = localdatetime.now().toepochsecond(zoneoffset.utc) / 10 * 10;\n        // 获取当前窗口的请求总量\n        int currentwindowcount = getcurrentwindowcount(currentwindowtime);\n        if (currentwindowcount >= permitsperminute) {\n            return false;\n        }\n        // 计数器 + 1\n        counters.merge(currentwindowtime, 1, integer::sum);\n        return true;\n    }\n    /**\n     * 获取当前窗口中的所有请求数（并删除所有无效的子窗口计数器）\n     *\n     * @param currentwindowtime 当前子窗口时间\n     * @return 当前窗口中的计数\n     */\n    private int getcurrentwindowcount(long currentwindowtime) {\n        // 计算出窗口的开始位置时间\n        long starttime = currentwindowtime - 50;\n        int result = 0;\n\n        // 遍历当前存储的计数器，删除无效的子窗口计数器，并累加当前窗口中的所有计数器之和\n        iterator<map.entry<long, integer>> iterator = counters.entryset().iterator();\n        while (iterator.hasnext()) {\n            map.entry<long, integer> entry = iterator.next();\n            if (entry.getkey() < starttime) {\n                iterator.remove();\n            } else {\n                result += entry.getvalue();\n            }\n        }\n        return result;\n    }\n}\n\n\n同样，也可以借助redis实现滑动窗口限流，使用redis的zset结构来实现真的很舒服~\nzset的名称可以使用唯一标识确定，例如userid、ip、请求方法...\nzset里面的每一个值可以设置为当前时间。\n每一个值对应的score可以设置为当前时间。 这样，redis可以给zset中的所有值排序，因为是时间戳，所以它会从小到大排序，后面我们删除的时候直接将最上面的数据删除，删多少？小于当前时间 - 1000的全部删除就行了。\n（现在想想，下面这个例子举的很烂，大家可以直接看代码）\n举个例子（由于时间戳的精度太细，会对画图造成很大的困扰，这里我们假设每一个时间戳是0.01s）\n现在是第10s，zset中已经记录了 9-10 秒中的所有请求。\n\n想删除的时候，只需要删除小于 1000 - 0.01 * 1000 = 910 的数据，就可以向下统计 910 ~ 1010的数据了。\n\n如果一个zset中的元素超过了某个阈值，直接将以后的请求不处理即可。\n\npublic boolean isactionallowed(string userid, string actionkey, int period, int maxcount) {\n    // 生成唯一的key\n    string key = string.format("hist:%s:%s", userid, actionkey);\n    long nowts = system.currenttimemillis();\n    // 使用管道\n    pipeline pipe = jedis.pipelined();\n    pipe.multi();\n    // 添加当前操作当zset中\n    pipe.zadd(key, nowts, "" + nowts);\n    // 整理zset，删除时间窗口外的数据\n    pipe.zremrangebyscore(key, 0, nowts - period * 1000);\n    response<long> count = pipe.zcard(key);\n    pipe.expire(key, period + 1);\n    pipe.exec();\n    pipe.close();\n    \n    return count.get() <= maxcount;\n}\n\n\n你可能忘记了pipeline的操作，来看这个方法的作用：\n\n> pipeline.zremrangebyscore(para1, para2, para3)\n> 第一个参数 ：zset的名称\n> 第二个参数 ：要删除的分数范围的下限\n> 第三个参数 ：要删除的分数范围的上限\n\n使用pipeline还有一个好处：它是批量操作，操作提交后并不会马上执行，而是等其他操作一起批量执行。\n滑动窗口的优点是减小了临界效应的影响，但缺点也很明显，不好实现、维护难。\n\n\n# 2.3 令牌桶算法\n\n令牌桶算法：定期生成令牌放入桶中，请求先去桶中拿令牌，如果拿到令牌就可以执行；如果没拿到令牌就不执行。\n桶中的令牌可以堆积，取决于桶的大小。 令牌桶的处理过程是这样的：\n\n * 生产令牌\n   假设我们设置的发送速率为r,那么每隔1/r秒，就生产一个令牌放入桶中。\n * 令牌上限\n   假设令牌桶的上限为n，如果令牌桶已经满了，那么放进来的令牌就会被丢弃\n * 消耗令牌\n   每当收到一个请求，就消耗掉1个令牌\n * 突发流量\n   因为桶的上限为n，那么最多就允许n个请求的突发流量\n * 限流处理\n   因为生产令牌的速率是固定的，所以请求的处理也是限定的\n\npublic class tokenbucketlimiter {\n\n    private int capaticy; //令牌桶容量\n    private int rate; //令牌产生速率\n    private int tokenamount; //令牌数量\n\n    public tokenbucketlimiter(int capaticy, int rate) {\n        this.capaticy = capaticy;\n        this.rate = rate;\n        tokenamount = capaticy;\n        new thread(new runnable() {\n            @override\n            public void run() {\n                //以恒定速率放令牌\n                while (true){\n                    synchronized (this){\n                        tokenamount ++;\n                        if(tokenamount > capaticy){\n                            tokenamount = capaticy;\n                        }\n                    }\n                    try {\n                        thread.sleep(1000 / rate);\n                    } catch (interruptedexception e) {\n                        e.printstacktrace();\n                    }\n                }\n            }\n        }).start();\n    }\n\n    public synchronized boolean tryacquire(request request){\n        // 如果桶中还有令牌，拿走一个 \n        if(tokenamount > 0){\n            tokenamount --;\n            // 这里省略处理请求的代码....\n            return true;\n        }else{\n        \n            return false;\n        }\n\n    }\n    \n}\n \n\n\n令牌桶算法一般用于保护自身的系统，对客户的请求进行限流，保护自己不被突发流量打垮。但是它的缺点就是会丢弃很多请求。\n\n\n# 2.4 漏桶算法\n\n跟令牌桶算法有点类似，不过令牌桶算法是将令牌放入桶中，而漏桶算法是将请求放入桶中，以一定速度将请求"漏出来"处理。\n这跟消息队列的思想就很像了。这种算法适用于保护客户的系统，尽量不让客户的操作丢弃，即使没办法第一时间处理，也要存起来慢慢来。\n\npublic class leakybucketlimiter {\n\n    private int capaticy;//漏斗容量\n    private int rate;//漏斗速率\n    private int left;//剩余容量\n    private linkedlist<request> requestlist;\n\n    public leakybucketlimiter(int capaticy, int rate) {\n        this.capaticy = capaticy;\n        this.rate = rate;\n        this.left = capaticy;\n        requestlist = new linkedlist<>();\n\n        //开启一个定时线程，以固定的速率将漏斗中的请求流出，进行处理\n        new thread(new runnable() {\n            @override\n            public void run() {\n                while(true){\n                    if(!requestlist.isempty()){\n                        request request = requestlist.removefirst();\n                        // 此方法是执行请求的方法\n                        handlerequest(request);\n                    }\n                    try {\n                        thread.sleep(1000 / rate); //睡眠\n                    } catch (interruptedexception e) {\n                        e.printstacktrace();\n                    }\n                }\n            }\n        }).start();\n    }\n\n    public synchronized boolean tryacquire(request request){\n        if(left <= 0){\n            return false;\n        }else{\n            left --;\n            requestlist.addlast(request);\n            return true;\n        }\n    }\n\n}\n\n \n\n\n\n# 3. 总结\n\n以上就是四种常见的限流算法的思想及实现。算法没有优劣，只有是否合适~',charsets:{cjk:!0},lastUpdated:"2023/07/28, 15:53:40",lastUpdatedTimestamp:169053082e4},{title:"一致性哈希算法",frontmatter:{title:"一致性哈希算法",date:"2023-11-09T12:25:01.000Z",permalink:"/pages/7e25cb/"},regularPath:"/02.%E6%96%87%E7%AB%A0/85.%E7%AE%97%E6%B3%95/30.%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95.html",relativePath:"02.文章/85.算法/30.一致性哈希算法.md",key:"v-ed0ea22a",path:"/pages/7e25cb/",headers:[{level:2,title:"1. 普通哈希",slug:"_1-普通哈希",normalizedTitle:"1. 普通哈希",charIndex:2},{level:2,title:"2. 一致性哈希",slug:"_2-一致性哈希",normalizedTitle:"2. 一致性哈希",charIndex:445}],headersStr:"1. 普通哈希 2. 一致性哈希",content:"# 1. 普通哈希\n\n在介绍一致性哈希算法之前，先说一下普通的哈希算法，以便介绍它俩的区别。\n\n在负载均衡中，使用普通的哈希算法进行负载均衡，假如用户上传一个图片，我们有三台服务器可以存储，上传到哪一个图片？\n\n 1. 将服务器编号，0、1、2\n 2. 将图片进行哈希算法，hash（图片）= 13，得到的 hash 值再跟机器的数量取模，13 % 3 = 1，将图片存储到服务器1 中。\n 3. 以后访问该图片，按照上述顺序得到存储图片的机器即可。\n\n但是，普通哈希有个很大的坏处：假如我又添加了两台机器，此时机器数量变成 5，之前那张图片使用 hash（图片）= 13，取模 13 % 5 = 3，于是程序去 服务器2 找图片，但是我们的图片之前存储在 服务器1。bug不就来了？\n\n> 看到这里你应该意识到：一旦服务器数量修改，hash之后的取模运算就会改变，对应的计算结果也就改变了，之前的计算结果 与 现在的计算结果 不一样，绝大多数数据就需要重新存储。这是个致命错误。\n\n\n# 2. 一致性哈希\n\n普通哈希失误就失误在对机器数量取模上，我们不对机器数取模，对 2^32 取模，什么意思呢？\n\n我们首先将 [0， 2^32-1] 围成一个圆圈：\n\n\n\n如图，0 的左侧就是 2^32-1。我们把这个由 2^32 个数组成的圆圈称为哈希环\n\n于是我们存图片的步骤变为：\n\n将服务器的地址计算哈希值，hash(服务器)，用这个值与 2^32 取模，那么所有服务器都会在这个圆圈上代表一个点\n\n将要存储的图片计算哈希值，hash(图片)，用这个值与 2^32 取模，那么所有图片都会在这个圆圈上代表一个点\n\n怎么给这些图片选择一个服务器呢？只需要在这个环上一直往后遍历就行了，上图中左边三个图片存储在服务器A，右边的三个图片存储在服务器C。\n\n程序查找时也可以这样做：计算hash值 -> 与 2^32 取模 -> 放在哈希环上往右找第一个服务器。\n\n遇到服务器宕机或者新增服务器时，就可以只破坏一部分数据，保护其余数据。\n\n假如此时 服务器C 宕机，那么右边的三个文件就只能存储到 服务器B 中，但是也仅仅是三个文件。\n\n一致性哈希的的优缺点：\n\n * 优点 ：遇到节点不稳定的情况可以保护多数数据\n\n * 缺点 ：在节点数量太少的情况下，容易因为节点分布不均匀而造成数据倾斜问题，也就是被缓存的数据大都集中存储在某个节点上，从而出现数据分布不均匀的情况，这种情况被称为哈希倾斜\n\n为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个节点都计算多个哈希值，每个计算结果都放置在哈希环上，称为虚拟节点。一个实际的物理节点可以对应多个虚拟节点，虚拟节点越多，哈希环上的节点就越多，数据被均匀分配的概率就越大，哈希环倾斜造成的影响就越小。",normalizedContent:"# 1. 普通哈希\n\n在介绍一致性哈希算法之前，先说一下普通的哈希算法，以便介绍它俩的区别。\n\n在负载均衡中，使用普通的哈希算法进行负载均衡，假如用户上传一个图片，我们有三台服务器可以存储，上传到哪一个图片？\n\n 1. 将服务器编号，0、1、2\n 2. 将图片进行哈希算法，hash（图片）= 13，得到的 hash 值再跟机器的数量取模，13 % 3 = 1，将图片存储到服务器1 中。\n 3. 以后访问该图片，按照上述顺序得到存储图片的机器即可。\n\n但是，普通哈希有个很大的坏处：假如我又添加了两台机器，此时机器数量变成 5，之前那张图片使用 hash（图片）= 13，取模 13 % 5 = 3，于是程序去 服务器2 找图片，但是我们的图片之前存储在 服务器1。bug不就来了？\n\n> 看到这里你应该意识到：一旦服务器数量修改，hash之后的取模运算就会改变，对应的计算结果也就改变了，之前的计算结果 与 现在的计算结果 不一样，绝大多数数据就需要重新存储。这是个致命错误。\n\n\n# 2. 一致性哈希\n\n普通哈希失误就失误在对机器数量取模上，我们不对机器数取模，对 2^32 取模，什么意思呢？\n\n我们首先将 [0， 2^32-1] 围成一个圆圈：\n\n\n\n如图，0 的左侧就是 2^32-1。我们把这个由 2^32 个数组成的圆圈称为哈希环\n\n于是我们存图片的步骤变为：\n\n将服务器的地址计算哈希值，hash(服务器)，用这个值与 2^32 取模，那么所有服务器都会在这个圆圈上代表一个点\n\n将要存储的图片计算哈希值，hash(图片)，用这个值与 2^32 取模，那么所有图片都会在这个圆圈上代表一个点\n\n怎么给这些图片选择一个服务器呢？只需要在这个环上一直往后遍历就行了，上图中左边三个图片存储在服务器a，右边的三个图片存储在服务器c。\n\n程序查找时也可以这样做：计算hash值 -> 与 2^32 取模 -> 放在哈希环上往右找第一个服务器。\n\n遇到服务器宕机或者新增服务器时，就可以只破坏一部分数据，保护其余数据。\n\n假如此时 服务器c 宕机，那么右边的三个文件就只能存储到 服务器b 中，但是也仅仅是三个文件。\n\n一致性哈希的的优缺点：\n\n * 优点 ：遇到节点不稳定的情况可以保护多数数据\n\n * 缺点 ：在节点数量太少的情况下，容易因为节点分布不均匀而造成数据倾斜问题，也就是被缓存的数据大都集中存储在某个节点上，从而出现数据分布不均匀的情况，这种情况被称为哈希倾斜\n\n为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个节点都计算多个哈希值，每个计算结果都放置在哈希环上，称为虚拟节点。一个实际的物理节点可以对应多个虚拟节点，虚拟节点越多，哈希环上的节点就越多，数据被均匀分配的概率就越大，哈希环倾斜造成的影响就越小。",charsets:{cjk:!0},lastUpdated:"2023/11/09, 20:11:05",lastUpdatedTimestamp:1699531865e3},{title:"雪花算法",frontmatter:{title:"雪花算法",date:"2023-11-09T21:07:05.000Z",permalink:"/pages/3fe609/"},regularPath:"/02.%E6%96%87%E7%AB%A0/85.%E7%AE%97%E6%B3%95/40.%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95.html",relativePath:"02.文章/85.算法/40.雪花算法.md",key:"v-218f759f",path:"/pages/3fe609/",headers:[{level:2,title:"1. 概念",slug:"_1-概念",normalizedTitle:"1. 概念",charIndex:2},{level:2,title:"2. 实现Snowflake",slug:"_2-实现snowflake",normalizedTitle:"2. 实现snowflake",charIndex:720}],headersStr:"1. 概念 2. 实现Snowflake",content:'# 1. 概念\n\n雪花算法是一种生成唯一ID的算法，主要用于分布式系统中。它可以在不依赖数据库等其他设备的情况下，生成全局唯一的ID。\n\n雪花算法生成的 ID 为 64位整数，具体格式如下：\n\n\n\n图片太不清晰了😡😡😡😡\n\n * 1 个符号位 0：生成的 ID 需要是正整数，所以符号位必须是0\n * 41个时间戳 ：一般使用毫秒为时间戳。如果使用毫秒，2^41 ➗ (12 * 30 * 24 * 60 * 60 * 1000) ≈ 70，可以使用70年\n * 10个机器标识 ：其实可以分开，5 + 5，数据中心标识 + 机器标识，但是也可以指定10位来标识一个机器。\n * 12个计数序号 ：计数序号表示在指定的时间戳内能生成的最多ID数。若使用毫秒为时间戳，则表示 1毫秒最多生成 2^12 个序号。\n\n但是嘞，算法是死的人是活的，雪花算法只是提供了一个思想，将64位整数拆开各个部分分别表示不同的意思，再通过时间戳来实现递增，那么如果我的机器数量不多，可以只用 5 个比特表示机器，省下来那5个可以用于加大时间精度，也可以用于加大单位时间内序号数量。反正看你怎么实现喽~\n\n如果使用开源的 Snowflake 生成器，那么生成规则就跟上面说的一样。\n\nSnowflake也并不全是优点，缺点就是它是根据时间戳生成ID的，但是各个机器上的时钟可能不一致，同时如果一个机器的时间钟回拨，会有ID重复或者乱序的可能。怎么解决这种问题呢？利用拓展位，回拨之后再扩展位上加1就可以了，这样ID依然可以保持唯一。但是找个要求我们提前预留出位数，要么从机器id中，要么从序列号中，腾出一定的位，在时间回拨的时候，这个位置+1.\n\n\n# 2. 实现Snowflake\n\n开源的Snowflake很多，就不再介绍了，hutool就可以用，百度、美团也有相关的实现。\n\n在这里放一个网上看到的：\n\npublic class SnowFlakeUtil {\n \n    /**\n     * 初始时间戳，可以根据业务需求更改时间戳\n     */\n    private final long twepoch = 11681452025134L;\n \n    /**\n     * 机器ID所占位数，长度为5位\n     */\n    private final long workerIdBits = 5L;\n \n    /**\n     * 数据标识ID所占位数，长度位5位\n     */\n    private final long datacenterIdBits = 5L;\n \n    /**\n     * 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数)\n     */\n    private final long maxWorkerId = -1L ^ (-1L << workerIdBits);\n \n    /**\n     * 支持的最大数据标识id，结果是31\n     */\n    private final long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);\n \n    /**\n     * 序列在id中占的位数，默认12位\n     */\n    private final long sequenceBits = 12L;\n \n    /**\n     * 工作机器ID向左移12位\n     */\n    private final long workerIdShift = sequenceBits;\n \n    /**\n     * 数据标识id向左移17位(12+5)\n     */\n    private final long dataCenterIdShift = sequenceBits + workerIdBits;\n \n    /**\n     * 时间截向左移22位(5+5+12)\n     */\n    private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;\n \n    /**\n     * 序列号最大值; 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095)\n     */\n    private final long sequenceMask = -1L ^ (-1L << sequenceBits);\n \n    /**\n     * 工作机器ID(0~31)，2进制5位  32位减掉1位 31个\n     */\n    private volatile long workerId;\n \n    /**\n     * 数据中心ID(0~31)，2进制5位  32位减掉1位 31个\n     */\n    private volatile long datacenterId;\n \n    /**\n     * 毫秒内序列(0~4095)，2进制12位 4096 - 1 = 4095个\n     */\n    private volatile long sequence = 0L;\n \n    /**\n     * 上次时间戳，初始值为负数\n     */\n    private volatile long lastTimestamp = -1L;\n \n \n    // ==============================Constructors=====================================\n \n    /**\n     * 有参构造\n     * @param workerId 工作机器ID(0~31)\n     * @param datacenterId 数据中心ID(0~31)\n     * @param sequence 毫秒内序列(0~4095)\n     */\n    public SnowFlakeUtil(long workerId, long datacenterId, long sequence){\n        // sanity check for workerId\n        if (workerId > maxWorkerId || workerId < 0) {\n            throw new IllegalArgumentException(String.format("worker Id can\'t be greater than %d or less than 0",maxWorkerId));\n        }\n        if (datacenterId > maxDatacenterId || datacenterId < 0) {\n            throw new IllegalArgumentException(String.format("datacenter Id can\'t be greater than %d or less than 0",maxDatacenterId));\n        }\n        System.out.printf("worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d",\n                timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId);\n \n        this.workerId = workerId;\n        this.datacenterId = datacenterId;\n        this.sequence = sequence;\n    }\n \n    // ==============================Methods==========================================\n \n    /**\n     * 获得下一个ID (该方法是线程安全的)\n     *  如果一个线程反复获取Synchronized锁，那么synchronized锁将变成偏向锁。\n     * @return 生成的ID\n     */\n    public synchronized long nextId() {\n        // 获取当前时间的时间戳，单位（毫秒）\n        long timestamp = timeGen();\n \n        // 获取当前时间戳如果小于上次时间戳，则表示时间戳获取出现异常\n        if (timestamp < lastTimestamp) {\n            System.err.printf("当前时间戳不能小于上次时间戳，上次时间戳为： %d.", lastTimestamp);\n            throw new RuntimeException(String.format("当前时间戳不能小于上次时间戳，生成ID失败. 时间戳差值： %d milliseconds",\n                    lastTimestamp - timestamp));\n        }\n \n        // 获取当前时间戳如果等于上次时间戳（同一毫秒内），则在序列号加一；否则序列号赋值为0，从0开始。\n        if (lastTimestamp == timestamp) {\n            /* \n                逻辑：意思是说一个毫秒内最多只能有4096个数字，无论你传递多少进来，\n                    这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围\n            */\n            // sequence：毫秒内序列(0~4095);  sequenceMask: 序列号最大值;\n            sequence = (sequence + 1) & sequenceMask;\n            /* 逻辑：当某一毫秒的时间，产生的id数 超过4095，系统会进入等待，直到下一毫秒，系统继续产生ID */\n            if (sequence == 0) {\n                timestamp = tilNextMillis(lastTimestamp);\n            }\n        } else {\n            sequence = 0;\n        }\n \n        // 将上次时间戳值刷新（逻辑：记录一下最近一次生成id的时间戳，单位是毫秒）\n        lastTimestamp = timestamp;\n \n        /* 核心逻辑：生成一个64bit的id；\n                  先将当前时间戳左移，放到41 bit那儿；\n                  将机房id左移放到5 bit那儿；\n                  将机器id左移放到5 bit那儿；\n                  将序号放最后12 bit\n                  最后拼接起来成一个64 bit的二进制数字，转换成10进制就是个long型 */\n        /*\n         * 返回结果：\n         * (timestamp - twepoch) << timestampLeftShift) 表示将时间戳减去初始时间戳，再左移相应位数\n         * (datacenterId << datacenterIdShift) 表示将数据id左移相应位数\n         * (workerId << workerIdShift) 表示将工作id左移相应位数\n         * | 是按位或运算符，例如：x | y，只有当x，y不为0的时候结果才为0，其它情况结果都为1。\n         * 因为个部分只有相应位上的值有意义，其它位上都是0，所以将各部分的值进行 | 运算就能得到最终拼接好的id\n         */\n        return ((timestamp - twepoch) << timestampLeftShift) |\n                (datacenterId << dataCenterIdShift) |\n                (workerId << workerIdShift) |\n                sequence;\n    }\n \n    /**\n     * 上次时间戳与当前时间戳进行比较\n     * 逻辑：当某一毫秒的时间，产生的id数 超过4095，系统会进入等待，直到下一毫秒，系统继续产生ID\n     * @param lastTimestamp 上次时间戳\n     * @return 若当前时间戳小于等于上次时间戳（时间回拨了），则返回最新当前时间戳； 否则，返回当前时间戳\n     */\n    private long tilNextMillis(long lastTimestamp) {\n        long timestamp = timeGen();\n        while (timestamp <= lastTimestamp) {\n            timestamp = timeGen();\n        }\n        return timestamp;\n    }\n \n    /**\n     * 获取系统时间戳\n     * @return 当前时间的时间戳 14位\n     */\n    private long timeGen(){\n        return System.currentTimeMillis();\n    }\n \n    public static void main(String[] args) {\n        SnowFlakeUtil snowFlakeUtil = new SnowFlakeUtil(1,1,0);\n        System.out.println(snowFlakeUtil.timeGen());\n        for (int i = 0; i < 100; i++) {\n            System.out.println("雪花算法生成第【"+(i+1)+"】个ID:"+ snowFlakeUtil.nextId());\n        }\n \n    }\n \n}\n\n\n代码解释的很详细，我非常喜欢这种代码注释详细的。',normalizedContent:'# 1. 概念\n\n雪花算法是一种生成唯一id的算法，主要用于分布式系统中。它可以在不依赖数据库等其他设备的情况下，生成全局唯一的id。\n\n雪花算法生成的 id 为 64位整数，具体格式如下：\n\n\n\n图片太不清晰了😡😡😡😡\n\n * 1 个符号位 0：生成的 id 需要是正整数，所以符号位必须是0\n * 41个时间戳 ：一般使用毫秒为时间戳。如果使用毫秒，2^41 ➗ (12 * 30 * 24 * 60 * 60 * 1000) ≈ 70，可以使用70年\n * 10个机器标识 ：其实可以分开，5 + 5，数据中心标识 + 机器标识，但是也可以指定10位来标识一个机器。\n * 12个计数序号 ：计数序号表示在指定的时间戳内能生成的最多id数。若使用毫秒为时间戳，则表示 1毫秒最多生成 2^12 个序号。\n\n但是嘞，算法是死的人是活的，雪花算法只是提供了一个思想，将64位整数拆开各个部分分别表示不同的意思，再通过时间戳来实现递增，那么如果我的机器数量不多，可以只用 5 个比特表示机器，省下来那5个可以用于加大时间精度，也可以用于加大单位时间内序号数量。反正看你怎么实现喽~\n\n如果使用开源的 snowflake 生成器，那么生成规则就跟上面说的一样。\n\nsnowflake也并不全是优点，缺点就是它是根据时间戳生成id的，但是各个机器上的时钟可能不一致，同时如果一个机器的时间钟回拨，会有id重复或者乱序的可能。怎么解决这种问题呢？利用拓展位，回拨之后再扩展位上加1就可以了，这样id依然可以保持唯一。但是找个要求我们提前预留出位数，要么从机器id中，要么从序列号中，腾出一定的位，在时间回拨的时候，这个位置+1.\n\n\n# 2. 实现snowflake\n\n开源的snowflake很多，就不再介绍了，hutool就可以用，百度、美团也有相关的实现。\n\n在这里放一个网上看到的：\n\npublic class snowflakeutil {\n \n    /**\n     * 初始时间戳，可以根据业务需求更改时间戳\n     */\n    private final long twepoch = 11681452025134l;\n \n    /**\n     * 机器id所占位数，长度为5位\n     */\n    private final long workeridbits = 5l;\n \n    /**\n     * 数据标识id所占位数，长度位5位\n     */\n    private final long datacenteridbits = 5l;\n \n    /**\n     * 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数)\n     */\n    private final long maxworkerid = -1l ^ (-1l << workeridbits);\n \n    /**\n     * 支持的最大数据标识id，结果是31\n     */\n    private final long maxdatacenterid = -1l ^ (-1l << datacenteridbits);\n \n    /**\n     * 序列在id中占的位数，默认12位\n     */\n    private final long sequencebits = 12l;\n \n    /**\n     * 工作机器id向左移12位\n     */\n    private final long workeridshift = sequencebits;\n \n    /**\n     * 数据标识id向左移17位(12+5)\n     */\n    private final long datacenteridshift = sequencebits + workeridbits;\n \n    /**\n     * 时间截向左移22位(5+5+12)\n     */\n    private final long timestampleftshift = sequencebits + workeridbits + datacenteridbits;\n \n    /**\n     * 序列号最大值; 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095)\n     */\n    private final long sequencemask = -1l ^ (-1l << sequencebits);\n \n    /**\n     * 工作机器id(0~31)，2进制5位  32位减掉1位 31个\n     */\n    private volatile long workerid;\n \n    /**\n     * 数据中心id(0~31)，2进制5位  32位减掉1位 31个\n     */\n    private volatile long datacenterid;\n \n    /**\n     * 毫秒内序列(0~4095)，2进制12位 4096 - 1 = 4095个\n     */\n    private volatile long sequence = 0l;\n \n    /**\n     * 上次时间戳，初始值为负数\n     */\n    private volatile long lasttimestamp = -1l;\n \n \n    // ==============================constructors=====================================\n \n    /**\n     * 有参构造\n     * @param workerid 工作机器id(0~31)\n     * @param datacenterid 数据中心id(0~31)\n     * @param sequence 毫秒内序列(0~4095)\n     */\n    public snowflakeutil(long workerid, long datacenterid, long sequence){\n        // sanity check for workerid\n        if (workerid > maxworkerid || workerid < 0) {\n            throw new illegalargumentexception(string.format("worker id can\'t be greater than %d or less than 0",maxworkerid));\n        }\n        if (datacenterid > maxdatacenterid || datacenterid < 0) {\n            throw new illegalargumentexception(string.format("datacenter id can\'t be greater than %d or less than 0",maxdatacenterid));\n        }\n        system.out.printf("worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d",\n                timestampleftshift, datacenteridbits, workeridbits, sequencebits, workerid);\n \n        this.workerid = workerid;\n        this.datacenterid = datacenterid;\n        this.sequence = sequence;\n    }\n \n    // ==============================methods==========================================\n \n    /**\n     * 获得下一个id (该方法是线程安全的)\n     *  如果一个线程反复获取synchronized锁，那么synchronized锁将变成偏向锁。\n     * @return 生成的id\n     */\n    public synchronized long nextid() {\n        // 获取当前时间的时间戳，单位（毫秒）\n        long timestamp = timegen();\n \n        // 获取当前时间戳如果小于上次时间戳，则表示时间戳获取出现异常\n        if (timestamp < lasttimestamp) {\n            system.err.printf("当前时间戳不能小于上次时间戳，上次时间戳为： %d.", lasttimestamp);\n            throw new runtimeexception(string.format("当前时间戳不能小于上次时间戳，生成id失败. 时间戳差值： %d milliseconds",\n                    lasttimestamp - timestamp));\n        }\n \n        // 获取当前时间戳如果等于上次时间戳（同一毫秒内），则在序列号加一；否则序列号赋值为0，从0开始。\n        if (lasttimestamp == timestamp) {\n            /* \n                逻辑：意思是说一个毫秒内最多只能有4096个数字，无论你传递多少进来，\n                    这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围\n            */\n            // sequence：毫秒内序列(0~4095);  sequencemask: 序列号最大值;\n            sequence = (sequence + 1) & sequencemask;\n            /* 逻辑：当某一毫秒的时间，产生的id数 超过4095，系统会进入等待，直到下一毫秒，系统继续产生id */\n            if (sequence == 0) {\n                timestamp = tilnextmillis(lasttimestamp);\n            }\n        } else {\n            sequence = 0;\n        }\n \n        // 将上次时间戳值刷新（逻辑：记录一下最近一次生成id的时间戳，单位是毫秒）\n        lasttimestamp = timestamp;\n \n        /* 核心逻辑：生成一个64bit的id；\n                  先将当前时间戳左移，放到41 bit那儿；\n                  将机房id左移放到5 bit那儿；\n                  将机器id左移放到5 bit那儿；\n                  将序号放最后12 bit\n                  最后拼接起来成一个64 bit的二进制数字，转换成10进制就是个long型 */\n        /*\n         * 返回结果：\n         * (timestamp - twepoch) << timestampleftshift) 表示将时间戳减去初始时间戳，再左移相应位数\n         * (datacenterid << datacenteridshift) 表示将数据id左移相应位数\n         * (workerid << workeridshift) 表示将工作id左移相应位数\n         * | 是按位或运算符，例如：x | y，只有当x，y不为0的时候结果才为0，其它情况结果都为1。\n         * 因为个部分只有相应位上的值有意义，其它位上都是0，所以将各部分的值进行 | 运算就能得到最终拼接好的id\n         */\n        return ((timestamp - twepoch) << timestampleftshift) |\n                (datacenterid << datacenteridshift) |\n                (workerid << workeridshift) |\n                sequence;\n    }\n \n    /**\n     * 上次时间戳与当前时间戳进行比较\n     * 逻辑：当某一毫秒的时间，产生的id数 超过4095，系统会进入等待，直到下一毫秒，系统继续产生id\n     * @param lasttimestamp 上次时间戳\n     * @return 若当前时间戳小于等于上次时间戳（时间回拨了），则返回最新当前时间戳； 否则，返回当前时间戳\n     */\n    private long tilnextmillis(long lasttimestamp) {\n        long timestamp = timegen();\n        while (timestamp <= lasttimestamp) {\n            timestamp = timegen();\n        }\n        return timestamp;\n    }\n \n    /**\n     * 获取系统时间戳\n     * @return 当前时间的时间戳 14位\n     */\n    private long timegen(){\n        return system.currenttimemillis();\n    }\n \n    public static void main(string[] args) {\n        snowflakeutil snowflakeutil = new snowflakeutil(1,1,0);\n        system.out.println(snowflakeutil.timegen());\n        for (int i = 0; i < 100; i++) {\n            system.out.println("雪花算法生成第【"+(i+1)+"】个id:"+ snowflakeutil.nextid());\n        }\n \n    }\n \n}\n\n\n代码解释的很详细，我非常喜欢这种代码注释详细的。',charsets:{cjk:!0},lastUpdated:"2023/12/21, 16:18:02",lastUpdatedTimestamp:1703146682e3},{title:"CAP理论",frontmatter:{title:"CAP理论",date:"2023-11-03T00:16:23.000Z",permalink:"/pages/db9f45/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/1.%E7%90%86%E8%AE%BA/10.CAP%E7%90%86%E8%AE%BA.html",relativePath:"02.文章/91.框架/1.理论/10.CAP理论.md",key:"v-1a0380cd",path:"/pages/db9f45/",headers:[{level:2,title:"1. CAP 简介",slug:"_1-cap-简介",normalizedTitle:"1. cap 简介",charIndex:2},{level:2,title:"2. 为何只能三选二？",slug:"_2-为何只能三选二",normalizedTitle:"2. 为何只能三选二？",charIndex:777},{level:3,title:"2.1 CP",slug:"_2-1-cp",normalizedTitle:"2.1 cp",charIndex:860},{level:3,title:"2.2 AP",slug:"_2-2-ap",normalizedTitle:"2.2 ap",charIndex:1029},{level:3,title:"2.3 CA",slug:"_2-3-ca",normalizedTitle:"2.3 ca",charIndex:1194},{level:2,title:"3. 如何抉择",slug:"_3-如何抉择",normalizedTitle:"3. 如何抉择",charIndex:1286}],headersStr:"1. CAP 简介 2. 为何只能三选二？ 2.1 CP 2.2 AP 2.3 CA 3. 如何抉择",content:"# 1. CAP 简介\n\n> CAP理论指出 ：一个分布式系统不能同时满足一致性、高可用性、分区容错性。\n\n\n\nC、A、P 是三个约束属性 ：\n\n 1. C ：Consistency，一致性。访问所有的节点，得到数据结果是一样的。\n    \n    注意 ：这里的 一致性 指的是强一致性，也就是数据更新完，访问任意节点看到的数据完全一致，要和弱一致性、最终一致性区分开。\n\n 2. A ：Availability，可用性。所有节点都保持高可用性。\n    \n    注意 ：这里的高可用还包括，不能出现延迟，如 节点B 由于等待数据同步而阻塞了请求，那么 节点B 就不满足高可用性。A 就是满足客户端访问始终能有回复即可(不管回复的是否正确)\n\n 3. P ：Partition Tolerance，分区容错性 。分布式系统出现网络分区的时候，仍然能够对外提供服务。\n    \n    注意 ：这里的分区指的是网络意义上的分区。由于网络是不可靠的，所有节点可能出现无法通信的情况，在节点被迫分区而无法通信时，要保证节点可以继续服务\n\n什么是分区？\n\n分布式系统中，多个节点之间的网络本来是连通的，但是因为某些故障，比如某个节点出了问题，某些节点与另外的节点无法通信了，整个网络就被分为两个网络分区。无法通信就无法进行数据同步。最终两个分区会出现数据不一致。\n\n\n\nCAP理论对于那些本身带有数据存储的分布式系统更加有用，假设一个分布式系统的各个节点都读写同一个MySQL，那么对于这个分布式系统而言，讨论CAP没有意义。\n\n所以在讨论CAP理论时，更多的是针对那些有数据存储、数据复制场景的分布式存储系统，比如MySQL、Redis。\n\nZookeeper 用的是 CP，Eureka 用的是 AP，Nacos 不仅支持 CP 也支持 AP。\n\n\n# 2. 为何只能三选二？\n\n假设现在有两个机子 ：服务器A 、服务器B。它们内部都有一个值 number。\n\n此时 服务器A 中的 number 被改变...\n\n\n# 2.1 CP\n\n我们在保证 一致性、分区容错性，试试能否再实现 高可用性。\n\n为了保证一致性，服务器A 中 number 的改变一定要发送给 服务器B，但是因为网络原因，服务器A 发送给 服务器B 的消息阻塞或丢失。那么数据就有可能出现不一致问题，但是我们想保证一致性，所以服务B 要停止服务等待数据同步，那么就违反了高可用性。\n\n\n# 2.2 AP\n\n我们在保证 高可用性、分区容错性，试试能否再实现 一致性。\n\n为了保证高可用性，服务器A 和 服务器B 都必须快速响应。同样的由于网络不可靠，服务器B 还没来得及接收到服务器A 发来的数据同步请求，就要响应用户的获取数据请求，导致 服务器A 返回的数据与 服务器B 返回的数据不一致。这就无法实现一致性。\n\n\n# 2.3 CA\n\n如果保证高可用和一致性，能否保证分区后正常提供服务？\n\n网络是不可靠的，万一某个数据同步请求在发送过程中丢失，就会导致分区现象，各个网络区域的数据就会不一致。\n\n\n# 3. 如何抉择\n\n首先最起码要保证 P，如果分区了，可以把机器少的那个区域主动下线，也不能让它们一致提供错误数据。\n\n在保证 P 的基础上再谈 A 和 C。当然，如果你不使用分布式系统，那肯定不需要考虑P，也就不会三选二😁",normalizedContent:"# 1. cap 简介\n\n> cap理论指出 ：一个分布式系统不能同时满足一致性、高可用性、分区容错性。\n\n\n\nc、a、p 是三个约束属性 ：\n\n 1. c ：consistency，一致性。访问所有的节点，得到数据结果是一样的。\n    \n    注意 ：这里的 一致性 指的是强一致性，也就是数据更新完，访问任意节点看到的数据完全一致，要和弱一致性、最终一致性区分开。\n\n 2. a ：availability，可用性。所有节点都保持高可用性。\n    \n    注意 ：这里的高可用还包括，不能出现延迟，如 节点b 由于等待数据同步而阻塞了请求，那么 节点b 就不满足高可用性。a 就是满足客户端访问始终能有回复即可(不管回复的是否正确)\n\n 3. p ：partition tolerance，分区容错性 。分布式系统出现网络分区的时候，仍然能够对外提供服务。\n    \n    注意 ：这里的分区指的是网络意义上的分区。由于网络是不可靠的，所有节点可能出现无法通信的情况，在节点被迫分区而无法通信时，要保证节点可以继续服务\n\n什么是分区？\n\n分布式系统中，多个节点之间的网络本来是连通的，但是因为某些故障，比如某个节点出了问题，某些节点与另外的节点无法通信了，整个网络就被分为两个网络分区。无法通信就无法进行数据同步。最终两个分区会出现数据不一致。\n\n\n\ncap理论对于那些本身带有数据存储的分布式系统更加有用，假设一个分布式系统的各个节点都读写同一个mysql，那么对于这个分布式系统而言，讨论cap没有意义。\n\n所以在讨论cap理论时，更多的是针对那些有数据存储、数据复制场景的分布式存储系统，比如mysql、redis。\n\nzookeeper 用的是 cp，eureka 用的是 ap，nacos 不仅支持 cp 也支持 ap。\n\n\n# 2. 为何只能三选二？\n\n假设现在有两个机子 ：服务器a 、服务器b。它们内部都有一个值 number。\n\n此时 服务器a 中的 number 被改变...\n\n\n# 2.1 cp\n\n我们在保证 一致性、分区容错性，试试能否再实现 高可用性。\n\n为了保证一致性，服务器a 中 number 的改变一定要发送给 服务器b，但是因为网络原因，服务器a 发送给 服务器b 的消息阻塞或丢失。那么数据就有可能出现不一致问题，但是我们想保证一致性，所以服务b 要停止服务等待数据同步，那么就违反了高可用性。\n\n\n# 2.2 ap\n\n我们在保证 高可用性、分区容错性，试试能否再实现 一致性。\n\n为了保证高可用性，服务器a 和 服务器b 都必须快速响应。同样的由于网络不可靠，服务器b 还没来得及接收到服务器a 发来的数据同步请求，就要响应用户的获取数据请求，导致 服务器a 返回的数据与 服务器b 返回的数据不一致。这就无法实现一致性。\n\n\n# 2.3 ca\n\n如果保证高可用和一致性，能否保证分区后正常提供服务？\n\n网络是不可靠的，万一某个数据同步请求在发送过程中丢失，就会导致分区现象，各个网络区域的数据就会不一致。\n\n\n# 3. 如何抉择\n\n首先最起码要保证 p，如果分区了，可以把机器少的那个区域主动下线，也不能让它们一致提供错误数据。\n\n在保证 p 的基础上再谈 a 和 c。当然，如果你不使用分布式系统，那肯定不需要考虑p，也就不会三选二😁",charsets:{cjk:!0},lastUpdated:"2023/11/03, 18:29:13",lastUpdatedTimestamp:1699007353e3},{title:"BASE理论",frontmatter:{title:"BASE理论",date:"2023-11-03T00:16:49.000Z",permalink:"/pages/793cbb/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/1.%E7%90%86%E8%AE%BA/20.BASE%E7%90%86%E8%AE%BA.html",relativePath:"02.文章/91.框架/1.理论/20.BASE理论.md",key:"v-2232d43f",path:"/pages/793cbb/",headers:[{level:2,title:"1. 简介",slug:"_1-简介",normalizedTitle:"1. 简介",charIndex:2},{level:2,title:"2. 核心思想",slug:"_2-核心思想",normalizedTitle:"2. 核心思想",charIndex:201}],headersStr:"1. 简介 2. 核心思想",content:"# 1. 简介\n\nBASE ：Basically Available（基本可用）、Soft-state（软状态）、Eventually Consistent（最终一致性）\n\nBASE 理论就是这三个单词的缩写，BASE 理论是对 CAP 中一致性（C）和可用性（A）的权衡的结果，其来源于对大规模互联网系统分布式实践的经验，是基于 CAP 理论逐步演化而来的，它大大降低了我们对于系统的要求。\n\n\n# 2. 核心思想\n\n即使无法做到强一致性，但每个应用都可以根据自身业务的特点，采用适当的方式来使系统打到最终一致性。\n\n> 也就是牺牲数据的一致性来满足系统的高可用性，系统一部分数据不可用或者不一致时，仍需要保持系统整体的“主要可用”。\n\nBASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。因为它牺牲了一部分一致性，采用最终一致性来换取高可用性。\n\n * 基本可用 ：基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是这不等价于不可用。\n   \n   什么叫允许损失部分可用性？\n   \n   * 响应时间上的损失 ：正常情况下，处理用户请求需要0.5s返回结果，如果出现故障，我接受系统在3s内返回结果\n   * 系统功能上的损失 ：正常情况下，用户可以使用所有系统的功能，如果出现故障，我接受非核心功能无法使用。\n\n * 软状态 ：软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延迟。\n\n * 最终一致性 ：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够打到的一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，\n   \n   分布式中，一致性的三种级别：\n   \n   * 强一致性 ：系统写入了什么，读出来就是什么\n   * 弱一致性 ：不一定可以读取到最新写入的值，也不保证多少时间后读取的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。\n   * 最终一致性 ：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。",normalizedContent:"# 1. 简介\n\nbase ：basically available（基本可用）、soft-state（软状态）、eventually consistent（最终一致性）\n\nbase 理论就是这三个单词的缩写，base 理论是对 cap 中一致性（c）和可用性（a）的权衡的结果，其来源于对大规模互联网系统分布式实践的经验，是基于 cap 理论逐步演化而来的，它大大降低了我们对于系统的要求。\n\n\n# 2. 核心思想\n\n即使无法做到强一致性，但每个应用都可以根据自身业务的特点，采用适当的方式来使系统打到最终一致性。\n\n> 也就是牺牲数据的一致性来满足系统的高可用性，系统一部分数据不可用或者不一致时，仍需要保持系统整体的“主要可用”。\n\nbase 理论本质上是对 cap 的延伸和补充，更具体地说，是对 cap 中 ap 方案的一个补充。因为它牺牲了一部分一致性，采用最终一致性来换取高可用性。\n\n * 基本可用 ：基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是这不等价于不可用。\n   \n   什么叫允许损失部分可用性？\n   \n   * 响应时间上的损失 ：正常情况下，处理用户请求需要0.5s返回结果，如果出现故障，我接受系统在3s内返回结果\n   * 系统功能上的损失 ：正常情况下，用户可以使用所有系统的功能，如果出现故障，我接受非核心功能无法使用。\n\n * 软状态 ：软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延迟。\n\n * 最终一致性 ：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够打到的一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，\n   \n   分布式中，一致性的三种级别：\n   \n   * 强一致性 ：系统写入了什么，读出来就是什么\n   * 弱一致性 ：不一定可以读取到最新写入的值，也不保证多少时间后读取的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。\n   * 最终一致性 ：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。",charsets:{cjk:!0},lastUpdated:"2023/11/03, 18:29:13",lastUpdatedTimestamp:1699007353e3},{title:"Raft算法",frontmatter:{title:"Raft算法",date:"2023-11-03T18:28:49.000Z",permalink:"/pages/208bb3/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/1.%E7%90%86%E8%AE%BA/30.Raft%E7%AE%97%E6%B3%95.html",relativePath:"02.文章/91.框架/1.理论/30.Raft算法.md",key:"v-75b72c80",path:"/pages/208bb3/",headers:[{level:2,title:"1. 简述",slug:"_1-简述",normalizedTitle:"1. 简述",charIndex:2},{level:2,title:"2. 任期",slug:"_2-任期",normalizedTitle:"2. 任期",charIndex:799},{level:2,title:"3. 日志",slug:"_3-日志",normalizedTitle:"3. 日志",charIndex:1126},{level:2,title:"4. 节点类型",slug:"_4-节点类型",normalizedTitle:"4. 节点类型",charIndex:1468},{level:3,title:"4.1 Follower 跟随者",slug:"_4-1-follower-跟随者",normalizedTitle:"4.1 follower 跟随者",charIndex:1779},{level:3,title:"4.2 Candidate 候选者",slug:"_4-2-candidate-候选者",normalizedTitle:"4.2 candidate 候选者",charIndex:2698},{level:3,title:"4.3 Leader 领导者",slug:"_4-3-leader-领导者",normalizedTitle:"4.3 leader 领导者",charIndex:3363},{level:2,title:"5. Leader 的选举",slug:"_5-leader-的选举",normalizedTitle:"5. leader 的选举",charIndex:3802},{level:2,title:"6. 投票分裂",slug:"_6-投票分裂",normalizedTitle:"6. 投票分裂",charIndex:4332},{level:2,title:"7. 日志复制",slug:"_7-日志复制",normalizedTitle:"7. 日志复制",charIndex:4807},{level:2,title:"8. 保证数据安全",slug:"_8-保证数据安全",normalizedTitle:"8. 保证数据安全",charIndex:5729}],headersStr:"1. 简述 2. 任期 3. 日志 4. 节点类型 4.1 Follower 跟随者 4.2 Candidate 候选者 4.3 Leader 领导者 5. Leader 的选举 6. 投票分裂 7. 日志复制 8. 保证数据安全",content:"# 1. 简述\n\n什么是 Raft 算法，它是一种分布式共识算法，这个算法是干啥的呢？\n\nRaft 是一种共识算法，其特点是让多个参与者针对某一件事达成完全一致：一件事，一个结论。\n\n同时，已达成一致的结论是不可推翻的。可以举一个银行账户的例子来解释共识算法：假如由一批服务器组成一个集群来维护银行账户系统，如果有一个 Client 向集群的 Leader 发出“存 100 元”的指令，那么当集群返回成功应答之后，Client 再向集群发起查询时，一定能够查到被存储成功的这 100 元钱，就算有机器出现不可用情况，这 100 元的账也不可篡改。这就是共识算法要达到的效果。\n\n上面那段话有个重点 ：client 向集群中的 Leader 发送消息。对，整个集群中只有 Leader 可以对外提供服务。\n\n所有分布式项目都要使用 Raft 达成共识吗？\n\n不需要，我们写的什么商城、博客系统，为什么搭建集群？为什么分布式部署？一方面是为了承载更多的流量，可以用负载均衡手段把流量分发，另一方面是害怕单体项目宕机了就无法提供服务。\n\n但是 Raft 算法呢？一整个集群中只有 Leader 能够提供服务，无法做到请求分发，所以不适合刚刚说的应用场景，那 Raft 有啥用呢？主要用于对数据敏感的系统，例如数据存储、文件存储，用户上传的文件可以保证只要上传成功就一定安全，即使有节点宕机或者整个集群宕机，在集群恢复后仍然可以看到这些文件。\n\nRaft 算法和 Zookeeper 的算法很像，Zookeeper 写入数据的步骤 ：用户向集群发送写命令，Zookeeper 的 Leader 节点在征求半数以上节点的同意之后才落盘。\n\n现在来介绍一下什么是 Raft。\n\n私你马赛，先来推荐一个B站视频 ：【动画：Raft算法Leader选举、脑裂后选举、日志复制、修复不一致日志和数据安全】\n\n\n# 2. 任期\n\nRaft算法将 Leader 的当选 分为一个个任期（Term），每一个任期的开始都是 Leader 选举步骤。\n\n每一个任期以一次选举作为起点，所以当一个节点成为 Candidate 并向其他节点拉票时，会将自己的 Term 加1，表示自己要竞争这个任期的 Leader。其他节点如果同意了这个请求，会将自己的 Term 与该请求中的 Term 同步。\n\n比如有 A、B、C、D 三个节点，A 作为 Term = 1 时的 Leader，那么 B、C 就是 Term = 1 时的跟随者。此时 A 节点宕机，B 节点想要成为 Leader，要先将自己的 Term + 1，表示自己想要竞争 Term = 2 时的 Leader。\n\n\n# 3. 日志\n\n日志是节点之间传输的数据，Raft 被称为共识算法，就是对日志的共识。如果一个系统想要使用 Raft 算法完成某项功能，那么日志就是需要更改的东西，比如这个系统要存储文件，文件数据就是各个节点之间需要进行共识的日志。\n\n在 Raft 中，日志由三个重要部分组成：\n\n * Term ID ：该日志是在哪个任期形成的\n * Log Index ：该日志在这个任期内是第几个日志，当然了这个Log Index可以跟随Term ID 的改变而清零重计，也可以一直递增，就看你是怎么实现 Raft 算法了。\n * Data ：该日志记录的数据是啥\n\n所以节点之间传输的 RPC Message 就是 ：第 1 个任期的第 4 条日志，存储的数据为 abcdefg...\n\n\n# 4. 节点类型\n\n遵循 Raft算法 的分布式集群中每个节点扮演以下三种角色之一 ：\n\n 1. Leader ：领导者。负责和客户端通信，接收来自客户端的命令并发给 Follower，创建日志、与 Follower 同步日志。\n 2. Follower ：跟随者，一丝不苟的执行来自 Leader 的命令，可以投票给 Candidate 使其成为 Leader。\n 3. Candidate ：候选者，当 Follower 长时间没有接收到 Leader 的消息时，Follower就会揭竿而起成为候选者。\n\n解释一下 ：在 Raft 系统中并没有固定的 Leader，每一个节点都有成为 Leader 的机会。\n\n\n# 4.1 Follower 跟随者\n\n接收来自 Leader 的数据，并与之同步。\n\n如果没有 Leader 怎么办？集群刚启动时，所有节点都为 Follower，每一个节点维护一个随机的过期时间 Timeout，时间到的时候就会变成 Candidate，给集群中其他节点发送 RPC 消息拉票，如果超过半数的节点同意，它就变成 Leader了。\n\n当然了，毕竟不是谁都能当上 Leader 的，如果 Follower 在 Timeout 时间内接收到 Candidate 的拉票消息，怎么判断是否投票给它呢？\n\n 1. 候选者的 Term ID 比自己小，拒绝投票，如果比自己大继续下一步\n 2. 候选者的最新日志的 Term ID 比自己最新日志的 Term ID小，拒绝投票，如果比自己大继续下一步\n 3. 候选者的最新日志的 Index 比自己小，拒绝投票\n\n如果上面三条没有筛选掉候选者，Follower 会支持它当 Leader，Follower 要做的事 ：\n\n 1. 将自己的 Term ID 与 候选者同步\n 2. 发送 RPC 给这个候选者投票\n\n当 Follower 把票投给某候选者后，会将自己的 Term ID 与该候选者保持一致。\n\nshow me code ：\n\nif (candidate.termId < this.termId) {\n    return false;\n}\nif (candidate.logTermID < this.logTermId) {\n    return false;\n}\nif (candidate.logIndex < this.logIndex) {\n    return false;\n} \n// 将自己的任期与候选者同步\nthis.termId = candidate.termID;\n// 给候选者发送RPC请求，告诉它我同意你当 Leader\nthis.rpcServer.sendRPCVote(true);\n\n\n一个 Follower 每一个任期都只能投出一票。避免了一个 Follower 支持多个 Candidate 当 Leader 的情况。\n\n\n# 4.2 Candidate 候选者\n\n当 Follower 超时之后变成 Candidate，变成 Candidate 后要做的事：\n\n 1. 把 Term 加一，代表要竞争这个任期的 Leader\n 2. 给自己投一票\n 3. 然后给集群中每一个节点发送拉票消息\n\n拉票信息中携带的数据：\n\n 1. Term ID\n 2. Last Log Term ID\n 3. Last Log Index\n\n当长时间没有 Leader 给自己发消息时，Follower 会认为此时没有 Leader，王侯将相宁有种乎？这次我当Leader！此 Follower 就成为 Candidate，给其他的 Follower 发送拉票请求。其他的 Follower 会根据上面的投票规则选择是否给此 Candidate 投票。\n\n万一有一个 Follower 通过选举成为 Leader，那么它会每一个周期给所有 Follower 发送心跳，告诉他们老大还在，你们不要太猖狂。\n\n需要注意的是，候选者会拒绝所有其他候选者的拉票请求，但是如果收到 Leader 的心跳请求，那么此候选者会成为该 Leader 的 Follower\n\n同时，你应该也猜到了 Follower 的 timeout 时间为啥是随机的\n\n> 由于 Candidate 不会同意其他 Candidate 的拉票，如果所有 Follower 的 timeout 时间是一致的，那么大概率同时成为 Candidate，会造成多次选举都无法选举出 Leader 的情况。\n\n\n# 4.3 Leader 领导者\n\n当一个 Candidate 成为 Leader 时后，会向所有节点发送属于 Leader 的心跳，这个心跳可以让 Candidate 变成 Follower，同时将所有 Follower 的 Timeout 刷新。并且心跳是定时发送的。\n\n当 Leader 收到 来自客户端的请求后，会进行两阶段 ：\n\n 1. 将请求（或者说数据）放入日志中，向所有 Follower 发送这个日志\n 2. 当超过半数的 Follower 同步日志之后，Leader 会将这条日志落盘，并通知 Follower 进行落盘。\n\n当然了，我说 落盘 只是因为落盘容易理解，正确的说法是 ：交给状态机执行。\n\n状态机执行的实际上就是这个系统的核心操作，比如 ：\n\n 1. 文件系统的状态机执行的是将用户提交的文件保存到本地\n 2. 银行系统的状态机执行的操作是将用户存的钱保存到数据库\n\n所以说，根据 Raft 算法实现系统时，自定义日志后还要自定义状态机。\n\n\n# 5. Leader 的选举\n\n最初所有的节点都是 Follower，并且每一个节点都会生成一个随机等待时间，在这个等待时间结束之前还没有 Leader 给我发来消息，那我就变成 Candidate 向其他节点拉票。\n\n\n\n图中的 S1、S2...代表节点名，圆圈内部的数字 1 代表任期号（Term）。圆圈外面那层灰色进度条代表随即等待时间。\n\n可以看到 S1 的等待时间已经快结束了。等待时间一旦结束，S1 会成为 Candidate，并且：\n\n * 将自己的任期加一\n * 给自己投一票，再向其他节点拉票，发送 RequestVote RPC\n\n\n\n如图，S1 的任期变为 2，内部多了 一个实心黑圈和四个空心白圈，代表现在只有一票，是自己投的。\n\nS2、S3、S4、S5 在收到这个拉票请求后，由于此时没有日志，那么只比较任期 Term ID。很明显 S1 更胜一筹。\n\n那么不出意外的情况下， S2、S3、S4、S5 都支持 S1 当选 Leader。\n\n但是不出意外的话要出意外了：\n\nS3、S4、S5 都支持 S1 当选 Leader。只有 S2 不支持，为什么？因为 S2 的等待时间结束了，它也要成为 Candidate 进行拉票了。\n\n\n# 6. 投票分裂\n\n其他节点在接收到 S1 发送的拉票请求后，发现 S1 的 Term 比自己大，于是欣然同意 S1，并将自己的任期与 S1 进行同步。\n\n但是！S2 成为了 Candidate，Term 变成2，Candidate 会拒绝其他 Candidate 的拉票，所以 S2 拒绝了 S1 的拉票：\n\n\n\n图中的 RequestVote RPC 挺多挺乱的，一共有两种消息，\n\n 1. 一种是 同意/拒绝S1拉票 的请求。\n 2. 一种是 S2 向其他节点发送的拉票请求。\n\n那么 S2 发送的拉票请求一定不会成功，因为其他节点已经同意 S1 当选 Leader 了，不会重复投票。\n\n后来 S1 已经成为了 Leader，会发送心跳告知其他节点 ：\n\n\n\n当 S1 的 Leader 心跳到达其他节点后，他们就都变为 Follower。\n\n需要注意的是，每一次接收到来自 Leader 的心跳，Follower 都必须更新自己的等待时间，重新等。但是如果在等待时间结束的时候还没有 Leader 的心跳，说明它死了，我可取而代之。\n\n\n# 7. 日志复制\n\n虽然说是日志，其实在我们的实现中复制的也可以是数据，所以这一部分很重要。\n\n在前面的叙述中，S1 已经当选了 Leader，这时它接收到了用户产生的数据，如下：\n\n\n\nS1 现在有三条日志，日志的 Term ID = 2，代表这条日志产生时的任期为2。为什么是虚线呢？\n\n我们可以将虚线日志看作为 还存在于内存中的数据，在半数节点统一内存中的数据后才能刷新到磁盘。\n\n是不是跟 Zookeeper 一样。\n\n那么日志同步就是 Leader 中产生的日志，发送给 Follower 去同步，如果同步成功就给 Leader 返回成功。\n\n如果一个日志同步请求得到半数以上的 Follower 的支持，这个日志将会被写入状态机（写入磁盘）。Leader 将日志写入磁盘后也会通知 Follower 让他们将此条日志写到磁盘。\n\n这里需要介绍两个变量 ：这两个变量要用于日志同步。\n\n 1. next index ：下一个需要同步的日志下标。\n 2. match index ：可以写入磁盘的最大下标。\n\n在图里的表现形式是 ：箭头是 next index；圆点是 match index\n\n补充到现在，来看看Leader 发送给 Follower 的请求中都有哪些数据？\n\n 1. Leader 的 next index 位置的日志\n 2. Leader 的 match index，表示所有 Follower 可以将 match index 前的数据都写入磁盘。\n\n复制 Index 为 1 的日志 ：可以看到 S2、S3、S4、S5 都应用了这条日志。那么 Leader 接收到所有返回后，将会把 Index 为 1 的日志写入磁盘。\n\n\n\n由于超半数节点都同意将 index = 1的日志同步进内存。于是S1下一条消息就是\n\n * next index ：2\n * match index ：1\n\n其他节点在接收到这个消息时，如果同意，会将 next index 日志复制到内存中，match index 的日志写入磁盘中。\n\n\n\n当出现新的节点进入集群时，Leader 会发送很多个 RPC 请求给它进行日志同步。\n\n\n# 8. 保证数据安全\n\n上面说 Raft 算法是以 Leader 为主的强一致性算法。那么如果出现以下情况：\n\n\n\n先说一下是什么情况吧，在 S1、S2、S3、S4 开心愉悦的工作期间，S5一直处于宕机状态，所以 S5 一条日志都没有。但是此时 S1 宕机了，万一让 S5 当上了 Leader，S5 肯定要进行数据同步，难道让它将其他节点的数据全部清除吗？\n\n肯定不可以，别说让它同步数据了，就连 Leader 都不能让它当。还记得之前说的 “投票”吗？\n\n\n\nS5 苏醒之后，首先它的 Term 就一定没有其他节点大，根本没有它当 Leader 的机会。\n\n其次，就算你的 Term 侥幸跟其他节点一样大了，但是你日志的Term没有其他节点大，其他节点根本不会投你啊。\n\n所以其他节点都不会搭理 S5 的投票，当 S2、S3、S4 其中一个节点超时，就会加任期然后拉票然后当上Leader。",normalizedContent:"# 1. 简述\n\n什么是 raft 算法，它是一种分布式共识算法，这个算法是干啥的呢？\n\nraft 是一种共识算法，其特点是让多个参与者针对某一件事达成完全一致：一件事，一个结论。\n\n同时，已达成一致的结论是不可推翻的。可以举一个银行账户的例子来解释共识算法：假如由一批服务器组成一个集群来维护银行账户系统，如果有一个 client 向集群的 leader 发出“存 100 元”的指令，那么当集群返回成功应答之后，client 再向集群发起查询时，一定能够查到被存储成功的这 100 元钱，就算有机器出现不可用情况，这 100 元的账也不可篡改。这就是共识算法要达到的效果。\n\n上面那段话有个重点 ：client 向集群中的 leader 发送消息。对，整个集群中只有 leader 可以对外提供服务。\n\n所有分布式项目都要使用 raft 达成共识吗？\n\n不需要，我们写的什么商城、博客系统，为什么搭建集群？为什么分布式部署？一方面是为了承载更多的流量，可以用负载均衡手段把流量分发，另一方面是害怕单体项目宕机了就无法提供服务。\n\n但是 raft 算法呢？一整个集群中只有 leader 能够提供服务，无法做到请求分发，所以不适合刚刚说的应用场景，那 raft 有啥用呢？主要用于对数据敏感的系统，例如数据存储、文件存储，用户上传的文件可以保证只要上传成功就一定安全，即使有节点宕机或者整个集群宕机，在集群恢复后仍然可以看到这些文件。\n\nraft 算法和 zookeeper 的算法很像，zookeeper 写入数据的步骤 ：用户向集群发送写命令，zookeeper 的 leader 节点在征求半数以上节点的同意之后才落盘。\n\n现在来介绍一下什么是 raft。\n\n私你马赛，先来推荐一个b站视频 ：【动画：raft算法leader选举、脑裂后选举、日志复制、修复不一致日志和数据安全】\n\n\n# 2. 任期\n\nraft算法将 leader 的当选 分为一个个任期（term），每一个任期的开始都是 leader 选举步骤。\n\n每一个任期以一次选举作为起点，所以当一个节点成为 candidate 并向其他节点拉票时，会将自己的 term 加1，表示自己要竞争这个任期的 leader。其他节点如果同意了这个请求，会将自己的 term 与该请求中的 term 同步。\n\n比如有 a、b、c、d 三个节点，a 作为 term = 1 时的 leader，那么 b、c 就是 term = 1 时的跟随者。此时 a 节点宕机，b 节点想要成为 leader，要先将自己的 term + 1，表示自己想要竞争 term = 2 时的 leader。\n\n\n# 3. 日志\n\n日志是节点之间传输的数据，raft 被称为共识算法，就是对日志的共识。如果一个系统想要使用 raft 算法完成某项功能，那么日志就是需要更改的东西，比如这个系统要存储文件，文件数据就是各个节点之间需要进行共识的日志。\n\n在 raft 中，日志由三个重要部分组成：\n\n * term id ：该日志是在哪个任期形成的\n * log index ：该日志在这个任期内是第几个日志，当然了这个log index可以跟随term id 的改变而清零重计，也可以一直递增，就看你是怎么实现 raft 算法了。\n * data ：该日志记录的数据是啥\n\n所以节点之间传输的 rpc message 就是 ：第 1 个任期的第 4 条日志，存储的数据为 abcdefg...\n\n\n# 4. 节点类型\n\n遵循 raft算法 的分布式集群中每个节点扮演以下三种角色之一 ：\n\n 1. leader ：领导者。负责和客户端通信，接收来自客户端的命令并发给 follower，创建日志、与 follower 同步日志。\n 2. follower ：跟随者，一丝不苟的执行来自 leader 的命令，可以投票给 candidate 使其成为 leader。\n 3. candidate ：候选者，当 follower 长时间没有接收到 leader 的消息时，follower就会揭竿而起成为候选者。\n\n解释一下 ：在 raft 系统中并没有固定的 leader，每一个节点都有成为 leader 的机会。\n\n\n# 4.1 follower 跟随者\n\n接收来自 leader 的数据，并与之同步。\n\n如果没有 leader 怎么办？集群刚启动时，所有节点都为 follower，每一个节点维护一个随机的过期时间 timeout，时间到的时候就会变成 candidate，给集群中其他节点发送 rpc 消息拉票，如果超过半数的节点同意，它就变成 leader了。\n\n当然了，毕竟不是谁都能当上 leader 的，如果 follower 在 timeout 时间内接收到 candidate 的拉票消息，怎么判断是否投票给它呢？\n\n 1. 候选者的 term id 比自己小，拒绝投票，如果比自己大继续下一步\n 2. 候选者的最新日志的 term id 比自己最新日志的 term id小，拒绝投票，如果比自己大继续下一步\n 3. 候选者的最新日志的 index 比自己小，拒绝投票\n\n如果上面三条没有筛选掉候选者，follower 会支持它当 leader，follower 要做的事 ：\n\n 1. 将自己的 term id 与 候选者同步\n 2. 发送 rpc 给这个候选者投票\n\n当 follower 把票投给某候选者后，会将自己的 term id 与该候选者保持一致。\n\nshow me code ：\n\nif (candidate.termid < this.termid) {\n    return false;\n}\nif (candidate.logtermid < this.logtermid) {\n    return false;\n}\nif (candidate.logindex < this.logindex) {\n    return false;\n} \n// 将自己的任期与候选者同步\nthis.termid = candidate.termid;\n// 给候选者发送rpc请求，告诉它我同意你当 leader\nthis.rpcserver.sendrpcvote(true);\n\n\n一个 follower 每一个任期都只能投出一票。避免了一个 follower 支持多个 candidate 当 leader 的情况。\n\n\n# 4.2 candidate 候选者\n\n当 follower 超时之后变成 candidate，变成 candidate 后要做的事：\n\n 1. 把 term 加一，代表要竞争这个任期的 leader\n 2. 给自己投一票\n 3. 然后给集群中每一个节点发送拉票消息\n\n拉票信息中携带的数据：\n\n 1. term id\n 2. last log term id\n 3. last log index\n\n当长时间没有 leader 给自己发消息时，follower 会认为此时没有 leader，王侯将相宁有种乎？这次我当leader！此 follower 就成为 candidate，给其他的 follower 发送拉票请求。其他的 follower 会根据上面的投票规则选择是否给此 candidate 投票。\n\n万一有一个 follower 通过选举成为 leader，那么它会每一个周期给所有 follower 发送心跳，告诉他们老大还在，你们不要太猖狂。\n\n需要注意的是，候选者会拒绝所有其他候选者的拉票请求，但是如果收到 leader 的心跳请求，那么此候选者会成为该 leader 的 follower\n\n同时，你应该也猜到了 follower 的 timeout 时间为啥是随机的\n\n> 由于 candidate 不会同意其他 candidate 的拉票，如果所有 follower 的 timeout 时间是一致的，那么大概率同时成为 candidate，会造成多次选举都无法选举出 leader 的情况。\n\n\n# 4.3 leader 领导者\n\n当一个 candidate 成为 leader 时后，会向所有节点发送属于 leader 的心跳，这个心跳可以让 candidate 变成 follower，同时将所有 follower 的 timeout 刷新。并且心跳是定时发送的。\n\n当 leader 收到 来自客户端的请求后，会进行两阶段 ：\n\n 1. 将请求（或者说数据）放入日志中，向所有 follower 发送这个日志\n 2. 当超过半数的 follower 同步日志之后，leader 会将这条日志落盘，并通知 follower 进行落盘。\n\n当然了，我说 落盘 只是因为落盘容易理解，正确的说法是 ：交给状态机执行。\n\n状态机执行的实际上就是这个系统的核心操作，比如 ：\n\n 1. 文件系统的状态机执行的是将用户提交的文件保存到本地\n 2. 银行系统的状态机执行的操作是将用户存的钱保存到数据库\n\n所以说，根据 raft 算法实现系统时，自定义日志后还要自定义状态机。\n\n\n# 5. leader 的选举\n\n最初所有的节点都是 follower，并且每一个节点都会生成一个随机等待时间，在这个等待时间结束之前还没有 leader 给我发来消息，那我就变成 candidate 向其他节点拉票。\n\n\n\n图中的 s1、s2...代表节点名，圆圈内部的数字 1 代表任期号（term）。圆圈外面那层灰色进度条代表随即等待时间。\n\n可以看到 s1 的等待时间已经快结束了。等待时间一旦结束，s1 会成为 candidate，并且：\n\n * 将自己的任期加一\n * 给自己投一票，再向其他节点拉票，发送 requestvote rpc\n\n\n\n如图，s1 的任期变为 2，内部多了 一个实心黑圈和四个空心白圈，代表现在只有一票，是自己投的。\n\ns2、s3、s4、s5 在收到这个拉票请求后，由于此时没有日志，那么只比较任期 term id。很明显 s1 更胜一筹。\n\n那么不出意外的情况下， s2、s3、s4、s5 都支持 s1 当选 leader。\n\n但是不出意外的话要出意外了：\n\ns3、s4、s5 都支持 s1 当选 leader。只有 s2 不支持，为什么？因为 s2 的等待时间结束了，它也要成为 candidate 进行拉票了。\n\n\n# 6. 投票分裂\n\n其他节点在接收到 s1 发送的拉票请求后，发现 s1 的 term 比自己大，于是欣然同意 s1，并将自己的任期与 s1 进行同步。\n\n但是！s2 成为了 candidate，term 变成2，candidate 会拒绝其他 candidate 的拉票，所以 s2 拒绝了 s1 的拉票：\n\n\n\n图中的 requestvote rpc 挺多挺乱的，一共有两种消息，\n\n 1. 一种是 同意/拒绝s1拉票 的请求。\n 2. 一种是 s2 向其他节点发送的拉票请求。\n\n那么 s2 发送的拉票请求一定不会成功，因为其他节点已经同意 s1 当选 leader 了，不会重复投票。\n\n后来 s1 已经成为了 leader，会发送心跳告知其他节点 ：\n\n\n\n当 s1 的 leader 心跳到达其他节点后，他们就都变为 follower。\n\n需要注意的是，每一次接收到来自 leader 的心跳，follower 都必须更新自己的等待时间，重新等。但是如果在等待时间结束的时候还没有 leader 的心跳，说明它死了，我可取而代之。\n\n\n# 7. 日志复制\n\n虽然说是日志，其实在我们的实现中复制的也可以是数据，所以这一部分很重要。\n\n在前面的叙述中，s1 已经当选了 leader，这时它接收到了用户产生的数据，如下：\n\n\n\ns1 现在有三条日志，日志的 term id = 2，代表这条日志产生时的任期为2。为什么是虚线呢？\n\n我们可以将虚线日志看作为 还存在于内存中的数据，在半数节点统一内存中的数据后才能刷新到磁盘。\n\n是不是跟 zookeeper 一样。\n\n那么日志同步就是 leader 中产生的日志，发送给 follower 去同步，如果同步成功就给 leader 返回成功。\n\n如果一个日志同步请求得到半数以上的 follower 的支持，这个日志将会被写入状态机（写入磁盘）。leader 将日志写入磁盘后也会通知 follower 让他们将此条日志写到磁盘。\n\n这里需要介绍两个变量 ：这两个变量要用于日志同步。\n\n 1. next index ：下一个需要同步的日志下标。\n 2. match index ：可以写入磁盘的最大下标。\n\n在图里的表现形式是 ：箭头是 next index；圆点是 match index\n\n补充到现在，来看看leader 发送给 follower 的请求中都有哪些数据？\n\n 1. leader 的 next index 位置的日志\n 2. leader 的 match index，表示所有 follower 可以将 match index 前的数据都写入磁盘。\n\n复制 index 为 1 的日志 ：可以看到 s2、s3、s4、s5 都应用了这条日志。那么 leader 接收到所有返回后，将会把 index 为 1 的日志写入磁盘。\n\n\n\n由于超半数节点都同意将 index = 1的日志同步进内存。于是s1下一条消息就是\n\n * next index ：2\n * match index ：1\n\n其他节点在接收到这个消息时，如果同意，会将 next index 日志复制到内存中，match index 的日志写入磁盘中。\n\n\n\n当出现新的节点进入集群时，leader 会发送很多个 rpc 请求给它进行日志同步。\n\n\n# 8. 保证数据安全\n\n上面说 raft 算法是以 leader 为主的强一致性算法。那么如果出现以下情况：\n\n\n\n先说一下是什么情况吧，在 s1、s2、s3、s4 开心愉悦的工作期间，s5一直处于宕机状态，所以 s5 一条日志都没有。但是此时 s1 宕机了，万一让 s5 当上了 leader，s5 肯定要进行数据同步，难道让它将其他节点的数据全部清除吗？\n\n肯定不可以，别说让它同步数据了，就连 leader 都不能让它当。还记得之前说的 “投票”吗？\n\n\n\ns5 苏醒之后，首先它的 term 就一定没有其他节点大，根本没有它当 leader 的机会。\n\n其次，就算你的 term 侥幸跟其他节点一样大了，但是你日志的term没有其他节点大，其他节点根本不会投你啊。\n\n所以其他节点都不会搭理 s5 的投票，当 s2、s3、s4 其中一个节点超时，就会加任期然后拉票然后当上leader。",charsets:{cjk:!0},lastUpdated:"2023/12/21, 20:32:43",lastUpdatedTimestamp:1703161963e3},{title:"2. XXL-JOB的使用",frontmatter:{title:"2. XXL-JOB的使用",date:"2023-11-20T12:56:32.000Z",permalink:"/pages/fcb98f/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/100.XXL-JOB/2.XXL-JOB%E7%9A%84%E4%BD%BF%E7%94%A8.html",relativePath:"02.文章/91.框架/100.XXL-JOB/2.XXL-JOB的使用.md",key:"v-64094560",path:"/pages/fcb98f/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 简单任务的执行",slug:"_1-简单任务的执行",normalizedTitle:"1. 简单任务的执行",charIndex:312},{level:3,title:"1.2 添加配置",slug:"_1-2-添加配置",normalizedTitle:"1.2 添加配置",charIndex:871},{level:3,title:"1.3 添加任务",slug:"_1-3-添加任务",normalizedTitle:"1.3 添加任务",charIndex:2946},{level:3,title:"1.4 执行任务",slug:"_1-4-执行任务",normalizedTitle:"1.4 执行任务",charIndex:3938},{level:2,title:"2. 日志记录",slug:"_2-日志记录",normalizedTitle:"2. 日志记录",charIndex:4037},{level:2,title:"3. 固定速率执行",slug:"_3-固定速率执行",normalizedTitle:"3. 固定速率执行",charIndex:5939},{level:2,title:"4. 执行任务参数",slug:"_4-执行任务参数",normalizedTitle:"4. 执行任务参数",charIndex:6022},{level:2,title:"5. 任务超时时间",slug:"_5-任务超时时间",normalizedTitle:"5. 任务超时时间",charIndex:6497}],headersStr:"0. 前言 1. 简单任务的执行 1.2 添加配置 1.3 添加任务 1.4 执行任务 2. 日志记录 3. 固定速率执行 4. 执行任务参数 5. 任务超时时间",content:'# 0. 前言\n\n上一章带大家安装了 xxl-job，下载出来源码一共三个大模块：\n\n- xxl-job-admin\n- xxl-job-core\n- xxl-job-executor-sample\n  - xxl-job-executor-sample-frameless\n  - xxl-job-executor-sample-springboot\n\n\n * xxl-job-admin ：调度中心\n * xxl-job-core ：核心类，其中有调度中心需要的功能和执行器需要的所有功能。\n * xxl-job-executor-sample ：xxl-job提供的实例，有无框架版本、整合spring的版本\n\n\n# 1. 简单任务的执行\n\nXxl-Job 提供了一个注解 @XxlJob标注定时任务，我们只需要定义一个bean对象，在方法上加上 @XxlJob注解，这个方法就成为定时任务方法了。\n\n@Target({ElementType.METHOD})\n@Retention(RetentionPolicy.RUNTIME)\n@Inherited\npublic @interface XxlJob {\n    String value();\n\n    String init() default "";\n\n    String destroy() default "";\n}\n\n\n可以看到 @XxlJob只能指定定时任务的方法名和初始化方法、销毁方法。但是一个定时任务的关键应该是执行频率啊，在哪里指定呢？在web控制台指定。\n\n\n\n###1.1 添加依赖\n\n一定要跟下载的 xxl-job 版本一致 ：\n\n\x3c!-- xxl-job-core --\x3e\n<dependency>\n    <groupId>com.xuxueli</groupId>\n    <artifactId>xxl-job-core</artifactId>\n    <version>2.4.0</version>\n</dependency>\n\n\n\n# 1.2 添加配置\n\n# web port\nserver.port=3999\n# no web\n#spring.main.web-environment=false\n\n# log config\nlogging.config=classpath:logback.xml\n\n\n### xxl-job admin address list, such as "http://address" or "http://address01,http://address02"\nxxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin\n\n### xxl-job, access token\nxxl.job.accessToken=default_token\n\n### xxl-job executor appname\nxxl.job.executor.appname=xxl-job-executor-sample\n### xxl-job executor registry-address: default use address to registry , otherwise use ip:port if address is null\nxxl.job.executor.address=\n### xxl-job executor server-info\nxxl.job.executor.ip=\nxxl.job.executor.port=9999\n### xxl-job executor log-path\nxxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler\n### xxl-job executor log-retention-days\nxxl.job.executor.logretentiondays=30\n\n\n对了，logging.config 这个日志配置 logback.xml 你如果没有的话可以把 xxl-job-executor-sample-springboot 里的配置拿过来。\n\n\n@Configuration\npublic class XxlJobConfig {\n    private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class);\n    @Value("${xxl.job.admin.addresses}")\n    private String adminAddresses;\n    @Value("${xxl.job.accessToken}")\n    private String accessToken;\n    @Value("${xxl.job.executor.appname}")\n    private String appname;\n    @Value("${xxl.job.executor.port}")\n    private int port;\n    @Value("${xxl.job.executor.logpath}")\n    private String logPath;\n    @Value("${xxl.job.executor.logretentiondays}")\n    private int logRetentionDays;\n\n    @Bean\n    public XxlJobSpringExecutor xxlJobExecutor() {\n        logger.info(">>>>>>>>>>> xxl-job config init.");\n        XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor();\n        xxlJobSpringExecutor.setAdminAddresses(adminAddresses);\n        xxlJobSpringExecutor.setAppname(appname);\n        // 省略 IP 和 address 的配置\n        xxlJobSpringExecutor.setPort(port);\n        xxlJobSpringExecutor.setAccessToken(accessToken);\n        xxlJobSpringExecutor.setLogPath(logPath);\n        xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays);\n\n        return xxlJobSpringExecutor;\n    }\n}\n\n\n\n# 1.3 添加任务\n\nXxl-job与SpringBoot整合时\n\n 1. 写代码\n    \n    假如我们有一个需求 ：每分钟检查商品的库存是否足够，如果不够就提醒商家添加库存。\n    \n    在代码中只是完成任务 ：\n    \n    import com.xxl.job.core.handler.annotation.XxlJob;\n    import org.slf4j.Logger;\n    import org.slf4j.LoggerFactory;\n    import org.springframework.stereotype.Component;\n    \n    import java.util.Random;\n    \n    @Component\n    public class XxlJobHandler {\n        private static final Logger logger = LoggerFactory.getLogger(XxlJobHandler.class);\n        @XxlJob("checkStore")\n        public void check() {\n            logger.info("开始执行定时任务");\n            System.out.println("检查库存");\n            int store = new Random().nextInt(3);\n            if (store <= 0) {\n                System.out.println("东西卖的太快了，快添加库存");\n            }\n            System.out.println("检查完毕");\n            logger.info("定时任务执行完毕");\n        }\n    }\n    \n\n 2. 配置任务\n    \n    打开web控制台，其他的我们不懂也不动，但是要把执行频率改了\n    \n    -- 每分钟指定的corn表达式：\n    0 * * * * ? \n    \n    \n    点击新增任务，将以下四项填完就可以了。\n    \n    \n\n\n# 1.4 执行任务\n\n启动项目，将任务状态改为 启动。\n\n\n\n一共执行了三次~ 可以看到它的精准度还是蛮高的，\n\n好了，现在你可以去web界面将这个任务停止，或者你可以看看这个任务的其他信息\n\n\n# 2. 日志记录\n\n为什么将它作为单独一个章节，因为 xxl-job 的日志是很多人困扰&烦躁的地方，因为每一个任务的每一次执行都对应一个日志文件，如果一个任务每5s执行一次，那么这个任务一天就可以产出 24 * 60 * 60 / 5 = 17280 个日志文件，假设这个任务全部成功，一个文件只有1kb，那就是16M。\n\n现在我们来看看日志都记录了什么，并且在代码中如何将重要信息记录到 Xxl-Job 的日志文件中。\n\n想看日志就要知道日志在哪，我们通过配置，让 xxl-job 在桌面生成日志;\n\nxxl.job.executor.logpath=C:/Users/23825/Desktop/xxl-job/jobhandler\n\n\n未来我想看日志，就可以去 C:/Users/23825/Desktop/xxl-job/jobhandler 查找\n\nXxl-Job 提供了一个工具类 ：XxlJobHelper，使用 XxlJobHelper.log() 就可以记录日志到文件中。\n\n@Component\npublic class XxlJobHandler {\n    private static final Logger logger = LoggerFactory.getLogger(XxlJobHandler.class);\n    @XxlJob("checkStore")\n    public void check() {\n        logger.info("开始执行定时任务");\n        int store = new Random().nextInt(3);\n        XxlJobHelper.log("检查库存，库存余量: {}", store);\n        if (store <= 0) {\n            System.out.println("东西卖的太快了，快添加库存");\n        }\n        logger.info("定时任务执行完毕");\n    }\n}\n\n\n上述代码，每次检查出库存之后都将库存记录到日志中，启动项目，运行任务\n\n好了，在执行几分钟后，你在桌面会看到如下文件夹：C:\\Users\\23825\\Desktop\\xxl-job\\jobhandler\\2023-11-19\n\n可以猜测 xxl-job 会为每一天创建一个文件夹，每一次执行任务创建一个文件。\n\n随便打开一个日志文件：\n\n2023-11-19 22:52:00 [com.xxl.job.core.thread.JobThread#run]-[133]-[xxl-job, JobThread-2-1700405520094] <br>----------- xxl-job job execute start -----------<br>----------- Param:\n2023-11-19 22:52:00 [com.xiaohe.mailtest.job.XxlJobHandler#check]-[23]-[xxl-job, JobThread-2-1700405520094] 检查库存，库存余量: 0\n2023-11-19 22:52:00 [com.xxl.job.core.thread.JobThread#run]-[179]-[xxl-job, JobThread-2-1700405520094] <br>----------- xxl-job job execute end(finish) -----------<br>----------- Result: handleCode=200, handleMsg = null\n2023-11-19 22:52:00 [com.xxl.job.core.thread.TriggerCallbackThread#callbackLog]-[197]-[xxl-job, executor TriggerCallbackThread] <br>----------- xxl-job job callback finish.\n\n\n日志共有四部分\n\n 1. 开始执行的信息 ：负责执行的线程编号\n 2. 程序员打印的信息 ：定时任务的全限定类名+方法名、负责执行的线程编号、自定义的日志信息\n 3. 执行结束的信息 ：执行的结果\n 4. 回调信息 ：执行器将执行结果交给调度中心\n\n如果以后执行的时候出现什么bug就可以往日志里面记录。\n\n\n# 3. 固定速率执行\n\n刚才的简单任务是定时执行，每一分钟执行一次。现在来试试固定速率执行，我们将速率设置为每60s执行一次。\n\n执行之后的日志我就不再贴了。\n\n\n# 4. 执行任务参数\n\nXxl-Job的定时任务可以指定参数，这个参数使用 XxlJobHelper.getJobParam()获取。获取的是一整个字符串，你需要在自己的代码中切割这个字符串获得你想要的参数：\n\n@XxlJob("checkStore")\npublic void check() {\n    String jobParam = XxlJobHelper.getJobParam();\n    System.out.println("定时任务的参数: " + jobParam);\n\n    logger.info("开始执行定时任务");\n    int store = new Random().nextInt(3);\n    XxlJobHelper.log("检查库存，库存余量: {}", store);\n    if (store <= 0) {\n        System.out.println("东西卖的太快了，快添加库存");\n    }\n    logger.info("定时任务执行完毕");\n}\n\n\n\n\n\n# 5. 任务超时时间\n\n如果对任务的执行时间有要求，还可以设置任务的最大执行时间，也就是任务超时时间\n\npublic void check() throws InterruptedException {\n    String jobParam = XxlJobHelper.getJobParam();\n    System.out.println("定时任务的参数: " + jobParam);\n\n    Thread.sleep(5 * 1000);\n\n    logger.info("开始执行定时任务");\n    int store = new Random().nextInt(3);\n    XxlJobHelper.log("检查库存，库存余量: {}", store);\n    if (store <= 0) {\n        System.out.println("东西卖的太快了，快添加库存");\n    }\n    logger.info("定时任务执行完毕");\n}\n\n\n我给任务设置的超时时间是3s，在任务中睡了5s，那么任务一定会超时。\n\n\n\n可以看到，这分明是两次执行，但是都没有执行到 Thread.sleep() 后面的一大段代码\n\n打开此任务的调度日志：\n\n',normalizedContent:'# 0. 前言\n\n上一章带大家安装了 xxl-job，下载出来源码一共三个大模块：\n\n- xxl-job-admin\n- xxl-job-core\n- xxl-job-executor-sample\n  - xxl-job-executor-sample-frameless\n  - xxl-job-executor-sample-springboot\n\n\n * xxl-job-admin ：调度中心\n * xxl-job-core ：核心类，其中有调度中心需要的功能和执行器需要的所有功能。\n * xxl-job-executor-sample ：xxl-job提供的实例，有无框架版本、整合spring的版本\n\n\n# 1. 简单任务的执行\n\nxxl-job 提供了一个注解 @xxljob标注定时任务，我们只需要定义一个bean对象，在方法上加上 @xxljob注解，这个方法就成为定时任务方法了。\n\n@target({elementtype.method})\n@retention(retentionpolicy.runtime)\n@inherited\npublic @interface xxljob {\n    string value();\n\n    string init() default "";\n\n    string destroy() default "";\n}\n\n\n可以看到 @xxljob只能指定定时任务的方法名和初始化方法、销毁方法。但是一个定时任务的关键应该是执行频率啊，在哪里指定呢？在web控制台指定。\n\n\n\n###1.1 添加依赖\n\n一定要跟下载的 xxl-job 版本一致 ：\n\n\x3c!-- xxl-job-core --\x3e\n<dependency>\n    <groupid>com.xuxueli</groupid>\n    <artifactid>xxl-job-core</artifactid>\n    <version>2.4.0</version>\n</dependency>\n\n\n\n# 1.2 添加配置\n\n# web port\nserver.port=3999\n# no web\n#spring.main.web-environment=false\n\n# log config\nlogging.config=classpath:logback.xml\n\n\n### xxl-job admin address list, such as "http://address" or "http://address01,http://address02"\nxxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin\n\n### xxl-job, access token\nxxl.job.accesstoken=default_token\n\n### xxl-job executor appname\nxxl.job.executor.appname=xxl-job-executor-sample\n### xxl-job executor registry-address: default use address to registry , otherwise use ip:port if address is null\nxxl.job.executor.address=\n### xxl-job executor server-info\nxxl.job.executor.ip=\nxxl.job.executor.port=9999\n### xxl-job executor log-path\nxxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler\n### xxl-job executor log-retention-days\nxxl.job.executor.logretentiondays=30\n\n\n对了，logging.config 这个日志配置 logback.xml 你如果没有的话可以把 xxl-job-executor-sample-springboot 里的配置拿过来。\n\n\n@configuration\npublic class xxljobconfig {\n    private logger logger = loggerfactory.getlogger(xxljobconfig.class);\n    @value("${xxl.job.admin.addresses}")\n    private string adminaddresses;\n    @value("${xxl.job.accesstoken}")\n    private string accesstoken;\n    @value("${xxl.job.executor.appname}")\n    private string appname;\n    @value("${xxl.job.executor.port}")\n    private int port;\n    @value("${xxl.job.executor.logpath}")\n    private string logpath;\n    @value("${xxl.job.executor.logretentiondays}")\n    private int logretentiondays;\n\n    @bean\n    public xxljobspringexecutor xxljobexecutor() {\n        logger.info(">>>>>>>>>>> xxl-job config init.");\n        xxljobspringexecutor xxljobspringexecutor = new xxljobspringexecutor();\n        xxljobspringexecutor.setadminaddresses(adminaddresses);\n        xxljobspringexecutor.setappname(appname);\n        // 省略 ip 和 address 的配置\n        xxljobspringexecutor.setport(port);\n        xxljobspringexecutor.setaccesstoken(accesstoken);\n        xxljobspringexecutor.setlogpath(logpath);\n        xxljobspringexecutor.setlogretentiondays(logretentiondays);\n\n        return xxljobspringexecutor;\n    }\n}\n\n\n\n# 1.3 添加任务\n\nxxl-job与springboot整合时\n\n 1. 写代码\n    \n    假如我们有一个需求 ：每分钟检查商品的库存是否足够，如果不够就提醒商家添加库存。\n    \n    在代码中只是完成任务 ：\n    \n    import com.xxl.job.core.handler.annotation.xxljob;\n    import org.slf4j.logger;\n    import org.slf4j.loggerfactory;\n    import org.springframework.stereotype.component;\n    \n    import java.util.random;\n    \n    @component\n    public class xxljobhandler {\n        private static final logger logger = loggerfactory.getlogger(xxljobhandler.class);\n        @xxljob("checkstore")\n        public void check() {\n            logger.info("开始执行定时任务");\n            system.out.println("检查库存");\n            int store = new random().nextint(3);\n            if (store <= 0) {\n                system.out.println("东西卖的太快了，快添加库存");\n            }\n            system.out.println("检查完毕");\n            logger.info("定时任务执行完毕");\n        }\n    }\n    \n\n 2. 配置任务\n    \n    打开web控制台，其他的我们不懂也不动，但是要把执行频率改了\n    \n    -- 每分钟指定的corn表达式：\n    0 * * * * ? \n    \n    \n    点击新增任务，将以下四项填完就可以了。\n    \n    \n\n\n# 1.4 执行任务\n\n启动项目，将任务状态改为 启动。\n\n\n\n一共执行了三次~ 可以看到它的精准度还是蛮高的，\n\n好了，现在你可以去web界面将这个任务停止，或者你可以看看这个任务的其他信息\n\n\n# 2. 日志记录\n\n为什么将它作为单独一个章节，因为 xxl-job 的日志是很多人困扰&烦躁的地方，因为每一个任务的每一次执行都对应一个日志文件，如果一个任务每5s执行一次，那么这个任务一天就可以产出 24 * 60 * 60 / 5 = 17280 个日志文件，假设这个任务全部成功，一个文件只有1kb，那就是16m。\n\n现在我们来看看日志都记录了什么，并且在代码中如何将重要信息记录到 xxl-job 的日志文件中。\n\n想看日志就要知道日志在哪，我们通过配置，让 xxl-job 在桌面生成日志;\n\nxxl.job.executor.logpath=c:/users/23825/desktop/xxl-job/jobhandler\n\n\n未来我想看日志，就可以去 c:/users/23825/desktop/xxl-job/jobhandler 查找\n\nxxl-job 提供了一个工具类 ：xxljobhelper，使用 xxljobhelper.log() 就可以记录日志到文件中。\n\n@component\npublic class xxljobhandler {\n    private static final logger logger = loggerfactory.getlogger(xxljobhandler.class);\n    @xxljob("checkstore")\n    public void check() {\n        logger.info("开始执行定时任务");\n        int store = new random().nextint(3);\n        xxljobhelper.log("检查库存，库存余量: {}", store);\n        if (store <= 0) {\n            system.out.println("东西卖的太快了，快添加库存");\n        }\n        logger.info("定时任务执行完毕");\n    }\n}\n\n\n上述代码，每次检查出库存之后都将库存记录到日志中，启动项目，运行任务\n\n好了，在执行几分钟后，你在桌面会看到如下文件夹：c:\\users\\23825\\desktop\\xxl-job\\jobhandler\\2023-11-19\n\n可以猜测 xxl-job 会为每一天创建一个文件夹，每一次执行任务创建一个文件。\n\n随便打开一个日志文件：\n\n2023-11-19 22:52:00 [com.xxl.job.core.thread.jobthread#run]-[133]-[xxl-job, jobthread-2-1700405520094] <br>----------- xxl-job job execute start -----------<br>----------- param:\n2023-11-19 22:52:00 [com.xiaohe.mailtest.job.xxljobhandler#check]-[23]-[xxl-job, jobthread-2-1700405520094] 检查库存，库存余量: 0\n2023-11-19 22:52:00 [com.xxl.job.core.thread.jobthread#run]-[179]-[xxl-job, jobthread-2-1700405520094] <br>----------- xxl-job job execute end(finish) -----------<br>----------- result: handlecode=200, handlemsg = null\n2023-11-19 22:52:00 [com.xxl.job.core.thread.triggercallbackthread#callbacklog]-[197]-[xxl-job, executor triggercallbackthread] <br>----------- xxl-job job callback finish.\n\n\n日志共有四部分\n\n 1. 开始执行的信息 ：负责执行的线程编号\n 2. 程序员打印的信息 ：定时任务的全限定类名+方法名、负责执行的线程编号、自定义的日志信息\n 3. 执行结束的信息 ：执行的结果\n 4. 回调信息 ：执行器将执行结果交给调度中心\n\n如果以后执行的时候出现什么bug就可以往日志里面记录。\n\n\n# 3. 固定速率执行\n\n刚才的简单任务是定时执行，每一分钟执行一次。现在来试试固定速率执行，我们将速率设置为每60s执行一次。\n\n执行之后的日志我就不再贴了。\n\n\n# 4. 执行任务参数\n\nxxl-job的定时任务可以指定参数，这个参数使用 xxljobhelper.getjobparam()获取。获取的是一整个字符串，你需要在自己的代码中切割这个字符串获得你想要的参数：\n\n@xxljob("checkstore")\npublic void check() {\n    string jobparam = xxljobhelper.getjobparam();\n    system.out.println("定时任务的参数: " + jobparam);\n\n    logger.info("开始执行定时任务");\n    int store = new random().nextint(3);\n    xxljobhelper.log("检查库存，库存余量: {}", store);\n    if (store <= 0) {\n        system.out.println("东西卖的太快了，快添加库存");\n    }\n    logger.info("定时任务执行完毕");\n}\n\n\n\n\n\n# 5. 任务超时时间\n\n如果对任务的执行时间有要求，还可以设置任务的最大执行时间，也就是任务超时时间\n\npublic void check() throws interruptedexception {\n    string jobparam = xxljobhelper.getjobparam();\n    system.out.println("定时任务的参数: " + jobparam);\n\n    thread.sleep(5 * 1000);\n\n    logger.info("开始执行定时任务");\n    int store = new random().nextint(3);\n    xxljobhelper.log("检查库存，库存余量: {}", store);\n    if (store <= 0) {\n        system.out.println("东西卖的太快了，快添加库存");\n    }\n    logger.info("定时任务执行完毕");\n}\n\n\n我给任务设置的超时时间是3s，在任务中睡了5s，那么任务一定会超时。\n\n\n\n可以看到，这分明是两次执行，但是都没有执行到 thread.sleep() 后面的一大段代码\n\n打开此任务的调度日志：\n\n',charsets:{cjk:!0},lastUpdated:"2023/11/20, 13:00:13",lastUpdatedTimestamp:1700456413e3},{title:"1. XXL-JOB的安装",frontmatter:{title:"1. XXL-JOB的安装",date:"2023-11-20T12:56:32.000Z",permalink:"/pages/bb013b/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/100.XXL-JOB/1.XXL-JOB%E7%9A%84%E5%AE%89%E8%A3%85.html",relativePath:"02.文章/91.框架/100.XXL-JOB/1.XXL-JOB的安装.md",key:"v-49c73577",path:"/pages/bb013b/",headers:[{level:2,title:"1. 下载",slug:"_1-下载",normalizedTitle:"1. 下载",charIndex:2},{level:2,title:"2. 导入SQL",slug:"_2-导入sql",normalizedTitle:"2. 导入sql",charIndex:230},{level:2,title:"3. 修改配置文件",slug:"_3-修改配置文件",normalizedTitle:"3. 修改配置文件",charIndex:504},{level:2,title:"4. 启动",slug:"_4-启动",normalizedTitle:"4. 启动",charIndex:1352},{level:2,title:"5. 执行实例",slug:"_5-执行实例",normalizedTitle:"5. 执行实例",charIndex:1700}],headersStr:"1. 下载 2. 导入SQL 3. 修改配置文件 4. 启动 5. 执行实例",content:'# 1. 下载\n\nXXL-JOB官网 ：https://www.xuxueli.com/xxl-job/\n\nXXL-JOB源码 ：\n\n * Gitee ：https://gitee.com/xuxueli0323/xxl-job\n * Github ：https://github.com/xuxueli/xxl-job/\n\n尽量去Gitee下载吧，这样快一点。\n\n注意版本哦，下载 2.4.0 或者 2.4.1 的，不要下载 2.2.0 或之前的。\n\n\n# 2. 导入SQL\n\n任务是需要记录的，所以 XXL-JOB 作为一个 SpringBoot 项目是需要MySQL数据库的在以下目录中找到SQL语句：\n\nxxl-job-master\\xxl-job-master\\doc\\db\\tables_xxl_job.sql\n\n在数据库中执行，一共有八张表：\n\n表名\nxxl_job_group\nxxl_job_info\nxxl_job_lock\nxxl_job_log\nxxl_job_log_report\nxxl_job_logglue\nxxl_job_registry\nxxl_job_user\n\n\n# 3. 修改配置文件\n\n找到 xxl-job-admin 项目，修改它的 application.properties 配置文件\n\n 1. 修改数据源 【必做】\n    \n    首先要将数据库改成我们上述导入的数据\n    \n    ### xxl-job, datasource\n    spring.datasource.url=jdbc:mysql://127.0.0.1:3309/xxl_job?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&serverTimezone=Asia/Shanghai\n    spring.datasource.username=root\n    spring.datasource.password=1234\n    spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver\n    \n\n 2. 修改日志文件 【选做】\n    \n    这个涉及到调度中心与执行器了，你可以不必配置这一处东西。\n    \n    一个项目的日志是非常重要的，在 xxl-job 中，每一天对应一个文件夹，这一天每一次执行的任务都对应一个文件，所以 xxl-job 日志的体量非常大。在配置文件中，xxl-job 默认在C盘创建日志，你可以将它放在比较显眼的位置，在后面讲 xxl-job 日志体系的时候更容易找到。\n    \n    在 xxl-job-executor 项目中有一个子项目：xxl-job-executor-sample-springboot 的 application.properties\n    \n    ### xxl-job executor log-path\n    xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler\n    \n\n\n# 4. 启动\n\n如果你已经更改好了上述的配置文件，现在就可以运行xxl-job-admin了，找到 XxlJobAdminApplication 启动类，点击运行后：\n\n20:27:40.009 logback [xxl-job, admin JobScheduleHelper#scheduleThread] INFO  c.x.j.a.c.thread.JobScheduleHelper - >>>>>>>>> init xxl-job admin scheduler success.\n\n\n显示这个算是运行成功，现在你可以登录web界面：http://localhost:8080/xxl-job-admin\n\n用户名 ：admin\n\n密码 ：123456\n\n登陆成功界面 ：\n\n\n\n\n# 5. 执行实例\n\n很多开源项目都提供了example，xxl-job也不例外，在 xxl-job-executor 项目中有一个子项目：xxl-job-executor-sample-springboot 就是集成了SpringBoot 的实例，打开它，运行。\n\n20:36:01.962 logback [Thread-8] INFO  com.xxl.job.core.server.EmbedServer - >>>>>>>>>>> xxl-job remoting server start success, nettype = class com.xxl.job.core.server.EmbedServer, port = 9999\n\n\n出现这个就是运行成功了。\n\n现在有两个进程启动了：\n\n\n\n * XxlJobAdminApplication ：调度中心\n * XxlJobExecutorApplication ：执行器\n\n实例的路径：com/xxl/job/executor/service/jobhandler/SampleXxlJob.java\n\n打开后看到一个示例任务\n\n@Component\npublic class SampleXxlJob {\n    private static Logger logger = LoggerFactory.getLogger(SampleXxlJob.class);\n\n\n    /**\n     * 1、简单任务示例（Bean模式）\n     */\n    @XxlJob("demoJobHandler")\n    public void demoJobHandler() throws Exception {\n        System.out.println("简单任务实例执行了");\n        // default success\n    }\n    \n    // ...省略其他的任务\n}\n\n\n我们想要让这个任务运行该怎么办？打开web界面 -> 任务管理 -> 测试任务一 -> 操作 -> 执行一次。\n\n\n\n于是，XxlJobExecutorApplication 的控制台就会出现 ：\n\n简单任务实例执行了\n',normalizedContent:'# 1. 下载\n\nxxl-job官网 ：https://www.xuxueli.com/xxl-job/\n\nxxl-job源码 ：\n\n * gitee ：https://gitee.com/xuxueli0323/xxl-job\n * github ：https://github.com/xuxueli/xxl-job/\n\n尽量去gitee下载吧，这样快一点。\n\n注意版本哦，下载 2.4.0 或者 2.4.1 的，不要下载 2.2.0 或之前的。\n\n\n# 2. 导入sql\n\n任务是需要记录的，所以 xxl-job 作为一个 springboot 项目是需要mysql数据库的在以下目录中找到sql语句：\n\nxxl-job-master\\xxl-job-master\\doc\\db\\tables_xxl_job.sql\n\n在数据库中执行，一共有八张表：\n\n表名\nxxl_job_group\nxxl_job_info\nxxl_job_lock\nxxl_job_log\nxxl_job_log_report\nxxl_job_logglue\nxxl_job_registry\nxxl_job_user\n\n\n# 3. 修改配置文件\n\n找到 xxl-job-admin 项目，修改它的 application.properties 配置文件\n\n 1. 修改数据源 【必做】\n    \n    首先要将数据库改成我们上述导入的数据\n    \n    ### xxl-job, datasource\n    spring.datasource.url=jdbc:mysql://127.0.0.1:3309/xxl_job?useunicode=true&characterencoding=utf-8&autoreconnect=true&servertimezone=asia/shanghai\n    spring.datasource.username=root\n    spring.datasource.password=1234\n    spring.datasource.driver-class-name=com.mysql.cj.jdbc.driver\n    \n\n 2. 修改日志文件 【选做】\n    \n    这个涉及到调度中心与执行器了，你可以不必配置这一处东西。\n    \n    一个项目的日志是非常重要的，在 xxl-job 中，每一天对应一个文件夹，这一天每一次执行的任务都对应一个文件，所以 xxl-job 日志的体量非常大。在配置文件中，xxl-job 默认在c盘创建日志，你可以将它放在比较显眼的位置，在后面讲 xxl-job 日志体系的时候更容易找到。\n    \n    在 xxl-job-executor 项目中有一个子项目：xxl-job-executor-sample-springboot 的 application.properties\n    \n    ### xxl-job executor log-path\n    xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler\n    \n\n\n# 4. 启动\n\n如果你已经更改好了上述的配置文件，现在就可以运行xxl-job-admin了，找到 xxljobadminapplication 启动类，点击运行后：\n\n20:27:40.009 logback [xxl-job, admin jobschedulehelper#schedulethread] info  c.x.j.a.c.thread.jobschedulehelper - >>>>>>>>> init xxl-job admin scheduler success.\n\n\n显示这个算是运行成功，现在你可以登录web界面：http://localhost:8080/xxl-job-admin\n\n用户名 ：admin\n\n密码 ：123456\n\n登陆成功界面 ：\n\n\n\n\n# 5. 执行实例\n\n很多开源项目都提供了example，xxl-job也不例外，在 xxl-job-executor 项目中有一个子项目：xxl-job-executor-sample-springboot 就是集成了springboot 的实例，打开它，运行。\n\n20:36:01.962 logback [thread-8] info  com.xxl.job.core.server.embedserver - >>>>>>>>>>> xxl-job remoting server start success, nettype = class com.xxl.job.core.server.embedserver, port = 9999\n\n\n出现这个就是运行成功了。\n\n现在有两个进程启动了：\n\n\n\n * xxljobadminapplication ：调度中心\n * xxljobexecutorapplication ：执行器\n\n实例的路径：com/xxl/job/executor/service/jobhandler/samplexxljob.java\n\n打开后看到一个示例任务\n\n@component\npublic class samplexxljob {\n    private static logger logger = loggerfactory.getlogger(samplexxljob.class);\n\n\n    /**\n     * 1、简单任务示例（bean模式）\n     */\n    @xxljob("demojobhandler")\n    public void demojobhandler() throws exception {\n        system.out.println("简单任务实例执行了");\n        // default success\n    }\n    \n    // ...省略其他的任务\n}\n\n\n我们想要让这个任务运行该怎么办？打开web界面 -> 任务管理 -> 测试任务一 -> 操作 -> 执行一次。\n\n\n\n于是，xxljobexecutorapplication 的控制台就会出现 ：\n\n简单任务实例执行了\n',charsets:{cjk:!0},lastUpdated:"2023/11/20, 13:00:13",lastUpdatedTimestamp:1700456413e3},{title:"XXL-JOB负载均衡策略",frontmatter:{title:"XXL-JOB负载均衡策略",date:"2023-08-17T17:41:45.000Z",permalink:"/pages/75326c/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/100.XXL-JOB/20.XXL-JOB%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5.html",relativePath:"02.文章/91.框架/100.XXL-JOB/20.XXL-JOB负载均衡策略.md",key:"v-2a546378",path:"/pages/75326c/",headers:[{level:2,title:"1. 简述",slug:"_1-简述",normalizedTitle:"1. 简述",charIndex:2},{level:2,title:"2. 选取第一个、最后一个",slug:"_2-选取第一个、最后一个",normalizedTitle:"2. 选取第一个、最后一个",charIndex:770},{level:2,title:"3. 随机选取",slug:"_3-随机选取",normalizedTitle:"3. 随机选取",charIndex:623},{level:2,title:"4. 轮询",slug:"_4-轮询",normalizedTitle:"4. 轮询",charIndex:632},{level:2,title:"5. LRU",slug:"_5-lru",normalizedTitle:"5. lru",charIndex:5464},{level:2,title:"6. LFU",slug:"_6-lfu",normalizedTitle:"6. lfu",charIndex:7745},{level:2,title:"7. hash",slug:"_7-hash",normalizedTitle:"7. hash",charIndex:671},{level:2,title:"8. 忙碌转移",slug:"_8-忙碌转移",normalizedTitle:"8. 忙碌转移",charIndex:680},{level:2,title:"9. 故障转移",slug:"_9-故障转移",normalizedTitle:"9. 故障转移",charIndex:689}],headersStr:"1. 简述 2. 选取第一个、最后一个 3. 随机选取 4. 轮询 5. LRU 6. LFU 7. hash 8. 忙碌转移 9. 故障转移",content:'# 1. 简述\n\n算法要服务于业务才能体现出它的价值，算法只是提供了整体上的思路，至于如何实现它，那要看具体的业务场景，所以我首先要介绍一下 XXL-JOB 使用负载均衡策略的背景 ：由于XXL-JOB的自我定位是**分布式定时任务框架。所以一个任务可能部署在多个服务器上，但是我们只想要一个机器可以执行这个任务**。那么在执行的时候就需要挑选一个 IP 地址去执行这个任务。\n\nXXL-JOB 中使用策略设计模式实现负载均衡算法，源码地址：XXL-JOB负载均衡策略。\n\n首先是顶级接口 ：\n\npublic abstract class ExecutorRouter {\n\n    public abstract ReturnT<String> route(int jobId, \n                                          List<String> addressList);\n\n}\n\n\n我把它改装了一下，route 方法的第一个参数在源码中其实并不是 jobId，它是一个类，但是文章的重点是介绍负载均衡算法，所以此处直截了当使用 jobId。先介绍一下两个参数：\n\n 1. jobId ：定时任务的id\n 2. addressList ：该定时任务可以被这些 IP 地址执行，但是我们要从中选取一个。\n\nXXL-JOB使用的负载均衡策略共有 9 种：\n\n 1. 选取第一个\n 2. 选取最后一个\n 3. 随机选取\n 4. 轮询\n 5. 最近最少使用（LRU）\n 6. 最少频率使用（LFU）\n 7. hash\n 8. 忙碌转移\n 9. 故障转移\n\n前两种太简单了，放在一起介绍。\n\n最后两种策略其实就很偏业务了，如果对XXL-JOB的了解不够的话可能看不懂，但是我会尽力将它写明白。\n\n\n# 2. 选取第一个、最后一个\n\n这两种非常简单，方法参数中已经有了 IP地址 集合，那我们直接 list.get(0)、list.get(list.size() - 1) 不就行了？\n\n事实上 XXL-JOB 确实是这么做的。\n\n选取第一个：\n\npublic class ExecutorRouteFirst extends ExecutorRouter {\n\n    @Override\n    public ReturnT<String> route(int jobId, List<String> addressList){\n        return new ReturnT<String>(addressList.get(0));\n    }\n\n}\n\n\n选取最后一个 ：\n\npublic class ExecutorRouteLast extends ExecutorRouter {\n\n    @Override\n    public ReturnT<String> route(int jobId, List<String> addressList) {\n        return new ReturnT<String>(addressList.get(addressList.size()-1));\n    }\n\n}\n\n\n是不是很简单？我就不再多说了哈。\n\n\n# 3. 随机选取\n\n如果在一个集合中随机选取一个数据，你会怎么做？生成一个随机数，这个随机数的范围为：[0，list.size() - 1]。这样不就行了吗😁\n\npublic class ExecutorRouteRandom extends ExecutorRouter {\n\n    private static Random localRandom = new Random();\n\n    @Override\n    public ReturnT<String> route(int jobId, List<String> addressList) {\n        String address = addressList.get(localRandom.nextInt(addressList.size()));\n        return new ReturnT<String>(address);\n    }\n\n}\n\n\n\n# 4. 轮询\n\n这个听起来很容易，但是实现的时候非常依赖于业务。XXL-JOB在实现的时候是这样做的 ：将所有定时任务与它们对应的 IP地址 都放在一个 Map 中管理。但是如何轮询呢？这样没有办法轮询啊，我们并不知道下一次该谁了，所以要改变一下思维，既然在方法参数中已经有了 IP地址 集合，那么可以在 Map 的 value 中记录：下一次该第几个了。所以 Map 的 key 为 定时任务id，value 为 下一次需要轮询的下标。\n\n说着挺简单，来看看 xxl-job 是怎么做的吧：\n\npublic class ExecutorRouteRound extends ExecutorRouter {\n    // key : 定时任务id\n    // value : 该id的定时任务轮询到哪一个下标了。\n    private static ConcurrentMap<Integer, AtomicInteger> routeCountEachJob \n        = new ConcurrentHashMap<>();\n\n    @Override\n    public ReturnT<String> route(int jobId, List<String> addressList) {\n        int count = count(jobId);\n        String address = addressList.get(count % addressList.size());\n        return new ReturnT<String>(address);\n    }\n    \n    // 获取指定定时任务id轮询的下标\n    private static int count(int jobId) {\n        AtomicInteger count = routeCountEachJob.get(jobId);\n        if (count == null || count.get() > 1000000) {\n            count = new AtomicInteger(0);\n        } else {\n            count.addAndGet(1);\n        }\n        routeCountEachJob.put(jobId, count);\n        return count.get();\n    }\n\n}\n\n\n主要是 count() 方法，它会获取指定id的定时任务该轮询到的下标。\n\n// 获取指定定时任务id轮询的下标\nprivate static int count(int jobId) {\n    AtomicInteger count = routeCountEachJob.get(jobId);\n    if (count == null) {\n        count = new AtomicInteger(0);\n    } else {\n        count.addAndGet(1);\n    }\n    routeCountEachJob.put(jobId, count);\n    return count.get();\n}\n\n\n如果此 定时任务id 在 Map 中不存在，那就新建一个，并将轮询下标初始化为 0，如果已经存在就将轮询下标加一，然后返回，这样的逻辑还是挺简单的。\n\n但是你有没有想过：如果此时有100个定时任务，它们都使用到了同样的100台机器，那么它们每一次执行时负载均衡得到的 IP地址 是一样的啊。\n\n使用负载均衡算法的初心是让请求分散，减小服务器压力。但此时明显还是亚历山大。那怎样才能让 这种情况消失呢？\n\n我们可以给初始的轮询下标生成随机值，这样它们轮询的顺序就不一样了，我从第一个开始，你从第五个开始，我们互不干扰~ 于是，初始值设置为 0 就不可取，我们设置0 - 100 以内的随机值。\n\n// 获取指定定时任务id轮询的下标\nprivate static int count(int jobId) {\n    AtomicInteger count = routeCountEachJob.get(jobId);\n    if (count == null) {\n        count = new AtomicInteger(new Random().nextInt(100));\n    } else {\n        count.addAndGet(1);\n    }\n    routeCountEachJob.put(jobId, count);\n    return count.get();\n}\n\n\n可现在还是有问题：如果一个定时任务轮询的次数太多了，超过了 int 类型的上限怎么办？我们需要在轮询下标达到某一个阈值时将它重置为随机数：不止count == null 时可以设置随机值，count.get() > 1000000 时也可以。\n\n// 获取指定定时任务id轮询的下标\nprivate static int count(int jobId) {\n    AtomicInteger count = routeCountEachJob.get(jobId);\n    if (count == null || count.get() > 1000000) {\n        count = new AtomicInteger(new Random().nextInt(100));\n    } else {\n        count.addAndGet(1);\n    }\n    routeCountEachJob.put(jobId, count);\n    return count.get();\n}\n\n\n现在和源码已经很接近了，源码中是以一天为单位重置定时任务的轮询下标的，如何重置？直接将 Map 清空。\n\npublic class ExecutorRouteRound extends ExecutorRouter {\n\n    private static ConcurrentMap<Integer, AtomicInteger> routeCountEachJob =\n        new ConcurrentHashMap<>();\n    \n    private static long CACHE_VALID_TIME = 0;\n    \n    @Override\n    public ReturnT<String> route(int jobId, List<String> addressList) {\n        int count = count(jobId);\n        String address = addressList.get(count % addressList.size());\n        return new ReturnT<String>(address);\n    }\n\n    private static int count(int jobId) {\n        // 每天都清空 Map\n        if (System.currentTimeMillis() > CACHE_VALID_TIME) {\n            routeCountEachJob.clear();\n            // 将过期时间指定为一天后\n            CACHE_VALID_TIME = System.currentTimeMillis() + 1000*60*60*24;\n        }\n        \n        AtomicInteger count = routeCountEachJob.get(jobId);\n        if (count == null || count.get() > 1000000) {\n            // 初始化时主动Random一次，缓解首次压力\n            count = new AtomicInteger(new Random().nextInt(100));\n        } else {\n            // count++\n            count.addAndGet(1);\n        }\n        routeCountEachJob.put(jobId, count);\n        return count.get();\n    }\n}\n\n\n\n# 5. LRU\n\nLRU 我就不再多做介绍了吧，优先使用很久没有使用过的 IP 地址，借助 Java 提供的 LinkedHashMap 实现。\n\nXXL-JOB 实现 LRU 算法时也是用到了 Map ，key 为 任务id，value 为 LinkedHashMap，内部含有该定时任务的所有IP地址。\n\npublic class ExecutorRouteLRU extends ExecutorRouter {\n    // key : 定时任务id\n    // value : LinkedHashMap, key : IP地址\n    //                        value : IP地址\n    // LinkedHashMap的key和value都是IP地址，并没有什么特殊含义\n    private static ConcurrentMap<Integer, LinkedHashMap<String, String>> \n        jobLRUMap = new ConcurrentHashMap<Integer, LinkedHashMap<String, String>>();\n\n    // Map中数据的缓存时间\n    private static long CACHE_VALID_TIME = 0;\n\n    public String get(int jobId, List<String> addressList) {\n        // 每天刷新\n        if (System.currentTimeMillis() > CACHE_VALID_TIME) {\n            jobLRUMap.clear();\n            CACHE_VALID_TIME = System.currentTimeMillis() + 1000*60*60*24;\n        }\n        \n        // 根据定时任务id从jobLRUMap中获得对应的Map\n        LinkedHashMap<String, String> lruItem = jobLRUMap.get(jobId);\n        if (lruItem == null) {\n            lruItem = new LinkedHashMap<String, String>(16, 0.75f, true);\n            // 把Map放到jobLRUMap中\n            jobLRUMap.putIfAbsent(jobId, lruItem);\n        }\n        // 由于 jobLRUMap 中会存储定时任务对应的所有IP地址，所以要和传入的最新IP地址做同步\n        // 判断有没有新添加的IP\n        for (String address: addressList) {\n            //如果有就把它加入到lruItem中\n            if (!lruItem.containsKey(address)) {\n                lruItem.put(address, address);\n            }\n        }\n        // 判断有没有需要删除IP\n        List<String> delKeys = new ArrayList<>();\n        for (String existKey: lruItem.keySet()) {\n            if (!addressList.contains(existKey)) {\n                delKeys.add(existKey);\n            }\n        }\n        //有就把执行器删除\n        if (delKeys.size() > 0) {\n            for (String delKey: delKeys) {\n                lruItem.remove(delKey);\n            }\n        }\n        // 获取LinkedHashMap中第一个元素并返回。\n        String eldestKey = lruItem.entrySet().iterator().next().getKey();\n        String eldestValue = lruItem.get(eldestKey);\n        return eldestValue;\n    }\n\n    @Override\n    public ReturnT<String> route(int jobId, List<String> addressList) {\n        String address = get(jobId, addressList);\n        return new ReturnT<String>(address);\n    }\n    \n}\n\n\n可以看到其实没啥操作，代码行数多的地方就是 同步 Map 中的 IP 与作为参数传入的 IP 地址。\n\n\n# 6. LFU\n\nLFU ：优先用那些 使用频率小的。\n\n可以使用一个 Map，key装定时任务id，value 还是一个Map，这个内部的 Map 的key是IP 地址，value是该 IP 地址的使用次数。\n\nConcurrentMap<Integer, HashMap<String, Integer>> jobLfuMap \n    = new ConcurrentHashMap<Integer, HashMap<String, Integer>>();\n\n\n当要选择时，将任务id对应的 Map 提取出来，按照 使用次数排序，将用的最少的那个返回就行了\n\npublic class ExecutorRouteLFU extends ExecutorRouter {\n    //这个Map缓存的key-value中的key就是定时任务的id，value是一个map，这个map中缓存的是执行器的地址和该地址被使用的次数\n    private static ConcurrentMap<Integer, HashMap<String, Integer>> jobLfuMap \n        = new ConcurrentHashMap<Integer, HashMap<String, Integer>>();\n    private static long CACHE_VALID_TIME = 0;\n\n    public String get(int jobId, List<String> addressList) {\n        // 每天都更新\n        if (System.currentTimeMillis() > CACHE_VALID_TIME) {\n            jobLfuMap.clear();\n            CACHE_VALID_TIME = System.currentTimeMillis() + 1000*60*60*24;\n        }\n        // 先通过定时任务的id从jobLfuMap中获得对应的value\n        HashMap<String, Integer> lfuItemMap = jobLfuMap.get(jobId);\n        //如果value为空，则创建一个Map\n        if (lfuItemMap == null) {\n            lfuItemMap = new HashMap<String, Integer>();\n            jobLfuMap.putIfAbsent(jobId, lfuItemMap);   \n        }\n        //下面开始遍历执行器地址集合\n        for (String address: addressList) {\n            // 如果是第一次使用，或者使用次数太多了，就更新使用次数\n            if (!lfuItemMap.containsKey(address) || lfuItemMap.get(address) >1000000 ) {\n      \t\t\t// 这里使用随机数的原因: 为了避免第一次负载均衡时很多定时任务都选择了同一台机器，\n                // 使用随机数避免这个情况。\n                lfuItemMap.put(address, new Random().nextInt(addressList.size()));\n            }\n        }\n        // 开始同步IP地址\n        //判断有没有过期的IP地址\n        List<String> delKeys = new ArrayList<>();\n        for (String existKey: lfuItemMap.keySet()) {\n            if (!addressList.contains(existKey)) {\n                delKeys.add(existKey);\n            }\n        }\n        //如果有就把过期的IP地址从lfuItemMap中移除\n        if (delKeys.size() > 0) {\n            for (String delKey: delKeys) {\n                lfuItemMap.remove(delKey);\n            }\n        } \n        // 下面就开始选择具体的执行器来执行定时任务了，把lfuItemMap中的数据转移到lfuItemList中\n        List<Map.Entry<String, Integer>> lfuItemList \n            = new ArrayList<Map.Entry<String, Integer>>(lfuItemMap.entrySet());\n        \n        // 将lfuItemList中的数据按照执行器的使用次数做排序\n        Collections.sort(lfuItemList, new Comparator<Map.Entry<String, Integer>>() {\n            @Override\n            public int compare(Map.Entry<String, Integer> o1, Map.Entry<String, Integer> o2) {\n                return o1.getValue().compareTo(o2.getValue());\n            }\n        });\n        // 获取到的第一个就是使用次数最少的执行器\n        Map.Entry<String, Integer> addressItem = lfuItemList.get(0);\n        String minAddress = addressItem.getKey();\n        //因为要是用它了，所以把执行器的使用次数加1\n        addressItem.setValue(addressItem.getValue() + 1);\n        //返回执行器地址\n        return addressItem.getKey();\n    }\n\n    @Override\n    public ReturnT<String> route(int jobId, List<String> addressList) {\n        String address = get(jobId, addressList);\n        return new ReturnT<String>(address);\n    }\n\n}\n\n\n\n# 7. hash\n\n这个我没有看懂，等到看懂了再说吧\n\n// TODO\n\npublic class ExecutorRouteConsistentHash extends ExecutorRouter {\n\n    private static int VIRTUAL_NODE_NUM = 100;\n\n    private static long hash(String key) {\n        MessageDigest md5;\n        try {\n            md5 = MessageDigest.getInstance("MD5");\n        } catch (NoSuchAlgorithmException e) {\n            throw new RuntimeException("MD5 not supported", e);\n        }\n        md5.reset();\n        byte[] keyBytes = null;\n        try {\n            keyBytes = key.getBytes("UTF-8");\n        } catch (UnsupportedEncodingException e) {\n            throw new RuntimeException("Unknown string :" + key, e);\n        }\n        md5.update(keyBytes);\n        byte[] digest = md5.digest();\n        long hashCode = ((long) (digest[3] & 0xFF) << 24)\n                | ((long) (digest[2] & 0xFF) << 16)\n                | ((long) (digest[1] & 0xFF) << 8)\n                | (digest[0] & 0xFF);\n        long truncateHashCode = hashCode & 0xffffffffL;\n        return truncateHashCode;\n    }\n\n\n    public String hashJob(int jobId, List<String> addressList) {\n        TreeMap<Long, String> addressRing = new TreeMap<Long, String>();\n        for (String address: addressList) {\n            for (int i = 0; i < VIRTUAL_NODE_NUM; i++) {\n                long addressHash = hash("SHARD-" + address + "-NODE-" + i);\n                addressRing.put(addressHash, address);\n            }\n        }\n        long jobHash = hash(String.valueOf(jobId));\n        SortedMap<Long, String> lastRing = addressRing.tailMap(jobHash);\n        if (!lastRing.isEmpty()) {\n            return lastRing.get(lastRing.firstKey());\n        }\n        return addressRing.firstEntry().getValue();\n    }\n\n    @Override\n    public ReturnT<String> route(TriggerParam triggerParam, List<String> addressList) {\n        String address = hashJob(triggerParam.getJobId(), addressList);\n        return new ReturnT<String>(address);\n    }\n\n}\n\n\n\n# 8. 忙碌转移\n\n见名思意 ：如果该 IP地址 正在执行该定时任务，那么此次负载均衡就不使用这个IP。\n\n怎么知道该 IP地址 是否在执行该定时任务呢？发消息问呗。\n\nXXL-JOB 为任务分配了线程，也就是一个线程专门负责一类定时任务，那么我们只需要给该IP地址服务器发送消息，询问 该定时任务id对应的线程是否在工作中，如果没有在工作中，可以将此任务分配给它；如果在工作中，那就不打扰他了，继续询问下一个IP。\n\npublic class ExecutorRouteBusyover extends ExecutorRouter {\n\n    @Override\n    public ReturnT<String> route(int jobId, List<String> addressList) {\n        StringBuffer idleBeatResultSB = new StringBuffer();\n        // 遍历IP地址,挨个询问\n        for (String address : addressList) {\n            ReturnT<String> idleBeatResult = null;\n            try {\n                // 得到向指定IP地址发送消息的客户端\n                ExecutorBiz executorBiz = XxlJobScheduler.getExecutorBiz(address);\n                // 向客户端发送忙碌检测请求，判断该执行器的定时任务线程是否正在执行对应的定时任务\n                // 如果正在执行，说明比较忙碌，就不使用该地址\n                idleBeatResult = executorBiz.idleBeat(new IdleBeatParam(jobId));\n            } catch (Exception e) {\n                logger.error(e.getMessage(), e);\n                idleBeatResult = new ReturnT<String>(ReturnT.FAIL_CODE, ""+e );\n            }\n            idleBeatResultSB.append( (idleBeatResultSB.length()>0)?"<br><br>":"")\n                    .append(I18nUtil.getString("jobconf_idleBeat") + "：")\n                    .append("<br>address：").append(address)\n                    .append("<br>code：").append(idleBeatResult.getCode())\n                    .append("<br>msg：").append(idleBeatResult.getMsg());\n            // 如果不忙碌就直接使用该地址\n            if (idleBeatResult.getCode() == ReturnT.SUCCESS_CODE) {\n                idleBeatResult.setMsg(idleBeatResultSB.toString());\n                idleBeatResult.setContent(address);\n                return idleBeatResult;\n            }\n        }\n        // 如果全都在忙碌，直接返回fail\n        return new ReturnT<String>(ReturnT.FAIL_CODE, idleBeatResultSB.toString());\n    }\n\n}\n\n\n\n# 9. 故障转移\n\n这个策略比忙碌转移容易实现，故障转移就是看看 该IP地址能不能用，如果它没有下线就可以使用，如果下线了肯定不能使用。只需要发消息问问对应IP的执行器。\n\npublic class ExecutorRouteFailover extends ExecutorRouter {\n\n    @Override\n    public ReturnT<String> route(int jobId, List<String> addressList) {\n        StringBuffer beatResultSB = new StringBuffer();\n        // 遍历得到的执行器的IP地址\n        for (String address : addressList) {\n            ReturnT<String> beatResult = null;\n            try {\n                // 得到访问执行器的客户端\n                ExecutorBiz executorBiz = XxlJobScheduler.getExecutorBiz(address);\n                // 向执行器发送心跳检测请求，看执行器是否还在线\n                beatResult = executorBiz.beat();\n            } catch (Exception e) {\n                logger.error(e.getMessage(), e);\n                beatResult = new ReturnT<String>(ReturnT.FAIL_CODE, ""+e );\n            }\n            beatResultSB.append( (beatResultSB.length()>0)?"<br><br>":"")\n                    .append(I18nUtil.getString("jobconf_beat") + "：")\n                    .append("<br>address：").append(address)\n                    .append("<br>code：").append(beatResult.getCode())\n                    .append("<br>msg：").append(beatResult.getMsg());\n            // 心跳检测没问题，就直接使用该执行器\n            if (beatResult.getCode() == ReturnT.SUCCESS_CODE) {\n\n                beatResult.setMsg(beatResultSB.toString());\n                beatResult.setContent(address);\n                return beatResult;\n            }\n        }\n        // 所有执行器都不能执行\n        return new ReturnT<String>(ReturnT.FAIL_CODE, beatResultSB.toString());\n    }\n}\n',normalizedContent:'# 1. 简述\n\n算法要服务于业务才能体现出它的价值，算法只是提供了整体上的思路，至于如何实现它，那要看具体的业务场景，所以我首先要介绍一下 xxl-job 使用负载均衡策略的背景 ：由于xxl-job的自我定位是**分布式定时任务框架。所以一个任务可能部署在多个服务器上，但是我们只想要一个机器可以执行这个任务**。那么在执行的时候就需要挑选一个 ip 地址去执行这个任务。\n\nxxl-job 中使用策略设计模式实现负载均衡算法，源码地址：xxl-job负载均衡策略。\n\n首先是顶级接口 ：\n\npublic abstract class executorrouter {\n\n    public abstract returnt<string> route(int jobid, \n                                          list<string> addresslist);\n\n}\n\n\n我把它改装了一下，route 方法的第一个参数在源码中其实并不是 jobid，它是一个类，但是文章的重点是介绍负载均衡算法，所以此处直截了当使用 jobid。先介绍一下两个参数：\n\n 1. jobid ：定时任务的id\n 2. addresslist ：该定时任务可以被这些 ip 地址执行，但是我们要从中选取一个。\n\nxxl-job使用的负载均衡策略共有 9 种：\n\n 1. 选取第一个\n 2. 选取最后一个\n 3. 随机选取\n 4. 轮询\n 5. 最近最少使用（lru）\n 6. 最少频率使用（lfu）\n 7. hash\n 8. 忙碌转移\n 9. 故障转移\n\n前两种太简单了，放在一起介绍。\n\n最后两种策略其实就很偏业务了，如果对xxl-job的了解不够的话可能看不懂，但是我会尽力将它写明白。\n\n\n# 2. 选取第一个、最后一个\n\n这两种非常简单，方法参数中已经有了 ip地址 集合，那我们直接 list.get(0)、list.get(list.size() - 1) 不就行了？\n\n事实上 xxl-job 确实是这么做的。\n\n选取第一个：\n\npublic class executorroutefirst extends executorrouter {\n\n    @override\n    public returnt<string> route(int jobid, list<string> addresslist){\n        return new returnt<string>(addresslist.get(0));\n    }\n\n}\n\n\n选取最后一个 ：\n\npublic class executorroutelast extends executorrouter {\n\n    @override\n    public returnt<string> route(int jobid, list<string> addresslist) {\n        return new returnt<string>(addresslist.get(addresslist.size()-1));\n    }\n\n}\n\n\n是不是很简单？我就不再多说了哈。\n\n\n# 3. 随机选取\n\n如果在一个集合中随机选取一个数据，你会怎么做？生成一个随机数，这个随机数的范围为：[0，list.size() - 1]。这样不就行了吗😁\n\npublic class executorrouterandom extends executorrouter {\n\n    private static random localrandom = new random();\n\n    @override\n    public returnt<string> route(int jobid, list<string> addresslist) {\n        string address = addresslist.get(localrandom.nextint(addresslist.size()));\n        return new returnt<string>(address);\n    }\n\n}\n\n\n\n# 4. 轮询\n\n这个听起来很容易，但是实现的时候非常依赖于业务。xxl-job在实现的时候是这样做的 ：将所有定时任务与它们对应的 ip地址 都放在一个 map 中管理。但是如何轮询呢？这样没有办法轮询啊，我们并不知道下一次该谁了，所以要改变一下思维，既然在方法参数中已经有了 ip地址 集合，那么可以在 map 的 value 中记录：下一次该第几个了。所以 map 的 key 为 定时任务id，value 为 下一次需要轮询的下标。\n\n说着挺简单，来看看 xxl-job 是怎么做的吧：\n\npublic class executorrouteround extends executorrouter {\n    // key : 定时任务id\n    // value : 该id的定时任务轮询到哪一个下标了。\n    private static concurrentmap<integer, atomicinteger> routecounteachjob \n        = new concurrenthashmap<>();\n\n    @override\n    public returnt<string> route(int jobid, list<string> addresslist) {\n        int count = count(jobid);\n        string address = addresslist.get(count % addresslist.size());\n        return new returnt<string>(address);\n    }\n    \n    // 获取指定定时任务id轮询的下标\n    private static int count(int jobid) {\n        atomicinteger count = routecounteachjob.get(jobid);\n        if (count == null || count.get() > 1000000) {\n            count = new atomicinteger(0);\n        } else {\n            count.addandget(1);\n        }\n        routecounteachjob.put(jobid, count);\n        return count.get();\n    }\n\n}\n\n\n主要是 count() 方法，它会获取指定id的定时任务该轮询到的下标。\n\n// 获取指定定时任务id轮询的下标\nprivate static int count(int jobid) {\n    atomicinteger count = routecounteachjob.get(jobid);\n    if (count == null) {\n        count = new atomicinteger(0);\n    } else {\n        count.addandget(1);\n    }\n    routecounteachjob.put(jobid, count);\n    return count.get();\n}\n\n\n如果此 定时任务id 在 map 中不存在，那就新建一个，并将轮询下标初始化为 0，如果已经存在就将轮询下标加一，然后返回，这样的逻辑还是挺简单的。\n\n但是你有没有想过：如果此时有100个定时任务，它们都使用到了同样的100台机器，那么它们每一次执行时负载均衡得到的 ip地址 是一样的啊。\n\n使用负载均衡算法的初心是让请求分散，减小服务器压力。但此时明显还是亚历山大。那怎样才能让 这种情况消失呢？\n\n我们可以给初始的轮询下标生成随机值，这样它们轮询的顺序就不一样了，我从第一个开始，你从第五个开始，我们互不干扰~ 于是，初始值设置为 0 就不可取，我们设置0 - 100 以内的随机值。\n\n// 获取指定定时任务id轮询的下标\nprivate static int count(int jobid) {\n    atomicinteger count = routecounteachjob.get(jobid);\n    if (count == null) {\n        count = new atomicinteger(new random().nextint(100));\n    } else {\n        count.addandget(1);\n    }\n    routecounteachjob.put(jobid, count);\n    return count.get();\n}\n\n\n可现在还是有问题：如果一个定时任务轮询的次数太多了，超过了 int 类型的上限怎么办？我们需要在轮询下标达到某一个阈值时将它重置为随机数：不止count == null 时可以设置随机值，count.get() > 1000000 时也可以。\n\n// 获取指定定时任务id轮询的下标\nprivate static int count(int jobid) {\n    atomicinteger count = routecounteachjob.get(jobid);\n    if (count == null || count.get() > 1000000) {\n        count = new atomicinteger(new random().nextint(100));\n    } else {\n        count.addandget(1);\n    }\n    routecounteachjob.put(jobid, count);\n    return count.get();\n}\n\n\n现在和源码已经很接近了，源码中是以一天为单位重置定时任务的轮询下标的，如何重置？直接将 map 清空。\n\npublic class executorrouteround extends executorrouter {\n\n    private static concurrentmap<integer, atomicinteger> routecounteachjob =\n        new concurrenthashmap<>();\n    \n    private static long cache_valid_time = 0;\n    \n    @override\n    public returnt<string> route(int jobid, list<string> addresslist) {\n        int count = count(jobid);\n        string address = addresslist.get(count % addresslist.size());\n        return new returnt<string>(address);\n    }\n\n    private static int count(int jobid) {\n        // 每天都清空 map\n        if (system.currenttimemillis() > cache_valid_time) {\n            routecounteachjob.clear();\n            // 将过期时间指定为一天后\n            cache_valid_time = system.currenttimemillis() + 1000*60*60*24;\n        }\n        \n        atomicinteger count = routecounteachjob.get(jobid);\n        if (count == null || count.get() > 1000000) {\n            // 初始化时主动random一次，缓解首次压力\n            count = new atomicinteger(new random().nextint(100));\n        } else {\n            // count++\n            count.addandget(1);\n        }\n        routecounteachjob.put(jobid, count);\n        return count.get();\n    }\n}\n\n\n\n# 5. lru\n\nlru 我就不再多做介绍了吧，优先使用很久没有使用过的 ip 地址，借助 java 提供的 linkedhashmap 实现。\n\nxxl-job 实现 lru 算法时也是用到了 map ，key 为 任务id，value 为 linkedhashmap，内部含有该定时任务的所有ip地址。\n\npublic class executorroutelru extends executorrouter {\n    // key : 定时任务id\n    // value : linkedhashmap, key : ip地址\n    //                        value : ip地址\n    // linkedhashmap的key和value都是ip地址，并没有什么特殊含义\n    private static concurrentmap<integer, linkedhashmap<string, string>> \n        joblrumap = new concurrenthashmap<integer, linkedhashmap<string, string>>();\n\n    // map中数据的缓存时间\n    private static long cache_valid_time = 0;\n\n    public string get(int jobid, list<string> addresslist) {\n        // 每天刷新\n        if (system.currenttimemillis() > cache_valid_time) {\n            joblrumap.clear();\n            cache_valid_time = system.currenttimemillis() + 1000*60*60*24;\n        }\n        \n        // 根据定时任务id从joblrumap中获得对应的map\n        linkedhashmap<string, string> lruitem = joblrumap.get(jobid);\n        if (lruitem == null) {\n            lruitem = new linkedhashmap<string, string>(16, 0.75f, true);\n            // 把map放到joblrumap中\n            joblrumap.putifabsent(jobid, lruitem);\n        }\n        // 由于 joblrumap 中会存储定时任务对应的所有ip地址，所以要和传入的最新ip地址做同步\n        // 判断有没有新添加的ip\n        for (string address: addresslist) {\n            //如果有就把它加入到lruitem中\n            if (!lruitem.containskey(address)) {\n                lruitem.put(address, address);\n            }\n        }\n        // 判断有没有需要删除ip\n        list<string> delkeys = new arraylist<>();\n        for (string existkey: lruitem.keyset()) {\n            if (!addresslist.contains(existkey)) {\n                delkeys.add(existkey);\n            }\n        }\n        //有就把执行器删除\n        if (delkeys.size() > 0) {\n            for (string delkey: delkeys) {\n                lruitem.remove(delkey);\n            }\n        }\n        // 获取linkedhashmap中第一个元素并返回。\n        string eldestkey = lruitem.entryset().iterator().next().getkey();\n        string eldestvalue = lruitem.get(eldestkey);\n        return eldestvalue;\n    }\n\n    @override\n    public returnt<string> route(int jobid, list<string> addresslist) {\n        string address = get(jobid, addresslist);\n        return new returnt<string>(address);\n    }\n    \n}\n\n\n可以看到其实没啥操作，代码行数多的地方就是 同步 map 中的 ip 与作为参数传入的 ip 地址。\n\n\n# 6. lfu\n\nlfu ：优先用那些 使用频率小的。\n\n可以使用一个 map，key装定时任务id，value 还是一个map，这个内部的 map 的key是ip 地址，value是该 ip 地址的使用次数。\n\nconcurrentmap<integer, hashmap<string, integer>> joblfumap \n    = new concurrenthashmap<integer, hashmap<string, integer>>();\n\n\n当要选择时，将任务id对应的 map 提取出来，按照 使用次数排序，将用的最少的那个返回就行了\n\npublic class executorroutelfu extends executorrouter {\n    //这个map缓存的key-value中的key就是定时任务的id，value是一个map，这个map中缓存的是执行器的地址和该地址被使用的次数\n    private static concurrentmap<integer, hashmap<string, integer>> joblfumap \n        = new concurrenthashmap<integer, hashmap<string, integer>>();\n    private static long cache_valid_time = 0;\n\n    public string get(int jobid, list<string> addresslist) {\n        // 每天都更新\n        if (system.currenttimemillis() > cache_valid_time) {\n            joblfumap.clear();\n            cache_valid_time = system.currenttimemillis() + 1000*60*60*24;\n        }\n        // 先通过定时任务的id从joblfumap中获得对应的value\n        hashmap<string, integer> lfuitemmap = joblfumap.get(jobid);\n        //如果value为空，则创建一个map\n        if (lfuitemmap == null) {\n            lfuitemmap = new hashmap<string, integer>();\n            joblfumap.putifabsent(jobid, lfuitemmap);   \n        }\n        //下面开始遍历执行器地址集合\n        for (string address: addresslist) {\n            // 如果是第一次使用，或者使用次数太多了，就更新使用次数\n            if (!lfuitemmap.containskey(address) || lfuitemmap.get(address) >1000000 ) {\n      \t\t\t// 这里使用随机数的原因: 为了避免第一次负载均衡时很多定时任务都选择了同一台机器，\n                // 使用随机数避免这个情况。\n                lfuitemmap.put(address, new random().nextint(addresslist.size()));\n            }\n        }\n        // 开始同步ip地址\n        //判断有没有过期的ip地址\n        list<string> delkeys = new arraylist<>();\n        for (string existkey: lfuitemmap.keyset()) {\n            if (!addresslist.contains(existkey)) {\n                delkeys.add(existkey);\n            }\n        }\n        //如果有就把过期的ip地址从lfuitemmap中移除\n        if (delkeys.size() > 0) {\n            for (string delkey: delkeys) {\n                lfuitemmap.remove(delkey);\n            }\n        } \n        // 下面就开始选择具体的执行器来执行定时任务了，把lfuitemmap中的数据转移到lfuitemlist中\n        list<map.entry<string, integer>> lfuitemlist \n            = new arraylist<map.entry<string, integer>>(lfuitemmap.entryset());\n        \n        // 将lfuitemlist中的数据按照执行器的使用次数做排序\n        collections.sort(lfuitemlist, new comparator<map.entry<string, integer>>() {\n            @override\n            public int compare(map.entry<string, integer> o1, map.entry<string, integer> o2) {\n                return o1.getvalue().compareto(o2.getvalue());\n            }\n        });\n        // 获取到的第一个就是使用次数最少的执行器\n        map.entry<string, integer> addressitem = lfuitemlist.get(0);\n        string minaddress = addressitem.getkey();\n        //因为要是用它了，所以把执行器的使用次数加1\n        addressitem.setvalue(addressitem.getvalue() + 1);\n        //返回执行器地址\n        return addressitem.getkey();\n    }\n\n    @override\n    public returnt<string> route(int jobid, list<string> addresslist) {\n        string address = get(jobid, addresslist);\n        return new returnt<string>(address);\n    }\n\n}\n\n\n\n# 7. hash\n\n这个我没有看懂，等到看懂了再说吧\n\n// todo\n\npublic class executorrouteconsistenthash extends executorrouter {\n\n    private static int virtual_node_num = 100;\n\n    private static long hash(string key) {\n        messagedigest md5;\n        try {\n            md5 = messagedigest.getinstance("md5");\n        } catch (nosuchalgorithmexception e) {\n            throw new runtimeexception("md5 not supported", e);\n        }\n        md5.reset();\n        byte[] keybytes = null;\n        try {\n            keybytes = key.getbytes("utf-8");\n        } catch (unsupportedencodingexception e) {\n            throw new runtimeexception("unknown string :" + key, e);\n        }\n        md5.update(keybytes);\n        byte[] digest = md5.digest();\n        long hashcode = ((long) (digest[3] & 0xff) << 24)\n                | ((long) (digest[2] & 0xff) << 16)\n                | ((long) (digest[1] & 0xff) << 8)\n                | (digest[0] & 0xff);\n        long truncatehashcode = hashcode & 0xffffffffl;\n        return truncatehashcode;\n    }\n\n\n    public string hashjob(int jobid, list<string> addresslist) {\n        treemap<long, string> addressring = new treemap<long, string>();\n        for (string address: addresslist) {\n            for (int i = 0; i < virtual_node_num; i++) {\n                long addresshash = hash("shard-" + address + "-node-" + i);\n                addressring.put(addresshash, address);\n            }\n        }\n        long jobhash = hash(string.valueof(jobid));\n        sortedmap<long, string> lastring = addressring.tailmap(jobhash);\n        if (!lastring.isempty()) {\n            return lastring.get(lastring.firstkey());\n        }\n        return addressring.firstentry().getvalue();\n    }\n\n    @override\n    public returnt<string> route(triggerparam triggerparam, list<string> addresslist) {\n        string address = hashjob(triggerparam.getjobid(), addresslist);\n        return new returnt<string>(address);\n    }\n\n}\n\n\n\n# 8. 忙碌转移\n\n见名思意 ：如果该 ip地址 正在执行该定时任务，那么此次负载均衡就不使用这个ip。\n\n怎么知道该 ip地址 是否在执行该定时任务呢？发消息问呗。\n\nxxl-job 为任务分配了线程，也就是一个线程专门负责一类定时任务，那么我们只需要给该ip地址服务器发送消息，询问 该定时任务id对应的线程是否在工作中，如果没有在工作中，可以将此任务分配给它；如果在工作中，那就不打扰他了，继续询问下一个ip。\n\npublic class executorroutebusyover extends executorrouter {\n\n    @override\n    public returnt<string> route(int jobid, list<string> addresslist) {\n        stringbuffer idlebeatresultsb = new stringbuffer();\n        // 遍历ip地址,挨个询问\n        for (string address : addresslist) {\n            returnt<string> idlebeatresult = null;\n            try {\n                // 得到向指定ip地址发送消息的客户端\n                executorbiz executorbiz = xxljobscheduler.getexecutorbiz(address);\n                // 向客户端发送忙碌检测请求，判断该执行器的定时任务线程是否正在执行对应的定时任务\n                // 如果正在执行，说明比较忙碌，就不使用该地址\n                idlebeatresult = executorbiz.idlebeat(new idlebeatparam(jobid));\n            } catch (exception e) {\n                logger.error(e.getmessage(), e);\n                idlebeatresult = new returnt<string>(returnt.fail_code, ""+e );\n            }\n            idlebeatresultsb.append( (idlebeatresultsb.length()>0)?"<br><br>":"")\n                    .append(i18nutil.getstring("jobconf_idlebeat") + "：")\n                    .append("<br>address：").append(address)\n                    .append("<br>code：").append(idlebeatresult.getcode())\n                    .append("<br>msg：").append(idlebeatresult.getmsg());\n            // 如果不忙碌就直接使用该地址\n            if (idlebeatresult.getcode() == returnt.success_code) {\n                idlebeatresult.setmsg(idlebeatresultsb.tostring());\n                idlebeatresult.setcontent(address);\n                return idlebeatresult;\n            }\n        }\n        // 如果全都在忙碌，直接返回fail\n        return new returnt<string>(returnt.fail_code, idlebeatresultsb.tostring());\n    }\n\n}\n\n\n\n# 9. 故障转移\n\n这个策略比忙碌转移容易实现，故障转移就是看看 该ip地址能不能用，如果它没有下线就可以使用，如果下线了肯定不能使用。只需要发消息问问对应ip的执行器。\n\npublic class executorroutefailover extends executorrouter {\n\n    @override\n    public returnt<string> route(int jobid, list<string> addresslist) {\n        stringbuffer beatresultsb = new stringbuffer();\n        // 遍历得到的执行器的ip地址\n        for (string address : addresslist) {\n            returnt<string> beatresult = null;\n            try {\n                // 得到访问执行器的客户端\n                executorbiz executorbiz = xxljobscheduler.getexecutorbiz(address);\n                // 向执行器发送心跳检测请求，看执行器是否还在线\n                beatresult = executorbiz.beat();\n            } catch (exception e) {\n                logger.error(e.getmessage(), e);\n                beatresult = new returnt<string>(returnt.fail_code, ""+e );\n            }\n            beatresultsb.append( (beatresultsb.length()>0)?"<br><br>":"")\n                    .append(i18nutil.getstring("jobconf_beat") + "：")\n                    .append("<br>address：").append(address)\n                    .append("<br>code：").append(beatresult.getcode())\n                    .append("<br>msg：").append(beatresult.getmsg());\n            // 心跳检测没问题，就直接使用该执行器\n            if (beatresult.getcode() == returnt.success_code) {\n\n                beatresult.setmsg(beatresultsb.tostring());\n                beatresult.setcontent(address);\n                return beatresult;\n            }\n        }\n        // 所有执行器都不能执行\n        return new returnt<string>(returnt.fail_code, beatresultsb.tostring());\n    }\n}\n',charsets:{cjk:!0},lastUpdated:"2023/10/30, 14:27:21",lastUpdatedTimestamp:1698647241e3},{title:"4. XXL-JOB数据库字段讲解",frontmatter:{title:"4. XXL-JOB数据库字段讲解",date:"2023-11-20T12:56:32.000Z",permalink:"/pages/ac1d9d/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/100.XXL-JOB/4.XXL-JOB%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%97%E6%AE%B5%E8%AE%B2%E8%A7%A3.html",relativePath:"02.文章/91.框架/100.XXL-JOB/4.XXL-JOB数据库字段讲解.md",key:"v-849ebb74",path:"/pages/ac1d9d/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. xxljobinfo",slug:"_1-xxl-job-info",normalizedTitle:"1. xxljobinfo",charIndex:null},{level:2,title:"2. xxljobgroup",slug:"_2-xxl-job-group",normalizedTitle:"2. xxljobgroup",charIndex:null},{level:2,title:"3. xxljobregistry",slug:"_3-xxl-job-registry",normalizedTitle:"3. xxljobregistry",charIndex:null},{level:2,title:"4. xxljoblog",slug:"_4-xxl-job-log",normalizedTitle:"4. xxljoblog",charIndex:null},{level:2,title:"5. xxljoblock",slug:"_5-xxl-job-lock",normalizedTitle:"5. xxljoblock",charIndex:null}],headersStr:"0. 前言 1. xxljobinfo 2. xxljobgroup 3. xxljobregistry 4. xxljoblog 5. xxljoblock",content:"# 0. 前言\n\nXxl-Job一共八张表：\n\n 1. xxl_job_group ：执行器组\n 2. xxl_job_info ：定时任务信息\n 3. xxl_job_lock ：分布式锁\n 4. xxl_job_log ：定时任务执行日志\n 5. xxl_job_log_report ：执行日志统计\n 6. xxl_job_logglue ：glue模式的日志\n 7. xxl_job_registry ：执行器的注册信息\n 8. xxl_job_user ：用户信息\n\n不会全部涉及，其中 xxl_job_logglue、xxl_job_user、xxl_job_log_report 不会讲解。\n\n\n# 1. xxl_job_info\n\n这张表是定时任务的信息表，字段如下：\n\n\n\n * id ：该任务的id\n * job_group ：该任务关联的执行器组\n * job_desc ：该任务的描述\n * alarm_email ：告警邮箱\n * schedule_type ：调度类型，corn模式、固定速率\n * schedule_conf ：调度配置，corn模式下，该值为cron表达式\n * misfire_strategy ：任务过期策略，假如执行器宕机任务没有计时处理怎么办。\n * executor_handler ：定时任务的名称\n * executor_param ：定时任务的参数\n * executor_block_strategy ：定时任务阻塞策略\n * executor_timeout ：定时任务的超时时间\n * executor_fail_retry_count ：定时任务失败重试次数\n * trigger_status ：任务的状态，0-停止，1-运行\n * trigger_last_time ：上次调度时间\n * trigger_next_time ：下次调度时间\n\n值得注意的是，在 xxl-job 中定时任务并没有跟执行器直接关联，而是跟执行器组关联。\n\n执行器组也就是 xxl_job_group表。每一个执行器组中都有1~n台执行器，定时任务的执行过程：\n\n 1. 通过 trigger_next_time 查到5秒内将要执行的任务，如果指定了执行器那么直接执行。\n 2. 如果没有指定执行器，通过 job_group 查到负责该任务的执行器组\n 3. 通过执行器组拿到负责该任务的所有执行器，通过负载均衡选出一个执行器去执行任务。\n\n\n# 2. xxl_job_group\n\n\n\n * id ：该执行器组的id\n * app_name ：执行器组的app_name，唯一标识，如xxl-job-executor-sample\n * title ：执行器组的name，如示例执行器\n * address_type ：执行器组的注册方式，手动/自动\n * address_list ：执行器组的所有执行器IP，以逗号隔开\n * update_time ：更新时间\n\n请不要将 app_name 与 title 混为一谈，app_name 比 title 更加重要。你可以翻翻我们之前为执行器做的配置，一个执行器可以不配置 title 但是一定要配置 app_name，因为执行器通过 app_name 才能找到它属于哪个执行器组。\n\n执行器的注册流程：\n\n 1. 通过 app_name 找到执行器组\n 2. 将自己的IP加入该执行器组的 address_list 字段\n 3. 留个悬念\n\n\n# 3. xxl_job_registry\n\n\n\n这个表是执行器的注册信息。\n\n * id ：注册信息id\n * registry_group ：这个执行器注册信息是属于哪个执行器组\n * registry_key ：执行器组的 app_name\n * registry_value ：该执行器的IP地址\n * update_time ：该执行器的上一次的注册时间\n\n这个表维护着 xxl_job 体系的心跳机制，我们怎么知道某个执行器是否还活着？通过查阅这个表就可以。\n\nxxl_job 规定执行器要每30s给调度中心发送心跳信息，心跳信息发送后会更新 xxl_job_registry 的 update_time 字段，如果三次没发送，也就是 update_time 字段的时间距离现在已经 90s 了，认定此执行器死亡，将此执行器移除。\n\n\n# 4. xxl_job_log\n\n\n\n * id ：日志id\n * job_group ：负责此任务的执行器组\n * executor_address ：负责执行此任务的执行器地址\n * executor_handler ：此任务的名称。就是 @XxlJob() 注解里的那个。\n * executor_param ：任务参数\n * executor_sharding_param ：分片参数\n * executor_fail_retry ：失败重试次数\n * trigger_code ：调度结果\n * handle_code ：执行结果\n\nxxl-job 规定一个任务的执行有两种状态 ：调度结果、执行结果。\n\n调度中心和执行器是通过 HTTP 通信的，这个 HTTP 消息发送出去算是调度成功，消息被执行器收到并执行完成算是执行成功。\n\n如果调度中心宕机，那么调度结果就是失败。如果执行器宕机，那么执行结果就是失败。xxl-job可以通过这两个字段大概判断失败类型。例如 ：一个任务10分钟前就调度成功了，现在还没有执行成功，并且执行器注册信息已经超过90s，那么这个执行器必然宕机了。\n\n\n# 5. xxl_job_lock\n\n\n\n没错，这个表只有一个字段，这个字段只有一条信息。\n\nxxl-job 的所谓分布式就是靠它实现的。\n\n你想啊，如果执行器有很多个，那么调度中心可以使用负载均衡挑选出一个。\n\n但是如果调度中心有很多个呢？谁来负责“挑选”这个重要的事情呢？那么就要抢分布式锁，谁抢到谁调度。\n\nselect lock_name from xxl_job_lock for update\n\n\n如上sql语句就可以实现抢占分布式锁功能。每一个调度中心的每一次调度前都会执行这个sql。抢到了就调度，没抢到就算了~",normalizedContent:"# 0. 前言\n\nxxl-job一共八张表：\n\n 1. xxl_job_group ：执行器组\n 2. xxl_job_info ：定时任务信息\n 3. xxl_job_lock ：分布式锁\n 4. xxl_job_log ：定时任务执行日志\n 5. xxl_job_log_report ：执行日志统计\n 6. xxl_job_logglue ：glue模式的日志\n 7. xxl_job_registry ：执行器的注册信息\n 8. xxl_job_user ：用户信息\n\n不会全部涉及，其中 xxl_job_logglue、xxl_job_user、xxl_job_log_report 不会讲解。\n\n\n# 1. xxl_job_info\n\n这张表是定时任务的信息表，字段如下：\n\n\n\n * id ：该任务的id\n * job_group ：该任务关联的执行器组\n * job_desc ：该任务的描述\n * alarm_email ：告警邮箱\n * schedule_type ：调度类型，corn模式、固定速率\n * schedule_conf ：调度配置，corn模式下，该值为cron表达式\n * misfire_strategy ：任务过期策略，假如执行器宕机任务没有计时处理怎么办。\n * executor_handler ：定时任务的名称\n * executor_param ：定时任务的参数\n * executor_block_strategy ：定时任务阻塞策略\n * executor_timeout ：定时任务的超时时间\n * executor_fail_retry_count ：定时任务失败重试次数\n * trigger_status ：任务的状态，0-停止，1-运行\n * trigger_last_time ：上次调度时间\n * trigger_next_time ：下次调度时间\n\n值得注意的是，在 xxl-job 中定时任务并没有跟执行器直接关联，而是跟执行器组关联。\n\n执行器组也就是 xxl_job_group表。每一个执行器组中都有1~n台执行器，定时任务的执行过程：\n\n 1. 通过 trigger_next_time 查到5秒内将要执行的任务，如果指定了执行器那么直接执行。\n 2. 如果没有指定执行器，通过 job_group 查到负责该任务的执行器组\n 3. 通过执行器组拿到负责该任务的所有执行器，通过负载均衡选出一个执行器去执行任务。\n\n\n# 2. xxl_job_group\n\n\n\n * id ：该执行器组的id\n * app_name ：执行器组的app_name，唯一标识，如xxl-job-executor-sample\n * title ：执行器组的name，如示例执行器\n * address_type ：执行器组的注册方式，手动/自动\n * address_list ：执行器组的所有执行器ip，以逗号隔开\n * update_time ：更新时间\n\n请不要将 app_name 与 title 混为一谈，app_name 比 title 更加重要。你可以翻翻我们之前为执行器做的配置，一个执行器可以不配置 title 但是一定要配置 app_name，因为执行器通过 app_name 才能找到它属于哪个执行器组。\n\n执行器的注册流程：\n\n 1. 通过 app_name 找到执行器组\n 2. 将自己的ip加入该执行器组的 address_list 字段\n 3. 留个悬念\n\n\n# 3. xxl_job_registry\n\n\n\n这个表是执行器的注册信息。\n\n * id ：注册信息id\n * registry_group ：这个执行器注册信息是属于哪个执行器组\n * registry_key ：执行器组的 app_name\n * registry_value ：该执行器的ip地址\n * update_time ：该执行器的上一次的注册时间\n\n这个表维护着 xxl_job 体系的心跳机制，我们怎么知道某个执行器是否还活着？通过查阅这个表就可以。\n\nxxl_job 规定执行器要每30s给调度中心发送心跳信息，心跳信息发送后会更新 xxl_job_registry 的 update_time 字段，如果三次没发送，也就是 update_time 字段的时间距离现在已经 90s 了，认定此执行器死亡，将此执行器移除。\n\n\n# 4. xxl_job_log\n\n\n\n * id ：日志id\n * job_group ：负责此任务的执行器组\n * executor_address ：负责执行此任务的执行器地址\n * executor_handler ：此任务的名称。就是 @xxljob() 注解里的那个。\n * executor_param ：任务参数\n * executor_sharding_param ：分片参数\n * executor_fail_retry ：失败重试次数\n * trigger_code ：调度结果\n * handle_code ：执行结果\n\nxxl-job 规定一个任务的执行有两种状态 ：调度结果、执行结果。\n\n调度中心和执行器是通过 http 通信的，这个 http 消息发送出去算是调度成功，消息被执行器收到并执行完成算是执行成功。\n\n如果调度中心宕机，那么调度结果就是失败。如果执行器宕机，那么执行结果就是失败。xxl-job可以通过这两个字段大概判断失败类型。例如 ：一个任务10分钟前就调度成功了，现在还没有执行成功，并且执行器注册信息已经超过90s，那么这个执行器必然宕机了。\n\n\n# 5. xxl_job_lock\n\n\n\n没错，这个表只有一个字段，这个字段只有一条信息。\n\nxxl-job 的所谓分布式就是靠它实现的。\n\n你想啊，如果执行器有很多个，那么调度中心可以使用负载均衡挑选出一个。\n\n但是如果调度中心有很多个呢？谁来负责“挑选”这个重要的事情呢？那么就要抢分布式锁，谁抢到谁调度。\n\nselect lock_name from xxl_job_lock for update\n\n\n如上sql语句就可以实现抢占分布式锁功能。每一个调度中心的每一次调度前都会执行这个sql。抢到了就调度，没抢到就算了~",charsets:{cjk:!0},lastUpdated:"2023/11/20, 13:00:13",lastUpdatedTimestamp:1700456413e3},{title:"6. 执行器端的日志组件",frontmatter:{title:"6. 执行器端的日志组件",date:"2023-11-23T20:16:07.000Z",permalink:"/pages/a25535/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/100.XXL-JOB/6.%E6%89%A7%E8%A1%8C%E5%99%A8%E7%AB%AF%E7%9A%84%E6%97%A5%E5%BF%97%E7%BB%84%E4%BB%B6.html",relativePath:"02.文章/91.框架/100.XXL-JOB/6.执行器端的日志组件.md",key:"v-18bfcd63",path:"/pages/a25535/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. XxlJobHelper",slug:"_1-xxljobhelper",normalizedTitle:"1. xxljobhelper",charIndex:285},{level:2,title:"2. XxlJobFileAppender",slug:"_2-xxljobfileappender",normalizedTitle:"2. xxljobfileappender",charIndex:1968},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:11660}],headersStr:"0. 前言 1. XxlJobHelper 2. XxlJobFileAppender 3. 总结",content:'# 0. 前言\n\n不知不觉上一篇文章就写了1w字，那么这一篇就整点简单的。\n\n为什么文章的名字叫做 执行器端的日志组件呢？哈哈哈哈你应该猜到了，调度中心和执行器的日志记录方式是截然不同的。\n\n * 调度中心 ：将日志记录到数据库，可以在web端显示给开发人员看。\n * 执行器 ：将日志记录到本地文件夹中\n\n一般来说，出现bug首先看web端从数据库里 xxl_job_log 表中查出的日志，再看执行器端记录的日志文件。如果还是找不出bug，就只能求助喽~~\n\n执行器的日志组件要将东西记录到文件中，所以都是文件操作，这个东西真是没啥说的，这一章当个乐子看吧\n\n\n# 1. XxlJobHelper\n\n又见到了我们的老朋友，这个工具类在前面已经出现过两次了\n\n 1. 在定时任务内部使用 XxlJobHelper.log() 记录日志\n 2. 在任务执行过程中持有 XxlJobContext ，并提供改变 XxlJobContext 的API\n\n这一章我们着重介绍一下它记录日志是如何实现的。其实也是调别人的API。\n\npublic static boolean log(String appendLogPattern, Object ... appendLogArguments) {\n\n    FormattingTuple ft = MessageFormatter.arrayFormat(appendLogPattern, appendLogArguments);\n    String appendLog = ft.getMessage();\n\n    StackTraceElement callInfo = new Throwable().getStackTrace()[1];\n    return logDetail(callInfo, appendLog);\n}\n\nprivate static boolean logDetail(StackTraceElement callInfo, String appendLog) {\n    XxlJobContext xxlJobContext = XxlJobContext.getXxlJobContext();\n    if (xxlJobContext == null) {\n        return false;\n    }\n    // 拼接日志\n    StringBuffer stringBuffer = new StringBuffer();\n    stringBuffer.append(DateUtil.formatDateTime(new Date())).append(" ")\n        .append("["+ callInfo.getClassName() + "#" + callInfo.getMethodName() +"]").append("-")\n        .append("["+ callInfo.getLineNumber() +"]").append("-")\n        .append("["+ Thread.currentThread().getName() +"]").append(" ")\n        .append(appendLog!=null?appendLog:"");\n    String formatAppendLog = stringBuffer.toString();\n\n    // 获取日志文件名\n    String logFileName = xxlJobContext.getJobLogFileName();\n\t// 调用 XxlJobFileAppender.appendLog() 写日志\n    if (logFileName!=null && logFileName.trim().length()>0) {\n        XxlJobFileAppender.appendLog(logFileName, formatAppendLog);\n        return true;\n    } else {\n        logger.info(">>>>>>>>>>> {}", formatAppendLog);\n        return false;\n    }\n}\n\n\n从上面代码的执行流程可以看出 ：log -> logDetail -> XxlJobFileAppender.appendLog()\n\n从名字可以猜出来，XxlJobFileAppender.appendLog() 的功能是续写文件。\n\n\n# 2. XxlJobFileAppender\n\n这个类其实在上一章中出现过，在任务执行之前有这样一段代码：\n\nXxlJobFileAppender.makeLogFileName(Date, logId);\n\n\n也就是根据今天的时间和这个调度参数生成日志文件的名字\n\n> 注 ：调度参数一词我已经在上文解释过，我称一个任务的一次执行为一个调度参数\n> \n> 如果一个任务一个小时执行一次，那么这一天它会产生24个调度参数。\n\n在 xxl-job 中，每一个调度参数在执行前都要创建独属于它的日志文件，并放在用户配置好的日志文件夹下，具体的路径实例如下：\n\n\\data\\applogs\\xxl-job\\jobhandler\\2023-11-20\\24.log\n\n\n所以作为执行器端的日志组件，XxlJobFileAppender 的两大重要任务就是\n\n 1. 生成日志文件并返回日志文件的名字\n    \n    在此处补充一下，JobThread会将日志名字存入 XxlJobContext\n\n 2. 根据 XxlJobContext中的日志文件名 以及用户传入的日志内容记录日志\n\n首先，xxl-job 要将存储所有日志文件的日志文件夹创建出来。\n\npublic class XxlJobFileAppender {\n\tprivate static Logger logger = LoggerFactory.getLogger(XxlJobFileAppender.class);\n\t// 日志文件根路径，默认是/data/applogs/xxl-job/jobhandler，可配置\n\tprivate static String logBasePath = "/data/applogs/xxl-job/jobhandler";\n    \n    public static String getLogPath() {\n\t\treturn logBasePath;\n\t}\n    // 传入的参数是用户指定的文件夹名\n    public static void initLogPath(String logPath){\n\t\t// 如果不为空说明用户指定了，使用他指定的。\n\t\tif (logPath != null && logPath.trim().length() > 0) {\n\t\t\tlogBasePath = logPath;\n\t\t}\n\t\t// 开始创建文件夹\n\t\tFile logPathDir = new File(logBasePath);\n\t\tif (!logPathDir.exists()) {\n\t\t\tlogPathDir.mkdirs();\n\t\t}\n\t\tlogBasePath = logPathDir.getPath();\n\t}\n}\n\n\n * 如果传入的logPath不空就用这个\n * 如果此文件夹不存在就创建\n\n> 你一定很疑惑，如果让我做我就直接在 logBasePath 上面加一个 @Value注解 读取Spring配置文件中的配置，哪还需要传入啊。对，你说的是一种方案，但是为什么不这样做呢？思考一下。\n\n接下来是生成日志文件名的代码，需要传入日期和日志id。\n\npublic class XxlJobFileAppender {\n\tprivate static Logger logger = LoggerFactory.getLogger(XxlJobFileAppender.class);\n\t// 日志文件根路径，默认是/data/applogs/xxl-job/jobhandler，可配置\n\tprivate static String logBasePath = "/data/applogs/xxl-job/jobhandler";\n    \n    public static String getLogPath() {\n\t\treturn logBasePath;\n\t}\n    // 传入的参数是用户指定的文件夹名\n    public static void initLogPath(String logPath){\n\t\t// 如果不为空说明用户指定了，使用他指定的。\n\t\tif (logPath!=null && logPath.trim().length()>0) {\n\t\t\tlogBasePath = logPath;\n\t\t}\n\t\t// 开始创建文件夹\n\t\tFile logPathDir = new File(logBasePath);\n\t\tif (!logPathDir.exists()) {\n\t\t\tlogPathDir.mkdirs();\n\t\t}\n\t\tlogBasePath = logPathDir.getPath();\n\t}\n    // 根据日期和日志id生成对应任务的执行的日志\n    // 生成的路径为: /yyyy-MM-dd/logId.log\n\tpublic static String makeLogFileName(Date triggerDate, long logId) {\n\t\t// 把日期格式化一下\n\t\tSimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd");\t\n        // 没有文件夹就创建一个\n\t\tFile logFilePath = new File(getLogPath(), sdf.format(triggerDate));\n\t\tif (!logFilePath.exists()) {\n\t\t\tlogFilePath.mkdir();\n\t\t}\n\n        // 拼接文件名\n\t\t// filePath/yyyy-MM-dd/9999.log\n\t\tString logFileName = logFilePath.getPath()\n\t\t\t\t.concat(File.separator)\n\t\t\t\t.concat(String.valueOf(logId))\n\t\t\t\t.concat(".log");\n\t\treturn logFileName;\n\t}\n}\n\n\n最终生成的文件名可能为 ：\\data\\applogs\\xxl-job\\jobhandler\\2023-11-20\\24.log\n\n> 思考 ：为什么日志文件使用 logId 命名而不用 jobId？\n> \n> 如果有疑问可以询问我哈~也可以在github链接提issue。\n\n接下来就是记录日志，现在来说一下为啥记录日志需要进行续写呢？因为记录日志还需要在执行任务前记录、执行任务后记录。所以必须续写\n\n如下为截取的 JobThread 执行任务前后的逻辑，一共有三处记录日志的代码。\n\n\n\n> show me code\n\npublic static void appendLog(String logFileName, String appendLog) {\n    // log file\n    if (logFileName==null || logFileName.trim().length()==0) {\n        return;\n    }\n    File logFile = new File(logFileName);\n\n    if (!logFile.exists()) {\n        try {\n            logFile.createNewFile();\n        } catch (IOException e) {\n            logger.error(e.getMessage(), e);\n            return;\n        }\n    }\n\n    // log\n    if (appendLog == null) {\n        appendLog = "";\n    }\n    appendLog += "\\r\\n";\n\n    // append file content\n    FileOutputStream fos = null;\n    try {\n        fos = new FileOutputStream(logFile, true);\n        fos.write(appendLog.getBytes("utf-8"));\n        fos.flush();\n    } catch (Exception e) {\n        logger.error(e.getMessage(), e);\n    } finally {\n        if (fos != null) {\n            try {\n                fos.close();\n            } catch (IOException e) {\n                logger.error(e.getMessage(), e);\n            }\n        }\n    }\n\n}\n\n\n这应该不需要讲吧，除了 fos = new FileOutputStream(logFile, true) 这个true代表续写，其他的没啥了。\n\n除了写入，还要有读取，这个读取是要被调度中心使用的，也就是web端可能要看，所以我们要封装一个类放这些数据：\n\npublic class LogResult implements Serializable {\n    private static final long serialVersionUID = 42L;\n\n    /**\n     * 日志开始的行数\n     */\n    private int fromLineNum;\n\n    /**\n     * 日志结束的行数\n     */\n    private int toLineNum;\n\n    /**\n     * 日志内容\n     */\n    private String logContent;\n\n    /**\n     * 是否为结尾\n     */\n    private boolean isEnd;\n}\n\n\n接下来就是将文件中的内容读取给 LogResult。\n\npublic static LogResult readLog(String logFileName, int fromLineNum){\n\n    // valid log file\n    if (logFileName==null || logFileName.trim().length()==0) {\n        return new LogResult(fromLineNum, 0, "readLog fail, logFile not found", true);\n    }\n    File logFile = new File(logFileName);\n\n    if (!logFile.exists()) {\n        return new LogResult(fromLineNum, 0, "readLog fail, logFile not exists", true);\n    }\n\n    // read file\n    StringBuffer logContentBuffer = new StringBuffer();\n    int toLineNum = 0;\n    LineNumberReader reader = null;\n    try {\n        //reader = new LineNumberReader(new FileReader(logFile));\n        reader = new LineNumberReader(new InputStreamReader(new FileInputStream(logFile), "utf-8"));\n        String line = null;\n\n        while ((line = reader.readLine())!=null) {\n            toLineNum = reader.getLineNumber();\t\t// [from, to], start as 1\n            if (toLineNum >= fromLineNum) {\n                logContentBuffer.append(line).append("\\n");\n            }\n        }\n    } catch (IOException e) {\n        logger.error(e.getMessage(), e);\n    } finally {\n        if (reader != null) {\n            try {\n                reader.close();\n            } catch (IOException e) {\n                logger.error(e.getMessage(), e);\n            }\n        }\n    }\n\n    // result\n    LogResult logResult = new LogResult(fromLineNum, toLineNum, logContentBuffer.toString(), false);\n    return logResult;\n\n}\n\n\n那么整体的代码：\n\npublic class XxlJobFileAppender {\n\tprivate static Logger logger = LoggerFactory.getLogger(XxlJobFileAppender.class);\n\t// 日志文件根路径，默认是/data/applogs/xxl-job/jobhandler，可配置\n\tprivate static String logBasePath = "/data/applogs/xxl-job/jobhandler";\n    \n    public static String getLogPath() {\n\t\treturn logBasePath;\n\t}\n    // 传入的参数是用户指定的文件夹名\n    public static void initLogPath(String logPath){\n\t\t// 如果不为空说明用户指定了，使用他指定的。\n\t\tif (logPath!=null && logPath.trim().length()>0) {\n\t\t\tlogBasePath = logPath;\n\t\t}\n\t\t// 开始创建文件夹\n\t\tFile logPathDir = new File(logBasePath);\n\t\tif (!logPathDir.exists()) {\n\t\t\tlogPathDir.mkdirs();\n\t\t}\n\t\tlogBasePath = logPathDir.getPath();\n\t}\n    // 根据日期和日志id生成对应任务的执行的日志\n    // 生成的路径为: /yyyy-MM-dd/logId.log\n\tpublic static String makeLogFileName(Date triggerDate, long logId) {\n\t\t// 把日期格式化一下\n\t\tSimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd");\t\n        // 没有文件夹就创建一个\n\t\tFile logFilePath = new File(getLogPath(), sdf.format(triggerDate));\n\t\tif (!logFilePath.exists()) {\n\t\t\tlogFilePath.mkdir();\n\t\t}\n\n        // 拼接文件名\n\t\t// filePath/yyyy-MM-dd/9999.log\n\t\tString logFileName = logFilePath.getPath()\n\t\t\t\t.concat(File.separator)\n\t\t\t\t.concat(String.valueOf(logId))\n\t\t\t\t.concat(".log");\n\t\treturn logFileName;\n\t}\n    public static void appendLog(String logFileName, String appendLog) {\n        // log file\n        if (logFileName==null || logFileName.trim().length()==0) {\n            return;\n        }\n        File logFile = new File(logFileName);\n\n        if (!logFile.exists()) {\n            try {\n                logFile.createNewFile();\n            } catch (IOException e) {\n                logger.error(e.getMessage(), e);\n                return;\n            }\n        }\n\n        // log\n        if (appendLog == null) {\n            appendLog = "";\n        }\n        appendLog += "\\r\\n";\n\n        // append file content\n        FileOutputStream fos = null;\n        try {\n            fos = new FileOutputStream(logFile, true);\n            fos.write(appendLog.getBytes("utf-8"));\n            fos.flush();\n        } catch (Exception e) {\n            logger.error(e.getMessage(), e);\n        } finally {\n            if (fos != null) {\n                try {\n                    fos.close();\n                } catch (IOException e) {\n                    logger.error(e.getMessage(), e);\n                }\n            }\n        }\n\n    }\n    public static LogResult readLog(String logFileName, int fromLineNum){\n\n        // valid log file\n        if (logFileName==null || logFileName.trim().length()==0) {\n            return new LogResult(fromLineNum, 0, "readLog fail, logFile not found", true);\n        }\n        File logFile = new File(logFileName);\n\n        if (!logFile.exists()) {\n            return new LogResult(fromLineNum, 0, "readLog fail, logFile not exists", true);\n        }\n\n        // read file\n        StringBuffer logContentBuffer = new StringBuffer();\n        int toLineNum = 0;\n        LineNumberReader reader = null;\n        try {\n            //reader = new LineNumberReader(new FileReader(logFile));\n            reader = new LineNumberReader(new InputStreamReader(new FileInputStream(logFile), "utf-8"));\n            String line = null;\n\n            while ((line = reader.readLine())!=null) {\n                toLineNum = reader.getLineNumber();\t\t// [from, to], start as 1\n                if (toLineNum >= fromLineNum) {\n                    logContentBuffer.append(line).append("\\n");\n                }\n            }\n        } catch (IOException e) {\n            logger.error(e.getMessage(), e);\n        } finally {\n            if (reader != null) {\n                try {\n                    reader.close();\n                } catch (IOException e) {\n                    logger.error(e.getMessage(), e);\n                }\n            }\n        }\n\n        // result\n        LogResult logResult = new LogResult(fromLineNum, toLineNum, logContentBuffer.toString(), false);\n        return logResult;\n\n    }\n}\n\n\n\n# 3. 总结\n\n调用逻辑 ：\n\n 1. 调度中心查到将要执行的任务，生成日志数据存入数据库，此时已经有了日志id，将信息封装为调度参数发给执行器\n\n 2. 执行器拿到调度参数放入阻塞队列中等待执行，取出后正式开始执行逻辑 ：\n    \n    * 给此调度参数生成一个日志文件，例如文件名为2023-11-20/24.log，\n    * 创建一个 XxlJobContext，专门放数据\n    * 将日志名字存入 XxlJobContext\n\n 3. 使用 XxlJobHelper.log() 记录任务执行过程中的日志，XxlJobHelper 首先使用 xxlJobContext.getJobLogFileName() 拿到日志文件名，再通过 appendLog(String logFileName, String appendLog) 将日志续写入文件。',normalizedContent:'# 0. 前言\n\n不知不觉上一篇文章就写了1w字，那么这一篇就整点简单的。\n\n为什么文章的名字叫做 执行器端的日志组件呢？哈哈哈哈你应该猜到了，调度中心和执行器的日志记录方式是截然不同的。\n\n * 调度中心 ：将日志记录到数据库，可以在web端显示给开发人员看。\n * 执行器 ：将日志记录到本地文件夹中\n\n一般来说，出现bug首先看web端从数据库里 xxl_job_log 表中查出的日志，再看执行器端记录的日志文件。如果还是找不出bug，就只能求助喽~~\n\n执行器的日志组件要将东西记录到文件中，所以都是文件操作，这个东西真是没啥说的，这一章当个乐子看吧\n\n\n# 1. xxljobhelper\n\n又见到了我们的老朋友，这个工具类在前面已经出现过两次了\n\n 1. 在定时任务内部使用 xxljobhelper.log() 记录日志\n 2. 在任务执行过程中持有 xxljobcontext ，并提供改变 xxljobcontext 的api\n\n这一章我们着重介绍一下它记录日志是如何实现的。其实也是调别人的api。\n\npublic static boolean log(string appendlogpattern, object ... appendlogarguments) {\n\n    formattingtuple ft = messageformatter.arrayformat(appendlogpattern, appendlogarguments);\n    string appendlog = ft.getmessage();\n\n    stacktraceelement callinfo = new throwable().getstacktrace()[1];\n    return logdetail(callinfo, appendlog);\n}\n\nprivate static boolean logdetail(stacktraceelement callinfo, string appendlog) {\n    xxljobcontext xxljobcontext = xxljobcontext.getxxljobcontext();\n    if (xxljobcontext == null) {\n        return false;\n    }\n    // 拼接日志\n    stringbuffer stringbuffer = new stringbuffer();\n    stringbuffer.append(dateutil.formatdatetime(new date())).append(" ")\n        .append("["+ callinfo.getclassname() + "#" + callinfo.getmethodname() +"]").append("-")\n        .append("["+ callinfo.getlinenumber() +"]").append("-")\n        .append("["+ thread.currentthread().getname() +"]").append(" ")\n        .append(appendlog!=null?appendlog:"");\n    string formatappendlog = stringbuffer.tostring();\n\n    // 获取日志文件名\n    string logfilename = xxljobcontext.getjoblogfilename();\n\t// 调用 xxljobfileappender.appendlog() 写日志\n    if (logfilename!=null && logfilename.trim().length()>0) {\n        xxljobfileappender.appendlog(logfilename, formatappendlog);\n        return true;\n    } else {\n        logger.info(">>>>>>>>>>> {}", formatappendlog);\n        return false;\n    }\n}\n\n\n从上面代码的执行流程可以看出 ：log -> logdetail -> xxljobfileappender.appendlog()\n\n从名字可以猜出来，xxljobfileappender.appendlog() 的功能是续写文件。\n\n\n# 2. xxljobfileappender\n\n这个类其实在上一章中出现过，在任务执行之前有这样一段代码：\n\nxxljobfileappender.makelogfilename(date, logid);\n\n\n也就是根据今天的时间和这个调度参数生成日志文件的名字\n\n> 注 ：调度参数一词我已经在上文解释过，我称一个任务的一次执行为一个调度参数\n> \n> 如果一个任务一个小时执行一次，那么这一天它会产生24个调度参数。\n\n在 xxl-job 中，每一个调度参数在执行前都要创建独属于它的日志文件，并放在用户配置好的日志文件夹下，具体的路径实例如下：\n\n\\data\\applogs\\xxl-job\\jobhandler\\2023-11-20\\24.log\n\n\n所以作为执行器端的日志组件，xxljobfileappender 的两大重要任务就是\n\n 1. 生成日志文件并返回日志文件的名字\n    \n    在此处补充一下，jobthread会将日志名字存入 xxljobcontext\n\n 2. 根据 xxljobcontext中的日志文件名 以及用户传入的日志内容记录日志\n\n首先，xxl-job 要将存储所有日志文件的日志文件夹创建出来。\n\npublic class xxljobfileappender {\n\tprivate static logger logger = loggerfactory.getlogger(xxljobfileappender.class);\n\t// 日志文件根路径，默认是/data/applogs/xxl-job/jobhandler，可配置\n\tprivate static string logbasepath = "/data/applogs/xxl-job/jobhandler";\n    \n    public static string getlogpath() {\n\t\treturn logbasepath;\n\t}\n    // 传入的参数是用户指定的文件夹名\n    public static void initlogpath(string logpath){\n\t\t// 如果不为空说明用户指定了，使用他指定的。\n\t\tif (logpath != null && logpath.trim().length() > 0) {\n\t\t\tlogbasepath = logpath;\n\t\t}\n\t\t// 开始创建文件夹\n\t\tfile logpathdir = new file(logbasepath);\n\t\tif (!logpathdir.exists()) {\n\t\t\tlogpathdir.mkdirs();\n\t\t}\n\t\tlogbasepath = logpathdir.getpath();\n\t}\n}\n\n\n * 如果传入的logpath不空就用这个\n * 如果此文件夹不存在就创建\n\n> 你一定很疑惑，如果让我做我就直接在 logbasepath 上面加一个 @value注解 读取spring配置文件中的配置，哪还需要传入啊。对，你说的是一种方案，但是为什么不这样做呢？思考一下。\n\n接下来是生成日志文件名的代码，需要传入日期和日志id。\n\npublic class xxljobfileappender {\n\tprivate static logger logger = loggerfactory.getlogger(xxljobfileappender.class);\n\t// 日志文件根路径，默认是/data/applogs/xxl-job/jobhandler，可配置\n\tprivate static string logbasepath = "/data/applogs/xxl-job/jobhandler";\n    \n    public static string getlogpath() {\n\t\treturn logbasepath;\n\t}\n    // 传入的参数是用户指定的文件夹名\n    public static void initlogpath(string logpath){\n\t\t// 如果不为空说明用户指定了，使用他指定的。\n\t\tif (logpath!=null && logpath.trim().length()>0) {\n\t\t\tlogbasepath = logpath;\n\t\t}\n\t\t// 开始创建文件夹\n\t\tfile logpathdir = new file(logbasepath);\n\t\tif (!logpathdir.exists()) {\n\t\t\tlogpathdir.mkdirs();\n\t\t}\n\t\tlogbasepath = logpathdir.getpath();\n\t}\n    // 根据日期和日志id生成对应任务的执行的日志\n    // 生成的路径为: /yyyy-mm-dd/logid.log\n\tpublic static string makelogfilename(date triggerdate, long logid) {\n\t\t// 把日期格式化一下\n\t\tsimpledateformat sdf = new simpledateformat("yyyy-mm-dd");\t\n        // 没有文件夹就创建一个\n\t\tfile logfilepath = new file(getlogpath(), sdf.format(triggerdate));\n\t\tif (!logfilepath.exists()) {\n\t\t\tlogfilepath.mkdir();\n\t\t}\n\n        // 拼接文件名\n\t\t// filepath/yyyy-mm-dd/9999.log\n\t\tstring logfilename = logfilepath.getpath()\n\t\t\t\t.concat(file.separator)\n\t\t\t\t.concat(string.valueof(logid))\n\t\t\t\t.concat(".log");\n\t\treturn logfilename;\n\t}\n}\n\n\n最终生成的文件名可能为 ：\\data\\applogs\\xxl-job\\jobhandler\\2023-11-20\\24.log\n\n> 思考 ：为什么日志文件使用 logid 命名而不用 jobid？\n> \n> 如果有疑问可以询问我哈~也可以在github链接提issue。\n\n接下来就是记录日志，现在来说一下为啥记录日志需要进行续写呢？因为记录日志还需要在执行任务前记录、执行任务后记录。所以必须续写\n\n如下为截取的 jobthread 执行任务前后的逻辑，一共有三处记录日志的代码。\n\n\n\n> show me code\n\npublic static void appendlog(string logfilename, string appendlog) {\n    // log file\n    if (logfilename==null || logfilename.trim().length()==0) {\n        return;\n    }\n    file logfile = new file(logfilename);\n\n    if (!logfile.exists()) {\n        try {\n            logfile.createnewfile();\n        } catch (ioexception e) {\n            logger.error(e.getmessage(), e);\n            return;\n        }\n    }\n\n    // log\n    if (appendlog == null) {\n        appendlog = "";\n    }\n    appendlog += "\\r\\n";\n\n    // append file content\n    fileoutputstream fos = null;\n    try {\n        fos = new fileoutputstream(logfile, true);\n        fos.write(appendlog.getbytes("utf-8"));\n        fos.flush();\n    } catch (exception e) {\n        logger.error(e.getmessage(), e);\n    } finally {\n        if (fos != null) {\n            try {\n                fos.close();\n            } catch (ioexception e) {\n                logger.error(e.getmessage(), e);\n            }\n        }\n    }\n\n}\n\n\n这应该不需要讲吧，除了 fos = new fileoutputstream(logfile, true) 这个true代表续写，其他的没啥了。\n\n除了写入，还要有读取，这个读取是要被调度中心使用的，也就是web端可能要看，所以我们要封装一个类放这些数据：\n\npublic class logresult implements serializable {\n    private static final long serialversionuid = 42l;\n\n    /**\n     * 日志开始的行数\n     */\n    private int fromlinenum;\n\n    /**\n     * 日志结束的行数\n     */\n    private int tolinenum;\n\n    /**\n     * 日志内容\n     */\n    private string logcontent;\n\n    /**\n     * 是否为结尾\n     */\n    private boolean isend;\n}\n\n\n接下来就是将文件中的内容读取给 logresult。\n\npublic static logresult readlog(string logfilename, int fromlinenum){\n\n    // valid log file\n    if (logfilename==null || logfilename.trim().length()==0) {\n        return new logresult(fromlinenum, 0, "readlog fail, logfile not found", true);\n    }\n    file logfile = new file(logfilename);\n\n    if (!logfile.exists()) {\n        return new logresult(fromlinenum, 0, "readlog fail, logfile not exists", true);\n    }\n\n    // read file\n    stringbuffer logcontentbuffer = new stringbuffer();\n    int tolinenum = 0;\n    linenumberreader reader = null;\n    try {\n        //reader = new linenumberreader(new filereader(logfile));\n        reader = new linenumberreader(new inputstreamreader(new fileinputstream(logfile), "utf-8"));\n        string line = null;\n\n        while ((line = reader.readline())!=null) {\n            tolinenum = reader.getlinenumber();\t\t// [from, to], start as 1\n            if (tolinenum >= fromlinenum) {\n                logcontentbuffer.append(line).append("\\n");\n            }\n        }\n    } catch (ioexception e) {\n        logger.error(e.getmessage(), e);\n    } finally {\n        if (reader != null) {\n            try {\n                reader.close();\n            } catch (ioexception e) {\n                logger.error(e.getmessage(), e);\n            }\n        }\n    }\n\n    // result\n    logresult logresult = new logresult(fromlinenum, tolinenum, logcontentbuffer.tostring(), false);\n    return logresult;\n\n}\n\n\n那么整体的代码：\n\npublic class xxljobfileappender {\n\tprivate static logger logger = loggerfactory.getlogger(xxljobfileappender.class);\n\t// 日志文件根路径，默认是/data/applogs/xxl-job/jobhandler，可配置\n\tprivate static string logbasepath = "/data/applogs/xxl-job/jobhandler";\n    \n    public static string getlogpath() {\n\t\treturn logbasepath;\n\t}\n    // 传入的参数是用户指定的文件夹名\n    public static void initlogpath(string logpath){\n\t\t// 如果不为空说明用户指定了，使用他指定的。\n\t\tif (logpath!=null && logpath.trim().length()>0) {\n\t\t\tlogbasepath = logpath;\n\t\t}\n\t\t// 开始创建文件夹\n\t\tfile logpathdir = new file(logbasepath);\n\t\tif (!logpathdir.exists()) {\n\t\t\tlogpathdir.mkdirs();\n\t\t}\n\t\tlogbasepath = logpathdir.getpath();\n\t}\n    // 根据日期和日志id生成对应任务的执行的日志\n    // 生成的路径为: /yyyy-mm-dd/logid.log\n\tpublic static string makelogfilename(date triggerdate, long logid) {\n\t\t// 把日期格式化一下\n\t\tsimpledateformat sdf = new simpledateformat("yyyy-mm-dd");\t\n        // 没有文件夹就创建一个\n\t\tfile logfilepath = new file(getlogpath(), sdf.format(triggerdate));\n\t\tif (!logfilepath.exists()) {\n\t\t\tlogfilepath.mkdir();\n\t\t}\n\n        // 拼接文件名\n\t\t// filepath/yyyy-mm-dd/9999.log\n\t\tstring logfilename = logfilepath.getpath()\n\t\t\t\t.concat(file.separator)\n\t\t\t\t.concat(string.valueof(logid))\n\t\t\t\t.concat(".log");\n\t\treturn logfilename;\n\t}\n    public static void appendlog(string logfilename, string appendlog) {\n        // log file\n        if (logfilename==null || logfilename.trim().length()==0) {\n            return;\n        }\n        file logfile = new file(logfilename);\n\n        if (!logfile.exists()) {\n            try {\n                logfile.createnewfile();\n            } catch (ioexception e) {\n                logger.error(e.getmessage(), e);\n                return;\n            }\n        }\n\n        // log\n        if (appendlog == null) {\n            appendlog = "";\n        }\n        appendlog += "\\r\\n";\n\n        // append file content\n        fileoutputstream fos = null;\n        try {\n            fos = new fileoutputstream(logfile, true);\n            fos.write(appendlog.getbytes("utf-8"));\n            fos.flush();\n        } catch (exception e) {\n            logger.error(e.getmessage(), e);\n        } finally {\n            if (fos != null) {\n                try {\n                    fos.close();\n                } catch (ioexception e) {\n                    logger.error(e.getmessage(), e);\n                }\n            }\n        }\n\n    }\n    public static logresult readlog(string logfilename, int fromlinenum){\n\n        // valid log file\n        if (logfilename==null || logfilename.trim().length()==0) {\n            return new logresult(fromlinenum, 0, "readlog fail, logfile not found", true);\n        }\n        file logfile = new file(logfilename);\n\n        if (!logfile.exists()) {\n            return new logresult(fromlinenum, 0, "readlog fail, logfile not exists", true);\n        }\n\n        // read file\n        stringbuffer logcontentbuffer = new stringbuffer();\n        int tolinenum = 0;\n        linenumberreader reader = null;\n        try {\n            //reader = new linenumberreader(new filereader(logfile));\n            reader = new linenumberreader(new inputstreamreader(new fileinputstream(logfile), "utf-8"));\n            string line = null;\n\n            while ((line = reader.readline())!=null) {\n                tolinenum = reader.getlinenumber();\t\t// [from, to], start as 1\n                if (tolinenum >= fromlinenum) {\n                    logcontentbuffer.append(line).append("\\n");\n                }\n            }\n        } catch (ioexception e) {\n            logger.error(e.getmessage(), e);\n        } finally {\n            if (reader != null) {\n                try {\n                    reader.close();\n                } catch (ioexception e) {\n                    logger.error(e.getmessage(), e);\n                }\n            }\n        }\n\n        // result\n        logresult logresult = new logresult(fromlinenum, tolinenum, logcontentbuffer.tostring(), false);\n        return logresult;\n\n    }\n}\n\n\n\n# 3. 总结\n\n调用逻辑 ：\n\n 1. 调度中心查到将要执行的任务，生成日志数据存入数据库，此时已经有了日志id，将信息封装为调度参数发给执行器\n\n 2. 执行器拿到调度参数放入阻塞队列中等待执行，取出后正式开始执行逻辑 ：\n    \n    * 给此调度参数生成一个日志文件，例如文件名为2023-11-20/24.log，\n    * 创建一个 xxljobcontext，专门放数据\n    * 将日志名字存入 xxljobcontext\n\n 3. 使用 xxljobhelper.log() 记录任务执行过程中的日志，xxljobhelper 首先使用 xxljobcontext.getjoblogfilename() 拿到日志文件名，再通过 appendlog(string logfilename, string appendlog) 将日志续写入文件。',charsets:{cjk:!0},lastUpdated:"2023/11/23, 20:17:49",lastUpdatedTimestamp:1700741869e3},{title:"Nacos",frontmatter:{title:"Nacos",date:"2023-10-30T14:30:05.000Z",permalink:"/pages/243013/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/20.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/10.Nacos.html",relativePath:"02.文章/91.框架/20.微服务中间件的使用/10.Nacos.md",key:"v-55669653",path:"/pages/243013/",headers:[{level:2,title:"0. Nacos安装部署",slug:"_0-nacos安装部署",normalizedTitle:"0. nacos安装部署",charIndex:2},{level:2,title:"1. 简述",slug:"_1-简述",normalizedTitle:"1. 简述",charIndex:1103},{level:2,title:"2. Nacos服务发现 入门案例",slug:"_2-nacos服务发现-入门案例",normalizedTitle:"2. nacos服务发现 入门案例",charIndex:1416},{level:3,title:"2.1 版本选择",slug:"_2-1-版本选择",normalizedTitle:"2.1 版本选择",charIndex:1519},{level:3,title:"2.2 创建父工程",slug:"_2-2-创建父工程",normalizedTitle:"2.2 创建父工程",charIndex:2831},{level:3,title:"2.3 DOMAIN对象层",slug:"_2-3-domain对象层",normalizedTitle:"2.3 domain对象层",charIndex:4736},{level:3,title:"2.4 服务提供者",slug:"_2-4-服务提供者",normalizedTitle:"2.4 服务提供者",charIndex:5920},{level:3,title:"2.5 服务消费者",slug:"_2-5-服务消费者",normalizedTitle:"2.5 服务消费者",charIndex:8387},{level:3,title:"2.6 运行",slug:"_2-6-运行",normalizedTitle:"2.6 运行",charIndex:11178},{level:2,title:"3. Nacos服务发现 领域模型",slug:"_3-nacos服务发现-领域模型",normalizedTitle:"3. nacos服务发现 领域模型",charIndex:11397}],headersStr:"0. Nacos安装部署 1. 简述 2. Nacos服务发现 入门案例 2.1 版本选择 2.2 创建父工程 2.3 DOMAIN对象层 2.4 服务提供者 2.5 服务消费者 2.6 运行 3. Nacos服务发现 领域模型",content:'# 0. Nacos安装部署\n\nNacos 官网：https://nacos.io/zh-cn/index.html\n\nNacos生态图：\n\n\n\n太乱了看不懂，直接来安装。\n\nNacos源码地址 ：https://github.com/alibaba/nacos\n\n下载 2.0.3 版本，点击下载：https://github.com/alibaba/nacos/releases/download/2.0.3/nacos-server-2.0.3.zip\n\n\n\n一共有四个，我们下载的是第二个，这个链接中只有一些配置文件、脚本、sql文件和一个 jar包，这个jar包就是Nacos打包好的。\n\n后两个是源码，不要下载源码，初学就看源码不太现实。\n\n解压后如下：\n\n\n\n- bin : 初始情况下只有运行脚本。\n  - shutdown.cmd \n  - shutdown.sh \n  - startup.cmd \n  - startup.sh\n  以后点击startup.cmd就可以运行。不过在此之前需要改个东西。运行之后这个文件就会多一些日志目录、工作目录。\n  \n- conf :配置文件、sql文件，点击 startup.cmd 后会读取此处的配置文件。\n  - application.properties : Nacos终归是一个SpringBoot项目，需要配置文件。\n  - nacos-mysql.sql : Nacos运行需要的配置。\n\n\n只介绍了两个需要使用的文件夹。现在我们还不能点击 startup.cmd 运行\n\n 1. 在数据库新建 nacos 库。\n 2. 将 conf / nacos-mysql.sql 的数据导入，一共有12张表。\n\n\n\n 3. 修改 conf / application.properties 文件，将数据库改成自己的。\n\n\n\n 4. 修改 bin / startup.cmd，将运行模式改为单机运行。\n\n\n\n之后点击 startup.cmd 即可运行。运行时可能需要点击 回车键，不打印日志的时候就点一下回车，直到出现如下界面：\n\n\n\n最后访问 Nacos web界面：http://localhost:8848/nacos/\n\n用户名 ：nacos\n\n密码 ：nacos\n\n\n\n如果版本不一样，web界面也可能不一样。\n\n注意\n\n关闭的时候要使用 ctrl + c 关闭 Nacos，如果直接叉掉命令行，下次运行可能跑不动。\n\n但是如果你真的忘记 ctrl + c 关闭，并在下次开启时出现异常，将之前的数据库删掉，重新导入即可。\n\n\n# 1. 简述\n\nNacos 的两大功能 ：服务注册与发现、配置中心。\n\n服务注册与发现 ：我们的项目，只要引入 nacos-discovery 依赖，就会自动注册到 Nacos Server 端，进而在web界面管理。同时，不同的服务之间调用也变得简单起来了。\n\n> 思考 ：为什么引入 nacos-discovery 依赖后就可以自动注册了呢？\n> \n> 原因 ：nacos-discovery 会向 Nacos Server 端发送消息，其中包含了自己的 IP、服务名、命名空间、group 等关键信息。Nacos Server 接收到后将其注册到数据库中，打开web界面就可以查询数据库，显示已经注册的服务。\n\n\n\n\n# 2. Nacos服务发现 入门案例\n\n本章节会带大家搭建一个 SpringCloud 服务，由于 SpringCloud 与 SpringBoot 之间有版本依赖关系，所以尽量跟我选择一样的版本。\n\n\n# 2.1 版本选择\n\n注 ：千万不要不重视版本的选择。要不然运行不起来。\n\nspringboot 版本查看地址：https://spring.io/projects/spring-boot#learnopen in new window\n\nspringcloud 版本查看地址：https://spring.io/projects/spring-cloud#overviewopen in new window\n\nspringcloud alibaba 的版本查看地址 ：https://github.com/alibaba/spring-cloud-alibaba/wiki/open in new window\n\n详细版本对应信息查看：https://start.spring.io/actuator/info\n\nSPRING CLOUD VERSION          SPRING CLOUD ALIBABA VERSION   SPRING BOOT VERSION\nSpring Cloud Hoxton.SR12      2.2.7.RELEASE                  2.3.12.RELEASE\nSpring Cloud Hoxton.SR8       2.2.4.RELEASE                  2.3.2.RELEASE\nSpring Cloud Greenwich.SR6    2.1.3.RELEASE                  2.1.13.RELEASE\nSpring Cloud Hoxton.SR3       2.2.1.RELEASE                  2.2.5.RELEASE\nSpring Cloud Hoxton.RELEASE   2.2.0.RELEASE                  2.2.X.RELEASE\nSpring Cloud Greenwich        2.1.2.RELEASE                  2.1.X.RELEASE\nSpring Cloud Finchley         2.0.3.RELEASE                  2.0.X.RELEASE\nSpring Cloud Edgware          1.5.1.RELEASE(停止维护，建议升级)       1.5.X.RELEASE\n\n最终的版本选择：\n\nSPRING CLOUD ALIBABA VERSION   SENTINEL   NACOS   ROCKETMQ   DUBBO    SEATA\n2.2.7.RELEASE                  1.8.1      2.0.3   4.6.1      2.7.13   1.3.0\n\nSpringCloud Alibaba ：2.2.7.RELEASE\n\nSpringCloud ：Hoxton.SR12\n\nSpringBoot ：2.3.12.RELEASE\n\nNacos ：2.0.3\n\n\n# 2.2 创建父工程\n\n> 工程名 ：cloud-parent\n> \n> 此工程只负责确定依赖版本\n\n在父工程锁定 SpringBoot、SpringCloud、SpringCloud Alibaba的版本。\n\n<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>org.example</groupId>\n    <artifactId>Nacos-Learn</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <name>Archetype - Nacos-Learn</name>\n    <url>http://maven.apache.org</url>\n    \n    <modules>\n        <module>cloud-goods</module>\n        <module>cloud-entity</module>\n        <module>cloud-orders</module>\n    </modules>\n\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>2.3.12.RELEASE</version>\n        <relativePath/>\n    </parent>\n\n    \x3c!-- 打包方式为pom --\x3e\n    <packaging>pom</packaging>\n\n    <properties>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>\n        <java.version>1.8</java.version>\n    </properties>\n\n    <dependencyManagement>\n        <dependencies>\n            <dependency>\n                <groupId>com.alibaba.cloud</groupId>\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n                <version>2.2.7.RELEASE</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.springframework.cloud</groupId>\n                <artifactId>spring-cloud-dependencies</artifactId>\n                <version>Hoxton.SR12</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n        </dependencies>\n    </dependencyManagement>\n\n</project>\n\n\n\n# 2.3 DOMAIN对象层\n\n> 工程名 ：cloud-entiry\n> \n> 此工程中只有实体类，工具类等，不需要单独启动，故无需编写启动类和配置文件。\n\npom.xml：\n\n<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>org.example</groupId>\n  <artifactId>cloud-entity</artifactId>\n  <version>1.0-SNAPSHOT</version>\n  <name>Archetype - cloud-entity</name>\n  <url>http://maven.apache.org</url>\n    \n  <parent>\n    <groupId>org.example</groupId>\n    <artifactId>Nacos-Learn</artifactId>\n    <version>1.0-SNAPSHOT</version>\n  </parent>\n\n  <properties>\n    <maven.compiler.source>8</maven.compiler.source>\n    <maven.compiler.target>8</maven.compiler.target>\n  </properties>\n\n  <dependencies>\n    <dependency>\n      <groupId>org.projectlombok</groupId>\n      <artifactId>lombok</artifactId>\n    </dependency>\n  </dependencies>\n    \n</project>\n\n\n实体类 ：\n\nimport lombok.AllArgsConstructor;\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\n\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class Goods {\n    private String name;\n    private Integer price;\n}\n\n\n\n\n# 2.4 服务提供者\n\n> 工程名 ：cloud-goods\n> \n> 此工程提供一个 goods 查询服务。\n\npom文件 ：\n\n<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>org.example</groupId>\n        <artifactId>Nacos-Learn</artifactId>\n        <version>1.0-SNAPSHOT</version>\n    </parent>\n    \n    <artifactId>cloud-goods</artifactId>\n    <name>Archetype - cloud-goods</name>\n    <url>http://maven.apache.org</url>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.example</groupId>\n            <artifactId>cloud-entity</artifactId>\n            <version>1.0-SNAPSHOT</version>\n        </dependency>\n    </dependencies>\n</project>\n\n\n> cloud-goods 模块依赖 cloud-entiry 模块，它们都属于 cloud-parent 的子模块。\n\napplication.yml：\n\nspring:\n  application:\n    name: cloud-goods #服务名称，必须，保证唯一\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848 #指定nacos-server的地址\n        username: nacos\n        password: nacos\nserver:\n  port: 9001\n\n\n> 向Nacos Server注册，项目名就是服务名称。没用Nacos时可以不指定，使用 Nacos 就必须指定。\n> \n> spring.cloud.nacos.discovery 后分别填入 Nacos Server 运行 ip + port ，用户名和密码。\n\n启动类加注解：\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\n@SpringBootApplication\n@EnableDiscoveryClient // 打开开关，开启服务的注册与发现功能。\npublic class GoodsApp {\n    public static void main(String[] args) {\n        SpringApplication.run(GoodsApp.class, args);\n    }\n}\n\n\n> 只有加了 @EnableDiscoveryClient 才会自动注册参与服务发现。\n\n查询商品接口：\n\n@RestController\n@RequestMapping("goods")\npublic class GoodsController {\n\n    @RequestMapping("findById/{id}")\n    public Goods findById(@PathVariable String id){\n\n        System.out.println("id"+id);\n        return  new Goods("小米", 99);\n    }\n\n}\n\n\n\n# 2.5 服务消费者\n\n> 工程名 ：cloud-orders\n> \n> 订单模块，它要调用商品模块，进行商品下单前的查询。\n\npom依赖：\n\n<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>org.example</groupId>\n        <artifactId>Nacos-Learn</artifactId>\n        <version>1.0-SNAPSHOT</version>\n    </parent>\n    <artifactId>cloud-orders</artifactId>\n    <name>Archetype - cloud-orders</name>\n    <url>http://maven.apache.org</url>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.example</groupId>\n            <artifactId>cloud-entity</artifactId>\n            <version>1.0-SNAPSHOT</version>\n        </dependency>\n    </dependencies>\n</project>\n\n\napplication.yml ：\n\nspring:\n  application:\n    name: cloud-orders  #服务的应用名称\n  cloud:\n    nacos:\n      discovery: #nacos配置\n        server-addr: localhost:8848\n        username: nacos\n        password: nacos\n\nserver:\n  port: 9002\n\n\n> 此服务的名称为 cloud-orders\n\n启动类加注解：\n\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class OrdersApp {\n\n    /**\n     * 注入 rest template 发送请求\n     * @return\n     */\n    @Bean\n    @LoadBalanced\n    public RestTemplate restTemplate() {\n        return new RestTemplate();\n    }\n\n    public static void main(String[] args) {\n        SpringApplication.run(OrdersApp.class, args);\n    }\n}\n\n\n我们向容器中注入了 RestTemplate，它是Spring集成HttpClient的工具，用于发送HTTP请求。\n\n> 注意 ：在 RestTemplate 上必须加 @LoadBalanced 注解，否则会出现 java.net.UnknownHostException 异常。\n\n在 controller 中调用cloud-goods中的服务：\n\n@Slf4j\n@RestController\n@RequestMapping("/order")\npublic class OrderController {\n\n    @Resource\n    private RestTemplate restTemplate;\n\n    @RequestMapping("save")\n    public Map save() {\n        // 从 cloud-goods 服务中获取商品信息\n        String url = "http://cloud-goods/goods/findById/1";\n        Goods goods = restTemplate.getForObject(url, Goods.class);\n        log.info("Goods: {}", goods);\n        // 保存订单\n        return new HashMap() {\n            {\n                put("code", 200);\n                put("message", "success");\n            }\n        };\n    }\n}\n\n\n代码中的 url 也可以是 http://127.0.0.1:9001/goods/findById/1，但是因为我们使用Nacos管理了模块，拥有了服务发现的功能， 所有 ip + port 可以使用服务名代替。\n\n\n# 2.6 运行\n\n运行 GoodsApp 和 OrderApp 后，打开Nacos web端 ：\n\n\n\n可以看到 cloud-goods、cloud-order 已经被 Nacos 管理。此时你可以使用 Postman发送请求，访问 orders 那个接口，就可以获取数据。\n\n打开 Nacos 的数据库，你会发现并没有出现这两个服务，因为 Nacos 会将 微服务的注册数据保存在内存中，相关的 服务配置数据 会保存在数据库中。\n\n\n# 3. Nacos服务发现 领域模型\n\n服务发现的领域模型为：namespace > group > service。即：命名空间 > 组 > 服务\n\n我们使用的 cloud-order、cloud-goods 就是最低级的service。但是上面我们并没有使用/配置 namespace、group。\n\n因为 Nacos 有默认的 namespace 和 group。\n\n领域模型               默认值\nnamespace （命名空间）   public\ngroup （组）          DEFAULT_GROUP\n\n打开web端的命名空间，即可看到不同的命名空间，public空间是默认也是保留，不可删除。\n\n\n\n可以新建命名空间，如图所示是我新建的 dev。\n\n新建的namespace（命名空间）可以在数据库表 tenant_info 中看到。\n\n在服务列表中的服务中，也就可以看到不同的组：\n\n\n\n所以，一个服务，它的 “全限定类名” 应该为：namespace.group.service。\n\n比如 public.DEFAULT_GROUP.cloud-order。\n\n> 当我们没有在yml文件中指定 namespace 和 group 时，该服务使用上面的默认的领域模型。\n> \n> namespace ：public\n> \n> group ：DEFAULT_GROUP\n\n当我们修改yml配置中的 namespace 和 group 后：\n\nserver:\n  port: 9001\n\n\nspring:\n  application:\n    name: cloud-goods # 注册到 Nacos 的服务名称\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n        username: nacos\n        password: nacos\n        ## namespace填写的是命名空间的id，id在web端有，可以直接复制\n        namespace: 93f4848e-ef28-4b9c-811e-8ef82324a17b\n        group: shangcheng\n\n\nserver:\n  port: 9002\n\n\nspring:\n  application:\n    name: cloud-orders\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n        username: nacos\n        password: nacos\n        ## namespace填写的是命名空间的id，id在web端有，可以直接复制\n        namespace: 93f4848e-ef28-4b9c-811e-8ef82324a17b\n        group: shangcheng\n\n\n我将这两个服务的命名空间改为 dev，分组名称改为 shangcheng。\n\n\n\n可以看到，原本在public命名空间中的服务转移到了dev。并且这两个服务的group也变了。\n\n如果你出现了这种情况：\n\n\n\n上面两个是原来的实例，下面两个是最新的实例。这是为什么？\n\n> 对于服务而言，需要以 5s/次 的频率向注册中心发送心跳，如果 15s 都没有收到心跳，会将此服务标记为不健康，如果 30s 都没有接收到心跳，才会将此服务删除。\n> \n> 上面两个被标记为橙色的服务就是不健康实例，同时由于我们修改了服务的 namespace 和 group，它们已经不是原来的服务了。所以就会有四个。',normalizedContent:'# 0. nacos安装部署\n\nnacos 官网：https://nacos.io/zh-cn/index.html\n\nnacos生态图：\n\n\n\n太乱了看不懂，直接来安装。\n\nnacos源码地址 ：https://github.com/alibaba/nacos\n\n下载 2.0.3 版本，点击下载：https://github.com/alibaba/nacos/releases/download/2.0.3/nacos-server-2.0.3.zip\n\n\n\n一共有四个，我们下载的是第二个，这个链接中只有一些配置文件、脚本、sql文件和一个 jar包，这个jar包就是nacos打包好的。\n\n后两个是源码，不要下载源码，初学就看源码不太现实。\n\n解压后如下：\n\n\n\n- bin : 初始情况下只有运行脚本。\n  - shutdown.cmd \n  - shutdown.sh \n  - startup.cmd \n  - startup.sh\n  以后点击startup.cmd就可以运行。不过在此之前需要改个东西。运行之后这个文件就会多一些日志目录、工作目录。\n  \n- conf :配置文件、sql文件，点击 startup.cmd 后会读取此处的配置文件。\n  - application.properties : nacos终归是一个springboot项目，需要配置文件。\n  - nacos-mysql.sql : nacos运行需要的配置。\n\n\n只介绍了两个需要使用的文件夹。现在我们还不能点击 startup.cmd 运行\n\n 1. 在数据库新建 nacos 库。\n 2. 将 conf / nacos-mysql.sql 的数据导入，一共有12张表。\n\n\n\n 3. 修改 conf / application.properties 文件，将数据库改成自己的。\n\n\n\n 4. 修改 bin / startup.cmd，将运行模式改为单机运行。\n\n\n\n之后点击 startup.cmd 即可运行。运行时可能需要点击 回车键，不打印日志的时候就点一下回车，直到出现如下界面：\n\n\n\n最后访问 nacos web界面：http://localhost:8848/nacos/\n\n用户名 ：nacos\n\n密码 ：nacos\n\n\n\n如果版本不一样，web界面也可能不一样。\n\n注意\n\n关闭的时候要使用 ctrl + c 关闭 nacos，如果直接叉掉命令行，下次运行可能跑不动。\n\n但是如果你真的忘记 ctrl + c 关闭，并在下次开启时出现异常，将之前的数据库删掉，重新导入即可。\n\n\n# 1. 简述\n\nnacos 的两大功能 ：服务注册与发现、配置中心。\n\n服务注册与发现 ：我们的项目，只要引入 nacos-discovery 依赖，就会自动注册到 nacos server 端，进而在web界面管理。同时，不同的服务之间调用也变得简单起来了。\n\n> 思考 ：为什么引入 nacos-discovery 依赖后就可以自动注册了呢？\n> \n> 原因 ：nacos-discovery 会向 nacos server 端发送消息，其中包含了自己的 ip、服务名、命名空间、group 等关键信息。nacos server 接收到后将其注册到数据库中，打开web界面就可以查询数据库，显示已经注册的服务。\n\n\n\n\n# 2. nacos服务发现 入门案例\n\n本章节会带大家搭建一个 springcloud 服务，由于 springcloud 与 springboot 之间有版本依赖关系，所以尽量跟我选择一样的版本。\n\n\n# 2.1 版本选择\n\n注 ：千万不要不重视版本的选择。要不然运行不起来。\n\nspringboot 版本查看地址：https://spring.io/projects/spring-boot#learnopen in new window\n\nspringcloud 版本查看地址：https://spring.io/projects/spring-cloud#overviewopen in new window\n\nspringcloud alibaba 的版本查看地址 ：https://github.com/alibaba/spring-cloud-alibaba/wiki/open in new window\n\n详细版本对应信息查看：https://start.spring.io/actuator/info\n\nspring cloud version          spring cloud alibaba version   spring boot version\nspring cloud hoxton.sr12      2.2.7.release                  2.3.12.release\nspring cloud hoxton.sr8       2.2.4.release                  2.3.2.release\nspring cloud greenwich.sr6    2.1.3.release                  2.1.13.release\nspring cloud hoxton.sr3       2.2.1.release                  2.2.5.release\nspring cloud hoxton.release   2.2.0.release                  2.2.x.release\nspring cloud greenwich        2.1.2.release                  2.1.x.release\nspring cloud finchley         2.0.3.release                  2.0.x.release\nspring cloud edgware          1.5.1.release(停止维护，建议升级)       1.5.x.release\n\n最终的版本选择：\n\nspring cloud alibaba version   sentinel   nacos   rocketmq   dubbo    seata\n2.2.7.release                  1.8.1      2.0.3   4.6.1      2.7.13   1.3.0\n\nspringcloud alibaba ：2.2.7.release\n\nspringcloud ：hoxton.sr12\n\nspringboot ：2.3.12.release\n\nnacos ：2.0.3\n\n\n# 2.2 创建父工程\n\n> 工程名 ：cloud-parent\n> \n> 此工程只负责确定依赖版本\n\n在父工程锁定 springboot、springcloud、springcloud alibaba的版本。\n\n<project xmlns="http://maven.apache.org/pom/4.0.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n         xsi:schemalocation="http://maven.apache.org/pom/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">\n    <modelversion>4.0.0</modelversion>\n    <groupid>org.example</groupid>\n    <artifactid>nacos-learn</artifactid>\n    <version>1.0-snapshot</version>\n    <name>archetype - nacos-learn</name>\n    <url>http://maven.apache.org</url>\n    \n    <modules>\n        <module>cloud-goods</module>\n        <module>cloud-entity</module>\n        <module>cloud-orders</module>\n    </modules>\n\n    <parent>\n        <groupid>org.springframework.boot</groupid>\n        <artifactid>spring-boot-starter-parent</artifactid>\n        <version>2.3.12.release</version>\n        <relativepath/>\n    </parent>\n\n    \x3c!-- 打包方式为pom --\x3e\n    <packaging>pom</packaging>\n\n    <properties>\n        <project.build.sourceencoding>utf-8</project.build.sourceencoding>\n        <project.reporting.outputencoding>utf-8</project.reporting.outputencoding>\n        <java.version>1.8</java.version>\n    </properties>\n\n    <dependencymanagement>\n        <dependencies>\n            <dependency>\n                <groupid>com.alibaba.cloud</groupid>\n                <artifactid>spring-cloud-alibaba-dependencies</artifactid>\n                <version>2.2.7.release</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n            <dependency>\n                <groupid>org.springframework.cloud</groupid>\n                <artifactid>spring-cloud-dependencies</artifactid>\n                <version>hoxton.sr12</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n        </dependencies>\n    </dependencymanagement>\n\n</project>\n\n\n\n# 2.3 domain对象层\n\n> 工程名 ：cloud-entiry\n> \n> 此工程中只有实体类，工具类等，不需要单独启动，故无需编写启动类和配置文件。\n\npom.xml：\n\n<project xmlns="http://maven.apache.org/pom/4.0.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n  xsi:schemalocation="http://maven.apache.org/pom/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">\n  <modelversion>4.0.0</modelversion>\n  <groupid>org.example</groupid>\n  <artifactid>cloud-entity</artifactid>\n  <version>1.0-snapshot</version>\n  <name>archetype - cloud-entity</name>\n  <url>http://maven.apache.org</url>\n    \n  <parent>\n    <groupid>org.example</groupid>\n    <artifactid>nacos-learn</artifactid>\n    <version>1.0-snapshot</version>\n  </parent>\n\n  <properties>\n    <maven.compiler.source>8</maven.compiler.source>\n    <maven.compiler.target>8</maven.compiler.target>\n  </properties>\n\n  <dependencies>\n    <dependency>\n      <groupid>org.projectlombok</groupid>\n      <artifactid>lombok</artifactid>\n    </dependency>\n  </dependencies>\n    \n</project>\n\n\n实体类 ：\n\nimport lombok.allargsconstructor;\nimport lombok.data;\nimport lombok.noargsconstructor;\n\n\n@data\n@allargsconstructor\n@noargsconstructor\npublic class goods {\n    private string name;\n    private integer price;\n}\n\n\n\n\n# 2.4 服务提供者\n\n> 工程名 ：cloud-goods\n> \n> 此工程提供一个 goods 查询服务。\n\npom文件 ：\n\n<project xmlns="http://maven.apache.org/pom/4.0.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n         xsi:schemalocation="http://maven.apache.org/pom/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">\n    <modelversion>4.0.0</modelversion>\n    <parent>\n        <groupid>org.example</groupid>\n        <artifactid>nacos-learn</artifactid>\n        <version>1.0-snapshot</version>\n    </parent>\n    \n    <artifactid>cloud-goods</artifactid>\n    <name>archetype - cloud-goods</name>\n    <url>http://maven.apache.org</url>\n\n    <dependencies>\n        <dependency>\n            <groupid>org.springframework.boot</groupid>\n            <artifactid>spring-boot-starter-web</artifactid>\n        </dependency>\n        <dependency>\n            <groupid>org.springframework.boot</groupid>\n            <artifactid>spring-boot-starter-actuator</artifactid>\n        </dependency>\n        <dependency>\n            <groupid>com.alibaba.cloud</groupid>\n            <artifactid>spring-cloud-starter-alibaba-nacos-discovery</artifactid>\n        </dependency>\n        <dependency>\n            <groupid>org.example</groupid>\n            <artifactid>cloud-entity</artifactid>\n            <version>1.0-snapshot</version>\n        </dependency>\n    </dependencies>\n</project>\n\n\n> cloud-goods 模块依赖 cloud-entiry 模块，它们都属于 cloud-parent 的子模块。\n\napplication.yml：\n\nspring:\n  application:\n    name: cloud-goods #服务名称，必须，保证唯一\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848 #指定nacos-server的地址\n        username: nacos\n        password: nacos\nserver:\n  port: 9001\n\n\n> 向nacos server注册，项目名就是服务名称。没用nacos时可以不指定，使用 nacos 就必须指定。\n> \n> spring.cloud.nacos.discovery 后分别填入 nacos server 运行 ip + port ，用户名和密码。\n\n启动类加注解：\n\nimport org.springframework.boot.springapplication;\nimport org.springframework.boot.autoconfigure.springbootapplication;\nimport org.springframework.cloud.client.discovery.enablediscoveryclient;\n\n@springbootapplication\n@enablediscoveryclient // 打开开关，开启服务的注册与发现功能。\npublic class goodsapp {\n    public static void main(string[] args) {\n        springapplication.run(goodsapp.class, args);\n    }\n}\n\n\n> 只有加了 @enablediscoveryclient 才会自动注册参与服务发现。\n\n查询商品接口：\n\n@restcontroller\n@requestmapping("goods")\npublic class goodscontroller {\n\n    @requestmapping("findbyid/{id}")\n    public goods findbyid(@pathvariable string id){\n\n        system.out.println("id"+id);\n        return  new goods("小米", 99);\n    }\n\n}\n\n\n\n# 2.5 服务消费者\n\n> 工程名 ：cloud-orders\n> \n> 订单模块，它要调用商品模块，进行商品下单前的查询。\n\npom依赖：\n\n<project xmlns="http://maven.apache.org/pom/4.0.0" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"\n         xsi:schemalocation="http://maven.apache.org/pom/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">\n    <modelversion>4.0.0</modelversion>\n    <parent>\n        <groupid>org.example</groupid>\n        <artifactid>nacos-learn</artifactid>\n        <version>1.0-snapshot</version>\n    </parent>\n    <artifactid>cloud-orders</artifactid>\n    <name>archetype - cloud-orders</name>\n    <url>http://maven.apache.org</url>\n\n    <dependencies>\n        <dependency>\n            <groupid>org.springframework.boot</groupid>\n            <artifactid>spring-boot-starter-web</artifactid>\n        </dependency>\n        <dependency>\n            <groupid>org.springframework.boot</groupid>\n            <artifactid>spring-boot-starter-actuator</artifactid>\n        </dependency>\n        <dependency>\n            <groupid>com.alibaba.cloud</groupid>\n            <artifactid>spring-cloud-starter-alibaba-nacos-discovery</artifactid>\n        </dependency>\n        <dependency>\n            <groupid>org.example</groupid>\n            <artifactid>cloud-entity</artifactid>\n            <version>1.0-snapshot</version>\n        </dependency>\n    </dependencies>\n</project>\n\n\napplication.yml ：\n\nspring:\n  application:\n    name: cloud-orders  #服务的应用名称\n  cloud:\n    nacos:\n      discovery: #nacos配置\n        server-addr: localhost:8848\n        username: nacos\n        password: nacos\n\nserver:\n  port: 9002\n\n\n> 此服务的名称为 cloud-orders\n\n启动类加注解：\n\n@springbootapplication\n@enablediscoveryclient\npublic class ordersapp {\n\n    /**\n     * 注入 rest template 发送请求\n     * @return\n     */\n    @bean\n    @loadbalanced\n    public resttemplate resttemplate() {\n        return new resttemplate();\n    }\n\n    public static void main(string[] args) {\n        springapplication.run(ordersapp.class, args);\n    }\n}\n\n\n我们向容器中注入了 resttemplate，它是spring集成httpclient的工具，用于发送http请求。\n\n> 注意 ：在 resttemplate 上必须加 @loadbalanced 注解，否则会出现 java.net.unknownhostexception 异常。\n\n在 controller 中调用cloud-goods中的服务：\n\n@slf4j\n@restcontroller\n@requestmapping("/order")\npublic class ordercontroller {\n\n    @resource\n    private resttemplate resttemplate;\n\n    @requestmapping("save")\n    public map save() {\n        // 从 cloud-goods 服务中获取商品信息\n        string url = "http://cloud-goods/goods/findbyid/1";\n        goods goods = resttemplate.getforobject(url, goods.class);\n        log.info("goods: {}", goods);\n        // 保存订单\n        return new hashmap() {\n            {\n                put("code", 200);\n                put("message", "success");\n            }\n        };\n    }\n}\n\n\n代码中的 url 也可以是 http://127.0.0.1:9001/goods/findbyid/1，但是因为我们使用nacos管理了模块，拥有了服务发现的功能， 所有 ip + port 可以使用服务名代替。\n\n\n# 2.6 运行\n\n运行 goodsapp 和 orderapp 后，打开nacos web端 ：\n\n\n\n可以看到 cloud-goods、cloud-order 已经被 nacos 管理。此时你可以使用 postman发送请求，访问 orders 那个接口，就可以获取数据。\n\n打开 nacos 的数据库，你会发现并没有出现这两个服务，因为 nacos 会将 微服务的注册数据保存在内存中，相关的 服务配置数据 会保存在数据库中。\n\n\n# 3. nacos服务发现 领域模型\n\n服务发现的领域模型为：namespace > group > service。即：命名空间 > 组 > 服务\n\n我们使用的 cloud-order、cloud-goods 就是最低级的service。但是上面我们并没有使用/配置 namespace、group。\n\n因为 nacos 有默认的 namespace 和 group。\n\n领域模型               默认值\nnamespace （命名空间）   public\ngroup （组）          default_group\n\n打开web端的命名空间，即可看到不同的命名空间，public空间是默认也是保留，不可删除。\n\n\n\n可以新建命名空间，如图所示是我新建的 dev。\n\n新建的namespace（命名空间）可以在数据库表 tenant_info 中看到。\n\n在服务列表中的服务中，也就可以看到不同的组：\n\n\n\n所以，一个服务，它的 “全限定类名” 应该为：namespace.group.service。\n\n比如 public.default_group.cloud-order。\n\n> 当我们没有在yml文件中指定 namespace 和 group 时，该服务使用上面的默认的领域模型。\n> \n> namespace ：public\n> \n> group ：default_group\n\n当我们修改yml配置中的 namespace 和 group 后：\n\nserver:\n  port: 9001\n\n\nspring:\n  application:\n    name: cloud-goods # 注册到 nacos 的服务名称\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n        username: nacos\n        password: nacos\n        ## namespace填写的是命名空间的id，id在web端有，可以直接复制\n        namespace: 93f4848e-ef28-4b9c-811e-8ef82324a17b\n        group: shangcheng\n\n\nserver:\n  port: 9002\n\n\nspring:\n  application:\n    name: cloud-orders\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n        username: nacos\n        password: nacos\n        ## namespace填写的是命名空间的id，id在web端有，可以直接复制\n        namespace: 93f4848e-ef28-4b9c-811e-8ef82324a17b\n        group: shangcheng\n\n\n我将这两个服务的命名空间改为 dev，分组名称改为 shangcheng。\n\n\n\n可以看到，原本在public命名空间中的服务转移到了dev。并且这两个服务的group也变了。\n\n如果你出现了这种情况：\n\n\n\n上面两个是原来的实例，下面两个是最新的实例。这是为什么？\n\n> 对于服务而言，需要以 5s/次 的频率向注册中心发送心跳，如果 15s 都没有收到心跳，会将此服务标记为不健康，如果 30s 都没有接收到心跳，才会将此服务删除。\n> \n> 上面两个被标记为橙色的服务就是不健康实例，同时由于我们修改了服务的 namespace 和 group，它们已经不是原来的服务了。所以就会有四个。',charsets:{cjk:!0},lastUpdated:"2023/10/30, 14:49:00",lastUpdatedTimestamp:169864854e4},{title:"Ribbon",frontmatter:{title:"Ribbon",date:"2023-10-30T14:34:43.000Z",permalink:"/pages/afe80c/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/20.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/20.Ribbon.html",relativePath:"02.文章/91.框架/20.微服务中间件的使用/20.Ribbon.md",key:"v-72a09f4a",path:"/pages/afe80c/",headers:[{level:2,title:"1. Ribbon 简介",slug:"_1-ribbon-简介",normalizedTitle:"1. ribbon 简介",charIndex:2},{level:2,title:"2. Ribbon 使用",slug:"_2-ribbon-使用",normalizedTitle:"2. ribbon 使用",charIndex:393},{level:2,title:"3. Ribbon 原理",slug:"_3-ribbon-原理",normalizedTitle:"3. ribbon 原理",charIndex:1418}],headersStr:"1. Ribbon 简介 2. Ribbon 使用 3. Ribbon 原理",content:'# 1. Ribbon 简介\n\nRibbon 是 Netflix 发布的负载均衡器，为 Ribbon 配置了服务提供者的地址后，Ribbon就会使用某种负载均衡算法自动帮助服务消费者去请求。Ribbon 提供了很多种负载均衡算法，例如轮询、随机等，当然，我们也可以为 Ribbon 实现自定义的负载均衡算法。\n\n如果单独使用 Ribbon ，那么需要引入依赖：\n\n\x3c!--添加ribbon的依赖--\x3e\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-netflix-ribbon</artifactId>\n<dependency>\n\n\n\n但是如果使用了 Nacos 就不需要引入了，因为 Nacos 已经集成了 Ribbon。\n\n\n# 2. Ribbon 使用\n\n在进行不同模块之间的通信时，我们用到了 RestTemplate ，当服务提供者是多实例时，就可以使用 Ribbon 进行负载均衡。只需要在注入 RestTemplate 时添加 @LoadBalanced\n\n@Bean\n@LoadBalanced\npublic RestTemplate restTemplate() {\n    return new RestTemplate();\n}\n\n\n加上这个注解后，Ribbon就会自动进行负载均衡（使用默认的负载均衡算法），使用非常简单。\n\nRibbon 默认采用的负载均衡策略是 轮询，如果我们想要使用其他的策略呢？\n\nRibbon一共支持8中策略：\n\n\n\n修改 Ribbon 的策略有两种方式：配置文件、配置类。\n\n 1. 配置文件\n    \n    在yml中进行配置：\n    \n    cloud-goods: ## 服务名\n      ribbon:\n        NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule\n    \n\n 2. 配置类\n    \n    @Configuration\n    public class RibbonRule {\n        @Bean\n        public IRule getRule() {\n            return new RandomRule();\n        }\n    }\n    \n    \n    @SpringBootApplication\n    @EnableDiscoveryClient // 打开开关，开启服务的注册与发现功能。\n    @RibbonClient(name="cloud-goods", configuration = {RibbonClient.class})\n    public class GoodsApp {\n        public static void main(String[] args) {\n            SpringApplication.run(GoodsApp.class, args);\n        }\n    }\n    \n\n可以看到，修改 Ribbon 的负载均衡策略需要指定两个值：服务名、具体的负载策略。\n\n\n# 3. Ribbon 原理\n\n在使用 RestTemplate 发送请求时是这样写的 ：http://order-service/order/getAllOrders ，使用 order-service 替代具体的 IP + PORT ，在发送之后肯定要将具体的 IP + PORT 替代进去。\n\n由于 Nacos 集成了 Ribbon，Ribbon 会获得 order-service 的全部地址，在发送 http://order-service/order/getAllOrders 请求后，Ribbon会在 order-service 的全部地址里面使用负载均衡策略挑选一个填充替代进去。\n\nRibbon 用于拦截请求的类：LoadBalancerInterceptor，拦截并替代IP后，使用 LoadBalancerClient将请求发出去。\n\n',normalizedContent:'# 1. ribbon 简介\n\nribbon 是 netflix 发布的负载均衡器，为 ribbon 配置了服务提供者的地址后，ribbon就会使用某种负载均衡算法自动帮助服务消费者去请求。ribbon 提供了很多种负载均衡算法，例如轮询、随机等，当然，我们也可以为 ribbon 实现自定义的负载均衡算法。\n\n如果单独使用 ribbon ，那么需要引入依赖：\n\n\x3c!--添加ribbon的依赖--\x3e\n<dependency>\n    <groupid>org.springframework.cloud</groupid>\n    <artifactid>spring-cloud-starter-netflix-ribbon</artifactid>\n<dependency>\n\n\n\n但是如果使用了 nacos 就不需要引入了，因为 nacos 已经集成了 ribbon。\n\n\n# 2. ribbon 使用\n\n在进行不同模块之间的通信时，我们用到了 resttemplate ，当服务提供者是多实例时，就可以使用 ribbon 进行负载均衡。只需要在注入 resttemplate 时添加 @loadbalanced\n\n@bean\n@loadbalanced\npublic resttemplate resttemplate() {\n    return new resttemplate();\n}\n\n\n加上这个注解后，ribbon就会自动进行负载均衡（使用默认的负载均衡算法），使用非常简单。\n\nribbon 默认采用的负载均衡策略是 轮询，如果我们想要使用其他的策略呢？\n\nribbon一共支持8中策略：\n\n\n\n修改 ribbon 的策略有两种方式：配置文件、配置类。\n\n 1. 配置文件\n    \n    在yml中进行配置：\n    \n    cloud-goods: ## 服务名\n      ribbon:\n        nfloadbalancerruleclassname: com.netflix.loadbalancer.randomrule\n    \n\n 2. 配置类\n    \n    @configuration\n    public class ribbonrule {\n        @bean\n        public irule getrule() {\n            return new randomrule();\n        }\n    }\n    \n    \n    @springbootapplication\n    @enablediscoveryclient // 打开开关，开启服务的注册与发现功能。\n    @ribbonclient(name="cloud-goods", configuration = {ribbonclient.class})\n    public class goodsapp {\n        public static void main(string[] args) {\n            springapplication.run(goodsapp.class, args);\n        }\n    }\n    \n\n可以看到，修改 ribbon 的负载均衡策略需要指定两个值：服务名、具体的负载策略。\n\n\n# 3. ribbon 原理\n\n在使用 resttemplate 发送请求时是这样写的 ：http://order-service/order/getallorders ，使用 order-service 替代具体的 ip + port ，在发送之后肯定要将具体的 ip + port 替代进去。\n\n由于 nacos 集成了 ribbon，ribbon 会获得 order-service 的全部地址，在发送 http://order-service/order/getallorders 请求后，ribbon会在 order-service 的全部地址里面使用负载均衡策略挑选一个填充替代进去。\n\nribbon 用于拦截请求的类：loadbalancerinterceptor，拦截并替代ip后，使用 loadbalancerclient将请求发出去。\n\n',charsets:{cjk:!0},lastUpdated:"2023/10/30, 14:49:07",lastUpdatedTimestamp:1698648547e3},{title:"OpenFeign",frontmatter:{title:"OpenFeign",date:"2023-10-30T14:35:40.000Z",permalink:"/pages/e020ec/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/20.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/30.OpenFeign.html",relativePath:"02.文章/91.框架/20.微服务中间件的使用/30.OpenFeign.md",key:"v-0000769a",path:"/pages/e020ec/",headers:[{level:2,title:"1. Feign 是什么",slug:"_1-feign-是什么",normalizedTitle:"1. feign 是什么",charIndex:2},{level:2,title:"2. OpenFeign 是什么",slug:"_2-openfeign-是什么",normalizedTitle:"2. openfeign 是什么",charIndex:254},{level:2,title:"3. OpenFeign 的使用",slug:"_3-openfeign-的使用",normalizedTitle:"3. openfeign 的使用",charIndex:548},{level:2,title:"4. 请求超时时间",slug:"_4-请求超时时间",normalizedTitle:"4. 请求超时时间",charIndex:2128},{level:2,title:"5. 开启日志增强",slug:"_5-开启日志增强",normalizedTitle:"5. 开启日志增强",charIndex:2924},{level:2,title:"6. 使用其他 HTTP Client",slug:"_6-使用其他-http-client",normalizedTitle:"6. 使用其他 http client",charIndex:4364},{level:2,title:"7. 自定义 请求拦截器",slug:"_7-自定义-请求拦截器",normalizedTitle:"7. 自定义 请求拦截器",charIndex:5438},{level:2,title:"7. 熔断降级",slug:"_7-熔断降级",normalizedTitle:"7. 熔断降级",charIndex:6458},{level:2,title:"8. 几种不同的RPC方案",slug:"_8-几种不同的rpc方案",normalizedTitle:"8. 几种不同的rpc方案",charIndex:6527}],headersStr:"1. Feign 是什么 2. OpenFeign 是什么 3. OpenFeign 的使用 4. 请求超时时间 5. 开启日志增强 6. 使用其他 HTTP Client 7. 自定义 请求拦截器 7. 熔断降级 8. 几种不同的RPC方案",content:'# 1. Feign 是什么\n\nFeign 旨在使 Java HTTP 客户端通信变得更容易\n\nFeign 集成了 Ribbon、RestTemplate 实现了负载均衡的执行HTTP调用，只不过对原有的方式（Ribbon + RestTemplate）进行了封装，开发者不需要手动使用 RestTemplate 调用服务，而是定义一个接口，在这个接口中标注一个注解即可完成服务调用，这样更加面向接口编程，简化了开发。\n\n但遗憾的是 Feign 已经停止迭代了。OpenFeign 才是今天的重点。\n\n\n# 2. OpenFeign 是什么\n\n简单来说，OpenFeign 使 SpringCloud 在 Feign 的基础上支持了 SpringMVC 的注解，如 @RequestMapping...\n\nOpenFeign 的 @FeignClient 可以解析 SpringMVC 的 @RequestMapping 注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用服务。\n\n> 官网：https://docs.spring.io/spring-cloud-openfeign/docs/2.2.10.BUILD-SNAPSHOT/reference/html\n\n\n# 3. OpenFeign 的使用\n\n接着之前 Nacos 的两个项目：cloud-goods、cloud-orders 来完成，在 cloud-orders 中远程调用了 cloud-goods 的服务。现在我们将它从 RestTemplate 改为 OpenFeign。\n\n给 cloud-orders 添加依赖：\n\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-openfeign</artifactId>\n</dependency>\n\n\n在启动类加上注解：@EnableFeignClients(basePackages = "xxx")\n\n@SpringBootApplication\n@EnableDiscoveryClient\n@EnableFeignClients(basePackages = "com.xiaohe.orders.api")\npublic class OrdersApp {\n    public static void main(String[] args) {\n        SpringApplication.run(OrdersApp.class, args);\n    }\n}\n\n\n在cloud-orders项目的 com.xiaohe.orders.api 包下创建映射 cloud-goods 服务的接口：\n\npackage com.xiaohe.orders.api;\n\nimport com.xiaohe.entity.Goods;\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@FeignClient("cloud-goods") // 指定服务名\n@RequestMapping("/goods") // 请求路径\npublic interface GoodsAPI {\n    @RequestMapping("/findById/{id}")\n    public Goods findById(@PathVariable("id") String id);\n}\n\n\n在controller中调用远程服务：\n\n@Slf4j\n@RestController\n@RequestMapping("/order")\npublic class OrderController {\n    @Resource\n    private GoodsAPI goodsAPI;\n\n\n    @RequestMapping("/save")\n    public Map save() {\n        // 从 cloud-goods 服务中获取商品信息\n        Goods goods = goodsAPI.findById("1");\n\n        return new HashMap() {\n            {\n                put("code", 200);\n                put("message", "success");\n                put("goods", goods);\n            }\n        };\n    }\n}\n\n\n\n# 4. 请求超时时间\n\n由于 OpenFeign 是发送 HTTP 请求的工具，HTTP 请求是有超时时间的，默认分别是连接超时时间10秒、读超时时间60秒\n\n但是又因为 OpenFeign 集成了 Ribbon ，Ribbon 的默认超时连接时间、读超时时间都是是1秒。\n\n在我们没有给 OpenFeign 指定 连接超时时间、读超时时间 的情况下，它默认使用 Ribbon 的，只要被调用的服务那里执行超过了1s，此次请求就会报错。1s实在是太勉强了，所以我们要单独给 OpenFeign 指定超时时间。\n\n 1. 设置全部接口的超时时间\n    \n    feign:\n      client:\n        config:\n          ## default 设置的全局超时时间，指定服务名称可以设置单个服务的超时时间\n          default:\n            connectTimeout: 5000\n            readTimeout: 5000\n    \n\n 2. 给某个调用服务单独设置超时时间：\n    \n    feign:\n      client:\n        config:\n          ## default 设置的全局超时时间，指定服务名称可以设置单个服务的超时时间 : 5s\n          default:\n            connectTimeout: 5000\n            readTimeout: 5000\n          ## 为serviceC这个服务单独配置超时时间 : 30s\n          serviceC:\n            connectTimeout: 30000\n            readTimeout: 30000\n    \n\n\n# 5. 开启日志增强\n\nOpenFeign 提供了日志增强功能，默认关闭，不过开发者在调试阶段可以自己配置 OpenFeign 的日志级别。\n\n如果不开启，发起请求的时候不会有日志，如果开启了，就会打印此次请求的url、请求头、响应头等信息。\n\nOpenFeign 的日志级别如下：\n\n 1. NONE ：默认，不显示任何日志\n 2. BASIC ：仅仅记录请求方法、URL、响应状态码、执行时间\n 3. HEADERS ：除了 BASIC 的信息之外，还记录请求头、响应头的信息。\n 4. FULL ：除了 HEADERS 的信息之外，还记录请求和响应的正文及元数据。\n\n配置如何开启？OpenFeign提供两种开启方式 ：全局配置和局部配置。\n\n 1. 全局配置：加了 @Configuration 注解表示全局配置，对所有服务起作用\n    \n    import feign.Logger;\n    import org.springframework.context.annotation.Bean;\n    import org.springframework.context.annotation.Configuration;\n    \n    @Configuration\n    public class FeignConfig {\n    \n        @Bean\n        public Logger.Level feignLoggerLevel(){\n            return Logger.Level.FULL;\n        }\n    }\n    \n\n 2. 局部配置 ：配置类上不加 @Configuration，并且在使用者的 @FeignClient 中的 configuration 变量指定使用这个配置类。\n    \n    import feign.Logger; // 导包不要导错了\n    import org.springframework.context.annotation.Bean;\n    import org.springframework.context.annotation.Configuration;\n    // 这里没有加 @Configuration，代表这是某一个服务专用的配置类\n    public class GoodsFeignConfig {\n        @Bean\n        public Logger.Level feignLoggerLevel(){\n            return Logger.Level.HEADERS;\n        }\n    }\n    \n    \n    // 指定服务名、配置类\n    @FeignClient(name = "cloud-goods", configuration = GoodsFeignConfig.class) \n    @RequestMapping("/goods") // 路径\n    public interface GoodsAPI {\n        @RequestMapping("/findById/{id}")\n        public Goods findById(@PathVariable("id") String id);\n    }\n    \n\n\n# 6. 使用其他 HTTP Client\n\nOpenFeign 使用的Http客户端是 JDK 自带的 HTTPURLConnection，它没有连接池，性能和效率也比较低。\n\n我们可以换成其他的 HTTP Client，比如 OkHttp、ApacheHttpClient。\n\n 1. 使用 ApacheHttpClient\n    \n    添加依赖：\n    \n    \x3c!--     使用Apache HttpClient替换Feign原生httpclient--\x3e\n        <dependency>\n          <groupId>org.apache.httpcomponents</groupId>\n          <artifactId>httpclient</artifactId>\n        </dependency>\n        \n        <dependency>\n          <groupId>io.github.openfeign</groupId>\n          <artifactId>feign-httpclient</artifactId>\n        </dependency>\n    \n    \n    添加配置：\n    \n    feign:\n      client:\n        httpclient:\n          # 开启 Http Client\n          enabled: true\n    \n\n 2. 使用 OkHttp\n    \n    添加依赖：\n    \n    <dependency>\n        <groupId>io.github.openfeign</groupId>\n        <artifactId>feign-okhttp</artifactId>\n    </dependency>\n    \n    \n    添加配置;\n    \n    feign: \n      ## 禁止使用自带的 http client\n      httpclient:\n        enabled: false\n      # Okhttp参数配置\n      okhttp:\n        enabled: true\n        max-connections: 200 # 默认值\n        max-connections-per-route: 50 # 默认值\n    \n\n\n# 7. 自定义 请求拦截器\n\n请求拦截器是用来拦截请求的，什么情况下要拦截我们发出去的请求呢？比如我的Http请求头中需要携带数据。\n\n一个最常用的场景就是请求头中携带token。cloud-orders 调用 cloud-goods，如果 cloud-goods 需要验证身份信息，也就是需要token，我们默认发出的请求可没有token，这时候就需要把请求拦截下来，把 token 塞进去。\n\n这个接口是 RequestInterceptor，不管是直接以 Bean 的放入注入，还是实现一下再注入，只要容器中有这个类就可以对请求进行拦截。\n\n@Slf4j\n@Configuration\npublic class OpenFeignConfig {\n    \n    @Bean\n    public RequestInterceptor requestInterceptor() {\n        \n        return requestTemplate -> {\n\n            String token;\n            // 请求方\n            ServletRequestAttributes requestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();\n            if (ObjUtil.isEmpty(requestAttributes)) {\n                return;\n            } else {\n                // 获取请求方token\n                HttpServletRequest request = requestAttributes.getRequest();\n                token = request.getHeader("Authorization");\n            }\n            // 被请求方设置token，实现token中转\n            requestTemplate.header("Authorization", token);\n        };\n    }\n    \n}\n\n\n\n# 7. 熔断降级\n\nOpenFeign 默认使用 Hystrix 进行熔断降级，但是我想用 Sentinel 怎么办？请见下一章。\n\n\n# 8. 几种不同的RPC方案\n\n 1. OpenFeign ：\n    * 基于 HTTP协议（Restful风格） 的 rpc请求工具，数据通常是 json 格式\n    * 由于集成了 Ribbon ，可以进行负载均衡\n    * 服务容错 ：支持多种容错，默认使用 Hsytrix，也集成了 Sentinel\n    * 性能 ：一般\n 2. Dubbo ：\n    * 基于自定义的二进制rpc协议\n    * 支持四种负载均衡策略\n    * 服务容错：支持多种容错\n    * 性能：较好\n 3. gRPC\n    * 基于 HTTP/2 协议，支持多种数据序列化格式，如Protocol Buffers。\n    * 支持多种负载均衡策略\n    * 服务容错：支持多种容错，如超时、重试和取消等特性\n    * 性能 ：很好\n\n> 选择框架应根据具体需求和项目特点来决定。OpenFeign适合简单的RESTful服务，Dubbo适合大规模分布式系统，而gRPC适合高性能、跨语言的微服务。编码难度和性能方面也需根据团队技术栈和项目需求来考虑。\n\n编码难度：\n\nOpenFeign相对较容易上手，特别适合Java开发者，因为它与Spring框架集成得很好。RESTful服务的开发通常比较直观。\n\nDubbo在配置和治理方面可能更复杂一些，但提供了更多的功能，如服务注册、动态代理等。需要更多的配置和管理。\n\ngRPC使用Protocol Buffers来定义服务接口和消息，这可能需要一些学习成本。但一旦掌握，它提供了强大的IDL支持，可以生成客户端和服务端的代码，减少了手动编码的工作。',normalizedContent:'# 1. feign 是什么\n\nfeign 旨在使 java http 客户端通信变得更容易\n\nfeign 集成了 ribbon、resttemplate 实现了负载均衡的执行http调用，只不过对原有的方式（ribbon + resttemplate）进行了封装，开发者不需要手动使用 resttemplate 调用服务，而是定义一个接口，在这个接口中标注一个注解即可完成服务调用，这样更加面向接口编程，简化了开发。\n\n但遗憾的是 feign 已经停止迭代了。openfeign 才是今天的重点。\n\n\n# 2. openfeign 是什么\n\n简单来说，openfeign 使 springcloud 在 feign 的基础上支持了 springmvc 的注解，如 @requestmapping...\n\nopenfeign 的 @feignclient 可以解析 springmvc 的 @requestmapping 注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用服务。\n\n> 官网：https://docs.spring.io/spring-cloud-openfeign/docs/2.2.10.build-snapshot/reference/html\n\n\n# 3. openfeign 的使用\n\n接着之前 nacos 的两个项目：cloud-goods、cloud-orders 来完成，在 cloud-orders 中远程调用了 cloud-goods 的服务。现在我们将它从 resttemplate 改为 openfeign。\n\n给 cloud-orders 添加依赖：\n\n<dependency>\n    <groupid>org.springframework.cloud</groupid>\n    <artifactid>spring-cloud-starter-openfeign</artifactid>\n</dependency>\n\n\n在启动类加上注解：@enablefeignclients(basepackages = "xxx")\n\n@springbootapplication\n@enablediscoveryclient\n@enablefeignclients(basepackages = "com.xiaohe.orders.api")\npublic class ordersapp {\n    public static void main(string[] args) {\n        springapplication.run(ordersapp.class, args);\n    }\n}\n\n\n在cloud-orders项目的 com.xiaohe.orders.api 包下创建映射 cloud-goods 服务的接口：\n\npackage com.xiaohe.orders.api;\n\nimport com.xiaohe.entity.goods;\nimport org.springframework.cloud.openfeign.feignclient;\nimport org.springframework.web.bind.annotation.pathvariable;\nimport org.springframework.web.bind.annotation.requestmapping;\n\n@feignclient("cloud-goods") // 指定服务名\n@requestmapping("/goods") // 请求路径\npublic interface goodsapi {\n    @requestmapping("/findbyid/{id}")\n    public goods findbyid(@pathvariable("id") string id);\n}\n\n\n在controller中调用远程服务：\n\n@slf4j\n@restcontroller\n@requestmapping("/order")\npublic class ordercontroller {\n    @resource\n    private goodsapi goodsapi;\n\n\n    @requestmapping("/save")\n    public map save() {\n        // 从 cloud-goods 服务中获取商品信息\n        goods goods = goodsapi.findbyid("1");\n\n        return new hashmap() {\n            {\n                put("code", 200);\n                put("message", "success");\n                put("goods", goods);\n            }\n        };\n    }\n}\n\n\n\n# 4. 请求超时时间\n\n由于 openfeign 是发送 http 请求的工具，http 请求是有超时时间的，默认分别是连接超时时间10秒、读超时时间60秒\n\n但是又因为 openfeign 集成了 ribbon ，ribbon 的默认超时连接时间、读超时时间都是是1秒。\n\n在我们没有给 openfeign 指定 连接超时时间、读超时时间 的情况下，它默认使用 ribbon 的，只要被调用的服务那里执行超过了1s，此次请求就会报错。1s实在是太勉强了，所以我们要单独给 openfeign 指定超时时间。\n\n 1. 设置全部接口的超时时间\n    \n    feign:\n      client:\n        config:\n          ## default 设置的全局超时时间，指定服务名称可以设置单个服务的超时时间\n          default:\n            connecttimeout: 5000\n            readtimeout: 5000\n    \n\n 2. 给某个调用服务单独设置超时时间：\n    \n    feign:\n      client:\n        config:\n          ## default 设置的全局超时时间，指定服务名称可以设置单个服务的超时时间 : 5s\n          default:\n            connecttimeout: 5000\n            readtimeout: 5000\n          ## 为servicec这个服务单独配置超时时间 : 30s\n          servicec:\n            connecttimeout: 30000\n            readtimeout: 30000\n    \n\n\n# 5. 开启日志增强\n\nopenfeign 提供了日志增强功能，默认关闭，不过开发者在调试阶段可以自己配置 openfeign 的日志级别。\n\n如果不开启，发起请求的时候不会有日志，如果开启了，就会打印此次请求的url、请求头、响应头等信息。\n\nopenfeign 的日志级别如下：\n\n 1. none ：默认，不显示任何日志\n 2. basic ：仅仅记录请求方法、url、响应状态码、执行时间\n 3. headers ：除了 basic 的信息之外，还记录请求头、响应头的信息。\n 4. full ：除了 headers 的信息之外，还记录请求和响应的正文及元数据。\n\n配置如何开启？openfeign提供两种开启方式 ：全局配置和局部配置。\n\n 1. 全局配置：加了 @configuration 注解表示全局配置，对所有服务起作用\n    \n    import feign.logger;\n    import org.springframework.context.annotation.bean;\n    import org.springframework.context.annotation.configuration;\n    \n    @configuration\n    public class feignconfig {\n    \n        @bean\n        public logger.level feignloggerlevel(){\n            return logger.level.full;\n        }\n    }\n    \n\n 2. 局部配置 ：配置类上不加 @configuration，并且在使用者的 @feignclient 中的 configuration 变量指定使用这个配置类。\n    \n    import feign.logger; // 导包不要导错了\n    import org.springframework.context.annotation.bean;\n    import org.springframework.context.annotation.configuration;\n    // 这里没有加 @configuration，代表这是某一个服务专用的配置类\n    public class goodsfeignconfig {\n        @bean\n        public logger.level feignloggerlevel(){\n            return logger.level.headers;\n        }\n    }\n    \n    \n    // 指定服务名、配置类\n    @feignclient(name = "cloud-goods", configuration = goodsfeignconfig.class) \n    @requestmapping("/goods") // 路径\n    public interface goodsapi {\n        @requestmapping("/findbyid/{id}")\n        public goods findbyid(@pathvariable("id") string id);\n    }\n    \n\n\n# 6. 使用其他 http client\n\nopenfeign 使用的http客户端是 jdk 自带的 httpurlconnection，它没有连接池，性能和效率也比较低。\n\n我们可以换成其他的 http client，比如 okhttp、apachehttpclient。\n\n 1. 使用 apachehttpclient\n    \n    添加依赖：\n    \n    \x3c!--     使用apache httpclient替换feign原生httpclient--\x3e\n        <dependency>\n          <groupid>org.apache.httpcomponents</groupid>\n          <artifactid>httpclient</artifactid>\n        </dependency>\n        \n        <dependency>\n          <groupid>io.github.openfeign</groupid>\n          <artifactid>feign-httpclient</artifactid>\n        </dependency>\n    \n    \n    添加配置：\n    \n    feign:\n      client:\n        httpclient:\n          # 开启 http client\n          enabled: true\n    \n\n 2. 使用 okhttp\n    \n    添加依赖：\n    \n    <dependency>\n        <groupid>io.github.openfeign</groupid>\n        <artifactid>feign-okhttp</artifactid>\n    </dependency>\n    \n    \n    添加配置;\n    \n    feign: \n      ## 禁止使用自带的 http client\n      httpclient:\n        enabled: false\n      # okhttp参数配置\n      okhttp:\n        enabled: true\n        max-connections: 200 # 默认值\n        max-connections-per-route: 50 # 默认值\n    \n\n\n# 7. 自定义 请求拦截器\n\n请求拦截器是用来拦截请求的，什么情况下要拦截我们发出去的请求呢？比如我的http请求头中需要携带数据。\n\n一个最常用的场景就是请求头中携带token。cloud-orders 调用 cloud-goods，如果 cloud-goods 需要验证身份信息，也就是需要token，我们默认发出的请求可没有token，这时候就需要把请求拦截下来，把 token 塞进去。\n\n这个接口是 requestinterceptor，不管是直接以 bean 的放入注入，还是实现一下再注入，只要容器中有这个类就可以对请求进行拦截。\n\n@slf4j\n@configuration\npublic class openfeignconfig {\n    \n    @bean\n    public requestinterceptor requestinterceptor() {\n        \n        return requesttemplate -> {\n\n            string token;\n            // 请求方\n            servletrequestattributes requestattributes = (servletrequestattributes) requestcontextholder.getrequestattributes();\n            if (objutil.isempty(requestattributes)) {\n                return;\n            } else {\n                // 获取请求方token\n                httpservletrequest request = requestattributes.getrequest();\n                token = request.getheader("authorization");\n            }\n            // 被请求方设置token，实现token中转\n            requesttemplate.header("authorization", token);\n        };\n    }\n    \n}\n\n\n\n# 7. 熔断降级\n\nopenfeign 默认使用 hystrix 进行熔断降级，但是我想用 sentinel 怎么办？请见下一章。\n\n\n# 8. 几种不同的rpc方案\n\n 1. openfeign ：\n    * 基于 http协议（restful风格） 的 rpc请求工具，数据通常是 json 格式\n    * 由于集成了 ribbon ，可以进行负载均衡\n    * 服务容错 ：支持多种容错，默认使用 hsytrix，也集成了 sentinel\n    * 性能 ：一般\n 2. dubbo ：\n    * 基于自定义的二进制rpc协议\n    * 支持四种负载均衡策略\n    * 服务容错：支持多种容错\n    * 性能：较好\n 3. grpc\n    * 基于 http/2 协议，支持多种数据序列化格式，如protocol buffers。\n    * 支持多种负载均衡策略\n    * 服务容错：支持多种容错，如超时、重试和取消等特性\n    * 性能 ：很好\n\n> 选择框架应根据具体需求和项目特点来决定。openfeign适合简单的restful服务，dubbo适合大规模分布式系统，而grpc适合高性能、跨语言的微服务。编码难度和性能方面也需根据团队技术栈和项目需求来考虑。\n\n编码难度：\n\nopenfeign相对较容易上手，特别适合java开发者，因为它与spring框架集成得很好。restful服务的开发通常比较直观。\n\ndubbo在配置和治理方面可能更复杂一些，但提供了更多的功能，如服务注册、动态代理等。需要更多的配置和管理。\n\ngrpc使用protocol buffers来定义服务接口和消息，这可能需要一些学习成本。但一旦掌握，它提供了强大的idl支持，可以生成客户端和服务端的代码，减少了手动编码的工作。',charsets:{cjk:!0},lastUpdated:"2023/10/30, 14:49:17",lastUpdatedTimestamp:1698648557e3},{title:"5. 定时任务是如何执行的",frontmatter:{title:"5. 定时任务是如何执行的",date:"2023-11-20T12:56:32.000Z",permalink:"/pages/5531a6/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/100.XXL-JOB/5.%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84.html",relativePath:"02.文章/91.框架/100.XXL-JOB/5.定时任务是如何执行的.md",key:"v-0112e9f6",path:"/pages/5531a6/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. TriggerParam",slug:"_1-triggerparam",normalizedTitle:"1. triggerparam",charIndex:149},{level:2,title:"2. 定义定时任务",slug:"_2-定义定时任务",normalizedTitle:"2. 定义定时任务",charIndex:1945},{level:2,title:"3. 收集定时任务",slug:"_3-收集定时任务",normalizedTitle:"3. 收集定时任务",charIndex:3815},{level:2,title:"4. 定时任务的执行",slug:"_4-定时任务的执行",normalizedTitle:"4. 定时任务的执行",charIndex:18422},{level:2,title:"5. XxlJobContext",slug:"_5-xxljobcontext",normalizedTitle:"5. xxljobcontext",charIndex:29552},{level:2,title:"7. 执行器对 JobThread 的管理",slug:"_7-执行器对-jobthread-的管理",normalizedTitle:"7. 执行器对 jobthread 的管理",charIndex:51471},{level:2,title:"7. 总结",slug:"_7-总结",normalizedTitle:"7. 总结",charIndex:53728}],headersStr:"0. 前言 1. TriggerParam 2. 定义定时任务 3. 收集定时任务 4. 定时任务的执行 5. XxlJobContext 7. 执行器对 JobThread 的管理 7. 总结",content:'# 0. 前言\n\n为什么从执行器开始讲，因为从上向下和从下向上讲都有利有弊，我选择隐藏上层实现的细节，等执行器讲完了再讲调度中心。\n\n由于没有讲调度中心，你只要把调度中心想象为一个黑盒，它会将马上就执行的任务从数据库中查出来，然后发送 HTTP 消息给执行器，执行器拿到信息后去执行。\n\n\n\n\n# 1. TriggerParam\n\n调度参数，什么叫调度参数？就是调度中心从数据库中查找到要执行的任务后，将这个参数发送给执行器，执行器根据调度参数内的值进行执行。\n\n这个消息包含什么信息呢？\n\npublic class TriggerParam implements Serializable {\n    // 使用了 JDK 序列化\n    private static final long serialVersionUID = 42L;\n\n    /**\n     * 任务id\n     */\n    private int jobId;\n\n    /**\n     * 定时任务名\n     */\n    private String executorHandler;\n\n    /**\n     * 定时任务的参数\n     */\n    private String executorParams;\n\n    /**\n     * 定时任务的阻塞策略                <br></br>\n     * 当一个定时任务想要执行，但是负责该任务的线程正在工作时会使用这个阻塞策略判断\n     */\n    private String executorBlockStrategy;\n\n    /**\n     * 任务的过期时间          <br></br>\n     * 如果开启了过期时间，执行任务时会额外创建一个新线程执行任务，\n     * 之前的线程负责监督新线程执行任务时间是否超时\n     */\n    private int executorTimeout;\n\n    /**\n     * 该任务对应的日志的id\n     */\n    private long logId;\n\n    /**\n     * 打日志的时间\n     */\n    private long logDateTime;\n\n    /**\n     * 运行模式\n     */\n    private String glueType;\n\n    /**\n     * 代码文本\n     */\n    private String glueSource;\n\n    /**\n     * 代码文本更新时间\n     */\n    private long glueUpdatetime;\n\n    /**\n     * 分片索引\n     */\n    private int broadcastIndex;\n\n    /**\n     * 分片总数\n     */\n    private int broadcastTotal;\n\n    public int getJobId() {\n        return jobId;\n    }\n}\n\n\n其实很多变量在意料之中，id、executorHandler啥的必须有，但是为什么有 logId 呢？执行的时候跟 logId 有什么关系呢？\n\n在上文中我们分析了 xxl-job 的数据库表，着重强调了 xxl_job_log 的两个字段 ：trigger_code、handle_code\n\n * trigger_code ：是否调度成功，也就是 HTTP消息发送成功没有\n * handle_code ：是否执行成功，也就是定时任务代码执行过程中是否出现了bug\n\nxxl-job 在消息发送之前，会为每一次执行生成一条日志，这条数据在数据库的 xxl_job_log 中，HTTP消息（也就是TriggerParam ）到达执行器时，这条log就已经有 trigger_code 了。所以我们要在执行的时候记录一些 handle_code、handle_message，等任务执行完再发送回调度中心，调度中心接收到这条消息后就可以补全本次执行的日志。\n\n有了 TriggerParam ，xxl-job 的工作流程变为 ：\n\n * 调度中心从数据库中查询定时任务\n * 将任务封装为 TriggerParam 发送给执行器\n * 执行器拿到 TriggerParam 后执行对应的任务\n\n现在我们不知道的是 ：定时任务以什么形式存在于执行器、定时任务如何执行的。接下来会具体分析这两点。\n\n\n# 2. 定义定时任务\n\n定时任务在 Xxl-Job 中以什么形式存在呢？肯定要有一个类封装它。\n\n首先，我们先定义接口，接口规定的是行为，一个任务需要有哪些行为？执行、初始化、销毁。\n\n但是并非所有任务都需要初始化、销毁，所以我们将 IJobHandler 定义为抽象类，给初始化和销毁方法默认实现。\n\npublic abstract class IJobHandler {\n\n\tpublic abstract void execute() throws Exception;\n\n\tpublic void init() throws Exception {\n\n\t}\n\n\tpublic void destroy() throws Exception {\n\n\t}\n}\n\n\n一个方法想要执行，肯定要有Class对象、Method方法，同时我想让功能更加丰富，于是给每一个定时任务加上初始化方法、销毁方法。\n\npublic class MethodJobHandler extends IJobHandler {\n    // bean对象的class\n    private final Object target;\n    // 需要执行的method\n    private final Method method;\n    // 初始化和销毁方法\n    private Method initMethod;\n    private Method destroyMethod;\n\n    public MethodJobHandler(Object target, Method method, Method initMethod, Method destroyMethod) {\n        this.target = target;\n        this.method = method;\n\n        this.initMethod = initMethod;\n        this.destroyMethod = destroyMethod;\n    }\n\n    @Override\n    public void execute() throws Exception {\n        Class<?>[] paramTypes = method.getParameterTypes();\n        if (paramTypes.length > 0) {\n            method.invoke(target, new Object[paramTypes.length]);       // method-param can not be primitive-types\n        } else {\n            method.invoke(target);\n        }\n    }\n\n    @Override\n    public void init() throws Exception {\n        if(initMethod != null) {\n            initMethod.invoke(target);\n        }\n    }\n\n    @Override\n    public void destroy() throws Exception {\n        if(destroyMethod != null) {\n            destroyMethod.invoke(target);\n        }\n    }\n\n    @Override\n    public String toString() {\n        return super.toString()+"["+ target.getClass() + "#" + method.getName() +"]";\n    }\n}\n\n\n其实上面的逻辑不难对吧，一共就三个方法，执行、初始化、销毁。\n\n * 执行 ：如果没有参数直接就 method.invoke(target)\n * 初始化 ：如果初始化Method不为空就执行\n * 销毁 ：如果销毁Method不为空就执行\n\n当想要执行一个定时任务的时候，只需要先 new MethodJobHandler，然后调用 jobhandler.executor() 就可执行。\n\n\n# 3. 收集定时任务\n\n光封装定时任务可不够，我们还要拿到定时任务，也就是凭借调度中心发送来的 TriggerParam 找到 MethodJobHandler，怎么找呢？难道每一次执行任务都需要重新找吗？\n\n别忘了，代码运行之后就没法更改了，所以我们可以趁代码运行后，将所有定时任务收集起来，可以用List、Map这种容器装起来，你想要？没问题，拿任务的唯一标识给我换~~说到唯一标识，聪明的你肯定想到了Map，因为它是 key-value 形式的，我们可以使用 id-jobHandler 也可以使用 jobName-jobHandler 存放任务，跟我们的业务完全符合！\n\n先来看看之前我们写的定时任务代码：\n\n@Component\npublic class SampleXxlJob {\n\n    @XxlJob("demoJobHandler")\n    public void demoJobHandler() throws Exception {\n        System.out.println("简单任务实例执行了");\n    }\n}\n\n\n如果是你，如何获取这个任务呢？由于 SampleXxlJob 这个类已经被注入到 Spring 容器中了，那么我们获取 Spring 容器遍历容器中的所有Bean，如果某个 Bean 有 @XxlJob 这个注解，那么这个 Bean + Method就是我们要找的定时任务。\n\n肯定要由执行器做这种事情，因为我们的项目引入的是执行器依赖，换言之，我们的项目现在就是一个执行器了。\n\n所以我将这个“收集定时任务”的类叫做 XxlJobSpringExecutor\n\n在代码中需要拿到 Spring 的上下文 context，然后就可以通过 context 获取所有的bean。\n\npublic class XxlJobSpringExecutor implements ApplicationContextAware {\n\n    private static ApplicationContext applicationContext;\n\n    @Override\n    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {\n        XxlJobSpringExecutor.applicationContext = applicationContext;\n    }\n\n    public static ApplicationContext getApplicationContext() {\n        return applicationContext;\n    }\n}\n\n\n现在又有一个新问题：什么时候开始收集定时任务呢？Spring容器初始化前？Spring容器初始化后？\n\n在定时任务中，有可能使用 Mapper、RedisTemplate、rpc 各种Spring bean去完成工作，那肯定是 Spring 的容器初始化之后收集定时任务了。\n\n所以我们要实现 SmartInitializingSingleton，在所有单例对象准备好之后，我们开始收集任务。\n\npublic class XxlJobSpringExecutor implements ApplicationContextAware, SmartInitializingSingleton {\n    \n    @Override\n    public void afterSingletonsInstantiated() {\n        // 在这里收集定时任务\n        initJobHandlerMethodRepository(applicationContext);\n    }\n   \n    private static ApplicationContext applicationContext;\n    \n\n    @Override\n    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {\n        XxlJobSpringExecutor.applicationContext = applicationContext;\n    }\n\n    public static ApplicationContext getApplicationContext() {\n        return applicationContext;\n    }\n}\n\n\n再来思考一个问题 ：收集定时任务，我们需要收集什么信息？执行一个任务，换言之，执行一个方法需要什么信息？\n\n 1. 被执行的方法 ：method\n 2. 反射执行任务的代码为 ：method.invoke(class)，所以还需要 class 对象，一个类中可能有多个定时任务，但是管它呢，有多少我要多少。\n 3. 上面两个属性可以封装为一个 MethodHandler，想要通过定时任务名找到MethodHandler，所以需要拿到定时任务名字。\n\n经过上面的分析，我们初步决定，遍历 Spring 的所有bean，必须拿到以下三个信息：\n\n 1. jobName\n 2. class\n 3. method\n\n伪代码应该是这样：\n\n// 这个Map负责收集所有定时任务\nMap<String, MethodJobHandler> jobMap = new ....();\n// 开始遍历每一个Bean\nfor (Object bean : springBeans) {\n    // 收集这个bean中的定时任务\n    Map<XxlJob, Method> map = new Map<>();\n    Method[] methods = bean.getMethods();\n    for (Method method : methods) {\n        if (method上有@XxlJob注解) {\n            map.put(xxljob, method);\n        }\n    }\n    // 如果这个bean里面没有定时任务就下一个。\n    if (map.size() <= 0) continue;\n    \n    // 遍历Map进行注册，将其注册到\n    for (Map.Entry<XxlJob, Method> entry : Map.entrySet()) {\n        MethodHandler handler = new MethodJobHandler(bean.class, entry.value());\n    \tjobMap.put(xxljob.name(), handler);\n    }\n    \n}\n\n\n但是 xxl-job 并没有这么做，它把 定时任务的收集 和定时任务的注册 分开进行，为什么？\n\n今天你使用 Spring 集成 xxl-job 可以使用 Spring 容器进行收集，但是明天你没有用 xxl-job 怎么办？收集怎么做？\n\n所以将这两步分开进行，可以减少集成其他框架时的工作量。那么寻找这一步就可能有很多种实现方式，但是注册不一样，不管你跟多少框架集成，最终你要给我 bean、method、xxljob注解，这三样东西就行。\n\n由于注册不需要依赖于任何框架， 收集需要依赖于Spring，而业务的逻辑肯定是收集之后再注册，所以我们将行为定义成这样：\n\npublic abstract class XxlJobExecutor {\n    public void 注册(Object bean, Method method, XxlJob xxljob) {\n        // 功能实现\n    }\n}\n\n\npublic abstract class XxlJobSringExecutor extends XxlJobExecutor {\n\tpublic  void 收集() {\n        // 从定时任务中找出所有定时任务\n        Map<XxlJob, Method> map = new Map<>();\n        Method[] methods = bean.getMethods();\n        for (Method method : methods) {\n            if (method上有@XxlJob注解) {\n                map.put(xxljob, method);\n            }\n        }\n        // 如果这个bean里面没有定时任务就下一个。\n        if (map.size() <= 0) continue;\n\n        // 调用从父类继承过来的注册方法进行注册。\n        for (Map.Entry<XxlJob, Method> entry : Map.entrys()) {\n        \t注册(bean, entry.key, entry.value);\n    \t}\n    }\n}\n\n\n先来看一下 XxlJobSpringExecutor 中收集定时任务的代码，代码多但是不难：\n\nprivate void initJobHandlerMethodRepository(ApplicationContext applicationContext) {\n        // 容器判空\n        if (applicationContext == null) {\n            return;\n        }\n        // 拿到所有bean对象的名字\n    \t// getBeanNamesForType有三个参数:\n    \t// type : 类型\n    \t// includeNonSingletons : 是否包含多实例对象\n    \t// allowEagerInit : 是否包含懒加载对象\n        String[] beanDefinitionNames = applicationContext.getBeanNamesForType(Object.class, false, true);\n        for (String beanDefinitionName : beanDefinitionNames) {\n\n            // 通过name拿到bean对象\n            Object bean = null;\n            Lazy onBean = applicationContext.findAnnotationOnBean(beanDefinitionName, Lazy.class);\n            if (onBean!=null){\n                logger.debug("xxl-job annotation scan, skip @Lazy Bean:{}", beanDefinitionName);\n                continue;\n            }else {\n                bean = applicationContext.getBean(beanDefinitionName);\n            }\n\n            // 这个Map用于收集定时任务，这个Map代表当前遍历的bean中所有的定时任务。\n            // Method : 定时任务方法\n            // XxlJob : 这个定时任务的注解，通过 XxlJob可以得到定时任务的名字\n            Map<Method, XxlJob> annotatedMethods = null;   \n            try {\n                annotatedMethods = MethodIntrospector.selectMethods(bean.getClass(),\n                        new MethodIntrospector.MetadataLookup<XxlJob>() {\n                            @Override\n                            public XxlJob inspect(Method method) {\n                                return AnnotatedElementUtils.findMergedAnnotation(method, XxlJob.class);\n                            }\n                        });\n            } catch (Throwable ex) {\n                logger.error("xxl-job method-jobhandler resolve error for bean[" + beanDefinitionName + "].", ex);\n            }\n            // 如果这个Bean中没有定时任务，跳过\n            if (annotatedMethods==null || annotatedMethods.isEmpty()) {\n                continue;\n            }\n\n            // 已经收集到该Bean的所有定时任务，要把它统一放在一个地方\n            // registJobHandler\n            for (Map.Entry<Method, XxlJob> methodXxlJobEntry : annotatedMethods.entrySet()) {\n                Method executeMethod = methodXxlJobEntry.getKey();\n                XxlJob xxlJob = methodXxlJobEntry.getValue();\n                // regist\n                registJobHandler(xxlJob, bean, executeMethod);\n            }\n\n        }\n    }\n\n\n 1. 拿到所有 Bean 对象的名字，遍历名字，根据名字获取Bean对象\n 2. 使用 Spring 提供的工具类 MethodIntrospector.selectMethods 查看一个类中有没有加了 @XxlJob 注解的方法\n 3. 如果有，就将这些方法按照 method:xxljob 的形式封装进 Map 中。\n 4. 将这个 Bean 中所有定时任务注册到某个地方，以便使用\n 5. 开始遍历下一个 Bean，重复上述步骤\n\n再看看 XxlJobExecutor 中 注册任务的逻辑 ：\n\npublic class XxlJobExecutor {\n    // 存放 MethodJobHandler 的Map容器\n    // key : 定时任务的名字\n    private static ConcurrentMap<String, IJobHandler> jobHandlerRepository = new ConcurrentHashMap<String, IJobHandler>();\n    public static IJobHandler registJobHandler(String name, IJobHandler jobHandler){\n        logger.info(">>>>>>>>>>> xxl-job register jobhandler success, name:{}, jobHandler:{}", name, jobHandler);\n        return jobHandlerRepository.put(name, jobHandler);\n    }\n    protected void registJobHandler(XxlJob xxlJob, Object bean, Method executeMethod){\n        if (xxlJob == null) {\n            return;\n        }\n\n        String name = xxlJob.value();\n        //make and simplify the variables since they\'ll be called several times later\n        Class<?> clazz = bean.getClass();\n        String methodName = executeMethod.getName();\n        if (name.trim().length() == 0) {\n            throw new RuntimeException("xxl-job method-jobhandler name invalid, for[" + clazz + "#" + methodName + "] .");\n        }\n        if (loadJobHandler(name) != null) {\n            throw new RuntimeException("xxl-job jobhandler[" + name + "] naming conflicts.");\n        }\n\n        executeMethod.setAccessible(true);\n\n        // init and destroy\n        Method initMethod = null;\n        Method destroyMethod = null;\n\n        if (xxlJob.init().trim().length() > 0) {\n            try {\n                initMethod = clazz.getDeclaredMethod(xxlJob.init());\n                initMethod.setAccessible(true);\n            } catch (NoSuchMethodException e) {\n                throw new RuntimeException("xxl-job method-jobhandler initMethod invalid, for[" + clazz + "#" + methodName + "] .");\n            }\n        }\n        if (xxlJob.destroy().trim().length() > 0) {\n            try {\n                destroyMethod = clazz.getDeclaredMethod(xxlJob.destroy());\n                destroyMethod.setAccessible(true);\n            } catch (NoSuchMethodException e) {\n                throw new RuntimeException("xxl-job method-jobhandler destroyMethod invalid, for[" + clazz + "#" + methodName + "] .");\n            }\n        }\n\n        // registry jobhandler\n        registJobHandler(name, new MethodJobHandler(bean, executeMethod, initMethod, destroyMethod));\n\n    }\n}\n\n\nregistJobHandler(XxlJob xxlJob, Object bean, Method executeMethod)\n\n 1. xxlJob ：定时任务头上的注解，含有该任务的名字、初始化方法、销毁方法\n 2. bean ：该任务方法属于哪个类，需要通过它拿到 class\n 3. executorMethod ：定时任务的方法\n\n这个方法的总流程：\n\n 1. 根据传入的参数获取定时任务的 名字、class对象、方法名\n 2. 检查参数，并且根据定时任务的名字判断是否已经出现过，不允许任务名重复\n 3. 如果初始化方法、销毁方法不为空，得到这两个方法\n 4. 将 class对象、定时任务方法、初始化方法、销毁方法 封装为 MethodJobHandler ，并且以方法名为 key 放入 Map\n\n以后就可以通过定时任务的名称来找到 MethodJobHandler，使用 execute() 来执行。\n\npublic static IJobHandler loadJobHandler(String name){\n    return jobHandlerRepository.get(name);\n}\n\n\n那么现在 收集定时任务的流程为：\n\n 1. XxlJobSpringExecutor 找到加了 @XxlJob 注解的方法\n 2. 注册到 XxlJobExecutor 的 Map 中。\n\n最后，上完整代码：\n\npublic class XxlJobSpringExecutor extends XxlJobExecutor implements ApplicationContextAware, SmartInitializingSingleton, DisposableBean {\n    @Override\n    public void afterSingletonsInstantiated() {\n        // 在这里收集定时任务\n        initJobHandlerMethodRepository(applicationContext);\n    }\n   \n    private static ApplicationContext applicationContext;\n    \n\n    @Override\n    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {\n        XxlJobSpringExecutor.applicationContext = applicationContext;\n    }\n\n    public static ApplicationContext getApplicationContext() {\n        return applicationContext;\n    }\n    private void initJobHandlerMethodRepository(ApplicationContext applicationContext) {\n        if (applicationContext == null) {\n            return;\n        }\n        // init job handler from method\n        String[] beanDefinitionNames = applicationContext.getBeanNamesForType(Object.class, false, true);\n        for (String beanDefinitionName : beanDefinitionNames) {\n\n            // get bean\n            Object bean = null;\n            Lazy onBean = applicationContext.findAnnotationOnBean(beanDefinitionName, Lazy.class);\n            if (onBean!=null){\n                logger.debug("xxl-job annotation scan, skip @Lazy Bean:{}", beanDefinitionName);\n                continue;\n            }else {\n                bean = applicationContext.getBean(beanDefinitionName);\n            }\n\n            // filter method\n            Map<Method, XxlJob> annotatedMethods = null;   // referred to ：org.springframework.context.event.EventListenerMethodProcessor.processBean\n            try {\n                annotatedMethods = MethodIntrospector.selectMethods(bean.getClass(),\n                        new MethodIntrospector.MetadataLookup<XxlJob>() {\n                            @Override\n                            public XxlJob inspect(Method method) {\n                                return AnnotatedElementUtils.findMergedAnnotation(method, XxlJob.class);\n                            }\n                        });\n            } catch (Throwable ex) {\n                logger.error("xxl-job method-jobhandler resolve error for bean[" + beanDefinitionName + "].", ex);\n            }\n            if (annotatedMethods==null || annotatedMethods.isEmpty()) {\n                continue;\n            }\n\n            // generate and regist method job handler\n            for (Map.Entry<Method, XxlJob> methodXxlJobEntry : annotatedMethods.entrySet()) {\n                Method executeMethod = methodXxlJobEntry.getKey();\n                XxlJob xxlJob = methodXxlJobEntry.getValue();\n                // regist\n                registJobHandler(xxlJob, bean, executeMethod);\n            }\n\n        }\n    }\n}\n\n\npublic class XxlJobExecutor {\n    // 存放 MethodJobHandler 的Map容器\n    // key : 定时任务的名字\n    private static ConcurrentMap<String, IJobHandler> jobHandlerRepository = new ConcurrentHashMap<String, IJobHandler>();\n    public static IJobHandler loadJobHandler(String name){\n    \treturn jobHandlerRepository.get(name);\n\t}\n\n    protected void registJobHandler(XxlJob xxlJob, Object bean, Method executeMethod){\n        if (xxlJob == null) {\n            return;\n        }\n\n        String name = xxlJob.value();\n        //make and simplify the variables since they\'ll be called several times later\n        Class<?> clazz = bean.getClass();\n        String methodName = executeMethod.getName();\n        if (name.trim().length() == 0) {\n            throw new RuntimeException("xxl-job method-jobhandler name invalid, for[" + clazz + "#" + methodName + "] .");\n        }\n        if (loadJobHandler(name) != null) {\n            throw new RuntimeException("xxl-job jobhandler[" + name + "] naming conflicts.");\n        }\n\n        executeMethod.setAccessible(true);\n\n        // init and destroy\n        Method initMethod = null;\n        Method destroyMethod = null;\n\n        if (xxlJob.init().trim().length() > 0) {\n            try {\n                initMethod = clazz.getDeclaredMethod(xxlJob.init());\n                initMethod.setAccessible(true);\n            } catch (NoSuchMethodException e) {\n                throw new RuntimeException("xxl-job method-jobhandler initMethod invalid, for[" + clazz + "#" + methodName + "] .");\n            }\n        }\n        if (xxlJob.destroy().trim().length() > 0) {\n            try {\n                destroyMethod = clazz.getDeclaredMethod(xxlJob.destroy());\n                destroyMethod.setAccessible(true);\n            } catch (NoSuchMethodException e) {\n                throw new RuntimeException("xxl-job method-jobhandler destroyMethod invalid, for[" + clazz + "#" + methodName + "] .");\n            }\n        }\n\n        // registry jobhandler\n        registJobHandler(name, new MethodJobHandler(bean, executeMethod, initMethod, destroyMethod));\n\n    }\n    public static IJobHandler registJobHandler(String name, IJobHandler jobHandler){\n        logger.info(">>>>>>>>>>> xxl-job register jobhandler success, name:{}, jobHandler:{}", name, jobHandler);\n        return jobHandlerRepository.put(name, jobHandler);\n    }\n}\n\n\n其实这两个类的代码远不及如此，我觉得 xxl-job 作为一个小而精的框架，它的代码虽然少但是读起来很难受。\n\n没有遵循 “一个方法占一屏” 的良好习惯~\n\n\n# 4. 定时任务的执行\n\n现在让我们分析一下使用什么模式去执行定时任务，列举一下可能用到的模式：\n\n 1. 每一次接收 TriggerParam 都新创建一个线程去执行。\n 2. 使用线程池接收 TriggerParam 执行。\n 3. 一个线程负责一个任务，同一个任务的TriggerParam都由这个线程接收并执行。\n\n如果是你，如何选择？不卖关子，xxl-job 使用第三种模式执行定时任务，而且对这种模式进行了改装 ：\n\n> xxl-job 是以每个线程负责某一个任务的执行，对于两种频率的任务 ：\n> \n>  1. 执行特别频繁的任务\n>     \n>     xxl-job 对线程进行了封装，每一个线程内部都有一个阻塞队列，所有 TriggerParam 都会进入负责对应任务的线程的阻塞队列中等待执行。\n> \n>  2. 执行不频繁的任务\n>     \n>     线程并不是一直都在工作，它是循环从阻塞队列中取 TriggerParam，如果 3秒钟取不到就进入下一次循环，同时记录这是第几次无效循环，如果超过30次，就将线程销毁。防止线程没事干又占资源。\n\n根据上面的描述，猜测一下 xxl-job 封装的线程需要哪些变量 ：\n\n阻塞队列、无效循环次数、线程是否还在工作的标志、线程是否正在运行任务的标志、任务执行需要的\n\npublic class JobThread extends Thread{\n    private static Logger logger = LoggerFactory.getLogger(JobThread.class);\n\t// 此时这个线程负责的定时任务的id\n\tprivate int jobId;\n    // 该定时任务的 MethodJobHandler\n\tprivate IJobHandler handler;\n    // 有任务时就会放到这个阻塞队列中\n\tprivate LinkedBlockingQueue<TriggerParam> triggerQueue;\n    // 防止重复调度\n    private Set<Long> triggerLogIdSet;\t\t\n\t// 该线程是否还在工作\n\tprivate volatile boolean toStop = false;\n    // 该线程停止的原因是什么，有可能是长时间没有任务，有可能是开发人员手动关闭定时任务\n\tprivate String stopReason;\n\t// 线程是否正在运行任务，"正在运行"不包括线程循环、阻塞等待任务到来，而是真真正正的正在运行任务\n    private boolean running = false;    \n    // 线程无效循环次数\n\tprivate int idleTimes = 0;\n    \n    public JobThread(int jobId, IJobHandler handler) {\n\t\tthis.jobId = jobId;\n\t\tthis.handler = handler;\n\t\tthis.triggerQueue = new LinkedBlockingQueue<TriggerParam>();\n\t\tthis.triggerLogIdSet = Collections.synchronizedSet(new HashSet<Long>());\n\n\t\tthis.setName("xxl-job, JobThread-"+jobId+"-"+System.currentTimeMillis());\n\t}\n}\n\n\n 1. 上面有一个 triggerLogIdSet，其实这个变量很难用上，所以这里先不说了。\n\n 2. toStop 和 running 有什么区别呢？\n    \n    toStop ：此线程是否还在运行\n    \n    running ：此线程是否正在运行任务\n    \n    它俩的区别 我们首先要阻塞着从队列中取值，这时 toStop = false，running = false，因为线程确实在运行，但是没有取到任务。\n    \n    从队列中取出 TriggerParam 后， toStop = false，running = true，因为现在已经可以开始运行任务了。\n\npublic class JobThread extends Thread{\n    private static Logger logger = LoggerFactory.getLogger(JobThread.class);\n\t// 此时这个线程负责的定时任务的id\n\tprivate int jobId;\n    // 该定时任务的 MethodJobHandler\n\tprivate IJobHandler handler;\n    // 有任务时就会放到这个阻塞队列中\n\tprivate LinkedBlockingQueue<TriggerParam> triggerQueue;\n    // 防止重复调度\n    private Set<Long> triggerLogIdSet;\t\t\n\t// 该线程是否还在工作\n\tprivate volatile boolean toStop = false;\n    // 该线程停止的原因是什么，有可能是长时间没有任务，有可能是开发人员手动关闭定时任务\n\tprivate String stopReason;\n\t// 线程是否正在运行任务，"正在运行"不包括线程循环、阻塞等待任务到来，而是真真正正的正在运行任务\n    private boolean running = false;    \n    // 线程无效循环次数\n\tprivate int idleTimes = 0;\t\t\t\n\n\n\tpublic JobThread(int jobId, IJobHandler handler) {\n\t\tthis.jobId = jobId;\n\t\tthis.handler = handler;\n\t\tthis.triggerQueue = new LinkedBlockingQueue<TriggerParam>();\n\t\tthis.triggerLogIdSet = Collections.synchronizedSet(new HashSet<Long>());\n\n\t\tthis.setName("xxl-job, JobThread-"+jobId+"-"+System.currentTimeMillis());\n\t}\n    // 调度中心从数据库中查出将要执行的任务，将这个任务发送给执行器\n    // 执行器收到消息后将这次执行放入队列中等待执行\n    public ReturnT<String> pushTriggerQueue(TriggerParam triggerParam) {\n\t\t// avoid repeat\n\t\tif (triggerLogIdSet.contains(triggerParam.getLogId())) {\n\t\t\tlogger.info(">>>>>>>>>>> repeate trigger job, logId:{}", triggerParam.getLogId());\n\t\t\treturn new ReturnT<String>(ReturnT.FAIL_CODE, "repeate trigger job, logId:" + triggerParam.getLogId());\n\t\t}\n\n\t\ttriggerLogIdSet.add(triggerParam.getLogId());\n\t\ttriggerQueue.add(triggerParam);\n        return ReturnT.SUCCESS;\n\t}\n    // 线程是否在工作，或者队列中是否有任务等待执行\n    public boolean isRunningOrHasQueue() {\n        return running || triggerQueue.size()>0;\n    }\n\n    @Override\n\tpublic void run() {\n\t\t// 暂不实现\n\t}\n}\n\n\n这个pushTriggerParam 没干啥事，无非就是判断一下是否重复调度，然后将triggerParam放入阻塞队列。\n\nrun方法才是重头戏：\n\n@Override\npublic void run() {\n\n    // init\n    try {\n        handler.init();\n    } catch (Throwable e) {\n        logger.error(e.getMessage(), e);\n    }\n\n    // \n    while(!toStop){\n        running = false;\n        idleTimes++;\n\n        TriggerParam triggerParam = null;\n        try {\n            triggerParam = triggerQueue.poll(3L, TimeUnit.SECONDS);\n            if (triggerParam != null) {\n                running = true;\n                idleTimes = 0;\n                triggerLogIdSet.remove(triggerParam.getLogId());\n                // 打印日志，表示任务将要执行\n                XxlJobHelper.log("<br>----------- xxl-job job execute start -----------<br>----------- Param:" + xxlJobContext.getJobParam());\n                // 执行任务!!!\n                handler.execute();\n            } else {\n                if (idleTimes > 30) {\n                    if(triggerQueue.size() == 0) {\t\n                        // 将此线程停止，或者说移除\n                        XxlJobExecutor.removeJobThread(jobId, "excutor idel times over limit.");\n                    }\n                }\n            }\n        } catch (Throwable e) {\n            if (toStop) {\n                XxlJobHelper.log("<br>----------- JobThread toStop, stopReason:" + stopReason);\n            }\n\n            // handle result\n            StringWriter stringWriter = new StringWriter();\n            e.printStackTrace(new PrintWriter(stringWriter));\n            String errorMsg = stringWriter.toString();\n\n            XxlJobHelper.handleFail(errorMsg);\n\n            XxlJobHelper.log("<br>----------- JobThread Exception:" + errorMsg + "<br>----------- xxl-job job execute end(error) -----------");\n        } finally {\n            if(triggerParam != null) {\n                // callback handler info\n                if (!toStop) {\n                    // commonm\n                    TriggerCallbackThread.pushCallBack(new HandleCallbackParam(\n                        triggerParam.getLogId(),\n                        triggerParam.getLogDateTime(),\n                        XxlJobContext.getXxlJobContext().getHandleCode(),\n                        XxlJobContext.getXxlJobContext().getHandleMsg() )\n                                                      );\n                } else {\n                    // is killed\n                    TriggerCallbackThread.pushCallBack(new HandleCallbackParam(\n                        triggerParam.getLogId(),\n                        triggerParam.getLogDateTime(),\n                        XxlJobContext.HANDLE_CODE_FAIL,\n                        stopReason + " [job running, killed]" )\n                                                      );\n                }\n            }\n        }\n    }\n    // destroy\n    try {\n        handler.destroy();\n    } catch (Throwable e) {\n        logger.error(e.getMessage(), e);\n    }\n    logger.info(">>>>>>>>>>> xxl-job JobThread stoped, hashCode:{}", Thread.currentThread());\n}\n\n\n源代码其实挺复杂的，而且很多东西现在没有讲到，所以我删减了很多，等会补上。\n\n 1. 执行初始化方法，进入循环\n\n 2. 每次循环都将 idleTimes 加一，从阻塞队列中取值，最多等待三秒，如果超过了就说明现在没有任务，再次循环，如果无效循环 30 次，就会触发 XxlJobExecutor.removeJobThread 将此线程停止并移除。\n\n 3. 如果从阻塞队列中取到了值，将 idleTimes置为0，并将 running = true 表示从现在开始要执行任务了\n    \n    打印一下日志，使用 handler.execute() 执行任务。\n\n 4. 如果出现异常，除了打印日志之外，执行了 XxlJobHelper.handleFail(errorMsg) 这句话，记住它，等会说\n\n 5. 在 finally 块中调用 TriggerCallbackThread.pushCallBack() 将任务执行的结果回调给调度中心，这个暂且不说，后面的章节会完善。\n\n但是现在定时任务的执行功能还不完善，我们之前使用的时候是有 超时时间 这个功能的，这个功能该如何实现？我们可以新创建一个线程，将定时任务包装为一个 FutureTask，在执行的时候 future.get(seconds)，如果执行超时，就会出现超时异常，我们将其捕获就可以了。\n\n添加了超时时间功能的代码：\n\n@Override\npublic void run() {\n\n    // init\n    try {\n        handler.init();\n    } catch (Throwable e) {\n        logger.error(e.getMessage(), e);\n    }\n\n    // execute\n    while(!toStop){\n        running = false;\n        idleTimes++;\n\n        TriggerParam triggerParam = null;\n        try {\n            triggerParam = triggerQueue.poll(3L, TimeUnit.SECONDS);\n            if (triggerParam!=null) {\n                running = true;\n                idleTimes = 0;\n                triggerLogIdSet.remove(triggerParam.getLogId());\n                // 打印日志，表示任务将要执行\n                XxlJobHelper.log("<br>----------- xxl-job job execute start -----------<br>----------- Param:" + xxlJobContext.getJobParam());\n                if (triggerParam.getExecutorTimeout() > 0) {\n                    // limit timeout\n                    Thread futureThread = null;\n                    try {\n                        FutureTask<Boolean> futureTask = new FutureTask<Boolean>(new Callable<Boolean>() {\n                            @Override\n                            public Boolean call() throws Exception {\n                                handler.execute();\n                                return true;\n                            }\n                        });\n                        futureThread = new Thread(futureTask);\n                        futureThread.start();\n\n                        Boolean tempResult = futureTask.get(triggerParam.getExecutorTimeout(), TimeUnit.SECONDS);\n                    } catch (TimeoutException e) {\n\n                        XxlJobHelper.log("<br>----------- xxl-job job execute timeout");\n                        XxlJobHelper.log(e);\n                    } finally {\n                        futureThread.interrupt();\n                    }\n                } else {\n                    // just execute\n                    handler.execute();\n                }\n            } else {\n                if (idleTimes > 30) {\n                    if(triggerQueue.size() == 0) {\t\n                        XxlJobExecutor.removeJobThread(jobId, "excutor idel times over limit.");\n                    }\n                }\n            }\n        } catch (Throwable e) {\n            if (toStop) {\n                XxlJobHelper.log("<br>----------- JobThread toStop, stopReason:" + stopReason);\n            }\n\n            // handle result\n            StringWriter stringWriter = new StringWriter();\n            e.printStackTrace(new PrintWriter(stringWriter));\n            String errorMsg = stringWriter.toString();\n\n            XxlJobHelper.handleFail(errorMsg);\n\n            XxlJobHelper.log("<br>----------- JobThread Exception:" + errorMsg + "<br>----------- xxl-job job execute end(error) -----------");\n        } finally {\n            if(triggerParam != null) {\n                // callback handler info\n                if (!toStop) {\n                    // commonm\n                    TriggerCallbackThread.pushCallBack(new HandleCallbackParam(\n                        triggerParam.getLogId(),\n                        triggerParam.getLogDateTime(),\n                        XxlJobContext.getXxlJobContext().getHandleCode(),\n                        XxlJobContext.getXxlJobContext().getHandleMsg() )\n                                                      );\n                } else {\n                    // is killed\n                    TriggerCallbackThread.pushCallBack(new HandleCallbackParam(\n                        triggerParam.getLogId(),\n                        triggerParam.getLogDateTime(),\n                        XxlJobContext.HANDLE_CODE_FAIL,\n                        stopReason + " [job running, killed]" )\n                                                      );\n                }\n            }\n        }\n    }\n    // destroy\n    try {\n        handler.destroy();\n    } catch (Throwable e) {\n        logger.error(e.getMessage(), e);\n    }\n    logger.info(">>>>>>>>>>> xxl-job JobThread stoped, hashCode:{}", Thread.currentThread());\n}\n\n\n可以看到这个循环其实很容易停下来，我们只需要将 toStop 设置为 true，这个多线程的循环就会停止。\n\npublic void toStop(String stopReason) {\n    toStop = true;\n    this.stopReason = stopReason;\n}\n\n\n\n# 5. XxlJobContext\n\n在上面的代码中，XxlJobContext 和 XxlJobHelper 出现了很多次，XxlJobHelper 我们在刚才已经试用了，就是记录日志的嘛，但是它不仅仅可以记录日志，还可以修改 XxlJobContext 的状态，那么 XxlJobContext 是什么呢？\n\n只要涉及 Context 的都是上下文，XxlJobContext 也不例外，我叫它任务上下文，使用 Context 的作用就是我们可以将某些信息直接放里面，想用的时候直接 XxlJobContext.getXXX() 拿出来，而不是将信息作为方法的参数传来传去的。\n\npublic class XxlJobContext {\n\n    public static final int HANDLE_CODE_SUCCESS = 200;\n    public static final int HANDLE_CODE_FAIL = 500;\n    public static final int HANDLE_CODE_TIMEOUT = 502;\n\n    // ---------------------- base info ----------------------\n\n    /**\n     * 任务id\n     */\n    private final long jobId;\n\n    /**\n     * 任务参数\n     */\n    private final String jobParam;\n\n    /**\n     * 任务日志文件的文件名\n     */\n    private final String jobLogFileName;\n\n    /**\n     * 分片索引\n     */\n    private final int shardIndex;\n\n    /**\n     * 分片总数\n     */\n    private final int shardTotal;\n\n    /**\n     * handleCode：执行结果\n     *\n     *      200 : success\n     *      500 : fail\n     *      502 : timeout\n     *\n     */\n    private int handleCode;\n\n    /**\n     * 执行信息\n     */\n    private String handleMsg;\n    \n    private static InheritableThreadLocal<XxlJobContext> contextHolder = new InheritableThreadLocal<XxlJobContext>(); \n\n    public static void setXxlJobContext(XxlJobContext xxlJobContext){\n        contextHolder.set(xxlJobContext);\n    }\n\n    public static XxlJobContext getXxlJobContext(){\n        return contextHolder.get();\n    }\n\n}\n\n\n除了一些基本信息以外，XxlJobContext 提供了 setXxlJobContext 的方法，将 XxlJobContext 放到 ThreadLocal 中，这个 InheritableThreadLocal 继承自 ThreadLocal，作用是可以保证父子线程共用数据。\n\n那么它什么时候创建？必然是有任务执行的时候创建。\n\n想要更改 XxlJobContext 的数据其实也挺麻烦的\n\nXxlJobContext xxlJobContext = XxlJobContext.getXxlJobContext();\nxxlJobContext.setHandlerMsg("xxxxxx");\n\n\n想要修改 XxlJobContext 中的 handle_code、handle_Msg 需要两行代码，挺麻烦的。\n\n所以 XxlJobHelper 给我们封装了一下，比如获取当前正在执行的任务的参数、获取当前正在执行的任务的调度信息、设置当前正在执行的任务的执行结果...\n\npublic class XxlJobHelper {\n\n    // ---------------------- base info ----------------------\n\n    /**\n     * current JobId\n     *\n     * @return\n     */\n    public static long getJobId() {\n        XxlJobContext xxlJobContext = XxlJobContext.getXxlJobContext();\n        if (xxlJobContext == null) {\n            return -1;\n        }\n\n        return xxlJobContext.getJobId();\n    }\n\n    /**\n     * current JobParam\n     *\n     * @return\n     */\n    public static String getJobParam() {\n        XxlJobContext xxlJobContext = XxlJobContext.getXxlJobContext();\n        if (xxlJobContext == null) {\n            return null;\n        }\n\n        return xxlJobContext.getJobParam();\n    }\n\n    // ---------------------- for log ----------------------\n\n    /**\n     * current JobLogFileName\n     *\n     * @return\n     */\n    public static String getJobLogFileName() {\n        XxlJobContext xxlJobContext = XxlJobContext.getXxlJobContext();\n        if (xxlJobContext == null) {\n            return null;\n        }\n\n        return xxlJobContext.getJobLogFileName();\n    }\n\n    public static int getShardIndex() {\n        XxlJobContext xxlJobContext = XxlJobContext.getXxlJobContext();\n        if (xxlJobContext == null) {\n            return -1;\n        }\n\n        return xxlJobContext.getShardIndex();\n    }\n\n    /**\n     * current ShardTotal\n     *\n     * @return\n     */\n    public static int getShardTotal() {\n        XxlJobContext xxlJobContext = XxlJobContext.getXxlJobContext();\n        if (xxlJobContext == null) {\n            return -1;\n        }\n\n        return xxlJobContext.getShardTotal();\n    }\n    public static boolean handleSuccess(){\n        return handleResult(XxlJobContext.HANDLE_CODE_SUCCESS, null);\n    }\n    public static boolean handleSuccess(String handleMsg) {\n        return handleResult(XxlJobContext.HANDLE_CODE_SUCCESS, handleMsg);\n    }\n    public static boolean handleFail(){\n        return handleResult(XxlJobContext.HANDLE_CODE_FAIL, null);\n    }\n\n    /**\n     * handle fail with log msg\n     *\n     * @param handleMsg\n     * @return\n     */\n    public static boolean handleFail(String handleMsg) {\n        return handleResult(XxlJobContext.HANDLE_CODE_FAIL, handleMsg);\n    }\n\n    /**\n     * handle timeout\n     *\n     * @return\n     */\n    public static boolean handleTimeout(){\n        return handleResult(XxlJobContext.HANDLE_CODE_TIMEOUT, null);\n    }\n\n    /**\n     * handle timeout with log msg\n     *\n     * @param handleMsg\n     * @return\n     */\n    public static boolean handleTimeout(String handleMsg){\n        return handleResult(XxlJobContext.HANDLE_CODE_TIMEOUT, handleMsg);\n    }\n\n    /**\n     * @param handleCode\n     *\n     *      200 : success\n     *      500 : fail\n     *      502 : timeout\n     *\n     * @param handleMsg\n     * @return\n     */\n    public static boolean handleResult(int handleCode, String handleMsg) {\n        XxlJobContext xxlJobContext = XxlJobContext.getXxlJobContext();\n        if (xxlJobContext == null) {\n            return false;\n        }\n\n        xxlJobContext.setHandleCode(handleCode);\n        if (handleMsg != null) {\n            xxlJobContext.setHandleMsg(handleMsg);\n        }\n        return true;\n    }\n\n}\n\n\n这代码我就不细讲了，无非就是获取 XxlJobContext，set/get 啥的。你就记住，使用 XxlJobContext 可以获取当前正在执行的任务的信息，而 XxlJobHelper 提供了便于操作它的API。\n\n现在可以贴 JobThread#run 的全部代码了\n\n@Override\npublic void run() {\n\n    // init\n    try {\n        handler.init();\n    } catch (Throwable e) {\n        logger.error(e.getMessage(), e);\n    }\n\n    // execute\n    while(!toStop){\n        running = false;\n        idleTimes++;\n\n        TriggerParam triggerParam = null;\n        try {\n            triggerParam = triggerQueue.poll(3L, TimeUnit.SECONDS);\n            if (triggerParam!=null) {\n                running = true;\n                idleTimes = 0;\n                triggerLogIdSet.remove(triggerParam.getLogId());\n\t\t\t\t// 生成日志文件，这个以后会说\n                String logFileName = XxlJobFileAppender.makeLogFileName(new Date(triggerParam.getLogDateTime()), triggerParam.getLogId());\n                \n                // 任务刚准备开始执行，是创建 XxlJobContext 的大好时机啊\n                XxlJobContext xxlJobContext = new XxlJobContext(\n                    triggerParam.getJobId(),\n                    triggerParam.getExecutorParams(),\n                    logFileName,\n                    triggerParam.getBroadcastIndex(),\n                    triggerParam.getBroadcastTotal()\n                );\n\n                // 将 XxlJobContext 放入 ThreadLocal\n                XxlJobContext.setXxlJobContext(xxlJobContext);\n\n                // 打印日志，开始执行!\n                XxlJobHelper.log("<br>----------- xxl-job job execute start -----------<br>----------- Param:" + xxlJobContext.getJobParam());\n\t\t\t\t// 如果设置了超时时间，开启新线程，包装为 FutureTask 执行。超时就结束\n                if (triggerParam.getExecutorTimeout() > 0) {\n                    // limit timeout\n                    Thread futureThread = null;\n                    try {\n                        FutureTask<Boolean> futureTask = new FutureTask<Boolean>(new Callable<Boolean>() {\n                            @Override\n                            public Boolean call() throws Exception {\n\t\t\t\t\t\t\t\t// 由于是开启新线程执行，所以要重新设置一下。\n                                XxlJobContext.setXxlJobContext(xxlJobContext);\n\t\t\t\t\t\t\t\t// 开始执行\n                                handler.execute();\n                                // 如果能执行完返回true\n                                return true;\n                            }\n                        });\n                        futureThread = new Thread(futureTask);\n                        futureThread.start();\n\t\t\t\t\t\t// get结果，指定时间内get不到就抛出异常。\n                        Boolean tempResult = futureTask.get(triggerParam.getExecutorTimeout(), TimeUnit.SECONDS);\n                    } catch (TimeoutException e) {\n\n                        XxlJobHelper.log("<br>----------- xxl-job job execute timeout");\n                        XxlJobHelper.log(e);\n\n                        // 捕获异常之后除了记录日志，还要将timeout记录在context中。\n                        XxlJobHelper.handleTimeout("job execute timeout ");\n                    } finally {\n                        futureThread.interrupt();\n                    }\n                } else {\n                    // just execute\n                    handler.execute();\n                }\n\n                // 走到这里如果 handler_code 还是 <= 0，只能说这个任务丢失了\n                if (XxlJobContext.getXxlJobContext().getHandleCode() <= 0) {\n                    XxlJobHelper.handleFail("job handle result lost.");\n                } else {\n                    // 否则这个任务就是成功了。因为万一出现异常会被catch到根本不会走到这里\n                    String tempHandleMsg = XxlJobContext.getXxlJobContext().getHandleMsg();\n                    tempHandleMsg = (tempHandleMsg!=null&&tempHandleMsg.length()>50000)\n                        ?tempHandleMsg.substring(0, 50000).concat("...")\n                        :tempHandleMsg;\n                    XxlJobContext.getXxlJobContext().setHandleMsg(tempHandleMsg);\n                }\n                // 打印日志\n                XxlJobHelper.log("<br>----------- xxl-job job execute end(finish) -----------<br>----------- Result: handleCode="\n                                 + XxlJobContext.getXxlJobContext().getHandleCode()\n                                 + ", handleMsg = "\n                                 + XxlJobContext.getXxlJobContext().getHandleMsg()\n                                );\n\n            } else {\n                // 如果没有在队列中取出任务，并且已经无效循环了30次 (也就是90s)，将线程销毁\n                if (idleTimes > 30) {\n                    // 再次重复判断，避免并发情况\n                    if(triggerQueue.size() == 0) {\t\n                        XxlJobExecutor.removeJobThread(jobId, "excutor idel times over limit.");\n                    }\n                }\n            }\n        } catch (Throwable e) {\n            if (toStop) {\n                XxlJobHelper.log("<br>----------- JobThread toStop, stopReason:" + stopReason);\n            }\n\n            // handle result\n            StringWriter stringWriter = new StringWriter();\n            e.printStackTrace(new PrintWriter(stringWriter));\n            String errorMsg = stringWriter.toString();\n\t\t\t// 如果出现异常，将任务设置为失败，并填上失败信息\n            XxlJobHelper.handleFail(errorMsg);\n\n            XxlJobHelper.log("<br>----------- JobThread Exception:" + errorMsg + "<br>----------- xxl-job job execute end(error) -----------");\n        } finally {\n            // 将此任务的执行结果发送给调度中心，这个先不管。\n            if(triggerParam != null) {\n                // callback handler info\n                if (!toStop) {\n                    // commonm\n                    TriggerCallbackThread.pushCallBack(new HandleCallbackParam(\n                        triggerParam.getLogId(),\n                        triggerParam.getLogDateTime(),\n                        XxlJobContext.getXxlJobContext().getHandleCode(),\n                        XxlJobContext.getXxlJobContext().getHandleMsg() )\n                                                      );\n                } else {\n                    // is killed\n                    TriggerCallbackThread.pushCallBack(new HandleCallbackParam(\n                        triggerParam.getLogId(),\n                        triggerParam.getLogDateTime(),\n                        XxlJobContext.HANDLE_CODE_FAIL,\n                        stopReason + " [job running, killed]" )\n                                                      );\n                }\n            }\n        }\n    }\n\n    // 能走到这里，说明 toStop变量被设置为true了，有以下两种可能:\n    // 1. 开发人员手动关闭定时任务\n    // 2. 任务很久没有执行，触发了 XxlJobExecutor.removeJobThread()将线程移除\n    // 现在要判断队列中是否还有值，如果是因为第二种情况走出的while循环，根本不会走下面的逻辑\n    // 如果定时任务关闭了，将所有这个任务没执行的"次数"全部取出来发送给调度中心，告诉开发人员这些没执行。\n    while(triggerQueue !=null && triggerQueue.size()>0){\n        TriggerParam triggerParam = triggerQueue.poll();\n        if (triggerParam!=null) {\n            // is killed\n            TriggerCallbackThread.pushCallBack(new HandleCallbackParam(\n                triggerParam.getLogId(),\n                triggerParam.getLogDateTime(),\n                XxlJobContext.HANDLE_CODE_FAIL,\n                stopReason + " [job not executed, in the job queue, killed.]")\n                                              );\n        }\n    }\n\n    // destroy\n    try {\n        handler.destroy();\n    } catch (Throwable e) {\n        logger.error(e.getMessage(), e);\n    }\n\n    logger.info(">>>>>>>>>>> xxl-job JobThread stoped, hashCode:{}", Thread.currentThread());\n}\n\n\n这里放出全部 JobThread 的代码：（真的可以下载源码去看，在这里看不能 ctrl 点击，难受）\n\n为了方便阅读，我将 判断是否有超时时间 那段逻辑封装为了 doExecutor 方法，希望你能理解。\n\npublic class JobThread extends Thread {\n    private static Logger logger = LoggerFactory.getLogger(JobThread.class);\n\n    /**\n     * 定时任务的id\n     */\n    private int jobId;\n\n    /**\n     * 此任务绑定的对象\n     */\n    private IJobHandler handler;\n\n    /**\n     * 内含需要被执行的定时任务(触发器参数)\n     */\n    private LinkedBlockingQueue<TriggerParam> triggerQueue;\n\n    /**\n     * 正在调度的任务的日志id集合(线程安全)\n     */\n    private Set<Long> triggerLogIdSet;\n\n    /**\n     * 该组件是否结束，如果这个组件结束，说明该线程正在负责的定时任务被取消了\n     */\n    private volatile boolean toStop = false;\n\n    /**\n     * 该任务被取消的原因\n     */\n    private String stopReason;\n\n    /**\n     * 该线程是否正在运行(正在运行任务，如果只是等待从队列中取任务不算运行中)\n     */\n    private boolean running = false;\n\n    /**\n     * 空转次数，达到一定次数便销毁该线程，连阻塞都不让它阻塞\n     */\n    private int idleTimes = 0;\n\n    public JobThread(int jobId, IJobHandler handler) {\n        this.jobId = jobId;\n        this.handler = handler;\n        this.triggerQueue = new LinkedBlockingQueue<>();\n        this.triggerLogIdSet = Collections.synchronizedSet(new HashSet<>());\n        this.setName("xxl-job, JobThread - " + jobId + " - " + System.currentTimeMillis());\n    }\n\n    /**\n     * 调度参数放入调度队列\n     *\n     * @param triggerParam\n     */\n    public Result pushTriggerQueue(TriggerParam triggerParam) {\n        // 如果日志id集合中包含此调度参数，说明可能重复调度了\n        if (triggerLogIdSet.contains(triggerParam.getLogId())) {\n            logger.info(">>>>>>>>>>>> repeate trigger job, logId: {}", triggerParam.getLogId());\n            return Result.error("repeate trigger job, logId:" + triggerParam.getLogId());\n        }\n        triggerLogIdSet.add(triggerParam.getLogId());\n        triggerQueue.add(triggerParam);\n        return Result.success();\n    }\n\n    /**\n     * 判断该线程是否正在忙碌，正在运行任务、阻塞队列中有调度参数等待执行 代表忙碌\n     */\n    public boolean isRunningOrHasQueue() {\n        return running || !triggerQueue.isEmpty();\n    }\n\n    @Override\n    public void run() {\n        // 执行初始化方法\n        runInitMethod();\n        // 开始执行\n        while (!toStop) {\n            // 刚进入循环不算执行，得到调度参数才算执行\n            running = false;\n            idleTimes += 1;\n            TriggerParam triggerParam = null;\n            try {\n                triggerParam = triggerQueue.poll(3L, TimeUnit.SECONDS);\n                if (triggerParam == null) {\n                    // 如果阻塞3s没有调度参数，并且现在已经循环了30次，队列中还是没有数据，得，销毁线程\n                    if (idleTimes > 30 && triggerQueue.isEmpty()) {\n                        // 调用XxlJobExecutor.removeJobThread() 去销毁线程\n                        XxlJobExecutor.removeJobThread(jobId, "太久不执行，线程销毁了");\n                    }\n                } else {\n                    // 调度参数不为空，将running改为true, 空转次数改为0\n                    running = true;\n                    idleTimes = 0;\n                    triggerLogIdSet.remove(triggerParam.getLogId());\n                    String logFileName = XxlJobFileAppender.makeLogFileName(new Date(triggerParam.getLogDateTime()), triggerParam.getLogId());\n                    XxlJobContext xxlJobContext = new XxlJobContext(\n                            triggerParam.getJobId(),\n                            triggerParam.getExecutorParams(),\n                            logFileName,\n                            triggerParam.getBroadcastIndex(),\n                            triggerParam.getBroadcastTotal()\n                    );\n                    XxlJobContext.setXxlJobContext(xxlJobContext);\n                    // 记录日志，开始执行\n                    XxlJobHelper.log("<br>----------- xxl-job job execute start -----------<br>----------- Param:" + xxlJobContext.getJobParam());\n                    // 执行定时任务，根据是否设置超时时间来执行。\n                    // 如果没有设置超时时间就直接执行。 如果设置了超时时间就开启子线程，使用 FutureTask 执行。\n                    doExecute(triggerParam, xxlJobContext);\n\n                    // 判断执行结果\n                    if (XxlJobContext.getXxlJobContext().getHandleCode() <= 0) {\n                        XxlJobHelper.handleFail("job handle result lost.");\n                    } else {\n                        // 如果执行结果大于0，不管成功还是失败就直接记录消息，等回调线程去回调。如果执行成功了handleMsg为空\n                        String tempHandleMsg = XxlJobContext.getXxlJobContext().getHandleMsg();\n                        tempHandleMsg = (tempHandleMsg != null && tempHandleMsg.length() > 50000) ? tempHandleMsg.substring(0, 50000).concat("...") : tempHandleMsg;\n                        XxlJobContext.getXxlJobContext().setHandleMsg(tempHandleMsg);\n                    }\n                    // 回调的执行结果咱不管，现在的执行结果先记录日志\n                    XxlJobHelper.log("<br>------------ xxl-job job execute end(finish)-------------<br>------------- Result: handleCode=" +\n                            XxlJobContext.getXxlJobContext().getHandleCode() +\n                            ", handleMsg = " +\n                            XxlJobContext.getXxlJobContext().getHandleMsg()\n                    );\n                }\n            } catch (Exception e) {\n                if (toStop) {\n                    // 如果线程停止了，记录停止原因、异常\n                    XxlJobHelper.log("<br>----------- JobThread toStop, stopReason:" + stopReason);\n                    StringWriter stringWriter = new StringWriter();\n                    e.printStackTrace(new PrintWriter(stringWriter));\n                    String errorMessage = stringWriter.toString();\n                    // 将XxlJobContext中任务的执行状态改为失败\n                    XxlJobHelper.handleFail(errorMessage);\n                    XxlJobHelper.log("<br>----------- JobThread Exception:" + errorMessage +\n                            "<br>----------- xxl-job job execute end(error)");\n                }\n            } finally {\n                // 在finally中执行将日志回调给调度中心的操作\n                if (triggerParam != null) {\n                    // 如果线程没有停止，不管任务执行成功还是失败，回调给调度中心即可。\n                    // 如果线程被终止了，将stopReason发送给调度中心\n                    if (!toStop) {\n                        TriggerCallbackThread.pushCallback(new HandlerCallbackParam(\n                                triggerParam.getLogId(),\n                                triggerParam.getLogDateTime(),\n                                XxlJobContext.getXxlJobContext().getHandleCode(),\n                                XxlJobContext.getXxlJobContext().getHandleMsg()\n                        ));\n                    } else {\n                        TriggerCallbackThread.pushCallback(new HandlerCallbackParam(\n                                triggerParam.getLogId(),\n                                triggerParam.getLogDateTime(),\n                                XxlJobContext.HANDLE_CODE_FAIL,\n                                stopReason + "[job running, killed]"\n                        ));\n                    }\n                }\n            }\n\n        }\n\n        // 退出while循环，最后将队列中没来得及执行的数据拿出来回调回去，告诉调度中心这些数据没有执行\n        while (triggerQueue != null && !triggerQueue.isEmpty()) {\n            TriggerParam triggerParam = triggerQueue.poll();\n            if (triggerParam == null) {\n                continue;\n            }\n            TriggerCallbackThread.pushCallback(new HandlerCallbackParam(\n                    triggerParam.getLogId(),\n                    triggerParam.getLogDateTime(),\n                    XxlJobContext.HANDLE_CODE_FAIL,\n                    stopReason + " [job not executed, in the job queue, killed.]"\n            ));\n        }\n        // 执行销毁方法\n        runDestroyMethod();\n    }\n\n    private void runInitMethod() {\n        try {\n            handler.init();\n        } catch (Exception e) {\n            logger.error(e.getMessage(), e);\n        }\n    }\n\n    private void runDestroyMethod() {\n        try {\n            handler.destroy();\n        } catch (Exception e) {\n            logger.error(e.getMessage(), e);\n        }\n    }\n\n    /**\n     * 执行定时任务，根据是否设置超时时间来执行。\n     * 如果设置了超时时间就开启子线程，使用 FutureTask 执行。\n     * 如果没有设置超时时间就直接执行\n     *\n     * @param triggerParam\n     * @param xxlJobContext\n     */\n    private void doExecute(TriggerParam triggerParam, XxlJobContext xxlJobContext) throws Exception {\n        // 没有设置超时时间，直接执行，设置了超时时间，开启子线程执行，此线程监督子线程执行\n        if (triggerParam.getExecutorTimeout() == 0) {\n            try {\n                handler.execute();\n            } catch (Exception e) {\n                XxlJobHelper.log("<br>-------------- xxl-job job execute timeout");\n                XxlJobHelper.log(e);\n                XxlJobHelper.handleFail("job execute fail, exception message: " + e.getMessage());\n            }\n        } else {\n            Thread futureThread = null;\n            try {\n                FutureTask<Boolean> futureTask = new FutureTask<>(new Callable<Boolean>() {\n                    @Override\n                    public Boolean call() throws Exception {\n                        XxlJobContext.setXxlJobContext(xxlJobContext);\n                        handler.execute();\n                        return true;\n                    }\n                });\n                // 创建并启动线程，get结果，如果指定时间get不到，说明超时\n                futureThread = new Thread(futureTask);\n                futureThread.start();\n                Boolean tempResult = futureTask.get(triggerParam.getExecutorTimeout(), TimeUnit.SECONDS);\n            } catch (TimeoutException e) {\n                XxlJobHelper.log("<br>-------------- xxl-job job execute timeout");\n                XxlJobHelper.log(e);\n                // 将超时设置到 XxlJobContext 中\n                XxlJobHelper.handleTimeout("job execute timeout");\n            } finally {\n                futureThread.interrupt();\n            }\n        }\n    }\n\n    public void toStop(String stopReason) {\n        toStop = true;\n        this.stopReason = stopReason;\n    }\n\n\n    public IJobHandler getHandler() {\n        return handler;\n    }\n\n}\n\n\n\n# 7. 执行器对 JobThread 的管理\n\nJobThread 完成le ，现在来想想怎么将 TriggerParam 放入阻塞队列吧，JobThread 提供了 API ：pushTriggerQueue.\n\n怎么调度它呢？如何知道负责某个任务的线程是否存在呢？如何将线程销毁呢（谁来调用 toStop() 方法呢）？\n\n这些都是问题待解决的问题。上面介绍 MethodJobHandler 时将 MethodJobHandler 收集起来放入 Map 中，那么 JobThread 也可以收集起来进行统一的管理啊，用 jobId-JobThread 这种 key-value 形式将线程封装进 Map 中，调度中心传入 TriggerParam 后，通过 jobId 找到负责该任务的线程，调用 pushTriggerQueue 将 TriggerParam 放入队列等待执行。那么由谁来管理这个装 JobThread 的 Map 呢？肯定是执行器，所以将这个 Map 放入 XxlJobExecutor 中。\n\n// 存放 JobThread线程 的Map\nprivate static ConcurrentHashMap<Integer, JobThread> jobThreadRepository = new ConcurrentHashMap<>();\n\n// 根据任务id获取对应线程\npublic static JobThread loadJobThread(int jobId) {\n    return jobThreadRepository.get(jobId);\n}\n\n// 注册新任务\npublic static JobThread registJobThread(int jobId, IJobHandler handler, String removeOldReason) {\n    JobThread newJobThread = new JobThread(jobId, handler);\n    newJobThread.start();\n    JobThread oldJobThread = jobThreadRepository.put(jobId, newJobThread);\n    // 如果任务之前注册过，可能是web端更改了任务。将旧线程停止。\n    if (oldJobThread != null) {\n        oldJobThread.toStop(removeOldReason);\n        oldJobThread.interrupt();\n    }\n    return newJobThread;\n}\n\n// 销毁线程\npublic static JobThread removeJobThread(int jobId, String removeReason) {\n    JobThread oldJobThread = jobThreadRepository.remove(jobId);\n    if (oldJobThread != null) {\n        oldJobThread.toStop(removeReason);\n        oldJobThread.interrupt();\n    }\n    return oldJobThread;\n}\n\n\n说一下为啥停止线程的时候不仅要调用 toStop 方法，还要调用 interrupt 方法呢？\n\n 1. 线程中使用 while(!toStop){} 的形式进行无限循环，所以想要停止这个线程肯定要让线程退出循环，调用 toStop 方法会将 toStop = true\n 2. 在 JobThread.run() 方法中，有 阻塞着从队列中取值 的步骤存在，如果想要让线程停止工作，肯定要让线程先退出阻塞状态再退出循环，所以调用 interrupt 纯粹是不让线程阻塞这么长时间。\n\n补全了对于 JobThread 的管理，现在的执行器执行任务的流程就很清晰了：\n\n 1. 执行器接收到来自调度中心的 TriggerParam\n\n 2. show me code：\n    \n    JobThread thread = XxlJobExecutor.loadJobThread(triggerPara.getJobId());\n    if (thread == null) {\n        thread = XxlJobExecutor.registJobThread(这里先不说);\n    }\n    thread.pushTriggerQueue(triggerParam);\n    \n\n 3. 调度参数放入队列后就会等待取出执行。这个步骤可以参考 JobThread 的代码\n\n最后，来看看 thread = XxlJobExecutor.registJobThread(这里先不说) 这一步，想要注册线程，就必须拿到 MethodJobHandler，怎么拿到？TriggerParam 中有 任务名，我们之前将所有 任务名-JobHandler 的键值对封装到 XxlJobExecutor 的一个 Map 中了，所以可以先通过那个 Map 获取 MethodJobHandler 再进行新建线程。\n\n\n# 7. 总结\n\n放上面涉及到的全部代码：\n\n@Configuration\npublic class XxlJobSpringExecutor extends XxlJobExecutor implements ApplicationContextAware, SmartInitializingSingleton, DisposableBean {\n    private static Logger logger = LoggerFactory.getLogger(XxlJobSpringExecutor.class);\n\n    private static ApplicationContext applicationContext;\n\n    @Override\n    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {\n        XxlJobSpringExecutor.applicationContext = applicationContext;\n    }\n\n    @Override\n    public void afterSingletonsInstantiated() {\n        try {\n            initJobHandlerMethodRepository(applicationContext);\n            super.start();\n        } catch (Exception e) {\n            logger.error(e.getMessage());\n        }\n    }\n\n    @Override\n    public void destroy() throws Exception {\n        super.stop();\n    }\n\n    private void initJobHandlerMethodRepository(ApplicationContext applicationContext) throws NoSuchMethodException {\n        if (applicationContext == null) return;\n        String[] beanDefinitionNames = applicationContext.getBeanNamesForType(Object.class, false, true);\n        for (String beanDefinitionName : beanDefinitionNames) {\n            Object bean = applicationContext.getBean(beanDefinitionName);\n            Map<Method, XxlJob> annotatedMethods = null;\n            try {\n                annotatedMethods = MethodIntrospector.selectMethods(bean.getClass(),\n                        new MethodIntrospector.MetadataLookup<XxlJob>() {\n                            @Override\n                            public XxlJob inspect(Method method) {\n                                return AnnotatedElementUtils.findMergedAnnotation(method, XxlJob.class);\n                            }\n                        }\n                );\n\n            } catch (Exception e) {\n                // 记录日志，代码太长就不放了\n            }\n            if (CollectionUtil.isEmpty(annotatedMethods)) {\n                continue;\n            }\n            // 将定时任务注册为JobHandler\n            for (Map.Entry<Method, XxlJob> methodXxlJobEntry : annotatedMethods.entrySet()) {\n                Method method = methodXxlJobEntry.getKey();\n                XxlJob value = methodXxlJobEntry.getValue();\n                registJobHandler(value, bean, method);\n            }\n\n        }\n\n    }\n\n    public static ApplicationContext getApplicationContext() {\n        return applicationContext;\n    }\n}\n\n\npublic class XxlJobExecutor {\n    private static final Logger logger = LoggerFactory.getLogger(XxlJobExecutor.class);\n        // ---------------------- job handler repository ----------------------\n    private static ConcurrentMap<String, IJobHandler> jobHandlerRepository = new ConcurrentHashMap<String, IJobHandler>();\n    public static IJobHandler loadJobHandler(String name){\n        return jobHandlerRepository.get(name);\n    }\n    public static IJobHandler registJobHandler(String name, IJobHandler jobHandler){\n        return jobHandlerRepository.put(name, jobHandler);\n    }\n    protected void registJobHandler(XxlJob xxlJob, Object bean, Method executeMethod){\n        if (xxlJob == null) {\n            return;\n        }\n\n        String name = xxlJob.value();\n        \n        Class<?> clazz = bean.getClass();\n        String methodName = executeMethod.getName();\n        if (name.trim().length() == 0) {\n            throw new RuntimeException("xxl-job method-jobhandler name invalid, for[" + clazz + "#" + methodName + "] .");\n        }\n        if (loadJobHandler(name) != null) {\n            throw new RuntimeException("xxl-job jobhandler[" + name + "] naming conflicts.");\n        }\n\n        executeMethod.setAccessible(true);\n\n        // init and destroy\n        Method initMethod = null;\n        Method destroyMethod = null;\n\n        if (xxlJob.init().trim().length() > 0) {\n            try {\n                initMethod = clazz.getDeclaredMethod(xxlJob.init());\n                initMethod.setAccessible(true);\n            } catch (NoSuchMethodException e) {\n                throw new RuntimeException("xxl-job method-jobhandler initMethod invalid, for[" + clazz + "#" + methodName + "] .");\n            }\n        }\n        if (xxlJob.destroy().trim().length() > 0) {\n            try {\n                destroyMethod = clazz.getDeclaredMethod(xxlJob.destroy());\n                destroyMethod.setAccessible(true);\n            } catch (NoSuchMethodException e) {\n                throw new RuntimeException("xxl-job method-jobhandler destroyMethod invalid, for[" + clazz + "#" + methodName + "] .");\n            }\n        }\n\n        // registry jobhandler\n        registJobHandler(name, new MethodJobHandler(bean, executeMethod, initMethod, destroyMethod));\n\n    }\n\n\n    // ---------------------- job thread repository ----------------------\n    private static ConcurrentMap<Integer, JobThread> jobThreadRepository = new ConcurrentHashMap<Integer, JobThread>();\n    public static JobThread registJobThread(int jobId, IJobHandler handler, String removeOldReason){\n        JobThread newJobThread = new JobThread(jobId, handler);\n        newJobThread.start();\n        \n\n        JobThread oldJobThread = jobThreadRepository.put(jobId, newJobThread);\t\n        if (oldJobThread != null) {\n            oldJobThread.toStop(removeOldReason);\n            oldJobThread.interrupt();\n        }\n\n        return newJobThread;\n    }\n\n    public static JobThread removeJobThread(int jobId, String removeOldReason){\n        JobThread oldJobThread = jobThreadRepository.remove(jobId);\n        if (oldJobThread != null) {\n            oldJobThread.toStop(removeOldReason);\n            oldJobThread.interrupt();\n\n            return oldJobThread;\n        }\n        return null;\n    }\n\n    public static JobThread loadJobThread(int jobId){\n        return jobThreadRepository.get(jobId);\n    }\n}\n\n\npublic class TriggerParam implements Serializable {\n    private static final long serialVersionUID = 42L;\n\n    /**\n     * 任务id\n     */\n    private int jobId;\n\n    /**\n     * 定时任务名字\n     */\n    private String executorHandler;\n\n    /**\n     * 定时任务的参数\n     */\n    private String executorParams;\n\n    /**\n     * 定时任务的阻塞策略                <br></br>\n     * 当一个定时任务想要执行，但是负责该任务的线程正在工作时会使用这个阻塞策略判断\n     */\n    private String executorBlockStrategy;\n\n    /**\n     * 任务的过期时间          <br></br>\n     * 如果开启了过期时间，执行任务时会额外创建一个新线程执行任务，\n     * 之前的线程负责监督新线程执行任务时间是否超时\n     */\n    private int executorTimeout;\n\n    /**\n     * 该任务对应的日志的id\n     */\n    private long logId;\n\n    /**\n     * 打日志的时间\n     */\n    private long logDateTime;\n\n    /**\n     * 运行模式\n     */\n    private String glueType;\n\n    /**\n     * 代码文本\n     */\n    private String glueSource;\n\n    /**\n     * 代码文本更新时间\n     */\n    private long glueUpdatetime;\n\n    /**\n     * 分片索引\n     */\n    private int broadcastIndex;\n\n    /**\n     * 分片总数\n     */\n    private int broadcastTotal;\n}\n\n\npackage com.xxl.job.core.thread;\n\nimport com.xxl.job.core.biz.model.HandleCallbackParam;\nimport com.xxl.job.core.biz.model.ReturnT;\nimport com.xxl.job.core.biz.model.TriggerParam;\nimport com.xxl.job.core.context.XxlJobContext;\nimport com.xxl.job.core.context.XxlJobHelper;\nimport com.xxl.job.core.executor.XxlJobExecutor;\nimport com.xxl.job.core.handler.IJobHandler;\nimport com.xxl.job.core.log.XxlJobFileAppender;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.PrintWriter;\nimport java.io.StringWriter;\nimport java.util.Collections;\nimport java.util.Date;\nimport java.util.HashSet;\nimport java.util.Set;\nimport java.util.concurrent.*;\n\n\n/**\n * handler thread\n * @author xuxueli 2016-1-16 19:52:47\n */\npublic class JobThread extends Thread{\n\tprivate static Logger logger = LoggerFactory.getLogger(JobThread.class);\n\n\tprivate int jobId;\n\tprivate IJobHandler handler;\n\tprivate LinkedBlockingQueue<TriggerParam> triggerQueue;\n\tprivate Set<Long> triggerLogIdSet;\t\t\n\n\tprivate volatile boolean toStop = false;\n\tprivate String stopReason;\n\n    private boolean running = false;    \n\tprivate int idleTimes = 0;\t\t\t\n\n\n\tpublic JobThread(int jobId, IJobHandler handler) {\n\t\tthis.jobId = jobId;\n\t\tthis.handler = handler;\n\t\tthis.triggerQueue = new LinkedBlockingQueue<TriggerParam>();\n\t\tthis.triggerLogIdSet = Collections.synchronizedSet(new HashSet<Long>());\n\n\t\t// assign job thread name\n\t\tthis.setName("xxl-job, JobThread-"+jobId+"-"+System.currentTimeMillis());\n\t}\n\tpublic IJobHandler getHandler() {\n\t\treturn handler;\n\t}\n\n    /**\n     * new trigger to queue\n     *\n     * @param triggerParam\n     * @return\n     */\n\tpublic ReturnT<String> pushTriggerQueue(TriggerParam triggerParam) {\n\t\t// avoid repeat\n\t\tif (triggerLogIdSet.contains(triggerParam.getLogId())) {\n\t\t\tlogger.info(">>>>>>>>>>> repeate trigger job, logId:{}", triggerParam.getLogId());\n\t\t\treturn new ReturnT<String>(ReturnT.FAIL_CODE, "repeate trigger job, logId:" + triggerParam.getLogId());\n\t\t}\n\n\t\ttriggerLogIdSet.add(triggerParam.getLogId());\n\t\ttriggerQueue.add(triggerParam);\n        return ReturnT.SUCCESS;\n\t}\n\n    /**\n     * kill job thread\n     *\n     * @param stopReason\n     */\n\tpublic void toStop(String stopReason) {\n\t\t/**\n\t\t * Thread.interrupt只支持终止线程的阻塞状态(wait、join、sleep)，\n\t\t * 在阻塞出抛出InterruptedException异常,但是并不会终止运行的线程本身；\n\t\t * 所以需要注意，此处彻底销毁本线程，需要通过共享变量方式；\n\t\t */\n\t\tthis.toStop = true;\n\t\tthis.stopReason = stopReason;\n\t}\n\n    /**\n     * is running job\n     * @return\n     */\n    public boolean isRunningOrHasQueue() {\n        return running || triggerQueue.size()>0;\n    }\n\n    @Override\n\tpublic void run() {\n\n    \t// init\n    \ttry {\n\t\t\thandler.init();\n\t\t} catch (Throwable e) {\n    \t\tlogger.error(e.getMessage(), e);\n\t\t}\n\n\t\t// execute\n\t\twhile(!toStop){\n\t\t\trunning = false;\n\t\t\tidleTimes++;\n\n            TriggerParam triggerParam = null;\n            try {\n\t\t\t\t// to check toStop signal, we need cycle, so wo cannot use queue.take(), instand of poll(timeout)\n\t\t\t\ttriggerParam = triggerQueue.poll(3L, TimeUnit.SECONDS);\n\t\t\t\tif (triggerParam!=null) {\n\t\t\t\t\trunning = true;\n\t\t\t\t\tidleTimes = 0;\n\t\t\t\t\ttriggerLogIdSet.remove(triggerParam.getLogId());\n\n\t\t\t\t\t// log filename, like "logPath/yyyy-MM-dd/9999.log"\n\t\t\t\t\tString logFileName = XxlJobFileAppender.makeLogFileName(new Date(triggerParam.getLogDateTime()), triggerParam.getLogId());\n\t\t\t\t\tXxlJobContext xxlJobContext = new XxlJobContext(\n\t\t\t\t\t\t\ttriggerParam.getJobId(),\n\t\t\t\t\t\t\ttriggerParam.getExecutorParams(),\n\t\t\t\t\t\t\tlogFileName,\n\t\t\t\t\t\t\ttriggerParam.getBroadcastIndex(),\n\t\t\t\t\t\t\ttriggerParam.getBroadcastTotal());\n\n\t\t\t\t\t// init job context\n\t\t\t\t\tXxlJobContext.setXxlJobContext(xxlJobContext);\n\n\t\t\t\t\t// execute\n\t\t\t\t\tXxlJobHelper.log("<br>----------- xxl-job job execute start -----------<br>----------- Param:" + xxlJobContext.getJobParam());\n\n\t\t\t\t\tif (triggerParam.getExecutorTimeout() > 0) {\n\t\t\t\t\t\t// limit timeout\n\t\t\t\t\t\tThread futureThread = null;\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tFutureTask<Boolean> futureTask = new FutureTask<Boolean>(new Callable<Boolean>() {\n\t\t\t\t\t\t\t\t@Override\n\t\t\t\t\t\t\t\tpublic Boolean call() throws Exception {\n\n\t\t\t\t\t\t\t\t\t// init job context\n\t\t\t\t\t\t\t\t\tXxlJobContext.setXxlJobContext(xxlJobContext);\n\n\t\t\t\t\t\t\t\t\thandler.execute();\n\t\t\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\tfutureThread = new Thread(futureTask);\n\t\t\t\t\t\t\tfutureThread.start();\n\n\t\t\t\t\t\t\tBoolean tempResult = futureTask.get(triggerParam.getExecutorTimeout(), TimeUnit.SECONDS);\n\t\t\t\t\t\t} catch (TimeoutException e) {\n\n\t\t\t\t\t\t\tXxlJobHelper.log("<br>----------- xxl-job job execute timeout");\n\t\t\t\t\t\t\tXxlJobHelper.log(e);\n\n\t\t\t\t\t\t\t// handle result\n\t\t\t\t\t\t\tXxlJobHelper.handleTimeout("job execute timeout ");\n\t\t\t\t\t\t} finally {\n\t\t\t\t\t\t\tfutureThread.interrupt();\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// just execute\n\t\t\t\t\t\thandler.execute();\n\t\t\t\t\t}\n\n\t\t\t\t\t// valid execute handle data\n\t\t\t\t\tif (XxlJobContext.getXxlJobContext().getHandleCode() <= 0) {\n\t\t\t\t\t\tXxlJobHelper.handleFail("job handle result lost.");\n\t\t\t\t\t} else {\n\t\t\t\t\t\tString tempHandleMsg = XxlJobContext.getXxlJobContext().getHandleMsg();\n\t\t\t\t\t\ttempHandleMsg = (tempHandleMsg!=null&&tempHandleMsg.length()>50000)\n\t\t\t\t\t\t\t\t?tempHandleMsg.substring(0, 50000).concat("...")\n\t\t\t\t\t\t\t\t:tempHandleMsg;\n\t\t\t\t\t\tXxlJobContext.getXxlJobContext().setHandleMsg(tempHandleMsg);\n\t\t\t\t\t}\n\t\t\t\t\tXxlJobHelper.log("<br>----------- xxl-job job execute end(finish) -----------<br>----------- Result: handleCode="\n\t\t\t\t\t\t\t+ XxlJobContext.getXxlJobContext().getHandleCode()\n\t\t\t\t\t\t\t+ ", handleMsg = "\n\t\t\t\t\t\t\t+ XxlJobContext.getXxlJobContext().getHandleMsg()\n\t\t\t\t\t);\n\n\t\t\t\t} else {\n\t\t\t\t\tif (idleTimes > 30) {\n\t\t\t\t\t\tif(triggerQueue.size() == 0) {\t\n\t\t\t\t\t\t\tXxlJobExecutor.removeJobThread(jobId, "excutor idel times over limit.");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch (Throwable e) {\n\t\t\t\tif (toStop) {\n\t\t\t\t\tXxlJobHelper.log("<br>----------- JobThread toStop, stopReason:" + stopReason);\n\t\t\t\t}\n\n\t\t\t\t// handle result\n\t\t\t\tStringWriter stringWriter = new StringWriter();\n\t\t\t\te.printStackTrace(new PrintWriter(stringWriter));\n\t\t\t\tString errorMsg = stringWriter.toString();\n\n\t\t\t\tXxlJobHelper.handleFail(errorMsg);\n\n\t\t\t\tXxlJobHelper.log("<br>----------- JobThread Exception:" + errorMsg + "<br>----------- xxl-job job execute end(error) -----------");\n\t\t\t} finally {\n                if(triggerParam != null) {\n                    // callback handler info\n                    if (!toStop) {\n                        // commonm\n                        TriggerCallbackThread.pushCallBack(new HandleCallbackParam(\n                        \t\ttriggerParam.getLogId(),\n\t\t\t\t\t\t\t\ttriggerParam.getLogDateTime(),\n\t\t\t\t\t\t\t\tXxlJobContext.getXxlJobContext().getHandleCode(),\n\t\t\t\t\t\t\t\tXxlJobContext.getXxlJobContext().getHandleMsg() )\n\t\t\t\t\t\t);\n                    } else {\n                        // is killed\n                        TriggerCallbackThread.pushCallBack(new HandleCallbackParam(\n                        \t\ttriggerParam.getLogId(),\n\t\t\t\t\t\t\t\ttriggerParam.getLogDateTime(),\n\t\t\t\t\t\t\t\tXxlJobContext.HANDLE_CODE_FAIL,\n\t\t\t\t\t\t\t\tstopReason + " [job running, killed]" )\n\t\t\t\t\t\t);\n                    }\n                }\n            }\n        }\n\n\t\t// callback trigger request in queue\n\t\twhile(triggerQueue !=null && triggerQueue.size()>0){\n\t\t\tTriggerParam triggerParam = triggerQueue.poll();\n\t\t\tif (triggerParam!=null) {\n\t\t\t\t// is killed\n\t\t\t\tTriggerCallbackThread.pushCallBack(new HandleCallbackParam(\n\t\t\t\t\t\ttriggerParam.getLogId(),\n\t\t\t\t\t\ttriggerParam.getLogDateTime(),\n\t\t\t\t\t\tXxlJobContext.HANDLE_CODE_FAIL,\n\t\t\t\t\t\tstopReason + " [job not executed, in the job queue, killed.]")\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\n\t\t// destroy\n\t\ttry {\n\t\t\thandler.destroy();\n\t\t} catch (Throwable e) {\n\t\t\tlogger.error(e.getMessage(), e);\n\t\t}\n\n\t\t\n\t}\n}\n',normalizedContent:'# 0. 前言\n\n为什么从执行器开始讲，因为从上向下和从下向上讲都有利有弊，我选择隐藏上层实现的细节，等执行器讲完了再讲调度中心。\n\n由于没有讲调度中心，你只要把调度中心想象为一个黑盒，它会将马上就执行的任务从数据库中查出来，然后发送 http 消息给执行器，执行器拿到信息后去执行。\n\n\n\n\n# 1. triggerparam\n\n调度参数，什么叫调度参数？就是调度中心从数据库中查找到要执行的任务后，将这个参数发送给执行器，执行器根据调度参数内的值进行执行。\n\n这个消息包含什么信息呢？\n\npublic class triggerparam implements serializable {\n    // 使用了 jdk 序列化\n    private static final long serialversionuid = 42l;\n\n    /**\n     * 任务id\n     */\n    private int jobid;\n\n    /**\n     * 定时任务名\n     */\n    private string executorhandler;\n\n    /**\n     * 定时任务的参数\n     */\n    private string executorparams;\n\n    /**\n     * 定时任务的阻塞策略                <br></br>\n     * 当一个定时任务想要执行，但是负责该任务的线程正在工作时会使用这个阻塞策略判断\n     */\n    private string executorblockstrategy;\n\n    /**\n     * 任务的过期时间          <br></br>\n     * 如果开启了过期时间，执行任务时会额外创建一个新线程执行任务，\n     * 之前的线程负责监督新线程执行任务时间是否超时\n     */\n    private int executortimeout;\n\n    /**\n     * 该任务对应的日志的id\n     */\n    private long logid;\n\n    /**\n     * 打日志的时间\n     */\n    private long logdatetime;\n\n    /**\n     * 运行模式\n     */\n    private string gluetype;\n\n    /**\n     * 代码文本\n     */\n    private string gluesource;\n\n    /**\n     * 代码文本更新时间\n     */\n    private long glueupdatetime;\n\n    /**\n     * 分片索引\n     */\n    private int broadcastindex;\n\n    /**\n     * 分片总数\n     */\n    private int broadcasttotal;\n\n    public int getjobid() {\n        return jobid;\n    }\n}\n\n\n其实很多变量在意料之中，id、executorhandler啥的必须有，但是为什么有 logid 呢？执行的时候跟 logid 有什么关系呢？\n\n在上文中我们分析了 xxl-job 的数据库表，着重强调了 xxl_job_log 的两个字段 ：trigger_code、handle_code\n\n * trigger_code ：是否调度成功，也就是 http消息发送成功没有\n * handle_code ：是否执行成功，也就是定时任务代码执行过程中是否出现了bug\n\nxxl-job 在消息发送之前，会为每一次执行生成一条日志，这条数据在数据库的 xxl_job_log 中，http消息（也就是triggerparam ）到达执行器时，这条log就已经有 trigger_code 了。所以我们要在执行的时候记录一些 handle_code、handle_message，等任务执行完再发送回调度中心，调度中心接收到这条消息后就可以补全本次执行的日志。\n\n有了 triggerparam ，xxl-job 的工作流程变为 ：\n\n * 调度中心从数据库中查询定时任务\n * 将任务封装为 triggerparam 发送给执行器\n * 执行器拿到 triggerparam 后执行对应的任务\n\n现在我们不知道的是 ：定时任务以什么形式存在于执行器、定时任务如何执行的。接下来会具体分析这两点。\n\n\n# 2. 定义定时任务\n\n定时任务在 xxl-job 中以什么形式存在呢？肯定要有一个类封装它。\n\n首先，我们先定义接口，接口规定的是行为，一个任务需要有哪些行为？执行、初始化、销毁。\n\n但是并非所有任务都需要初始化、销毁，所以我们将 ijobhandler 定义为抽象类，给初始化和销毁方法默认实现。\n\npublic abstract class ijobhandler {\n\n\tpublic abstract void execute() throws exception;\n\n\tpublic void init() throws exception {\n\n\t}\n\n\tpublic void destroy() throws exception {\n\n\t}\n}\n\n\n一个方法想要执行，肯定要有class对象、method方法，同时我想让功能更加丰富，于是给每一个定时任务加上初始化方法、销毁方法。\n\npublic class methodjobhandler extends ijobhandler {\n    // bean对象的class\n    private final object target;\n    // 需要执行的method\n    private final method method;\n    // 初始化和销毁方法\n    private method initmethod;\n    private method destroymethod;\n\n    public methodjobhandler(object target, method method, method initmethod, method destroymethod) {\n        this.target = target;\n        this.method = method;\n\n        this.initmethod = initmethod;\n        this.destroymethod = destroymethod;\n    }\n\n    @override\n    public void execute() throws exception {\n        class<?>[] paramtypes = method.getparametertypes();\n        if (paramtypes.length > 0) {\n            method.invoke(target, new object[paramtypes.length]);       // method-param can not be primitive-types\n        } else {\n            method.invoke(target);\n        }\n    }\n\n    @override\n    public void init() throws exception {\n        if(initmethod != null) {\n            initmethod.invoke(target);\n        }\n    }\n\n    @override\n    public void destroy() throws exception {\n        if(destroymethod != null) {\n            destroymethod.invoke(target);\n        }\n    }\n\n    @override\n    public string tostring() {\n        return super.tostring()+"["+ target.getclass() + "#" + method.getname() +"]";\n    }\n}\n\n\n其实上面的逻辑不难对吧，一共就三个方法，执行、初始化、销毁。\n\n * 执行 ：如果没有参数直接就 method.invoke(target)\n * 初始化 ：如果初始化method不为空就执行\n * 销毁 ：如果销毁method不为空就执行\n\n当想要执行一个定时任务的时候，只需要先 new methodjobhandler，然后调用 jobhandler.executor() 就可执行。\n\n\n# 3. 收集定时任务\n\n光封装定时任务可不够，我们还要拿到定时任务，也就是凭借调度中心发送来的 triggerparam 找到 methodjobhandler，怎么找呢？难道每一次执行任务都需要重新找吗？\n\n别忘了，代码运行之后就没法更改了，所以我们可以趁代码运行后，将所有定时任务收集起来，可以用list、map这种容器装起来，你想要？没问题，拿任务的唯一标识给我换~~说到唯一标识，聪明的你肯定想到了map，因为它是 key-value 形式的，我们可以使用 id-jobhandler 也可以使用 jobname-jobhandler 存放任务，跟我们的业务完全符合！\n\n先来看看之前我们写的定时任务代码：\n\n@component\npublic class samplexxljob {\n\n    @xxljob("demojobhandler")\n    public void demojobhandler() throws exception {\n        system.out.println("简单任务实例执行了");\n    }\n}\n\n\n如果是你，如何获取这个任务呢？由于 samplexxljob 这个类已经被注入到 spring 容器中了，那么我们获取 spring 容器遍历容器中的所有bean，如果某个 bean 有 @xxljob 这个注解，那么这个 bean + method就是我们要找的定时任务。\n\n肯定要由执行器做这种事情，因为我们的项目引入的是执行器依赖，换言之，我们的项目现在就是一个执行器了。\n\n所以我将这个“收集定时任务”的类叫做 xxljobspringexecutor\n\n在代码中需要拿到 spring 的上下文 context，然后就可以通过 context 获取所有的bean。\n\npublic class xxljobspringexecutor implements applicationcontextaware {\n\n    private static applicationcontext applicationcontext;\n\n    @override\n    public void setapplicationcontext(applicationcontext applicationcontext) throws beansexception {\n        xxljobspringexecutor.applicationcontext = applicationcontext;\n    }\n\n    public static applicationcontext getapplicationcontext() {\n        return applicationcontext;\n    }\n}\n\n\n现在又有一个新问题：什么时候开始收集定时任务呢？spring容器初始化前？spring容器初始化后？\n\n在定时任务中，有可能使用 mapper、redistemplate、rpc 各种spring bean去完成工作，那肯定是 spring 的容器初始化之后收集定时任务了。\n\n所以我们要实现 smartinitializingsingleton，在所有单例对象准备好之后，我们开始收集任务。\n\npublic class xxljobspringexecutor implements applicationcontextaware, smartinitializingsingleton {\n    \n    @override\n    public void aftersingletonsinstantiated() {\n        // 在这里收集定时任务\n        initjobhandlermethodrepository(applicationcontext);\n    }\n   \n    private static applicationcontext applicationcontext;\n    \n\n    @override\n    public void setapplicationcontext(applicationcontext applicationcontext) throws beansexception {\n        xxljobspringexecutor.applicationcontext = applicationcontext;\n    }\n\n    public static applicationcontext getapplicationcontext() {\n        return applicationcontext;\n    }\n}\n\n\n再来思考一个问题 ：收集定时任务，我们需要收集什么信息？执行一个任务，换言之，执行一个方法需要什么信息？\n\n 1. 被执行的方法 ：method\n 2. 反射执行任务的代码为 ：method.invoke(class)，所以还需要 class 对象，一个类中可能有多个定时任务，但是管它呢，有多少我要多少。\n 3. 上面两个属性可以封装为一个 methodhandler，想要通过定时任务名找到methodhandler，所以需要拿到定时任务名字。\n\n经过上面的分析，我们初步决定，遍历 spring 的所有bean，必须拿到以下三个信息：\n\n 1. jobname\n 2. class\n 3. method\n\n伪代码应该是这样：\n\n// 这个map负责收集所有定时任务\nmap<string, methodjobhandler> jobmap = new ....();\n// 开始遍历每一个bean\nfor (object bean : springbeans) {\n    // 收集这个bean中的定时任务\n    map<xxljob, method> map = new map<>();\n    method[] methods = bean.getmethods();\n    for (method method : methods) {\n        if (method上有@xxljob注解) {\n            map.put(xxljob, method);\n        }\n    }\n    // 如果这个bean里面没有定时任务就下一个。\n    if (map.size() <= 0) continue;\n    \n    // 遍历map进行注册，将其注册到\n    for (map.entry<xxljob, method> entry : map.entryset()) {\n        methodhandler handler = new methodjobhandler(bean.class, entry.value());\n    \tjobmap.put(xxljob.name(), handler);\n    }\n    \n}\n\n\n但是 xxl-job 并没有这么做，它把 定时任务的收集 和定时任务的注册 分开进行，为什么？\n\n今天你使用 spring 集成 xxl-job 可以使用 spring 容器进行收集，但是明天你没有用 xxl-job 怎么办？收集怎么做？\n\n所以将这两步分开进行，可以减少集成其他框架时的工作量。那么寻找这一步就可能有很多种实现方式，但是注册不一样，不管你跟多少框架集成，最终你要给我 bean、method、xxljob注解，这三样东西就行。\n\n由于注册不需要依赖于任何框架， 收集需要依赖于spring，而业务的逻辑肯定是收集之后再注册，所以我们将行为定义成这样：\n\npublic abstract class xxljobexecutor {\n    public void 注册(object bean, method method, xxljob xxljob) {\n        // 功能实现\n    }\n}\n\n\npublic abstract class xxljobsringexecutor extends xxljobexecutor {\n\tpublic  void 收集() {\n        // 从定时任务中找出所有定时任务\n        map<xxljob, method> map = new map<>();\n        method[] methods = bean.getmethods();\n        for (method method : methods) {\n            if (method上有@xxljob注解) {\n                map.put(xxljob, method);\n            }\n        }\n        // 如果这个bean里面没有定时任务就下一个。\n        if (map.size() <= 0) continue;\n\n        // 调用从父类继承过来的注册方法进行注册。\n        for (map.entry<xxljob, method> entry : map.entrys()) {\n        \t注册(bean, entry.key, entry.value);\n    \t}\n    }\n}\n\n\n先来看一下 xxljobspringexecutor 中收集定时任务的代码，代码多但是不难：\n\nprivate void initjobhandlermethodrepository(applicationcontext applicationcontext) {\n        // 容器判空\n        if (applicationcontext == null) {\n            return;\n        }\n        // 拿到所有bean对象的名字\n    \t// getbeannamesfortype有三个参数:\n    \t// type : 类型\n    \t// includenonsingletons : 是否包含多实例对象\n    \t// alloweagerinit : 是否包含懒加载对象\n        string[] beandefinitionnames = applicationcontext.getbeannamesfortype(object.class, false, true);\n        for (string beandefinitionname : beandefinitionnames) {\n\n            // 通过name拿到bean对象\n            object bean = null;\n            lazy onbean = applicationcontext.findannotationonbean(beandefinitionname, lazy.class);\n            if (onbean!=null){\n                logger.debug("xxl-job annotation scan, skip @lazy bean:{}", beandefinitionname);\n                continue;\n            }else {\n                bean = applicationcontext.getbean(beandefinitionname);\n            }\n\n            // 这个map用于收集定时任务，这个map代表当前遍历的bean中所有的定时任务。\n            // method : 定时任务方法\n            // xxljob : 这个定时任务的注解，通过 xxljob可以得到定时任务的名字\n            map<method, xxljob> annotatedmethods = null;   \n            try {\n                annotatedmethods = methodintrospector.selectmethods(bean.getclass(),\n                        new methodintrospector.metadatalookup<xxljob>() {\n                            @override\n                            public xxljob inspect(method method) {\n                                return annotatedelementutils.findmergedannotation(method, xxljob.class);\n                            }\n                        });\n            } catch (throwable ex) {\n                logger.error("xxl-job method-jobhandler resolve error for bean[" + beandefinitionname + "].", ex);\n            }\n            // 如果这个bean中没有定时任务，跳过\n            if (annotatedmethods==null || annotatedmethods.isempty()) {\n                continue;\n            }\n\n            // 已经收集到该bean的所有定时任务，要把它统一放在一个地方\n            // registjobhandler\n            for (map.entry<method, xxljob> methodxxljobentry : annotatedmethods.entryset()) {\n                method executemethod = methodxxljobentry.getkey();\n                xxljob xxljob = methodxxljobentry.getvalue();\n                // regist\n                registjobhandler(xxljob, bean, executemethod);\n            }\n\n        }\n    }\n\n\n 1. 拿到所有 bean 对象的名字，遍历名字，根据名字获取bean对象\n 2. 使用 spring 提供的工具类 methodintrospector.selectmethods 查看一个类中有没有加了 @xxljob 注解的方法\n 3. 如果有，就将这些方法按照 method:xxljob 的形式封装进 map 中。\n 4. 将这个 bean 中所有定时任务注册到某个地方，以便使用\n 5. 开始遍历下一个 bean，重复上述步骤\n\n再看看 xxljobexecutor 中 注册任务的逻辑 ：\n\npublic class xxljobexecutor {\n    // 存放 methodjobhandler 的map容器\n    // key : 定时任务的名字\n    private static concurrentmap<string, ijobhandler> jobhandlerrepository = new concurrenthashmap<string, ijobhandler>();\n    public static ijobhandler registjobhandler(string name, ijobhandler jobhandler){\n        logger.info(">>>>>>>>>>> xxl-job register jobhandler success, name:{}, jobhandler:{}", name, jobhandler);\n        return jobhandlerrepository.put(name, jobhandler);\n    }\n    protected void registjobhandler(xxljob xxljob, object bean, method executemethod){\n        if (xxljob == null) {\n            return;\n        }\n\n        string name = xxljob.value();\n        //make and simplify the variables since they\'ll be called several times later\n        class<?> clazz = bean.getclass();\n        string methodname = executemethod.getname();\n        if (name.trim().length() == 0) {\n            throw new runtimeexception("xxl-job method-jobhandler name invalid, for[" + clazz + "#" + methodname + "] .");\n        }\n        if (loadjobhandler(name) != null) {\n            throw new runtimeexception("xxl-job jobhandler[" + name + "] naming conflicts.");\n        }\n\n        executemethod.setaccessible(true);\n\n        // init and destroy\n        method initmethod = null;\n        method destroymethod = null;\n\n        if (xxljob.init().trim().length() > 0) {\n            try {\n                initmethod = clazz.getdeclaredmethod(xxljob.init());\n                initmethod.setaccessible(true);\n            } catch (nosuchmethodexception e) {\n                throw new runtimeexception("xxl-job method-jobhandler initmethod invalid, for[" + clazz + "#" + methodname + "] .");\n            }\n        }\n        if (xxljob.destroy().trim().length() > 0) {\n            try {\n                destroymethod = clazz.getdeclaredmethod(xxljob.destroy());\n                destroymethod.setaccessible(true);\n            } catch (nosuchmethodexception e) {\n                throw new runtimeexception("xxl-job method-jobhandler destroymethod invalid, for[" + clazz + "#" + methodname + "] .");\n            }\n        }\n\n        // registry jobhandler\n        registjobhandler(name, new methodjobhandler(bean, executemethod, initmethod, destroymethod));\n\n    }\n}\n\n\nregistjobhandler(xxljob xxljob, object bean, method executemethod)\n\n 1. xxljob ：定时任务头上的注解，含有该任务的名字、初始化方法、销毁方法\n 2. bean ：该任务方法属于哪个类，需要通过它拿到 class\n 3. executormethod ：定时任务的方法\n\n这个方法的总流程：\n\n 1. 根据传入的参数获取定时任务的 名字、class对象、方法名\n 2. 检查参数，并且根据定时任务的名字判断是否已经出现过，不允许任务名重复\n 3. 如果初始化方法、销毁方法不为空，得到这两个方法\n 4. 将 class对象、定时任务方法、初始化方法、销毁方法 封装为 methodjobhandler ，并且以方法名为 key 放入 map\n\n以后就可以通过定时任务的名称来找到 methodjobhandler，使用 execute() 来执行。\n\npublic static ijobhandler loadjobhandler(string name){\n    return jobhandlerrepository.get(name);\n}\n\n\n那么现在 收集定时任务的流程为：\n\n 1. xxljobspringexecutor 找到加了 @xxljob 注解的方法\n 2. 注册到 xxljobexecutor 的 map 中。\n\n最后，上完整代码：\n\npublic class xxljobspringexecutor extends xxljobexecutor implements applicationcontextaware, smartinitializingsingleton, disposablebean {\n    @override\n    public void aftersingletonsinstantiated() {\n        // 在这里收集定时任务\n        initjobhandlermethodrepository(applicationcontext);\n    }\n   \n    private static applicationcontext applicationcontext;\n    \n\n    @override\n    public void setapplicationcontext(applicationcontext applicationcontext) throws beansexception {\n        xxljobspringexecutor.applicationcontext = applicationcontext;\n    }\n\n    public static applicationcontext getapplicationcontext() {\n        return applicationcontext;\n    }\n    private void initjobhandlermethodrepository(applicationcontext applicationcontext) {\n        if (applicationcontext == null) {\n            return;\n        }\n        // init job handler from method\n        string[] beandefinitionnames = applicationcontext.getbeannamesfortype(object.class, false, true);\n        for (string beandefinitionname : beandefinitionnames) {\n\n            // get bean\n            object bean = null;\n            lazy onbean = applicationcontext.findannotationonbean(beandefinitionname, lazy.class);\n            if (onbean!=null){\n                logger.debug("xxl-job annotation scan, skip @lazy bean:{}", beandefinitionname);\n                continue;\n            }else {\n                bean = applicationcontext.getbean(beandefinitionname);\n            }\n\n            // filter method\n            map<method, xxljob> annotatedmethods = null;   // referred to ：org.springframework.context.event.eventlistenermethodprocessor.processbean\n            try {\n                annotatedmethods = methodintrospector.selectmethods(bean.getclass(),\n                        new methodintrospector.metadatalookup<xxljob>() {\n                            @override\n                            public xxljob inspect(method method) {\n                                return annotatedelementutils.findmergedannotation(method, xxljob.class);\n                            }\n                        });\n            } catch (throwable ex) {\n                logger.error("xxl-job method-jobhandler resolve error for bean[" + beandefinitionname + "].", ex);\n            }\n            if (annotatedmethods==null || annotatedmethods.isempty()) {\n                continue;\n            }\n\n            // generate and regist method job handler\n            for (map.entry<method, xxljob> methodxxljobentry : annotatedmethods.entryset()) {\n                method executemethod = methodxxljobentry.getkey();\n                xxljob xxljob = methodxxljobentry.getvalue();\n                // regist\n                registjobhandler(xxljob, bean, executemethod);\n            }\n\n        }\n    }\n}\n\n\npublic class xxljobexecutor {\n    // 存放 methodjobhandler 的map容器\n    // key : 定时任务的名字\n    private static concurrentmap<string, ijobhandler> jobhandlerrepository = new concurrenthashmap<string, ijobhandler>();\n    public static ijobhandler loadjobhandler(string name){\n    \treturn jobhandlerrepository.get(name);\n\t}\n\n    protected void registjobhandler(xxljob xxljob, object bean, method executemethod){\n        if (xxljob == null) {\n            return;\n        }\n\n        string name = xxljob.value();\n        //make and simplify the variables since they\'ll be called several times later\n        class<?> clazz = bean.getclass();\n        string methodname = executemethod.getname();\n        if (name.trim().length() == 0) {\n            throw new runtimeexception("xxl-job method-jobhandler name invalid, for[" + clazz + "#" + methodname + "] .");\n        }\n        if (loadjobhandler(name) != null) {\n            throw new runtimeexception("xxl-job jobhandler[" + name + "] naming conflicts.");\n        }\n\n        executemethod.setaccessible(true);\n\n        // init and destroy\n        method initmethod = null;\n        method destroymethod = null;\n\n        if (xxljob.init().trim().length() > 0) {\n            try {\n                initmethod = clazz.getdeclaredmethod(xxljob.init());\n                initmethod.setaccessible(true);\n            } catch (nosuchmethodexception e) {\n                throw new runtimeexception("xxl-job method-jobhandler initmethod invalid, for[" + clazz + "#" + methodname + "] .");\n            }\n        }\n        if (xxljob.destroy().trim().length() > 0) {\n            try {\n                destroymethod = clazz.getdeclaredmethod(xxljob.destroy());\n                destroymethod.setaccessible(true);\n            } catch (nosuchmethodexception e) {\n                throw new runtimeexception("xxl-job method-jobhandler destroymethod invalid, for[" + clazz + "#" + methodname + "] .");\n            }\n        }\n\n        // registry jobhandler\n        registjobhandler(name, new methodjobhandler(bean, executemethod, initmethod, destroymethod));\n\n    }\n    public static ijobhandler registjobhandler(string name, ijobhandler jobhandler){\n        logger.info(">>>>>>>>>>> xxl-job register jobhandler success, name:{}, jobhandler:{}", name, jobhandler);\n        return jobhandlerrepository.put(name, jobhandler);\n    }\n}\n\n\n其实这两个类的代码远不及如此，我觉得 xxl-job 作为一个小而精的框架，它的代码虽然少但是读起来很难受。\n\n没有遵循 “一个方法占一屏” 的良好习惯~\n\n\n# 4. 定时任务的执行\n\n现在让我们分析一下使用什么模式去执行定时任务，列举一下可能用到的模式：\n\n 1. 每一次接收 triggerparam 都新创建一个线程去执行。\n 2. 使用线程池接收 triggerparam 执行。\n 3. 一个线程负责一个任务，同一个任务的triggerparam都由这个线程接收并执行。\n\n如果是你，如何选择？不卖关子，xxl-job 使用第三种模式执行定时任务，而且对这种模式进行了改装 ：\n\n> xxl-job 是以每个线程负责某一个任务的执行，对于两种频率的任务 ：\n> \n>  1. 执行特别频繁的任务\n>     \n>     xxl-job 对线程进行了封装，每一个线程内部都有一个阻塞队列，所有 triggerparam 都会进入负责对应任务的线程的阻塞队列中等待执行。\n> \n>  2. 执行不频繁的任务\n>     \n>     线程并不是一直都在工作，它是循环从阻塞队列中取 triggerparam，如果 3秒钟取不到就进入下一次循环，同时记录这是第几次无效循环，如果超过30次，就将线程销毁。防止线程没事干又占资源。\n\n根据上面的描述，猜测一下 xxl-job 封装的线程需要哪些变量 ：\n\n阻塞队列、无效循环次数、线程是否还在工作的标志、线程是否正在运行任务的标志、任务执行需要的\n\npublic class jobthread extends thread{\n    private static logger logger = loggerfactory.getlogger(jobthread.class);\n\t// 此时这个线程负责的定时任务的id\n\tprivate int jobid;\n    // 该定时任务的 methodjobhandler\n\tprivate ijobhandler handler;\n    // 有任务时就会放到这个阻塞队列中\n\tprivate linkedblockingqueue<triggerparam> triggerqueue;\n    // 防止重复调度\n    private set<long> triggerlogidset;\t\t\n\t// 该线程是否还在工作\n\tprivate volatile boolean tostop = false;\n    // 该线程停止的原因是什么，有可能是长时间没有任务，有可能是开发人员手动关闭定时任务\n\tprivate string stopreason;\n\t// 线程是否正在运行任务，"正在运行"不包括线程循环、阻塞等待任务到来，而是真真正正的正在运行任务\n    private boolean running = false;    \n    // 线程无效循环次数\n\tprivate int idletimes = 0;\n    \n    public jobthread(int jobid, ijobhandler handler) {\n\t\tthis.jobid = jobid;\n\t\tthis.handler = handler;\n\t\tthis.triggerqueue = new linkedblockingqueue<triggerparam>();\n\t\tthis.triggerlogidset = collections.synchronizedset(new hashset<long>());\n\n\t\tthis.setname("xxl-job, jobthread-"+jobid+"-"+system.currenttimemillis());\n\t}\n}\n\n\n 1. 上面有一个 triggerlogidset，其实这个变量很难用上，所以这里先不说了。\n\n 2. tostop 和 running 有什么区别呢？\n    \n    tostop ：此线程是否还在运行\n    \n    running ：此线程是否正在运行任务\n    \n    它俩的区别 我们首先要阻塞着从队列中取值，这时 tostop = false，running = false，因为线程确实在运行，但是没有取到任务。\n    \n    从队列中取出 triggerparam 后， tostop = false，running = true，因为现在已经可以开始运行任务了。\n\npublic class jobthread extends thread{\n    private static logger logger = loggerfactory.getlogger(jobthread.class);\n\t// 此时这个线程负责的定时任务的id\n\tprivate int jobid;\n    // 该定时任务的 methodjobhandler\n\tprivate ijobhandler handler;\n    // 有任务时就会放到这个阻塞队列中\n\tprivate linkedblockingqueue<triggerparam> triggerqueue;\n    // 防止重复调度\n    private set<long> triggerlogidset;\t\t\n\t// 该线程是否还在工作\n\tprivate volatile boolean tostop = false;\n    // 该线程停止的原因是什么，有可能是长时间没有任务，有可能是开发人员手动关闭定时任务\n\tprivate string stopreason;\n\t// 线程是否正在运行任务，"正在运行"不包括线程循环、阻塞等待任务到来，而是真真正正的正在运行任务\n    private boolean running = false;    \n    // 线程无效循环次数\n\tprivate int idletimes = 0;\t\t\t\n\n\n\tpublic jobthread(int jobid, ijobhandler handler) {\n\t\tthis.jobid = jobid;\n\t\tthis.handler = handler;\n\t\tthis.triggerqueue = new linkedblockingqueue<triggerparam>();\n\t\tthis.triggerlogidset = collections.synchronizedset(new hashset<long>());\n\n\t\tthis.setname("xxl-job, jobthread-"+jobid+"-"+system.currenttimemillis());\n\t}\n    // 调度中心从数据库中查出将要执行的任务，将这个任务发送给执行器\n    // 执行器收到消息后将这次执行放入队列中等待执行\n    public returnt<string> pushtriggerqueue(triggerparam triggerparam) {\n\t\t// avoid repeat\n\t\tif (triggerlogidset.contains(triggerparam.getlogid())) {\n\t\t\tlogger.info(">>>>>>>>>>> repeate trigger job, logid:{}", triggerparam.getlogid());\n\t\t\treturn new returnt<string>(returnt.fail_code, "repeate trigger job, logid:" + triggerparam.getlogid());\n\t\t}\n\n\t\ttriggerlogidset.add(triggerparam.getlogid());\n\t\ttriggerqueue.add(triggerparam);\n        return returnt.success;\n\t}\n    // 线程是否在工作，或者队列中是否有任务等待执行\n    public boolean isrunningorhasqueue() {\n        return running || triggerqueue.size()>0;\n    }\n\n    @override\n\tpublic void run() {\n\t\t// 暂不实现\n\t}\n}\n\n\n这个pushtriggerparam 没干啥事，无非就是判断一下是否重复调度，然后将triggerparam放入阻塞队列。\n\nrun方法才是重头戏：\n\n@override\npublic void run() {\n\n    // init\n    try {\n        handler.init();\n    } catch (throwable e) {\n        logger.error(e.getmessage(), e);\n    }\n\n    // \n    while(!tostop){\n        running = false;\n        idletimes++;\n\n        triggerparam triggerparam = null;\n        try {\n            triggerparam = triggerqueue.poll(3l, timeunit.seconds);\n            if (triggerparam != null) {\n                running = true;\n                idletimes = 0;\n                triggerlogidset.remove(triggerparam.getlogid());\n                // 打印日志，表示任务将要执行\n                xxljobhelper.log("<br>----------- xxl-job job execute start -----------<br>----------- param:" + xxljobcontext.getjobparam());\n                // 执行任务!!!\n                handler.execute();\n            } else {\n                if (idletimes > 30) {\n                    if(triggerqueue.size() == 0) {\t\n                        // 将此线程停止，或者说移除\n                        xxljobexecutor.removejobthread(jobid, "excutor idel times over limit.");\n                    }\n                }\n            }\n        } catch (throwable e) {\n            if (tostop) {\n                xxljobhelper.log("<br>----------- jobthread tostop, stopreason:" + stopreason);\n            }\n\n            // handle result\n            stringwriter stringwriter = new stringwriter();\n            e.printstacktrace(new printwriter(stringwriter));\n            string errormsg = stringwriter.tostring();\n\n            xxljobhelper.handlefail(errormsg);\n\n            xxljobhelper.log("<br>----------- jobthread exception:" + errormsg + "<br>----------- xxl-job job execute end(error) -----------");\n        } finally {\n            if(triggerparam != null) {\n                // callback handler info\n                if (!tostop) {\n                    // commonm\n                    triggercallbackthread.pushcallback(new handlecallbackparam(\n                        triggerparam.getlogid(),\n                        triggerparam.getlogdatetime(),\n                        xxljobcontext.getxxljobcontext().gethandlecode(),\n                        xxljobcontext.getxxljobcontext().gethandlemsg() )\n                                                      );\n                } else {\n                    // is killed\n                    triggercallbackthread.pushcallback(new handlecallbackparam(\n                        triggerparam.getlogid(),\n                        triggerparam.getlogdatetime(),\n                        xxljobcontext.handle_code_fail,\n                        stopreason + " [job running, killed]" )\n                                                      );\n                }\n            }\n        }\n    }\n    // destroy\n    try {\n        handler.destroy();\n    } catch (throwable e) {\n        logger.error(e.getmessage(), e);\n    }\n    logger.info(">>>>>>>>>>> xxl-job jobthread stoped, hashcode:{}", thread.currentthread());\n}\n\n\n源代码其实挺复杂的，而且很多东西现在没有讲到，所以我删减了很多，等会补上。\n\n 1. 执行初始化方法，进入循环\n\n 2. 每次循环都将 idletimes 加一，从阻塞队列中取值，最多等待三秒，如果超过了就说明现在没有任务，再次循环，如果无效循环 30 次，就会触发 xxljobexecutor.removejobthread 将此线程停止并移除。\n\n 3. 如果从阻塞队列中取到了值，将 idletimes置为0，并将 running = true 表示从现在开始要执行任务了\n    \n    打印一下日志，使用 handler.execute() 执行任务。\n\n 4. 如果出现异常，除了打印日志之外，执行了 xxljobhelper.handlefail(errormsg) 这句话，记住它，等会说\n\n 5. 在 finally 块中调用 triggercallbackthread.pushcallback() 将任务执行的结果回调给调度中心，这个暂且不说，后面的章节会完善。\n\n但是现在定时任务的执行功能还不完善，我们之前使用的时候是有 超时时间 这个功能的，这个功能该如何实现？我们可以新创建一个线程，将定时任务包装为一个 futuretask，在执行的时候 future.get(seconds)，如果执行超时，就会出现超时异常，我们将其捕获就可以了。\n\n添加了超时时间功能的代码：\n\n@override\npublic void run() {\n\n    // init\n    try {\n        handler.init();\n    } catch (throwable e) {\n        logger.error(e.getmessage(), e);\n    }\n\n    // execute\n    while(!tostop){\n        running = false;\n        idletimes++;\n\n        triggerparam triggerparam = null;\n        try {\n            triggerparam = triggerqueue.poll(3l, timeunit.seconds);\n            if (triggerparam!=null) {\n                running = true;\n                idletimes = 0;\n                triggerlogidset.remove(triggerparam.getlogid());\n                // 打印日志，表示任务将要执行\n                xxljobhelper.log("<br>----------- xxl-job job execute start -----------<br>----------- param:" + xxljobcontext.getjobparam());\n                if (triggerparam.getexecutortimeout() > 0) {\n                    // limit timeout\n                    thread futurethread = null;\n                    try {\n                        futuretask<boolean> futuretask = new futuretask<boolean>(new callable<boolean>() {\n                            @override\n                            public boolean call() throws exception {\n                                handler.execute();\n                                return true;\n                            }\n                        });\n                        futurethread = new thread(futuretask);\n                        futurethread.start();\n\n                        boolean tempresult = futuretask.get(triggerparam.getexecutortimeout(), timeunit.seconds);\n                    } catch (timeoutexception e) {\n\n                        xxljobhelper.log("<br>----------- xxl-job job execute timeout");\n                        xxljobhelper.log(e);\n                    } finally {\n                        futurethread.interrupt();\n                    }\n                } else {\n                    // just execute\n                    handler.execute();\n                }\n            } else {\n                if (idletimes > 30) {\n                    if(triggerqueue.size() == 0) {\t\n                        xxljobexecutor.removejobthread(jobid, "excutor idel times over limit.");\n                    }\n                }\n            }\n        } catch (throwable e) {\n            if (tostop) {\n                xxljobhelper.log("<br>----------- jobthread tostop, stopreason:" + stopreason);\n            }\n\n            // handle result\n            stringwriter stringwriter = new stringwriter();\n            e.printstacktrace(new printwriter(stringwriter));\n            string errormsg = stringwriter.tostring();\n\n            xxljobhelper.handlefail(errormsg);\n\n            xxljobhelper.log("<br>----------- jobthread exception:" + errormsg + "<br>----------- xxl-job job execute end(error) -----------");\n        } finally {\n            if(triggerparam != null) {\n                // callback handler info\n                if (!tostop) {\n                    // commonm\n                    triggercallbackthread.pushcallback(new handlecallbackparam(\n                        triggerparam.getlogid(),\n                        triggerparam.getlogdatetime(),\n                        xxljobcontext.getxxljobcontext().gethandlecode(),\n                        xxljobcontext.getxxljobcontext().gethandlemsg() )\n                                                      );\n                } else {\n                    // is killed\n                    triggercallbackthread.pushcallback(new handlecallbackparam(\n                        triggerparam.getlogid(),\n                        triggerparam.getlogdatetime(),\n                        xxljobcontext.handle_code_fail,\n                        stopreason + " [job running, killed]" )\n                                                      );\n                }\n            }\n        }\n    }\n    // destroy\n    try {\n        handler.destroy();\n    } catch (throwable e) {\n        logger.error(e.getmessage(), e);\n    }\n    logger.info(">>>>>>>>>>> xxl-job jobthread stoped, hashcode:{}", thread.currentthread());\n}\n\n\n可以看到这个循环其实很容易停下来，我们只需要将 tostop 设置为 true，这个多线程的循环就会停止。\n\npublic void tostop(string stopreason) {\n    tostop = true;\n    this.stopreason = stopreason;\n}\n\n\n\n# 5. xxljobcontext\n\n在上面的代码中，xxljobcontext 和 xxljobhelper 出现了很多次，xxljobhelper 我们在刚才已经试用了，就是记录日志的嘛，但是它不仅仅可以记录日志，还可以修改 xxljobcontext 的状态，那么 xxljobcontext 是什么呢？\n\n只要涉及 context 的都是上下文，xxljobcontext 也不例外，我叫它任务上下文，使用 context 的作用就是我们可以将某些信息直接放里面，想用的时候直接 xxljobcontext.getxxx() 拿出来，而不是将信息作为方法的参数传来传去的。\n\npublic class xxljobcontext {\n\n    public static final int handle_code_success = 200;\n    public static final int handle_code_fail = 500;\n    public static final int handle_code_timeout = 502;\n\n    // ---------------------- base info ----------------------\n\n    /**\n     * 任务id\n     */\n    private final long jobid;\n\n    /**\n     * 任务参数\n     */\n    private final string jobparam;\n\n    /**\n     * 任务日志文件的文件名\n     */\n    private final string joblogfilename;\n\n    /**\n     * 分片索引\n     */\n    private final int shardindex;\n\n    /**\n     * 分片总数\n     */\n    private final int shardtotal;\n\n    /**\n     * handlecode：执行结果\n     *\n     *      200 : success\n     *      500 : fail\n     *      502 : timeout\n     *\n     */\n    private int handlecode;\n\n    /**\n     * 执行信息\n     */\n    private string handlemsg;\n    \n    private static inheritablethreadlocal<xxljobcontext> contextholder = new inheritablethreadlocal<xxljobcontext>(); \n\n    public static void setxxljobcontext(xxljobcontext xxljobcontext){\n        contextholder.set(xxljobcontext);\n    }\n\n    public static xxljobcontext getxxljobcontext(){\n        return contextholder.get();\n    }\n\n}\n\n\n除了一些基本信息以外，xxljobcontext 提供了 setxxljobcontext 的方法，将 xxljobcontext 放到 threadlocal 中，这个 inheritablethreadlocal 继承自 threadlocal，作用是可以保证父子线程共用数据。\n\n那么它什么时候创建？必然是有任务执行的时候创建。\n\n想要更改 xxljobcontext 的数据其实也挺麻烦的\n\nxxljobcontext xxljobcontext = xxljobcontext.getxxljobcontext();\nxxljobcontext.sethandlermsg("xxxxxx");\n\n\n想要修改 xxljobcontext 中的 handle_code、handle_msg 需要两行代码，挺麻烦的。\n\n所以 xxljobhelper 给我们封装了一下，比如获取当前正在执行的任务的参数、获取当前正在执行的任务的调度信息、设置当前正在执行的任务的执行结果...\n\npublic class xxljobhelper {\n\n    // ---------------------- base info ----------------------\n\n    /**\n     * current jobid\n     *\n     * @return\n     */\n    public static long getjobid() {\n        xxljobcontext xxljobcontext = xxljobcontext.getxxljobcontext();\n        if (xxljobcontext == null) {\n            return -1;\n        }\n\n        return xxljobcontext.getjobid();\n    }\n\n    /**\n     * current jobparam\n     *\n     * @return\n     */\n    public static string getjobparam() {\n        xxljobcontext xxljobcontext = xxljobcontext.getxxljobcontext();\n        if (xxljobcontext == null) {\n            return null;\n        }\n\n        return xxljobcontext.getjobparam();\n    }\n\n    // ---------------------- for log ----------------------\n\n    /**\n     * current joblogfilename\n     *\n     * @return\n     */\n    public static string getjoblogfilename() {\n        xxljobcontext xxljobcontext = xxljobcontext.getxxljobcontext();\n        if (xxljobcontext == null) {\n            return null;\n        }\n\n        return xxljobcontext.getjoblogfilename();\n    }\n\n    public static int getshardindex() {\n        xxljobcontext xxljobcontext = xxljobcontext.getxxljobcontext();\n        if (xxljobcontext == null) {\n            return -1;\n        }\n\n        return xxljobcontext.getshardindex();\n    }\n\n    /**\n     * current shardtotal\n     *\n     * @return\n     */\n    public static int getshardtotal() {\n        xxljobcontext xxljobcontext = xxljobcontext.getxxljobcontext();\n        if (xxljobcontext == null) {\n            return -1;\n        }\n\n        return xxljobcontext.getshardtotal();\n    }\n    public static boolean handlesuccess(){\n        return handleresult(xxljobcontext.handle_code_success, null);\n    }\n    public static boolean handlesuccess(string handlemsg) {\n        return handleresult(xxljobcontext.handle_code_success, handlemsg);\n    }\n    public static boolean handlefail(){\n        return handleresult(xxljobcontext.handle_code_fail, null);\n    }\n\n    /**\n     * handle fail with log msg\n     *\n     * @param handlemsg\n     * @return\n     */\n    public static boolean handlefail(string handlemsg) {\n        return handleresult(xxljobcontext.handle_code_fail, handlemsg);\n    }\n\n    /**\n     * handle timeout\n     *\n     * @return\n     */\n    public static boolean handletimeout(){\n        return handleresult(xxljobcontext.handle_code_timeout, null);\n    }\n\n    /**\n     * handle timeout with log msg\n     *\n     * @param handlemsg\n     * @return\n     */\n    public static boolean handletimeout(string handlemsg){\n        return handleresult(xxljobcontext.handle_code_timeout, handlemsg);\n    }\n\n    /**\n     * @param handlecode\n     *\n     *      200 : success\n     *      500 : fail\n     *      502 : timeout\n     *\n     * @param handlemsg\n     * @return\n     */\n    public static boolean handleresult(int handlecode, string handlemsg) {\n        xxljobcontext xxljobcontext = xxljobcontext.getxxljobcontext();\n        if (xxljobcontext == null) {\n            return false;\n        }\n\n        xxljobcontext.sethandlecode(handlecode);\n        if (handlemsg != null) {\n            xxljobcontext.sethandlemsg(handlemsg);\n        }\n        return true;\n    }\n\n}\n\n\n这代码我就不细讲了，无非就是获取 xxljobcontext，set/get 啥的。你就记住，使用 xxljobcontext 可以获取当前正在执行的任务的信息，而 xxljobhelper 提供了便于操作它的api。\n\n现在可以贴 jobthread#run 的全部代码了\n\n@override\npublic void run() {\n\n    // init\n    try {\n        handler.init();\n    } catch (throwable e) {\n        logger.error(e.getmessage(), e);\n    }\n\n    // execute\n    while(!tostop){\n        running = false;\n        idletimes++;\n\n        triggerparam triggerparam = null;\n        try {\n            triggerparam = triggerqueue.poll(3l, timeunit.seconds);\n            if (triggerparam!=null) {\n                running = true;\n                idletimes = 0;\n                triggerlogidset.remove(triggerparam.getlogid());\n\t\t\t\t// 生成日志文件，这个以后会说\n                string logfilename = xxljobfileappender.makelogfilename(new date(triggerparam.getlogdatetime()), triggerparam.getlogid());\n                \n                // 任务刚准备开始执行，是创建 xxljobcontext 的大好时机啊\n                xxljobcontext xxljobcontext = new xxljobcontext(\n                    triggerparam.getjobid(),\n                    triggerparam.getexecutorparams(),\n                    logfilename,\n                    triggerparam.getbroadcastindex(),\n                    triggerparam.getbroadcasttotal()\n                );\n\n                // 将 xxljobcontext 放入 threadlocal\n                xxljobcontext.setxxljobcontext(xxljobcontext);\n\n                // 打印日志，开始执行!\n                xxljobhelper.log("<br>----------- xxl-job job execute start -----------<br>----------- param:" + xxljobcontext.getjobparam());\n\t\t\t\t// 如果设置了超时时间，开启新线程，包装为 futuretask 执行。超时就结束\n                if (triggerparam.getexecutortimeout() > 0) {\n                    // limit timeout\n                    thread futurethread = null;\n                    try {\n                        futuretask<boolean> futuretask = new futuretask<boolean>(new callable<boolean>() {\n                            @override\n                            public boolean call() throws exception {\n\t\t\t\t\t\t\t\t// 由于是开启新线程执行，所以要重新设置一下。\n                                xxljobcontext.setxxljobcontext(xxljobcontext);\n\t\t\t\t\t\t\t\t// 开始执行\n                                handler.execute();\n                                // 如果能执行完返回true\n                                return true;\n                            }\n                        });\n                        futurethread = new thread(futuretask);\n                        futurethread.start();\n\t\t\t\t\t\t// get结果，指定时间内get不到就抛出异常。\n                        boolean tempresult = futuretask.get(triggerparam.getexecutortimeout(), timeunit.seconds);\n                    } catch (timeoutexception e) {\n\n                        xxljobhelper.log("<br>----------- xxl-job job execute timeout");\n                        xxljobhelper.log(e);\n\n                        // 捕获异常之后除了记录日志，还要将timeout记录在context中。\n                        xxljobhelper.handletimeout("job execute timeout ");\n                    } finally {\n                        futurethread.interrupt();\n                    }\n                } else {\n                    // just execute\n                    handler.execute();\n                }\n\n                // 走到这里如果 handler_code 还是 <= 0，只能说这个任务丢失了\n                if (xxljobcontext.getxxljobcontext().gethandlecode() <= 0) {\n                    xxljobhelper.handlefail("job handle result lost.");\n                } else {\n                    // 否则这个任务就是成功了。因为万一出现异常会被catch到根本不会走到这里\n                    string temphandlemsg = xxljobcontext.getxxljobcontext().gethandlemsg();\n                    temphandlemsg = (temphandlemsg!=null&&temphandlemsg.length()>50000)\n                        ?temphandlemsg.substring(0, 50000).concat("...")\n                        :temphandlemsg;\n                    xxljobcontext.getxxljobcontext().sethandlemsg(temphandlemsg);\n                }\n                // 打印日志\n                xxljobhelper.log("<br>----------- xxl-job job execute end(finish) -----------<br>----------- result: handlecode="\n                                 + xxljobcontext.getxxljobcontext().gethandlecode()\n                                 + ", handlemsg = "\n                                 + xxljobcontext.getxxljobcontext().gethandlemsg()\n                                );\n\n            } else {\n                // 如果没有在队列中取出任务，并且已经无效循环了30次 (也就是90s)，将线程销毁\n                if (idletimes > 30) {\n                    // 再次重复判断，避免并发情况\n                    if(triggerqueue.size() == 0) {\t\n                        xxljobexecutor.removejobthread(jobid, "excutor idel times over limit.");\n                    }\n                }\n            }\n        } catch (throwable e) {\n            if (tostop) {\n                xxljobhelper.log("<br>----------- jobthread tostop, stopreason:" + stopreason);\n            }\n\n            // handle result\n            stringwriter stringwriter = new stringwriter();\n            e.printstacktrace(new printwriter(stringwriter));\n            string errormsg = stringwriter.tostring();\n\t\t\t// 如果出现异常，将任务设置为失败，并填上失败信息\n            xxljobhelper.handlefail(errormsg);\n\n            xxljobhelper.log("<br>----------- jobthread exception:" + errormsg + "<br>----------- xxl-job job execute end(error) -----------");\n        } finally {\n            // 将此任务的执行结果发送给调度中心，这个先不管。\n            if(triggerparam != null) {\n                // callback handler info\n                if (!tostop) {\n                    // commonm\n                    triggercallbackthread.pushcallback(new handlecallbackparam(\n                        triggerparam.getlogid(),\n                        triggerparam.getlogdatetime(),\n                        xxljobcontext.getxxljobcontext().gethandlecode(),\n                        xxljobcontext.getxxljobcontext().gethandlemsg() )\n                                                      );\n                } else {\n                    // is killed\n                    triggercallbackthread.pushcallback(new handlecallbackparam(\n                        triggerparam.getlogid(),\n                        triggerparam.getlogdatetime(),\n                        xxljobcontext.handle_code_fail,\n                        stopreason + " [job running, killed]" )\n                                                      );\n                }\n            }\n        }\n    }\n\n    // 能走到这里，说明 tostop变量被设置为true了，有以下两种可能:\n    // 1. 开发人员手动关闭定时任务\n    // 2. 任务很久没有执行，触发了 xxljobexecutor.removejobthread()将线程移除\n    // 现在要判断队列中是否还有值，如果是因为第二种情况走出的while循环，根本不会走下面的逻辑\n    // 如果定时任务关闭了，将所有这个任务没执行的"次数"全部取出来发送给调度中心，告诉开发人员这些没执行。\n    while(triggerqueue !=null && triggerqueue.size()>0){\n        triggerparam triggerparam = triggerqueue.poll();\n        if (triggerparam!=null) {\n            // is killed\n            triggercallbackthread.pushcallback(new handlecallbackparam(\n                triggerparam.getlogid(),\n                triggerparam.getlogdatetime(),\n                xxljobcontext.handle_code_fail,\n                stopreason + " [job not executed, in the job queue, killed.]")\n                                              );\n        }\n    }\n\n    // destroy\n    try {\n        handler.destroy();\n    } catch (throwable e) {\n        logger.error(e.getmessage(), e);\n    }\n\n    logger.info(">>>>>>>>>>> xxl-job jobthread stoped, hashcode:{}", thread.currentthread());\n}\n\n\n这里放出全部 jobthread 的代码：（真的可以下载源码去看，在这里看不能 ctrl 点击，难受）\n\n为了方便阅读，我将 判断是否有超时时间 那段逻辑封装为了 doexecutor 方法，希望你能理解。\n\npublic class jobthread extends thread {\n    private static logger logger = loggerfactory.getlogger(jobthread.class);\n\n    /**\n     * 定时任务的id\n     */\n    private int jobid;\n\n    /**\n     * 此任务绑定的对象\n     */\n    private ijobhandler handler;\n\n    /**\n     * 内含需要被执行的定时任务(触发器参数)\n     */\n    private linkedblockingqueue<triggerparam> triggerqueue;\n\n    /**\n     * 正在调度的任务的日志id集合(线程安全)\n     */\n    private set<long> triggerlogidset;\n\n    /**\n     * 该组件是否结束，如果这个组件结束，说明该线程正在负责的定时任务被取消了\n     */\n    private volatile boolean tostop = false;\n\n    /**\n     * 该任务被取消的原因\n     */\n    private string stopreason;\n\n    /**\n     * 该线程是否正在运行(正在运行任务，如果只是等待从队列中取任务不算运行中)\n     */\n    private boolean running = false;\n\n    /**\n     * 空转次数，达到一定次数便销毁该线程，连阻塞都不让它阻塞\n     */\n    private int idletimes = 0;\n\n    public jobthread(int jobid, ijobhandler handler) {\n        this.jobid = jobid;\n        this.handler = handler;\n        this.triggerqueue = new linkedblockingqueue<>();\n        this.triggerlogidset = collections.synchronizedset(new hashset<>());\n        this.setname("xxl-job, jobthread - " + jobid + " - " + system.currenttimemillis());\n    }\n\n    /**\n     * 调度参数放入调度队列\n     *\n     * @param triggerparam\n     */\n    public result pushtriggerqueue(triggerparam triggerparam) {\n        // 如果日志id集合中包含此调度参数，说明可能重复调度了\n        if (triggerlogidset.contains(triggerparam.getlogid())) {\n            logger.info(">>>>>>>>>>>> repeate trigger job, logid: {}", triggerparam.getlogid());\n            return result.error("repeate trigger job, logid:" + triggerparam.getlogid());\n        }\n        triggerlogidset.add(triggerparam.getlogid());\n        triggerqueue.add(triggerparam);\n        return result.success();\n    }\n\n    /**\n     * 判断该线程是否正在忙碌，正在运行任务、阻塞队列中有调度参数等待执行 代表忙碌\n     */\n    public boolean isrunningorhasqueue() {\n        return running || !triggerqueue.isempty();\n    }\n\n    @override\n    public void run() {\n        // 执行初始化方法\n        runinitmethod();\n        // 开始执行\n        while (!tostop) {\n            // 刚进入循环不算执行，得到调度参数才算执行\n            running = false;\n            idletimes += 1;\n            triggerparam triggerparam = null;\n            try {\n                triggerparam = triggerqueue.poll(3l, timeunit.seconds);\n                if (triggerparam == null) {\n                    // 如果阻塞3s没有调度参数，并且现在已经循环了30次，队列中还是没有数据，得，销毁线程\n                    if (idletimes > 30 && triggerqueue.isempty()) {\n                        // 调用xxljobexecutor.removejobthread() 去销毁线程\n                        xxljobexecutor.removejobthread(jobid, "太久不执行，线程销毁了");\n                    }\n                } else {\n                    // 调度参数不为空，将running改为true, 空转次数改为0\n                    running = true;\n                    idletimes = 0;\n                    triggerlogidset.remove(triggerparam.getlogid());\n                    string logfilename = xxljobfileappender.makelogfilename(new date(triggerparam.getlogdatetime()), triggerparam.getlogid());\n                    xxljobcontext xxljobcontext = new xxljobcontext(\n                            triggerparam.getjobid(),\n                            triggerparam.getexecutorparams(),\n                            logfilename,\n                            triggerparam.getbroadcastindex(),\n                            triggerparam.getbroadcasttotal()\n                    );\n                    xxljobcontext.setxxljobcontext(xxljobcontext);\n                    // 记录日志，开始执行\n                    xxljobhelper.log("<br>----------- xxl-job job execute start -----------<br>----------- param:" + xxljobcontext.getjobparam());\n                    // 执行定时任务，根据是否设置超时时间来执行。\n                    // 如果没有设置超时时间就直接执行。 如果设置了超时时间就开启子线程，使用 futuretask 执行。\n                    doexecute(triggerparam, xxljobcontext);\n\n                    // 判断执行结果\n                    if (xxljobcontext.getxxljobcontext().gethandlecode() <= 0) {\n                        xxljobhelper.handlefail("job handle result lost.");\n                    } else {\n                        // 如果执行结果大于0，不管成功还是失败就直接记录消息，等回调线程去回调。如果执行成功了handlemsg为空\n                        string temphandlemsg = xxljobcontext.getxxljobcontext().gethandlemsg();\n                        temphandlemsg = (temphandlemsg != null && temphandlemsg.length() > 50000) ? temphandlemsg.substring(0, 50000).concat("...") : temphandlemsg;\n                        xxljobcontext.getxxljobcontext().sethandlemsg(temphandlemsg);\n                    }\n                    // 回调的执行结果咱不管，现在的执行结果先记录日志\n                    xxljobhelper.log("<br>------------ xxl-job job execute end(finish)-------------<br>------------- result: handlecode=" +\n                            xxljobcontext.getxxljobcontext().gethandlecode() +\n                            ", handlemsg = " +\n                            xxljobcontext.getxxljobcontext().gethandlemsg()\n                    );\n                }\n            } catch (exception e) {\n                if (tostop) {\n                    // 如果线程停止了，记录停止原因、异常\n                    xxljobhelper.log("<br>----------- jobthread tostop, stopreason:" + stopreason);\n                    stringwriter stringwriter = new stringwriter();\n                    e.printstacktrace(new printwriter(stringwriter));\n                    string errormessage = stringwriter.tostring();\n                    // 将xxljobcontext中任务的执行状态改为失败\n                    xxljobhelper.handlefail(errormessage);\n                    xxljobhelper.log("<br>----------- jobthread exception:" + errormessage +\n                            "<br>----------- xxl-job job execute end(error)");\n                }\n            } finally {\n                // 在finally中执行将日志回调给调度中心的操作\n                if (triggerparam != null) {\n                    // 如果线程没有停止，不管任务执行成功还是失败，回调给调度中心即可。\n                    // 如果线程被终止了，将stopreason发送给调度中心\n                    if (!tostop) {\n                        triggercallbackthread.pushcallback(new handlercallbackparam(\n                                triggerparam.getlogid(),\n                                triggerparam.getlogdatetime(),\n                                xxljobcontext.getxxljobcontext().gethandlecode(),\n                                xxljobcontext.getxxljobcontext().gethandlemsg()\n                        ));\n                    } else {\n                        triggercallbackthread.pushcallback(new handlercallbackparam(\n                                triggerparam.getlogid(),\n                                triggerparam.getlogdatetime(),\n                                xxljobcontext.handle_code_fail,\n                                stopreason + "[job running, killed]"\n                        ));\n                    }\n                }\n            }\n\n        }\n\n        // 退出while循环，最后将队列中没来得及执行的数据拿出来回调回去，告诉调度中心这些数据没有执行\n        while (triggerqueue != null && !triggerqueue.isempty()) {\n            triggerparam triggerparam = triggerqueue.poll();\n            if (triggerparam == null) {\n                continue;\n            }\n            triggercallbackthread.pushcallback(new handlercallbackparam(\n                    triggerparam.getlogid(),\n                    triggerparam.getlogdatetime(),\n                    xxljobcontext.handle_code_fail,\n                    stopreason + " [job not executed, in the job queue, killed.]"\n            ));\n        }\n        // 执行销毁方法\n        rundestroymethod();\n    }\n\n    private void runinitmethod() {\n        try {\n            handler.init();\n        } catch (exception e) {\n            logger.error(e.getmessage(), e);\n        }\n    }\n\n    private void rundestroymethod() {\n        try {\n            handler.destroy();\n        } catch (exception e) {\n            logger.error(e.getmessage(), e);\n        }\n    }\n\n    /**\n     * 执行定时任务，根据是否设置超时时间来执行。\n     * 如果设置了超时时间就开启子线程，使用 futuretask 执行。\n     * 如果没有设置超时时间就直接执行\n     *\n     * @param triggerparam\n     * @param xxljobcontext\n     */\n    private void doexecute(triggerparam triggerparam, xxljobcontext xxljobcontext) throws exception {\n        // 没有设置超时时间，直接执行，设置了超时时间，开启子线程执行，此线程监督子线程执行\n        if (triggerparam.getexecutortimeout() == 0) {\n            try {\n                handler.execute();\n            } catch (exception e) {\n                xxljobhelper.log("<br>-------------- xxl-job job execute timeout");\n                xxljobhelper.log(e);\n                xxljobhelper.handlefail("job execute fail, exception message: " + e.getmessage());\n            }\n        } else {\n            thread futurethread = null;\n            try {\n                futuretask<boolean> futuretask = new futuretask<>(new callable<boolean>() {\n                    @override\n                    public boolean call() throws exception {\n                        xxljobcontext.setxxljobcontext(xxljobcontext);\n                        handler.execute();\n                        return true;\n                    }\n                });\n                // 创建并启动线程，get结果，如果指定时间get不到，说明超时\n                futurethread = new thread(futuretask);\n                futurethread.start();\n                boolean tempresult = futuretask.get(triggerparam.getexecutortimeout(), timeunit.seconds);\n            } catch (timeoutexception e) {\n                xxljobhelper.log("<br>-------------- xxl-job job execute timeout");\n                xxljobhelper.log(e);\n                // 将超时设置到 xxljobcontext 中\n                xxljobhelper.handletimeout("job execute timeout");\n            } finally {\n                futurethread.interrupt();\n            }\n        }\n    }\n\n    public void tostop(string stopreason) {\n        tostop = true;\n        this.stopreason = stopreason;\n    }\n\n\n    public ijobhandler gethandler() {\n        return handler;\n    }\n\n}\n\n\n\n# 7. 执行器对 jobthread 的管理\n\njobthread 完成le ，现在来想想怎么将 triggerparam 放入阻塞队列吧，jobthread 提供了 api ：pushtriggerqueue.\n\n怎么调度它呢？如何知道负责某个任务的线程是否存在呢？如何将线程销毁呢（谁来调用 tostop() 方法呢）？\n\n这些都是问题待解决的问题。上面介绍 methodjobhandler 时将 methodjobhandler 收集起来放入 map 中，那么 jobthread 也可以收集起来进行统一的管理啊，用 jobid-jobthread 这种 key-value 形式将线程封装进 map 中，调度中心传入 triggerparam 后，通过 jobid 找到负责该任务的线程，调用 pushtriggerqueue 将 triggerparam 放入队列等待执行。那么由谁来管理这个装 jobthread 的 map 呢？肯定是执行器，所以将这个 map 放入 xxljobexecutor 中。\n\n// 存放 jobthread线程 的map\nprivate static concurrenthashmap<integer, jobthread> jobthreadrepository = new concurrenthashmap<>();\n\n// 根据任务id获取对应线程\npublic static jobthread loadjobthread(int jobid) {\n    return jobthreadrepository.get(jobid);\n}\n\n// 注册新任务\npublic static jobthread registjobthread(int jobid, ijobhandler handler, string removeoldreason) {\n    jobthread newjobthread = new jobthread(jobid, handler);\n    newjobthread.start();\n    jobthread oldjobthread = jobthreadrepository.put(jobid, newjobthread);\n    // 如果任务之前注册过，可能是web端更改了任务。将旧线程停止。\n    if (oldjobthread != null) {\n        oldjobthread.tostop(removeoldreason);\n        oldjobthread.interrupt();\n    }\n    return newjobthread;\n}\n\n// 销毁线程\npublic static jobthread removejobthread(int jobid, string removereason) {\n    jobthread oldjobthread = jobthreadrepository.remove(jobid);\n    if (oldjobthread != null) {\n        oldjobthread.tostop(removereason);\n        oldjobthread.interrupt();\n    }\n    return oldjobthread;\n}\n\n\n说一下为啥停止线程的时候不仅要调用 tostop 方法，还要调用 interrupt 方法呢？\n\n 1. 线程中使用 while(!tostop){} 的形式进行无限循环，所以想要停止这个线程肯定要让线程退出循环，调用 tostop 方法会将 tostop = true\n 2. 在 jobthread.run() 方法中，有 阻塞着从队列中取值 的步骤存在，如果想要让线程停止工作，肯定要让线程先退出阻塞状态再退出循环，所以调用 interrupt 纯粹是不让线程阻塞这么长时间。\n\n补全了对于 jobthread 的管理，现在的执行器执行任务的流程就很清晰了：\n\n 1. 执行器接收到来自调度中心的 triggerparam\n\n 2. show me code：\n    \n    jobthread thread = xxljobexecutor.loadjobthread(triggerpara.getjobid());\n    if (thread == null) {\n        thread = xxljobexecutor.registjobthread(这里先不说);\n    }\n    thread.pushtriggerqueue(triggerparam);\n    \n\n 3. 调度参数放入队列后就会等待取出执行。这个步骤可以参考 jobthread 的代码\n\n最后，来看看 thread = xxljobexecutor.registjobthread(这里先不说) 这一步，想要注册线程，就必须拿到 methodjobhandler，怎么拿到？triggerparam 中有 任务名，我们之前将所有 任务名-jobhandler 的键值对封装到 xxljobexecutor 的一个 map 中了，所以可以先通过那个 map 获取 methodjobhandler 再进行新建线程。\n\n\n# 7. 总结\n\n放上面涉及到的全部代码：\n\n@configuration\npublic class xxljobspringexecutor extends xxljobexecutor implements applicationcontextaware, smartinitializingsingleton, disposablebean {\n    private static logger logger = loggerfactory.getlogger(xxljobspringexecutor.class);\n\n    private static applicationcontext applicationcontext;\n\n    @override\n    public void setapplicationcontext(applicationcontext applicationcontext) throws beansexception {\n        xxljobspringexecutor.applicationcontext = applicationcontext;\n    }\n\n    @override\n    public void aftersingletonsinstantiated() {\n        try {\n            initjobhandlermethodrepository(applicationcontext);\n            super.start();\n        } catch (exception e) {\n            logger.error(e.getmessage());\n        }\n    }\n\n    @override\n    public void destroy() throws exception {\n        super.stop();\n    }\n\n    private void initjobhandlermethodrepository(applicationcontext applicationcontext) throws nosuchmethodexception {\n        if (applicationcontext == null) return;\n        string[] beandefinitionnames = applicationcontext.getbeannamesfortype(object.class, false, true);\n        for (string beandefinitionname : beandefinitionnames) {\n            object bean = applicationcontext.getbean(beandefinitionname);\n            map<method, xxljob> annotatedmethods = null;\n            try {\n                annotatedmethods = methodintrospector.selectmethods(bean.getclass(),\n                        new methodintrospector.metadatalookup<xxljob>() {\n                            @override\n                            public xxljob inspect(method method) {\n                                return annotatedelementutils.findmergedannotation(method, xxljob.class);\n                            }\n                        }\n                );\n\n            } catch (exception e) {\n                // 记录日志，代码太长就不放了\n            }\n            if (collectionutil.isempty(annotatedmethods)) {\n                continue;\n            }\n            // 将定时任务注册为jobhandler\n            for (map.entry<method, xxljob> methodxxljobentry : annotatedmethods.entryset()) {\n                method method = methodxxljobentry.getkey();\n                xxljob value = methodxxljobentry.getvalue();\n                registjobhandler(value, bean, method);\n            }\n\n        }\n\n    }\n\n    public static applicationcontext getapplicationcontext() {\n        return applicationcontext;\n    }\n}\n\n\npublic class xxljobexecutor {\n    private static final logger logger = loggerfactory.getlogger(xxljobexecutor.class);\n        // ---------------------- job handler repository ----------------------\n    private static concurrentmap<string, ijobhandler> jobhandlerrepository = new concurrenthashmap<string, ijobhandler>();\n    public static ijobhandler loadjobhandler(string name){\n        return jobhandlerrepository.get(name);\n    }\n    public static ijobhandler registjobhandler(string name, ijobhandler jobhandler){\n        return jobhandlerrepository.put(name, jobhandler);\n    }\n    protected void registjobhandler(xxljob xxljob, object bean, method executemethod){\n        if (xxljob == null) {\n            return;\n        }\n\n        string name = xxljob.value();\n        \n        class<?> clazz = bean.getclass();\n        string methodname = executemethod.getname();\n        if (name.trim().length() == 0) {\n            throw new runtimeexception("xxl-job method-jobhandler name invalid, for[" + clazz + "#" + methodname + "] .");\n        }\n        if (loadjobhandler(name) != null) {\n            throw new runtimeexception("xxl-job jobhandler[" + name + "] naming conflicts.");\n        }\n\n        executemethod.setaccessible(true);\n\n        // init and destroy\n        method initmethod = null;\n        method destroymethod = null;\n\n        if (xxljob.init().trim().length() > 0) {\n            try {\n                initmethod = clazz.getdeclaredmethod(xxljob.init());\n                initmethod.setaccessible(true);\n            } catch (nosuchmethodexception e) {\n                throw new runtimeexception("xxl-job method-jobhandler initmethod invalid, for[" + clazz + "#" + methodname + "] .");\n            }\n        }\n        if (xxljob.destroy().trim().length() > 0) {\n            try {\n                destroymethod = clazz.getdeclaredmethod(xxljob.destroy());\n                destroymethod.setaccessible(true);\n            } catch (nosuchmethodexception e) {\n                throw new runtimeexception("xxl-job method-jobhandler destroymethod invalid, for[" + clazz + "#" + methodname + "] .");\n            }\n        }\n\n        // registry jobhandler\n        registjobhandler(name, new methodjobhandler(bean, executemethod, initmethod, destroymethod));\n\n    }\n\n\n    // ---------------------- job thread repository ----------------------\n    private static concurrentmap<integer, jobthread> jobthreadrepository = new concurrenthashmap<integer, jobthread>();\n    public static jobthread registjobthread(int jobid, ijobhandler handler, string removeoldreason){\n        jobthread newjobthread = new jobthread(jobid, handler);\n        newjobthread.start();\n        \n\n        jobthread oldjobthread = jobthreadrepository.put(jobid, newjobthread);\t\n        if (oldjobthread != null) {\n            oldjobthread.tostop(removeoldreason);\n            oldjobthread.interrupt();\n        }\n\n        return newjobthread;\n    }\n\n    public static jobthread removejobthread(int jobid, string removeoldreason){\n        jobthread oldjobthread = jobthreadrepository.remove(jobid);\n        if (oldjobthread != null) {\n            oldjobthread.tostop(removeoldreason);\n            oldjobthread.interrupt();\n\n            return oldjobthread;\n        }\n        return null;\n    }\n\n    public static jobthread loadjobthread(int jobid){\n        return jobthreadrepository.get(jobid);\n    }\n}\n\n\npublic class triggerparam implements serializable {\n    private static final long serialversionuid = 42l;\n\n    /**\n     * 任务id\n     */\n    private int jobid;\n\n    /**\n     * 定时任务名字\n     */\n    private string executorhandler;\n\n    /**\n     * 定时任务的参数\n     */\n    private string executorparams;\n\n    /**\n     * 定时任务的阻塞策略                <br></br>\n     * 当一个定时任务想要执行，但是负责该任务的线程正在工作时会使用这个阻塞策略判断\n     */\n    private string executorblockstrategy;\n\n    /**\n     * 任务的过期时间          <br></br>\n     * 如果开启了过期时间，执行任务时会额外创建一个新线程执行任务，\n     * 之前的线程负责监督新线程执行任务时间是否超时\n     */\n    private int executortimeout;\n\n    /**\n     * 该任务对应的日志的id\n     */\n    private long logid;\n\n    /**\n     * 打日志的时间\n     */\n    private long logdatetime;\n\n    /**\n     * 运行模式\n     */\n    private string gluetype;\n\n    /**\n     * 代码文本\n     */\n    private string gluesource;\n\n    /**\n     * 代码文本更新时间\n     */\n    private long glueupdatetime;\n\n    /**\n     * 分片索引\n     */\n    private int broadcastindex;\n\n    /**\n     * 分片总数\n     */\n    private int broadcasttotal;\n}\n\n\npackage com.xxl.job.core.thread;\n\nimport com.xxl.job.core.biz.model.handlecallbackparam;\nimport com.xxl.job.core.biz.model.returnt;\nimport com.xxl.job.core.biz.model.triggerparam;\nimport com.xxl.job.core.context.xxljobcontext;\nimport com.xxl.job.core.context.xxljobhelper;\nimport com.xxl.job.core.executor.xxljobexecutor;\nimport com.xxl.job.core.handler.ijobhandler;\nimport com.xxl.job.core.log.xxljobfileappender;\nimport org.slf4j.logger;\nimport org.slf4j.loggerfactory;\n\nimport java.io.printwriter;\nimport java.io.stringwriter;\nimport java.util.collections;\nimport java.util.date;\nimport java.util.hashset;\nimport java.util.set;\nimport java.util.concurrent.*;\n\n\n/**\n * handler thread\n * @author xuxueli 2016-1-16 19:52:47\n */\npublic class jobthread extends thread{\n\tprivate static logger logger = loggerfactory.getlogger(jobthread.class);\n\n\tprivate int jobid;\n\tprivate ijobhandler handler;\n\tprivate linkedblockingqueue<triggerparam> triggerqueue;\n\tprivate set<long> triggerlogidset;\t\t\n\n\tprivate volatile boolean tostop = false;\n\tprivate string stopreason;\n\n    private boolean running = false;    \n\tprivate int idletimes = 0;\t\t\t\n\n\n\tpublic jobthread(int jobid, ijobhandler handler) {\n\t\tthis.jobid = jobid;\n\t\tthis.handler = handler;\n\t\tthis.triggerqueue = new linkedblockingqueue<triggerparam>();\n\t\tthis.triggerlogidset = collections.synchronizedset(new hashset<long>());\n\n\t\t// assign job thread name\n\t\tthis.setname("xxl-job, jobthread-"+jobid+"-"+system.currenttimemillis());\n\t}\n\tpublic ijobhandler gethandler() {\n\t\treturn handler;\n\t}\n\n    /**\n     * new trigger to queue\n     *\n     * @param triggerparam\n     * @return\n     */\n\tpublic returnt<string> pushtriggerqueue(triggerparam triggerparam) {\n\t\t// avoid repeat\n\t\tif (triggerlogidset.contains(triggerparam.getlogid())) {\n\t\t\tlogger.info(">>>>>>>>>>> repeate trigger job, logid:{}", triggerparam.getlogid());\n\t\t\treturn new returnt<string>(returnt.fail_code, "repeate trigger job, logid:" + triggerparam.getlogid());\n\t\t}\n\n\t\ttriggerlogidset.add(triggerparam.getlogid());\n\t\ttriggerqueue.add(triggerparam);\n        return returnt.success;\n\t}\n\n    /**\n     * kill job thread\n     *\n     * @param stopreason\n     */\n\tpublic void tostop(string stopreason) {\n\t\t/**\n\t\t * thread.interrupt只支持终止线程的阻塞状态(wait、join、sleep)，\n\t\t * 在阻塞出抛出interruptedexception异常,但是并不会终止运行的线程本身；\n\t\t * 所以需要注意，此处彻底销毁本线程，需要通过共享变量方式；\n\t\t */\n\t\tthis.tostop = true;\n\t\tthis.stopreason = stopreason;\n\t}\n\n    /**\n     * is running job\n     * @return\n     */\n    public boolean isrunningorhasqueue() {\n        return running || triggerqueue.size()>0;\n    }\n\n    @override\n\tpublic void run() {\n\n    \t// init\n    \ttry {\n\t\t\thandler.init();\n\t\t} catch (throwable e) {\n    \t\tlogger.error(e.getmessage(), e);\n\t\t}\n\n\t\t// execute\n\t\twhile(!tostop){\n\t\t\trunning = false;\n\t\t\tidletimes++;\n\n            triggerparam triggerparam = null;\n            try {\n\t\t\t\t// to check tostop signal, we need cycle, so wo cannot use queue.take(), instand of poll(timeout)\n\t\t\t\ttriggerparam = triggerqueue.poll(3l, timeunit.seconds);\n\t\t\t\tif (triggerparam!=null) {\n\t\t\t\t\trunning = true;\n\t\t\t\t\tidletimes = 0;\n\t\t\t\t\ttriggerlogidset.remove(triggerparam.getlogid());\n\n\t\t\t\t\t// log filename, like "logpath/yyyy-mm-dd/9999.log"\n\t\t\t\t\tstring logfilename = xxljobfileappender.makelogfilename(new date(triggerparam.getlogdatetime()), triggerparam.getlogid());\n\t\t\t\t\txxljobcontext xxljobcontext = new xxljobcontext(\n\t\t\t\t\t\t\ttriggerparam.getjobid(),\n\t\t\t\t\t\t\ttriggerparam.getexecutorparams(),\n\t\t\t\t\t\t\tlogfilename,\n\t\t\t\t\t\t\ttriggerparam.getbroadcastindex(),\n\t\t\t\t\t\t\ttriggerparam.getbroadcasttotal());\n\n\t\t\t\t\t// init job context\n\t\t\t\t\txxljobcontext.setxxljobcontext(xxljobcontext);\n\n\t\t\t\t\t// execute\n\t\t\t\t\txxljobhelper.log("<br>----------- xxl-job job execute start -----------<br>----------- param:" + xxljobcontext.getjobparam());\n\n\t\t\t\t\tif (triggerparam.getexecutortimeout() > 0) {\n\t\t\t\t\t\t// limit timeout\n\t\t\t\t\t\tthread futurethread = null;\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tfuturetask<boolean> futuretask = new futuretask<boolean>(new callable<boolean>() {\n\t\t\t\t\t\t\t\t@override\n\t\t\t\t\t\t\t\tpublic boolean call() throws exception {\n\n\t\t\t\t\t\t\t\t\t// init job context\n\t\t\t\t\t\t\t\t\txxljobcontext.setxxljobcontext(xxljobcontext);\n\n\t\t\t\t\t\t\t\t\thandler.execute();\n\t\t\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\tfuturethread = new thread(futuretask);\n\t\t\t\t\t\t\tfuturethread.start();\n\n\t\t\t\t\t\t\tboolean tempresult = futuretask.get(triggerparam.getexecutortimeout(), timeunit.seconds);\n\t\t\t\t\t\t} catch (timeoutexception e) {\n\n\t\t\t\t\t\t\txxljobhelper.log("<br>----------- xxl-job job execute timeout");\n\t\t\t\t\t\t\txxljobhelper.log(e);\n\n\t\t\t\t\t\t\t// handle result\n\t\t\t\t\t\t\txxljobhelper.handletimeout("job execute timeout ");\n\t\t\t\t\t\t} finally {\n\t\t\t\t\t\t\tfuturethread.interrupt();\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// just execute\n\t\t\t\t\t\thandler.execute();\n\t\t\t\t\t}\n\n\t\t\t\t\t// valid execute handle data\n\t\t\t\t\tif (xxljobcontext.getxxljobcontext().gethandlecode() <= 0) {\n\t\t\t\t\t\txxljobhelper.handlefail("job handle result lost.");\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstring temphandlemsg = xxljobcontext.getxxljobcontext().gethandlemsg();\n\t\t\t\t\t\ttemphandlemsg = (temphandlemsg!=null&&temphandlemsg.length()>50000)\n\t\t\t\t\t\t\t\t?temphandlemsg.substring(0, 50000).concat("...")\n\t\t\t\t\t\t\t\t:temphandlemsg;\n\t\t\t\t\t\txxljobcontext.getxxljobcontext().sethandlemsg(temphandlemsg);\n\t\t\t\t\t}\n\t\t\t\t\txxljobhelper.log("<br>----------- xxl-job job execute end(finish) -----------<br>----------- result: handlecode="\n\t\t\t\t\t\t\t+ xxljobcontext.getxxljobcontext().gethandlecode()\n\t\t\t\t\t\t\t+ ", handlemsg = "\n\t\t\t\t\t\t\t+ xxljobcontext.getxxljobcontext().gethandlemsg()\n\t\t\t\t\t);\n\n\t\t\t\t} else {\n\t\t\t\t\tif (idletimes > 30) {\n\t\t\t\t\t\tif(triggerqueue.size() == 0) {\t\n\t\t\t\t\t\t\txxljobexecutor.removejobthread(jobid, "excutor idel times over limit.");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch (throwable e) {\n\t\t\t\tif (tostop) {\n\t\t\t\t\txxljobhelper.log("<br>----------- jobthread tostop, stopreason:" + stopreason);\n\t\t\t\t}\n\n\t\t\t\t// handle result\n\t\t\t\tstringwriter stringwriter = new stringwriter();\n\t\t\t\te.printstacktrace(new printwriter(stringwriter));\n\t\t\t\tstring errormsg = stringwriter.tostring();\n\n\t\t\t\txxljobhelper.handlefail(errormsg);\n\n\t\t\t\txxljobhelper.log("<br>----------- jobthread exception:" + errormsg + "<br>----------- xxl-job job execute end(error) -----------");\n\t\t\t} finally {\n                if(triggerparam != null) {\n                    // callback handler info\n                    if (!tostop) {\n                        // commonm\n                        triggercallbackthread.pushcallback(new handlecallbackparam(\n                        \t\ttriggerparam.getlogid(),\n\t\t\t\t\t\t\t\ttriggerparam.getlogdatetime(),\n\t\t\t\t\t\t\t\txxljobcontext.getxxljobcontext().gethandlecode(),\n\t\t\t\t\t\t\t\txxljobcontext.getxxljobcontext().gethandlemsg() )\n\t\t\t\t\t\t);\n                    } else {\n                        // is killed\n                        triggercallbackthread.pushcallback(new handlecallbackparam(\n                        \t\ttriggerparam.getlogid(),\n\t\t\t\t\t\t\t\ttriggerparam.getlogdatetime(),\n\t\t\t\t\t\t\t\txxljobcontext.handle_code_fail,\n\t\t\t\t\t\t\t\tstopreason + " [job running, killed]" )\n\t\t\t\t\t\t);\n                    }\n                }\n            }\n        }\n\n\t\t// callback trigger request in queue\n\t\twhile(triggerqueue !=null && triggerqueue.size()>0){\n\t\t\ttriggerparam triggerparam = triggerqueue.poll();\n\t\t\tif (triggerparam!=null) {\n\t\t\t\t// is killed\n\t\t\t\ttriggercallbackthread.pushcallback(new handlecallbackparam(\n\t\t\t\t\t\ttriggerparam.getlogid(),\n\t\t\t\t\t\ttriggerparam.getlogdatetime(),\n\t\t\t\t\t\txxljobcontext.handle_code_fail,\n\t\t\t\t\t\tstopreason + " [job not executed, in the job queue, killed.]")\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\n\t\t// destroy\n\t\ttry {\n\t\t\thandler.destroy();\n\t\t} catch (throwable e) {\n\t\t\tlogger.error(e.getmessage(), e);\n\t\t}\n\n\t\t\n\t}\n}\n',charsets:{cjk:!0},lastUpdated:"2023/11/29, 16:01:58",lastUpdatedTimestamp:1701244918e3},{title:"Spring事务",frontmatter:{title:"Spring事务",date:"2023-11-02T21:11:42.000Z",permalink:"/pages/b4dd7e/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/5.Spring/100.Spring%E4%BA%8B%E5%8A%A1.html",relativePath:"02.文章/91.框架/5.Spring/100.Spring事务.md",key:"v-40abcda6",path:"/pages/b4dd7e/",headers:[{level:2,title:"1. Spring 实现事务的方式",slug:"_1-spring-实现事务的方式",normalizedTitle:"1. spring 实现事务的方式",charIndex:2},{level:3,title:"1.1 编程式事务",slug:"_1-1-编程式事务",normalizedTitle:"1.1 编程式事务",charIndex:166},{level:3,title:"1.2 声明式事务",slug:"_1-2-声明式事务",normalizedTitle:"1.2 声明式事务",charIndex:1054},{level:2,title:"2. Spring 事务传播行为",slug:"_2-spring-事务传播行为",normalizedTitle:"2. spring 事务传播行为",charIndex:1291},{level:3,title:"2.1 REQUIRED（需要）",slug:"_2-1-required-需要",normalizedTitle:"2.1 required（需要）",charIndex:2189},{level:3,title:"2.2 REQUIRES_NEW（需要新的）",slug:"_2-2-requires-new-需要新的",normalizedTitle:"2.2 requires_new（需要新的）",charIndex:2402},{level:3,title:"2.3 SUPPORTS （支持）",slug:"_2-3-supports-支持",normalizedTitle:"2.3 supports （支持）",charIndex:2546},{level:3,title:"2.4 NOT_SUPPORTED（不支持）",slug:"_2-4-not-supported-不支持",normalizedTitle:"2.4 not_supported（不支持）",charIndex:2724},{level:3,title:"2.5 MANDATORY （强制）",slug:"_2-5-mandatory-强制",normalizedTitle:"2.5 mandatory （强制）",charIndex:2856},{level:3,title:"2.6 NEVER（从不）",slug:"_2-6-never-从不",normalizedTitle:"2.6 never（从不）",charIndex:3024},{level:3,title:"2.7 NESTED（嵌套的）",slug:"_2-7-nested-嵌套的",normalizedTitle:"2.7 nested（嵌套的）",charIndex:3188},{level:2,title:"3. Spring 事务的隔离级别",slug:"_3-spring-事务的隔离级别",normalizedTitle:"3. spring 事务的隔离级别",charIndex:3408}],headersStr:"1. Spring 实现事务的方式 1.1 编程式事务 1.2 声明式事务 2. Spring 事务传播行为 2.1 REQUIRED（需要） 2.2 REQUIRES_NEW（需要新的） 2.3 SUPPORTS （支持） 2.4 NOT_SUPPORTED（不支持） 2.5 MANDATORY （强制） 2.6 NEVER（从不） 2.7 NESTED（嵌套的） 3. Spring 事务的隔离级别",content:"# 1. Spring 实现事务的方式\n\n 1. 编程式事务\n    \n    通过 TransactionTemplate 或者 TreasactionManager 手动管理事务。\n\n 2. 声明式事务\n    \n    通过 @Transactional 注解 或 XML配置的形式声明事务。实际上是通过AOP完成。\n\n\n# 1.1 编程式事务\n\n通过硬编码的方式使用 Spring 中提供的抽象事务 API 来控制事务。\n\nSpring 使用模板方法对其封装为我们提供了事务模板类 ：TranscationTemplate 方便我们使用\n\n@Service\npublic class TransactionalService {\n    \n    @Autowired\n    private TransactionTemplate transactionTemplate;\n \n    public void performTransactionalOperation() {\n        transactionTemplate.execute(new TransactionCallback<Void>() {\n            public Void doInTransaction(TransactionStatus status) {\n                // 在这里执行事务操作\n                userMapper.add(user);\n                userMapper.delete(user);\n                // 可以进行数据库操作、调用其他需要事务支持的方法等\n \t\t\t\t\n                return null;\n            }\n        });\n    }\n}\n\n\n在上述示例中，我们通过 execute() 方法来执行事务操作。TransactionCallback 的 doInTransaction() 方法中的代码将在事务的上下文中执行。\n\n如果在 doInTransaction() 中发生了未捕获的异常，事务将会被回滚，并回到事务的起点。如果 doInTransaction() 正常执行，事务将被提交。\n\n这也是为啥我们加了 @Transactional 注解后，捕获的异常不要自己解决了。如果自己解决了，Spring的事务管理就不生效了。\n\n\n# 1.2 声明式事务\n\n这个更简单了。在需要事务的地方加上 @Transactional，加在方法上，这个方法有事务；加在类上，类中的所有方法都有事务。\n\n@Service\n@Transactional\npublic class UserService {\n    \n    public String addUser() {\n        \n    }\n    \n    public String deleteUser(){\n        \n    }\n}\n\n\n\n# 2. Spring 事务传播行为\n\n事务传播行为是为了解决业务层方法之间互相调用的事务问题。\n\n当事务被另一个事务方法调用时，必须指定事务该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在新事务中运行。\n\n举个例子 ：\n\n@Service\nClass A {\n    @Autowired\n    B b;\n    @Transactional(propagation = Propagation.xxx)\n    public void aMethod {\n\n        b.bMethod();\n    }\n}\n\n@Service\nClass B {\n    @Transactional(propagation = Propagation.xxx)\n    public void bMethod {\n       // do something\n    }\n}\n\n\n我们在 A 类的 aMethod() 中调用了 B 类的 bMethod() 方法，这个时候就涉及到业务层方法之间的互相调用的事务问题。如果 B 类的 bMethod() 要回滚，如何配置事务的传播机制才能让 aMethod() 也跟着回滚呢？\n\n在 Spring 的 TranscationDefinition 类中定义了几个常量，代表着 Spring 支持的事务传播机制。\n\npublic interface TransactionDefinition {\n    int PROPAGATION_REQUIRED = 0;\n    int PROPAGATION_SUPPORTS = 1;\n    int PROPAGATION_MANDATORY = 2;\n    int PROPAGATION_REQUIRES_NEW = 3;\n    int PROPAGATION_NOT_SUPPORTED = 4;\n    int PROPAGATION_NEVER = 5;\n    int PROPAGATION_NESTED = 6;\n    // 其他属性不再展示\n}\n\n\n\n# 2.1 REQUIRED（需要）\n\n默认的事务传播行为，也是我们平时使用最多的事务传播行为。\n\n如果当前存在事务，加入当前事务。如果不存在，新建事务。\n\n * 如果 aMethod() 没有开启事务的话，bMethod会开启一个新事务，执行完就结束\n * 如果 aMethod() 开启事务了，bMethod() 加入该事务。不管是 aMethod() 出现异常，还是 bMethod() 出现异常，两个方法都回滚。\n\n\n# 2.2 REQUIRES_NEW（需要新的）\n\n创建一个新事务，如果当前存在事务，则把当前事务挂起。\n\n也就是说不管外部方法是否开启事务，使用这个传播机制的方法都会开启一个新事务。aMethod() 和 bMethod() 这俩方法的执行就没啥关系了，各自不影响各自的执行情况。\n\n\n# 2.3 SUPPORTS （支持）\n\n如果当前存在事务，则加入当前事务；如果当前没有事务，我也不用事务了。\n\n如果 aMethod() 中有事务，则 bMethod() 加入到 aMethod() 中，如果 aMethod() 回退，bMethod() 跟着回退。\n\n如果 aMethod() 中没有事务，bMethod() 也以无事务方式运行。\n\n\n# 2.4 NOT_SUPPORTED（不支持）\n\n以非事务的方法运行，如果当前存在事务，挂起当前事务。\n\n如果 aMethod() 中有事务，先挂起它，bMethod() 以非事务方法运行。\n\n如果 aMethod() 中没有事务，不管，以非事务方法运行。\n\n\n# 2.5 MANDATORY （强制）\n\n当前存在事务，加入当前事务；当前没有事务，抛出异常。\n\n如果 aMethod() 中有事务，则 bMethod() 加入到 aMethod() 中，如果 aMethod() 回退，bMethod() 跟着回退。\n\n如果 aMethod() 中没有事务，bMethod() 直接抛出异常。\n\n\n# 2.6 NEVER（从不）\n\n如果当前没有事务，就以非事务方法运行；如果有，抛出异常\n\n这个传播行为跟 NOT_SUPPORT 有点像，不过这个在有事务的情况下会抛出异常。\n\n如果 aMethod() 有事务，bMethod() 抛出异常。\n\n如果 aMethod() 没有事务，bMethod() 以非事务方法运行。\n\n\n# 2.7 NESTED（嵌套的）\n\n如果当前存在事务，开启一个子事务；如果当前没事务，开启一个新事务。\n\n什么是子事务？父事务回滚子事务必须回滚；子事务回滚父事务不必回滚。\n\n如果 aMethod() 有事务，bMethod() 开启一个子事务。aMethod() 回滚 bMethod() 也回滚；bMethod() 回滚 aMethod() 不回滚。\n\n如果 aMethod() 没有事务，bMethod() 新建一个事务运行。\n\n\n# 3. Spring 事务的隔离级别\n\n**隔离级别：**主要解决多个同时运行且访问数据库数据相同的事务带来的并发问题。在数据库中事务的隔离性是这样定义的：数据库系统必须具有隔离并发运行各个事务的能力，使他们不会互相影响，避免产生并发问题。\n\nSpring的接口TransactionDefinition中定义了表示隔离级别的常量，当然其实主要还是对应数据库的事务隔离级别：\n\n 1. ISOLATION_DEFAULT：使用后端数据库默认的隔离界别，MySQL 默认可重复读，Oracle 默认读已提交。\n\n 2. ISOLATION_READ_UNCOMMITTED：读未提交\n\n 3. ISOLATION_READ_COMMITTED：读已提交\n\n 4. ISOLATION_REPEATABLE_READ：可重复读\n\n 5. ISOLATION_SERIALIZABLE：串行化",normalizedContent:"# 1. spring 实现事务的方式\n\n 1. 编程式事务\n    \n    通过 transactiontemplate 或者 treasactionmanager 手动管理事务。\n\n 2. 声明式事务\n    \n    通过 @transactional 注解 或 xml配置的形式声明事务。实际上是通过aop完成。\n\n\n# 1.1 编程式事务\n\n通过硬编码的方式使用 spring 中提供的抽象事务 api 来控制事务。\n\nspring 使用模板方法对其封装为我们提供了事务模板类 ：transcationtemplate 方便我们使用\n\n@service\npublic class transactionalservice {\n    \n    @autowired\n    private transactiontemplate transactiontemplate;\n \n    public void performtransactionaloperation() {\n        transactiontemplate.execute(new transactioncallback<void>() {\n            public void dointransaction(transactionstatus status) {\n                // 在这里执行事务操作\n                usermapper.add(user);\n                usermapper.delete(user);\n                // 可以进行数据库操作、调用其他需要事务支持的方法等\n \t\t\t\t\n                return null;\n            }\n        });\n    }\n}\n\n\n在上述示例中，我们通过 execute() 方法来执行事务操作。transactioncallback 的 dointransaction() 方法中的代码将在事务的上下文中执行。\n\n如果在 dointransaction() 中发生了未捕获的异常，事务将会被回滚，并回到事务的起点。如果 dointransaction() 正常执行，事务将被提交。\n\n这也是为啥我们加了 @transactional 注解后，捕获的异常不要自己解决了。如果自己解决了，spring的事务管理就不生效了。\n\n\n# 1.2 声明式事务\n\n这个更简单了。在需要事务的地方加上 @transactional，加在方法上，这个方法有事务；加在类上，类中的所有方法都有事务。\n\n@service\n@transactional\npublic class userservice {\n    \n    public string adduser() {\n        \n    }\n    \n    public string deleteuser(){\n        \n    }\n}\n\n\n\n# 2. spring 事务传播行为\n\n事务传播行为是为了解决业务层方法之间互相调用的事务问题。\n\n当事务被另一个事务方法调用时，必须指定事务该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在新事务中运行。\n\n举个例子 ：\n\n@service\nclass a {\n    @autowired\n    b b;\n    @transactional(propagation = propagation.xxx)\n    public void amethod {\n\n        b.bmethod();\n    }\n}\n\n@service\nclass b {\n    @transactional(propagation = propagation.xxx)\n    public void bmethod {\n       // do something\n    }\n}\n\n\n我们在 a 类的 amethod() 中调用了 b 类的 bmethod() 方法，这个时候就涉及到业务层方法之间的互相调用的事务问题。如果 b 类的 bmethod() 要回滚，如何配置事务的传播机制才能让 amethod() 也跟着回滚呢？\n\n在 spring 的 transcationdefinition 类中定义了几个常量，代表着 spring 支持的事务传播机制。\n\npublic interface transactiondefinition {\n    int propagation_required = 0;\n    int propagation_supports = 1;\n    int propagation_mandatory = 2;\n    int propagation_requires_new = 3;\n    int propagation_not_supported = 4;\n    int propagation_never = 5;\n    int propagation_nested = 6;\n    // 其他属性不再展示\n}\n\n\n\n# 2.1 required（需要）\n\n默认的事务传播行为，也是我们平时使用最多的事务传播行为。\n\n如果当前存在事务，加入当前事务。如果不存在，新建事务。\n\n * 如果 amethod() 没有开启事务的话，bmethod会开启一个新事务，执行完就结束\n * 如果 amethod() 开启事务了，bmethod() 加入该事务。不管是 amethod() 出现异常，还是 bmethod() 出现异常，两个方法都回滚。\n\n\n# 2.2 requires_new（需要新的）\n\n创建一个新事务，如果当前存在事务，则把当前事务挂起。\n\n也就是说不管外部方法是否开启事务，使用这个传播机制的方法都会开启一个新事务。amethod() 和 bmethod() 这俩方法的执行就没啥关系了，各自不影响各自的执行情况。\n\n\n# 2.3 supports （支持）\n\n如果当前存在事务，则加入当前事务；如果当前没有事务，我也不用事务了。\n\n如果 amethod() 中有事务，则 bmethod() 加入到 amethod() 中，如果 amethod() 回退，bmethod() 跟着回退。\n\n如果 amethod() 中没有事务，bmethod() 也以无事务方式运行。\n\n\n# 2.4 not_supported（不支持）\n\n以非事务的方法运行，如果当前存在事务，挂起当前事务。\n\n如果 amethod() 中有事务，先挂起它，bmethod() 以非事务方法运行。\n\n如果 amethod() 中没有事务，不管，以非事务方法运行。\n\n\n# 2.5 mandatory （强制）\n\n当前存在事务，加入当前事务；当前没有事务，抛出异常。\n\n如果 amethod() 中有事务，则 bmethod() 加入到 amethod() 中，如果 amethod() 回退，bmethod() 跟着回退。\n\n如果 amethod() 中没有事务，bmethod() 直接抛出异常。\n\n\n# 2.6 never（从不）\n\n如果当前没有事务，就以非事务方法运行；如果有，抛出异常\n\n这个传播行为跟 not_support 有点像，不过这个在有事务的情况下会抛出异常。\n\n如果 amethod() 有事务，bmethod() 抛出异常。\n\n如果 amethod() 没有事务，bmethod() 以非事务方法运行。\n\n\n# 2.7 nested（嵌套的）\n\n如果当前存在事务，开启一个子事务；如果当前没事务，开启一个新事务。\n\n什么是子事务？父事务回滚子事务必须回滚；子事务回滚父事务不必回滚。\n\n如果 amethod() 有事务，bmethod() 开启一个子事务。amethod() 回滚 bmethod() 也回滚；bmethod() 回滚 amethod() 不回滚。\n\n如果 amethod() 没有事务，bmethod() 新建一个事务运行。\n\n\n# 3. spring 事务的隔离级别\n\n**隔离级别：**主要解决多个同时运行且访问数据库数据相同的事务带来的并发问题。在数据库中事务的隔离性是这样定义的：数据库系统必须具有隔离并发运行各个事务的能力，使他们不会互相影响，避免产生并发问题。\n\nspring的接口transactiondefinition中定义了表示隔离级别的常量，当然其实主要还是对应数据库的事务隔离级别：\n\n 1. isolation_default：使用后端数据库默认的隔离界别，mysql 默认可重复读，oracle 默认读已提交。\n\n 2. isolation_read_uncommitted：读未提交\n\n 3. isolation_read_committed：读已提交\n\n 4. isolation_repeatable_read：可重复读\n\n 5. isolation_serializable：串行化",charsets:{cjk:!0},lastUpdated:"2023/11/03, 18:29:13",lastUpdatedTimestamp:1699007353e3},{title:"Sentinel",frontmatter:{title:"Sentinel",date:"2023-10-30T14:36:24.000Z",permalink:"/pages/a7a70b/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/20.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/40.Sentinel.html",relativePath:"02.文章/91.框架/20.微服务中间件的使用/40.Sentinel.md",key:"v-7512a88a",path:"/pages/a7a70b/",headers:[{level:2,title:"1. 服务雪崩效应",slug:"_1-服务雪崩效应",normalizedTitle:"1. 服务雪崩效应",charIndex:2},{level:2,title:"2. 应对服务雪崩",slug:"_2-应对服务雪崩",normalizedTitle:"2. 应对服务雪崩",charIndex:293},{level:3,title:"2.1 限流",slug:"_2-1-限流",normalizedTitle:"2.1 限流",charIndex:307},{level:3,title:"2.2 舱壁模式",slug:"_2-2-舱壁模式",normalizedTitle:"2.2 舱壁模式",charIndex:421},{level:3,title:"2.3 断路器",slug:"_2-3-断路器",normalizedTitle:"2.3 断路器",charIndex:601},{level:2,title:"3. Sentinel 简介",slug:"_3-sentinel-简介",normalizedTitle:"3. sentinel 简介",charIndex:760},{level:2,title:"4. Sentinel 安装",slug:"_4-sentinel-安装",normalizedTitle:"4. sentinel 安装",charIndex:961},{level:3,title:"4.1 安装配置",slug:"_4-1-安装配置",normalizedTitle:"4.1 安装配置",charIndex:980},{level:3,title:"4.2 实时监控",slug:"_4-2-实时监控",normalizedTitle:"4.2 实时监控",charIndex:2545},{level:3,title:"4.3 簇点链路",slug:"_4-3-簇点链路",normalizedTitle:"4.3 簇点链路",charIndex:2604},{level:2,title:"5. Sentinel 流量控制",slug:"_5-sentinel-流量控制",normalizedTitle:"5. sentinel 流量控制",charIndex:2730},{level:3,title:"5.1 基于 QPS 的流量控制",slug:"_5-1-基于-qps-的流量控制",normalizedTitle:"5.1 基于 qps 的流量控制",charIndex:2751},{level:3,title:"5.2 基于线程数的流量控制",slug:"_5-2-基于线程数的流量控制",normalizedTitle:"5.2 基于线程数的流量控制",charIndex:2867},{level:3,title:"5.3 流控模式",slug:"_5-3-流控模式",normalizedTitle:"5.3 流控模式",charIndex:3066},{level:3,title:"5.4 流控效果",slug:"_5-4-流控效果",normalizedTitle:"5.4 流控效果",charIndex:3319},{level:3,title:"5.5 热点限流",slug:"_5-5-热点限流",normalizedTitle:"5.5 热点限流",charIndex:3724},{level:3,title:"5.6 来源限流",slug:"_5-6-来源限流",normalizedTitle:"5.6 来源限流",charIndex:4202},{level:2,title:"6. Sentinel 熔断降级",slug:"_6-sentinel-熔断降级",normalizedTitle:"6. sentinel 熔断降级",charIndex:4346},{level:3,title:"6.1 OpenFeign 整合 Sentinel",slug:"_6-1-openfeign-整合-sentinel",normalizedTitle:"6.1 openfeign 整合 sentinel",charIndex:4732},{level:3,title:"6.2 熔断降级",slug:"_6-2-熔断降级",normalizedTitle:"6.2 熔断降级",charIndex:6495}],headersStr:"1. 服务雪崩效应 2. 应对服务雪崩 2.1 限流 2.2 舱壁模式 2.3 断路器 3. Sentinel 简介 4. Sentinel 安装 4.1 安装配置 4.2 实时监控 4.3 簇点链路 5. Sentinel 流量控制 5.1 基于 QPS 的流量控制 5.2 基于线程数的流量控制 5.3 流控模式 5.4 流控效果 5.5 热点限流 5.6 来源限流 6. Sentinel 熔断降级 6.1 OpenFeign 整合 Sentinel 6.2 熔断降级",content:'# 1. 服务雪崩效应\n\n在微服务各个模块之间经常互相调用，假如一个调用链为 ：C/D -> B -> A\n\n\n\n一开始 A 是正常的，随着时间的推移，A 出现了不可名状的bug，导致 B 调用 A 失败，进而导致 C 和 D 也失败，最后，由于 A 出现的错误，C -> B -> A 和 D -> B -> A 这两条调用链都无法使用，这就叫做雪崩。\n\n还有这种情况：\n\n服务 A 调用 B 正常，但是调用 C 阻塞，时间长了，阻塞在 A 处的线程就变得多了，会将 A 的资源耗尽导致 A 不可用。\n\n还有种情况：请求，也就是流量太大了，服务无法承受，导致请求服务器宕机。\n\n\n# 2. 应对服务雪崩\n\n\n# 2.1 限流\n\n经过测试，发现某个请求能够承受的最大 QPS（每秒流量数） 是 1000，那我们就把这个请求的 QPS 阈值设置为800，超过了这个阈值，请求直接返回被限流的错误，或者返回其他提示信息、广告、商品...\n\n\n# 2.2 舱壁模式\n\n舱壁模式借鉴于现实生活中的船舱结构，如果一条船没有将船体隔开，一旦漏水整条船就会沉。如果将船体分为多个舱壁，一个地方漏水，船不至于直接沉。\n\n\n\n我们可以记录使用线程池负责各个业务的远程调用，A 调用 B 、A 调用 C，都最多占用 10 个线程，那么如果 C 宕机导致 A d调用 C 的时候阻塞，最多消耗 10 个线程的资源。\n\n\n# 2.3 断路器\n\n类似于高中物理电路图：\n\n\n\n当流量过多，或者远程调用失败过多的情况下，我们将断路器打开，这样请求就无法到达下游。\n\n断路器肯定不能永远关闭，在一定时间后，可以试探性的打开，让一个流量过去试试下游服务是否正常，如果正常，关闭断路器，让下游提供服务；如果不正常，打开断路器，不让请求过去。\n\n\n\n\n# 3. Sentinel 简介\n\n花点时间吹吹 Sentinel 的牛逼。\n\n> 官网 ：https://sentinelguard.io/zh-cn/\n\nSentinel 是以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。\n\nSentinel 的特征：\n\n 1. 丰富的应用场景\n 2. 完备的实时监控\n 3. 广泛的开原生态\n 4. 完善的 SPI 扩展点\n\n\n\n\n# 4. Sentinel 安装\n\n\n# 4.1 安装配置\n\n为了和上述 Nacos、Ribbon、OpenFeign 集成，Sentinel使用1.8.1版本。\n\nSPRING CLOUD ALIBABA VERSION   SENTINEL   NACOS   ROCKETMQ   SEATA\n2.2.7.RELEASE                  1.8.1      2.0.3   4.6.1      1.3.0\n\n点击下载 ：https://github.com/alibaba/Sentinel/releases/download/1.8.1/sentinel-dashboard-1.8.1.jar\n\n可以看到，下载的是一个 jar 包，使用Java运行的，它其实是一个 SpringBoot 项目。我们可以指定用户名、密码...\n\n但是在此处就用默认的。官网有指定运行端口、用户名、密码的命令。\n\n在cmd命令行中输入以下命令启动 Sentinel\n\n## java的版本得是 1.8 哦\njava -jar sentinel-dashboard-1.8.1.jar\n\n\n运行后访问 http://localhost:8080 即可打开 Sentinel 控制台。用户名、密码都为 sentinel\n\n\n\n登陆进去之后啥也没有，因为它是触发式的，等会发个请求就有了。\n\n继续使用上文中的 cloud-orders、cloud-goods，\n\n给它俩都加上 sentinel 依赖：\n\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>\n</dependency>\n\n\n配置 Sentinel dashboard 地址\n\ncloud-goods ：\n\nserver:\n  port: 9001\nspring:\n  application:\n    name: cloud-goods\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n        username: nacos\n        password: nacos\n        namespace: dev\n    sentinel:\n      transport:\n        dashboard: localhost:8080\n\n\ncloud-orders：\n\nserver:\n  port: 9002\n\nspring:\n  # 使用测试环境的配置文件，当然也可以不使用\n  profiles:\n    active: test\n  application:\n    name: cloud-orders\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n        username: nacos\n        password: nacos\n        namespace: dev\n    sentinel:\n      transport:\n        dashboard: localhost:8080\n\n\n启动项目后，访问之前写的两个接口：\n\nhttp://localhost:9001/goods/findById/1\nhttp://localhost:9002/order/save\n\n\n打开 Sentinel 控制台，就可以看到这两个服务:\n\n\n\n\n# 4.2 实时监控\n\n这个没啥好说的，在这里可以查看经过服务的所有请求，会以折线图以及表格的形式展现出来：\n\n\n\n\n# 4.3 簇点链路\n\n> 簇点链路 ：假如一个请求的访问路径为 ：A -> B 。那么称 A -> B 为一个链路。\n\n\n\n在簇点链路中可以添加流控规则，点击添加即可。\n\n\n\n当我们要给一个资源进行流量控制时，会发现有这些选项（打开高级选项后）\n\n\n# 5. Sentinel 流量控制\n\n\n# 5.1 基于 QPS 的流量控制\n\n这个非常好理解，QPS ：一个接口每秒的访问数量。\n\n如果将 /goods/gindById/{id} 这个资源的 QPS 设置为2，也就是 1s 最多访问两次，多了就限流不让访问。\n\n\n\n\n# 5.2 基于线程数的流量控制\n\n给某个接口分配线程，这个接口最多只有两个线程同时处理，能处理多少完全看性能。\n\n\n\n线程隔离的实现方式有两种：\n\n 1. 线程池隔离\n    \n    支持主动超时，支持异步调用。\n    \n    线程的开销大。\n\n 2. 信号量隔离 （Sentinel 默认采用）\n    \n    轻量，无额外开销\n    \n    不支持主动超时不支持异步调用\n\n\n\n\n# 5.3 流控模式\n\n流控模式一共有三个值：\n\n 1. 直接 ：对于资源名直接限流，达到阈值后限流资源名。这种限流简单直接。\n\n 2. 关联 ：两个资源进行关联，直接资源的 QPS 达到阈值后，限流关联资源。\n    \n    一般适用于两个有竞争关系的资源，并且关联资源的优先级低于直接资源。\n    \n    \n\n 3. 链路 ：两个资源是一个链路，A 调用 B，如果 B 达到阈值，限流 A 和 B。\n    \n    适用于调用链，如果下游服务达到阈值，上游也进行限流。\n    \n    \n\n\n# 5.4 流控效果\n\n达到流控阈值后的效果。有三种模式：\n\n 1. 快速失败\n    \n    不挣扎，一旦达到阈值，直接返回失败信息\n\n 2. Warm Up\n    \n    预热（冷启动）方式。\n    \n    当系统长期处于低水位流量的情况下，但流量突然增加时，可能会将系统拉升到高水位，瞬间把系统压垮。通过预热方式，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。默认以 QPS / 3为阈值，经过一段时间后，阈值慢慢上升到 QPS。\n    \n    \n\n 3. 排队等待\n    \n    匀速排队，严格控制请求通过的间隔时间，让请求匀速通过，对应的是漏桶算法。详细文档可以参考 流量控制 - 匀速器模式，具体的例子可以参见 PaceFlowDemoopen。\n    \n    这种模式主要用于处理间隔性突发的流量。\n    \n    \n\n\n# 5.5 热点限流\n\nSentinel 也可以对热点 key 做限流。热点即经常访问的数据，热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式对包含热点参数的请求进行限制。\n\n还是使用 http://localhost:9001/findById/{id} 做例子，如果我对 id 为 13 的商品做了秒杀活动，为了防止它太过火爆，就可以使用 Sentinel 对 http://localhost:9001/findById/13 的请求做限流，对于其他id商品的查询，我不管。\n\n\n\n需要注意的就是三个参数：参数索引、单机阈值、统计时长。\n\n这样会对所有 id 做限制，不管你是什么 id，3s内的流量必须在10以内。\n\n但是如果我想给 id=20 的参数做一个例外呢？别的 id 是 3秒内10次，我想让 id=20 3秒内66次呢？\n\n再添加后再点击编辑，就可以在 “高级选项” 中添加例外项。\n\n\n\n> 需要注意的是，热点限流的例外项不能再改变统计窗口时长，所以平时写的时候最好写成 1s ，就可以直接按照 QPS 算了。\n\n\n# 5.6 来源限流\n\n针对来源限流\n\n\n\n对于 cloud-goods 中的 /goods/findById，只要是来自 cloud-orders 的请求，每秒只能有一个。\n\n但是这种限流不要大量使用，由于需要为每个资源的调用来源做统计，大量使用会占用很多内存。官方也给出了提示。\n\n\n# 6. Sentinel 熔断降级\n\n除了流量控制外，对调用链路中不稳定的资源进行熔断降级也是保障高可用的重要措施之一。\n\n> 熔断跟限流有什么区别？\n> \n> 限流是预防流量太大导致服务不可用。\n> \n> 熔断是万一有服务因为各种原因宕机，保护整个链路还可以提供服务。\n\n一个服务经常会调用其他模块，可能是另外一个服务、数据库、三方API等。万一被调用服务出错或相应太慢，整条链路就会无法响应，但是熔断可以保证当调用方无法调用服务时，使用一个默认值，保护调用方正常提供服务。\n\n简而言之，熔断是对调用方的保护。\n\n熔断降级的原理是断路器，也就是上述的物理电路的开关。\n\n\n\n 1. 一开始是正常请求，直到达到熔断阈值，断路器打开，服务形成断路，服务开始熔断。\n 2. 熔断时间结束后，尝试放心一次请求。如果失败，继续进行熔断。如果成功，关闭断路器，服务结束熔断。\n\n\n# 6.1 OpenFeign 整合 Sentinel\n\nSentinel 是对调用者的保护，那我们肯定要在调用者出编写代码，同时，OpenFeign 提供了对 Sentinel 的集成，所以只需要在编写代码的时候按照步骤来，就可以实现 Sentinel 的熔断降级。\n\ncloud-orders 调用了 cloud-goods 的服务，那么 cloud-orders 就是调用方，我们想要保护它。\n\n 1. cloud-orders 添加配置：\n    \n    server:\n      port: 9002\n    spring:\n      application:\n        name: cloud-orders\n      cloud:\n        nacos:\n          discovery:\n            server-addr: localhost:8848\n            username: nacos\n            password: nacos\n            namespace: dev\n        sentinel:\n          transport:\n            dashboard: localhost:8080\n    feign:\n      sentinel:\n        enabled: true\n    \n\n 2. 编写触发熔断后的逻辑：\n    \n    有两种方案：FallbackClass、FallbackFactory，由于 FallbackClass 无法对远程调用的异常做出处理，所以我们使用 实现FallbackFactory的方式。注意，这个实现类要注入容器。\n    \n    @Slf4j\n    @Component\n    public class GoodsAPIClientFallbackFactory implements FallbackFactory<GoodsAPI> {\n        @Override\n        public GoodsAPI create(Throwable throwable) {\n            // 当熔断降级被触发时执行这个方法，我们在此处返回给前端一个默认值或者友好的报错\n            return new GoodsAPI() {\n                @Override\n                public Goods findById(String id) {\n                    log.error("远程调用 findById 错误，message : {}, id: {}", throwable.getMessage(), id);\n                    return new Goods();\n                }\n            };\n        }\n    }\n    \n\n 3. 在对应的 远程调用接口上指定上述熔断降级处理类。\n    \n    @FeignClient(name = "cloud-goods", fallbackFactory = GoodsAPIClientFallbackFactory.class)\n    @RequestMapping("/goods") // 路径\n    public interface GoodsAPI {\n        @RequestMapping("/findById/{id}")\n        public Goods findById(@PathVariable("id") String id);\n    }\n    \n\n现在我们已经确认好 万一 cloud-goods 达到了熔断条件，cloud-orders 该如何处理了，但是这个“熔断条件” 该如何指定呢？肯定是通过 Sentinel 客户端啊~\n\nSentinel 熔断降级策略有三种：\n\n 1. 慢调用比例\n 2. 异常比例\n 3. 异常数量\n\n\n# 6.2 熔断降级\n\n\n\n * 资源名 ：添加熔断降级的资源\n * 最大RT ：RT（return time），最大响应时间。\n * 比例阈值 ：取值为 0 到 1 之间的小数。\n * 熔断时长 ：单次处于熔断的时间\n * 最小请求数 ：熔断触发的最小请求数，请求书小于该值时，即使达到了熔断策略规定值也不触发熔断。\n * 统计时长 ：一般为 1s、1min\n * 熔断策略 ：使用什么样的熔断策略，达到该策略就触发熔断。\n   * 慢调用比例 ：响应时间超过最大RT的称为慢调用。\n   * 异常比例 ：异常请求 / 全部请求 的比例。\n   * 异常数 ：异常数量。\n\n举个例子：\n\n\n\n熔断策略为慢调用，在 1000ms，也就是 1s 内，如果请求数量大于5，并且全部慢调用（全部请求所消耗时间都超过 200ms），达到熔断比例阈值，触发熔断，熔断 5s 。5s 后尝试发送一次请求，根据请求结果来决定是否关闭熔断。',normalizedContent:'# 1. 服务雪崩效应\n\n在微服务各个模块之间经常互相调用，假如一个调用链为 ：c/d -> b -> a\n\n\n\n一开始 a 是正常的，随着时间的推移，a 出现了不可名状的bug，导致 b 调用 a 失败，进而导致 c 和 d 也失败，最后，由于 a 出现的错误，c -> b -> a 和 d -> b -> a 这两条调用链都无法使用，这就叫做雪崩。\n\n还有这种情况：\n\n服务 a 调用 b 正常，但是调用 c 阻塞，时间长了，阻塞在 a 处的线程就变得多了，会将 a 的资源耗尽导致 a 不可用。\n\n还有种情况：请求，也就是流量太大了，服务无法承受，导致请求服务器宕机。\n\n\n# 2. 应对服务雪崩\n\n\n# 2.1 限流\n\n经过测试，发现某个请求能够承受的最大 qps（每秒流量数） 是 1000，那我们就把这个请求的 qps 阈值设置为800，超过了这个阈值，请求直接返回被限流的错误，或者返回其他提示信息、广告、商品...\n\n\n# 2.2 舱壁模式\n\n舱壁模式借鉴于现实生活中的船舱结构，如果一条船没有将船体隔开，一旦漏水整条船就会沉。如果将船体分为多个舱壁，一个地方漏水，船不至于直接沉。\n\n\n\n我们可以记录使用线程池负责各个业务的远程调用，a 调用 b 、a 调用 c，都最多占用 10 个线程，那么如果 c 宕机导致 a d调用 c 的时候阻塞，最多消耗 10 个线程的资源。\n\n\n# 2.3 断路器\n\n类似于高中物理电路图：\n\n\n\n当流量过多，或者远程调用失败过多的情况下，我们将断路器打开，这样请求就无法到达下游。\n\n断路器肯定不能永远关闭，在一定时间后，可以试探性的打开，让一个流量过去试试下游服务是否正常，如果正常，关闭断路器，让下游提供服务；如果不正常，打开断路器，不让请求过去。\n\n\n\n\n# 3. sentinel 简介\n\n花点时间吹吹 sentinel 的牛逼。\n\n> 官网 ：https://sentinelguard.io/zh-cn/\n\nsentinel 是以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。\n\nsentinel 的特征：\n\n 1. 丰富的应用场景\n 2. 完备的实时监控\n 3. 广泛的开原生态\n 4. 完善的 spi 扩展点\n\n\n\n\n# 4. sentinel 安装\n\n\n# 4.1 安装配置\n\n为了和上述 nacos、ribbon、openfeign 集成，sentinel使用1.8.1版本。\n\nspring cloud alibaba version   sentinel   nacos   rocketmq   seata\n2.2.7.release                  1.8.1      2.0.3   4.6.1      1.3.0\n\n点击下载 ：https://github.com/alibaba/sentinel/releases/download/1.8.1/sentinel-dashboard-1.8.1.jar\n\n可以看到，下载的是一个 jar 包，使用java运行的，它其实是一个 springboot 项目。我们可以指定用户名、密码...\n\n但是在此处就用默认的。官网有指定运行端口、用户名、密码的命令。\n\n在cmd命令行中输入以下命令启动 sentinel\n\n## java的版本得是 1.8 哦\njava -jar sentinel-dashboard-1.8.1.jar\n\n\n运行后访问 http://localhost:8080 即可打开 sentinel 控制台。用户名、密码都为 sentinel\n\n\n\n登陆进去之后啥也没有，因为它是触发式的，等会发个请求就有了。\n\n继续使用上文中的 cloud-orders、cloud-goods，\n\n给它俩都加上 sentinel 依赖：\n\n<dependency>\n    <groupid>com.alibaba.cloud</groupid>\n    <artifactid>spring-cloud-starter-alibaba-sentinel</artifactid>\n</dependency>\n\n\n配置 sentinel dashboard 地址\n\ncloud-goods ：\n\nserver:\n  port: 9001\nspring:\n  application:\n    name: cloud-goods\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n        username: nacos\n        password: nacos\n        namespace: dev\n    sentinel:\n      transport:\n        dashboard: localhost:8080\n\n\ncloud-orders：\n\nserver:\n  port: 9002\n\nspring:\n  # 使用测试环境的配置文件，当然也可以不使用\n  profiles:\n    active: test\n  application:\n    name: cloud-orders\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n        username: nacos\n        password: nacos\n        namespace: dev\n    sentinel:\n      transport:\n        dashboard: localhost:8080\n\n\n启动项目后，访问之前写的两个接口：\n\nhttp://localhost:9001/goods/findbyid/1\nhttp://localhost:9002/order/save\n\n\n打开 sentinel 控制台，就可以看到这两个服务:\n\n\n\n\n# 4.2 实时监控\n\n这个没啥好说的，在这里可以查看经过服务的所有请求，会以折线图以及表格的形式展现出来：\n\n\n\n\n# 4.3 簇点链路\n\n> 簇点链路 ：假如一个请求的访问路径为 ：a -> b 。那么称 a -> b 为一个链路。\n\n\n\n在簇点链路中可以添加流控规则，点击添加即可。\n\n\n\n当我们要给一个资源进行流量控制时，会发现有这些选项（打开高级选项后）\n\n\n# 5. sentinel 流量控制\n\n\n# 5.1 基于 qps 的流量控制\n\n这个非常好理解，qps ：一个接口每秒的访问数量。\n\n如果将 /goods/gindbyid/{id} 这个资源的 qps 设置为2，也就是 1s 最多访问两次，多了就限流不让访问。\n\n\n\n\n# 5.2 基于线程数的流量控制\n\n给某个接口分配线程，这个接口最多只有两个线程同时处理，能处理多少完全看性能。\n\n\n\n线程隔离的实现方式有两种：\n\n 1. 线程池隔离\n    \n    支持主动超时，支持异步调用。\n    \n    线程的开销大。\n\n 2. 信号量隔离 （sentinel 默认采用）\n    \n    轻量，无额外开销\n    \n    不支持主动超时不支持异步调用\n\n\n\n\n# 5.3 流控模式\n\n流控模式一共有三个值：\n\n 1. 直接 ：对于资源名直接限流，达到阈值后限流资源名。这种限流简单直接。\n\n 2. 关联 ：两个资源进行关联，直接资源的 qps 达到阈值后，限流关联资源。\n    \n    一般适用于两个有竞争关系的资源，并且关联资源的优先级低于直接资源。\n    \n    \n\n 3. 链路 ：两个资源是一个链路，a 调用 b，如果 b 达到阈值，限流 a 和 b。\n    \n    适用于调用链，如果下游服务达到阈值，上游也进行限流。\n    \n    \n\n\n# 5.4 流控效果\n\n达到流控阈值后的效果。有三种模式：\n\n 1. 快速失败\n    \n    不挣扎，一旦达到阈值，直接返回失败信息\n\n 2. warm up\n    \n    预热（冷启动）方式。\n    \n    当系统长期处于低水位流量的情况下，但流量突然增加时，可能会将系统拉升到高水位，瞬间把系统压垮。通过预热方式，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。默认以 qps / 3为阈值，经过一段时间后，阈值慢慢上升到 qps。\n    \n    \n\n 3. 排队等待\n    \n    匀速排队，严格控制请求通过的间隔时间，让请求匀速通过，对应的是漏桶算法。详细文档可以参考 流量控制 - 匀速器模式，具体的例子可以参见 paceflowdemoopen。\n    \n    这种模式主要用于处理间隔性突发的流量。\n    \n    \n\n\n# 5.5 热点限流\n\nsentinel 也可以对热点 key 做限流。热点即经常访问的数据，热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式对包含热点参数的请求进行限制。\n\n还是使用 http://localhost:9001/findbyid/{id} 做例子，如果我对 id 为 13 的商品做了秒杀活动，为了防止它太过火爆，就可以使用 sentinel 对 http://localhost:9001/findbyid/13 的请求做限流，对于其他id商品的查询，我不管。\n\n\n\n需要注意的就是三个参数：参数索引、单机阈值、统计时长。\n\n这样会对所有 id 做限制，不管你是什么 id，3s内的流量必须在10以内。\n\n但是如果我想给 id=20 的参数做一个例外呢？别的 id 是 3秒内10次，我想让 id=20 3秒内66次呢？\n\n再添加后再点击编辑，就可以在 “高级选项” 中添加例外项。\n\n\n\n> 需要注意的是，热点限流的例外项不能再改变统计窗口时长，所以平时写的时候最好写成 1s ，就可以直接按照 qps 算了。\n\n\n# 5.6 来源限流\n\n针对来源限流\n\n\n\n对于 cloud-goods 中的 /goods/findbyid，只要是来自 cloud-orders 的请求，每秒只能有一个。\n\n但是这种限流不要大量使用，由于需要为每个资源的调用来源做统计，大量使用会占用很多内存。官方也给出了提示。\n\n\n# 6. sentinel 熔断降级\n\n除了流量控制外，对调用链路中不稳定的资源进行熔断降级也是保障高可用的重要措施之一。\n\n> 熔断跟限流有什么区别？\n> \n> 限流是预防流量太大导致服务不可用。\n> \n> 熔断是万一有服务因为各种原因宕机，保护整个链路还可以提供服务。\n\n一个服务经常会调用其他模块，可能是另外一个服务、数据库、三方api等。万一被调用服务出错或相应太慢，整条链路就会无法响应，但是熔断可以保证当调用方无法调用服务时，使用一个默认值，保护调用方正常提供服务。\n\n简而言之，熔断是对调用方的保护。\n\n熔断降级的原理是断路器，也就是上述的物理电路的开关。\n\n\n\n 1. 一开始是正常请求，直到达到熔断阈值，断路器打开，服务形成断路，服务开始熔断。\n 2. 熔断时间结束后，尝试放心一次请求。如果失败，继续进行熔断。如果成功，关闭断路器，服务结束熔断。\n\n\n# 6.1 openfeign 整合 sentinel\n\nsentinel 是对调用者的保护，那我们肯定要在调用者出编写代码，同时，openfeign 提供了对 sentinel 的集成，所以只需要在编写代码的时候按照步骤来，就可以实现 sentinel 的熔断降级。\n\ncloud-orders 调用了 cloud-goods 的服务，那么 cloud-orders 就是调用方，我们想要保护它。\n\n 1. cloud-orders 添加配置：\n    \n    server:\n      port: 9002\n    spring:\n      application:\n        name: cloud-orders\n      cloud:\n        nacos:\n          discovery:\n            server-addr: localhost:8848\n            username: nacos\n            password: nacos\n            namespace: dev\n        sentinel:\n          transport:\n            dashboard: localhost:8080\n    feign:\n      sentinel:\n        enabled: true\n    \n\n 2. 编写触发熔断后的逻辑：\n    \n    有两种方案：fallbackclass、fallbackfactory，由于 fallbackclass 无法对远程调用的异常做出处理，所以我们使用 实现fallbackfactory的方式。注意，这个实现类要注入容器。\n    \n    @slf4j\n    @component\n    public class goodsapiclientfallbackfactory implements fallbackfactory<goodsapi> {\n        @override\n        public goodsapi create(throwable throwable) {\n            // 当熔断降级被触发时执行这个方法，我们在此处返回给前端一个默认值或者友好的报错\n            return new goodsapi() {\n                @override\n                public goods findbyid(string id) {\n                    log.error("远程调用 findbyid 错误，message : {}, id: {}", throwable.getmessage(), id);\n                    return new goods();\n                }\n            };\n        }\n    }\n    \n\n 3. 在对应的 远程调用接口上指定上述熔断降级处理类。\n    \n    @feignclient(name = "cloud-goods", fallbackfactory = goodsapiclientfallbackfactory.class)\n    @requestmapping("/goods") // 路径\n    public interface goodsapi {\n        @requestmapping("/findbyid/{id}")\n        public goods findbyid(@pathvariable("id") string id);\n    }\n    \n\n现在我们已经确认好 万一 cloud-goods 达到了熔断条件，cloud-orders 该如何处理了，但是这个“熔断条件” 该如何指定呢？肯定是通过 sentinel 客户端啊~\n\nsentinel 熔断降级策略有三种：\n\n 1. 慢调用比例\n 2. 异常比例\n 3. 异常数量\n\n\n# 6.2 熔断降级\n\n\n\n * 资源名 ：添加熔断降级的资源\n * 最大rt ：rt（return time），最大响应时间。\n * 比例阈值 ：取值为 0 到 1 之间的小数。\n * 熔断时长 ：单次处于熔断的时间\n * 最小请求数 ：熔断触发的最小请求数，请求书小于该值时，即使达到了熔断策略规定值也不触发熔断。\n * 统计时长 ：一般为 1s、1min\n * 熔断策略 ：使用什么样的熔断策略，达到该策略就触发熔断。\n   * 慢调用比例 ：响应时间超过最大rt的称为慢调用。\n   * 异常比例 ：异常请求 / 全部请求 的比例。\n   * 异常数 ：异常数量。\n\n举个例子：\n\n\n\n熔断策略为慢调用，在 1000ms，也就是 1s 内，如果请求数量大于5，并且全部慢调用（全部请求所消耗时间都超过 200ms），达到熔断比例阈值，触发熔断，熔断 5s 。5s 后尝试发送一次请求，根据请求结果来决定是否关闭熔断。',charsets:{cjk:!0},lastUpdated:"2023/10/30, 14:49:23",lastUpdatedTimestamp:1698648563e3},{title:"1. Sentinel中的一些概念与核心类解析",frontmatter:{title:"1. Sentinel中的一些概念与核心类解析",date:"2023-11-29T16:08:05.000Z",permalink:"/pages/3d8a71/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/60.Sentinel/3.%20Sentinel%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5.html",relativePath:"02.文章/91.框架/60.Sentinel/3. Sentinel中的一些概念.md",key:"v-fa2c9a0c",path:"/pages/3d8a71/",headers:[{level:2,title:"1. 资源 ResourceWrapper",slug:"_1-资源-resourcewrapper",normalizedTitle:"1. 资源 resourcewrapper",charIndex:2},{level:2,title:"2. 节点 Node",slug:"_2-节点-node",normalizedTitle:"2. 节点 node",charIndex:1108},{level:3,title:"2.1 统计节点 ：StatisticNode",slug:"_2-1-统计节点-statisticnode",normalizedTitle:"2.1 统计节点 ：statisticnode",charIndex:3038},{level:3,title:"2.2 普通节点 ：DefaultNode",slug:"_2-2-普通节点-defaultnode",normalizedTitle:"2.2 普通节点 ：defaultnode",charIndex:4148},{level:3,title:"2.3 入口节点 ：EntranceNode",slug:"_2-3-入口节点-entrancenode",normalizedTitle:"2.3 入口节点 ：entrancenode",charIndex:6021},{level:3,title:"2.4 全局节点 ：ClusterNode",slug:"_2-4-全局节点-clusternode",normalizedTitle:"2.4 全局节点 ：clusternode",charIndex:6521},{level:2,title:"3. 根节点 Constants.ROOT",slug:"_3-根节点-constants-root",normalizedTitle:"3. 根节点 constants.root",charIndex:8175},{level:2,title:"4. Entry",slug:"_4-entry",normalizedTitle:"4. entry",charIndex:9275},{level:2,title:"5. 上下文 Context",slug:"_5-上下文-context",normalizedTitle:"5. 上下文 context",charIndex:12323},{level:3,title:"5.1 Context 的创建",slug:"_5-1-context-的创建",normalizedTitle:"5.1 context 的创建",charIndex:13674},{level:2,title:"6. 插槽 ProcessorSlot",slug:"_6-插槽-processorslot",normalizedTitle:"6. 插槽 processorslot",charIndex:18477}],headersStr:"1. 资源 ResourceWrapper 2. 节点 Node 2.1 统计节点 ：StatisticNode 2.2 普通节点 ：DefaultNode 2.3 入口节点 ：EntranceNode 2.4 全局节点 ：ClusterNode 3. 根节点 Constants.ROOT 4. Entry 5. 上下文 Context 5.1 Context 的创建 6. 插槽 ProcessorSlot",content:'# 1. 资源 ResourceWrapper\n\n想要做限流、熔断，目标是谁？肯定是资源。资源可以是一个方法、一段代码、一个接口...\n\nSentinel 统计的数据以资源为维度，资源使用 ResourceWrapper 表示\n\npublic abstract class ResourceWrapper {\n\t// 资源名\n    protected final String name;\n\t// 节点类型，进入或流出\n    protected final EntryType entryType;\n    // 资源类型，比如MVC、Dubbo、grpc..\n    protected final int resourceType;\n}\n\n\n * name ：资源名\n * entryType ：此资源表示的节点的类型，即流入流量还是流出流量，通俗一点说就是发起请求还是接收请求。\n * resourceType ：资源类型，Sentinel 集成了很多框架，不同的资源之间还会相互调用，所以要分清楚。\n\nEntryType 是一个枚举类 ：\n\npublic enum EntryType {\n    IN("IN"),\n    OUT("OUT");\n}\n\n\nSentinel1.8.1 支持的 resourceType 有以下几种 ：\n\npublic final class ResourceTypeConstants {\n\n    public static final int COMMON = 0;\n    public static final int COMMON_WEB = 1;\n    public static final int COMMON_RPC = 2;\n    public static final int COMMON_API_GATEWAY = 3;\n    public static final int COMMON_DB_SQL = 4;\n\n    private ResourceTypeConstants() {}\n}\n\n\n * COMMON ：不集成任何框架\n * COMMON_WEB ：集成web应用的接口\n * COMMON_RPC ：rpc接口\n * COMMON_API_GATEWAY ：用于 API GateWay 网关\n * COMMON_DB_SQL ：数据库SQL操作\n\n综上所述，Sentinel 中的资源可能的类型有\n\n * 进入程序的web请求\n * 程序发出的rpc请求\n * 程序发出的sql操作\n * .......\n\n\n# 2. 节点 Node\n\nSentinel 中的每一个资源都可以成为一个 Node，至于成为哪一个 Node 要看使用情况。\n\nNode 作为 Sentinel 中持有实时统计数据的接口，它定义了一个节点所需要提供的各项指标数据统计功能，为外部屏蔽统计数据的实现。\n\npublic interface Node extends OccupySupport, DebugSupport {\n    long totalRequest(); // 获取总的请求数\n    long totalPass(); // 获取通过的请求总数\n    long totalSuccess(); // 获取成功的请求总数\n    long blockRequest(); // 获取被 Sentinel 拒绝的请求总数\n    long totalException(); // 获取异常总数\n    double passQps(); // 通过 QPS\n    double blockQps(); // 拒绝 QPS\n    double totalQps(); // 总 qps\n    double successQps(); // 成功 qps\n    // 最大成功总数 QPS（例如秒级滑动窗口的数组大小默认配置为 2，则取数组中最大）\n    double maxSuccessQps(); \n    double exceptionQps(); // 异常 QPS\n    double avgRt(); // 平均耗时\n    double minRt(); // 最小耗时\n    int curThreadNum(); // 当前并发占用的线程数\n    double previousBlockQps(); // 前一个时间窗口的被拒绝 qps\n    double previousPassQps(); // 前一个时间窗口的通过 qps\n    Map<Long, MetricNode> metrics(); \n    List<MetricNode> rawMetricsInMin(Predicate<Long> timePredicate);\n    void addPassRequest(int count); // 添加通过请求数\n    void addRtAndSuccess(long rt, int success); // 添加成功请求数，并且添加处理成功的耗时\n    void increaseBlockQps(int count); // 添加被拒绝的请求数\n    void increaseExceptionQps(int count); // 添加异常请求数\n    void increaseThreadNum(); // 自增占用线程\n    void decreaseThreadNum(); // 自减占用线程\n    void reset(); // 重置滑动窗口\n}\n\n\n为啥 Node 是一个接口而不是实现类？因为要将 Sentinel 中的 “节点” 按照类型区分开。\n\n比如有三个资源 ：a、b、c\n\n这三个资源有以下调用链 ：\n\na -> b -> c\n\nb -> c -> a\n\na -> b -> a\n\n在三个调用链中，同一个节点充当了不同的角色，比如第三个调用链中，a 既是入口节点也是普通节点。\n\n我们给它起名 ：入口a、普通a\n\n同时如果要统计 “a” 这个资源的总访问量怎么办？难道要将全部的入口a、普通a 一个一个遍历相加？\n\n不，创建一个全局 a ，流量进入 入口a、普通a时将不仅将对应的节点流量加一，还将全局a的数据也加一\n\n现在有了三种节点，它们都是 Node 的子类：\n\n * 入口节点 EntranceNode\n * 普通节点 DefaultNode\n * 全局节点 ClusterNode\n\nSentinel 将这三种节点的共同属性 ：统计数据功能 抽取出来作为它们三个的父类 ：StatisticNode。关系图如下：\n\n\n\n * Node ：抽象类，提供规范\n * StatisticNode ：提供了统计数据的功能。\n * DefaultNode ：普通节点\n * EntranceNode ：入口节点\n * ClusterNode ：全局节点，一个资源只能有一个全局节点。\n\n一个资源可能有多个入口节点或普通节点，但是只能有一个全局节点。ClusterNode 与 DefaultNode 的关系是一对多。\n\n接下来详细介绍各种类型的 Node\n\n\n# 2.1 统计节点 ：StatisticNode\n\npublic class StatisticNode implements Node {\n    // 秒级滑动窗口，2 个时间窗口大小为 500 毫秒的 Bucket\n    private transient volatile Metric rollingCounterInSecond = new ArrayMetric(2,1000);\n    // 分钟级滑动窗口，60 个 Bucket 数组，每个 Bucket 统计的时间窗口大小为 1 秒\n    private transient Metric rollingCounterInMinute = new ArrayMetric(60, 60 * 1000, false);\n    \n    // 统计并发使用的线程数，可以根据线程数限流。\n    private LongAdder curThreadNum = new LongAdder();\n    \n    // 实现了从 Node 继承过来的其他统计方法，这里列举几个简单的\n    \n    // 一分钟内成功放心的全部请求数量\n    @Override\n    public long totalPass() {\n        return rollingCounterInMinute.pass();\n    }\n    \n    // 成功放行了一个请求，加上。\n    @Override\n    public void addPassRequest(int count) {\n        rollingCounterInSecond.addPass(count);\n        rollingCounterInMinute.addPass(count);\n    }\n\n    // 。。。。。。其他的就不放了，StatisticNode实现了Node的所有抽象方法。\n}\n\n\n在一般情况下，Sentinel 使用滑动窗口算法统计经过每一个 Node 的资源。滑动窗口算法会在以后的文章介绍到。\n\n通过实现 Node 规定的方法，StatisticNode 提供了统计秒级、分钟级成功请求数、失败请求数等等功能。\n\n当然了，现在不会这些很正常，你只需要知道：StatisticNode 可以统计流量，所有继承它的 Node ，也就是 ClusterNode、DefaultNode、EntranceNode 也都可以统计流量。\n\n注意 ：StatisticNode 只提供统计数据的功能，它不表示任何资源。\n\n\n# 2.2 普通节点 ：DefaultNode\n\npublic class DefaultNode extends StatisticNode {\n\n    // 这个节点表示的资源\n    private ResourceWrapper id;\n\n    // 这个节点的全部子节点\n    private volatile Set<Node> childList = new HashSet<>();\n\t\n    // 该节点对应的 ClusterNode\n    private ClusterNode clusterNode;\n\n\n    @Override\n    public void increaseBlockQps(int count) {\n        super.increaseBlockQps(count);\n        this.clusterNode.increaseBlockQps(count);\n    }\n\n    @Override\n    public void increaseExceptionQps(int count) {\n        super.increaseExceptionQps(count);\n        this.clusterNode.increaseExceptionQps(count);\n    }\n\n    @Override\n    public void addRtAndSuccess(long rt, int successCount) {\n        super.addRtAndSuccess(rt, successCount);\n        this.clusterNode.addRtAndSuccess(rt, successCount);\n    }\n\n    @Override\n    public void increaseThreadNum() {\n        super.increaseThreadNum();\n        this.clusterNode.increaseThreadNum();\n    }\n\n    @Override\n    public void decreaseThreadNum() {\n        super.decreaseThreadNum();\n        this.clusterNode.decreaseThreadNum();\n    }\n\n    @Override\n    public void addPassRequest(int count) {\n        super.addPassRequest(count);\n        this.clusterNode.addPassRequest(count);\n    }\n\n    public void printDefaultNode() {\n        visitTree(0, this);\n    }\n}\n\n\n * id ：这个节点表示的资源。\n * childList ：这个节点的全部子节点\n * clusterNode ：该节点对应的 ClusterNode。\n\n资源与 DefaultNode 之间是一对多的关系。资源与ClusterNode之间是一对一的关系。\n\n一个 DefaultNode 可以有多个子节点形成如下的结构 ：\n\n（其实最顶端的 A 不是 DefaultNode，这里只是做一个比喻）\n\n\n\n多个 DefaultNode 就形成了一棵树\n\n注 ：了解 Sentinel 的就能看出来这颗树还有很多缺陷，但是现在只是做一个比喻。\n\n同时，通过源码你可能看出来了，DefaultNode 在执行放行请求方法时如下：\n\n@Override\npublic void addRtAndSuccess(long rt, int successCount) {\n    super.addRtAndSuccess(rt, successCount);\n    this.clusterNode.addRtAndSuccess(rt, successCount);\n}\n\n\n先给自己的数据记录一下，再给自己所属的 ClusterNode 记录一下，跟咱们之前说的一样。\n\n再次提醒 ：所有节点统计数据时都要使用从 StatisticNode 继承过来的方法。\n\n\n# 2.3 入口节点 ：EntranceNode\n\n入口节点没有变量，功能被 StatisticNode 实现了，变量被 DefaultNode 拥有了，EntranceNode 就特别简洁了：\n\npublic class EntranceNode extends DefaultNode {\n\n    public EntranceNode(ResourceWrapper id, ClusterNode clusterNode) {\n        super(id, clusterNode);\n    }\n}\n\n\nEntranceNode 与 DefaultNode 的区别是重写 StatisticNode 的方法不一样。\n\n在这里可以剧透一下 ：EntranceNode 都是已经规定好的节点，命名方式根据集成的框架变化。比如\n\n * 不集成任何框架时，EntranceNode.name = "sentinel_default_context"\n * 集成Spring MVC 时，EntranceNode.name = "sentinel_spring_web_context"\n\n\n# 2.4 全局节点 ：ClusterNode\n\npublic class ClusterNode extends StatisticNode {\n\t// 节点名，即资源名，其实应该使用 ResourceWrapper的，不知道这里为啥用了String\n    private final String name;\n    // 资源类型\n    private final int resourceType;\n\n    // 维护每个调用来源的指标数据统计数据（StatisticNode）\n    // 在 ClusterNode 部分会具体说。\n    private Map<String, StatisticNode> originCountMap = new HashMap<>();\n    \n\t// 控制并发修改 originCountMap 用的锁\n    private final ReentrantLock lock = new ReentrantLock();\n}\n\n\n * name ：资源名，其实应该使用 ResourceWrapper的，不知道这里为啥用了String\n * resourceType ：资源类型\n * originCountMap ： 维护每个调用来源的指标数据统计数据（StatisticNode）\n * lock ：控制并发修改 originCountMap 用的锁\n\n其实它还有一个方法用来操作 originCountMap ：\n\npublic Node getOrCreateOriginNode(String origin) {\n    StatisticNode statisticNode = originCountMap.get(origin);\n    if (statisticNode == null) {\n        lock.lock();\n        try {\n            statisticNode = originCountMap.get(origin);\n            if (statisticNode == null) {\n                statisticNode = new StatisticNode();\n                HashMap<String, StatisticNode> newMap = new HashMap<>(originCountMap.size() + 1);\n                newMap.putAll(originCountMap);\n                newMap.put(origin, statisticNode);\n                originCountMap = newMap;\n            }\n        } finally {\n            lock.unlock();\n        }\n    }\n    return statisticNode;\n}\n\n\n具体是啥意思呢，请看这个图：\n\n\n\nspringmvc 框架中的 /hello1 通过 grpc 远程调用了 /hello2，那么在统计 /hello2 时是不是要标清楚 origin 是 hello1？\n\n所以就通过 origin 创建一个 hello1 节点，放在 hello2 的 ClusterNode 的 Map 中，注意，放入的节点类型为 StatisticNode，也就说明这个节点没有实际意义，只负责统计一下流量，方便做“来源限流、关联限流”。\n\n当用户要做 /hello1->/hello2 的来源限流时，将 hello2 的流量取出来，再将 hello2对应的 ClusterNode 中统计的 hello1 的数据取出来就可以判断是否限流了。\n\n\n# 3. 根节点 Constants.ROOT\n\n其实整个程序的 入口节点是固定的，它存放在常量类 Constants 中。\n\npublic final class Constants {\n    // 默认context的名称\n    public final static String CONTEXT_DEFAULT_NAME = "sentinel_default_context";\n    \n    // 根节点\n    public final static DefaultNode ROOT = new EntranceNode(\n        new StringResourceWrapper(ROOT_ID, EntryType.IN),\n        new ClusterNode(ROOT_ID, ResourceTypeConstants.COMMON)\n    );\n    \n    // 根节点对应的全局节点\n    public final static ClusterNode ENTRY_NODE = new ClusterNode(\n        TOTAL_IN_RESOURCE_NAME, \n        ResourceTypeConstants.COMMON\n    );\n\n}\n\n\n根节点的第一层子节点，即 EntranceNode 也是固定的，这个在前面已经剧透了\n\n也就是说，根节点和第一层节点都是固定的。只有从第二层节点开始才是我们的。\n\n（上面我说的 “第一层” 是指ROOT节点下的第一层，后续在提到 EntranceNode 时都会有 “第一层” 代称，请不要认为我说的第一层是ROOT😁）\n\n验证一下，我们不集成任何环境，那么 ROOT 下第一个 EntranceNode 就一定是 sentinel_default_context。\n\n将 abc 当作资源的话，abc就会是 sentinel_default_context 的子节点：\n\n\n\n（使用 sentinel-demo/sentinel-demo-basic/flow/FlowQpsDemo 测试类）\n\n集成了 web mvc 时，ROOT 的子节点就有俩了：\n\n\n\n(使用 sentinel-demo/sentinel-demo-spring-webmvc/WebMvcTestController 测试类，需要自己加上 Constants.ROOT 去 debug)\n\n更新一下节点树：\n\n\n\n这样做的好处是集成其他环境时很方便，坏处就是不好理解\n\n\n# 4. Entry\n\n在认识 资源 和 节点 之后就该 Entry 了，Entry是由 节点+处理器链 组成。\n\nSentinel 提供的是限流、熔断功能，具体来说就是热点限流、系统限流、来源限流.... 这些功能通过责任链模式组成了一个处理器链，由于每一个资源都需要进行判断，每一个资源要的限流规则都有差别，所以每一个资源都要走一遍处理器链，Sentinel 使用 Entry 将 节点和处理器链 封装起来。\n\n在 Sentinel 中，处理器链也可以称为责任链。\n\n听起来是不是特别麻烦？确实，要做到每一个资源都进行限流确实特别麻烦。\n\npublic abstract class Entry implements AutoCloseable {\n    // 创建时间\n    private long createTime;\n    // 当前节点（DefaultNode）\n    private Node curNode;\n    // 来源节点\n    private Node originNode;\n    // 错误\n    private Throwable error;\n    // 资源id\n    protected ResourceWrapper resourceWrapper;\n}\n\n\nCtEntry 是 Entry 的直接子类，后面分析源码时，我们所说 Entry 皆指 CtEntry。CtEntry 中声明的字段信息如下代码所示。\n\nclass CtEntry extends Entry {\n    // 当前 Entry 指向的父 Entry\n    protected Entry parent = null;\n    // 父 Entry 指向当前 Entry\n    protected Entry child = null;\n    // 当前资源的 ProcessorSlotChain，责任链模式，也就是很多拦截器\n    protected ProcessorSlot<Object> chain;\n    // 当前上下文\n    protected Context context;\n}\n\n\n为啥 Entry 要分 parent、child 关系 ？在 Node 章节中我们介绍了，多个 DefaultNode 可以组成树，我们一次只需要统计当前一条链路的 Node，也就是一个链表，所以这个 parent 和 child 其实也可以称作 pre 和 next。\n\n> 有一个特别需要注意的点 ：入口节点，即 EntranceNode 不会被封装为 Entry。\n\nEntry 是一次调用形成的调用链上的节点。\n\n这张图描述了多个 Node 的关系\n\n\n\n现在我们将 A -> B -> F 这条调用链来画一下 Entry\n\n\n\n（多个Entry是双向链表，多个Node是树）\n\n> 这里请你分清 处理器链 和 调用链 的区别。\n> \n>  * 每一个 Entry 由 Node + 处理器链 组成\n> \n>  * 多个 Entry 组成一个调用链\n\nEntry是啥时候创建的、怎么创建的呢？所有的资源都要封装为 Entry，然后在Entry内部的处理器链中封装为Node挂在树上。\n\n调用 SphU.entry(String entryName) 即可创建 Entry。如果集成了其他框架，比如SpringMVC，可以使用AOP创建。\n\nSphU.entry(String) 最终执行的如下方法：\n\nprivate Entry entryWithPriority(ResourceWrapper resourceWrapper, \n                                int count, \n                                boolean prioritized, \n                                Object... args) throws BlockException {\n    // 获取当前上下文\n    Context context = ContextUtil.getContext();\n    if (context instanceof NullContext) {\n        return new CtEntry(resourceWrapper, null, context);\n    }\n\t// 如果 Context 为空，使用默认 Context. (即name为 sentinel_default_context 的Context)\n    if (context == null) {\n        context = InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME);\n    }\n\n    // \n    if (!Constants.ON) {\n        return new CtEntry(resourceWrapper, null, context);\n    }\n\t// 加载调用链\n    ProcessorSlot<Object> chain = lookProcessChain(resourceWrapper);\n\n    // 如果加载的责任链为空\n    if (chain == null) {\n        return new CtEntry(resourceWrapper, null, context);\n    }\n\t// 正常情况下上面的代码都不会走到，这里会真正创建一个 CtEntry.\n    Entry e = new CtEntry(resourceWrapper, chain, context, count, args);\n    try {\n        // 开始执行整个责任链\n        chain.entry(context, resourceWrapper, null, count, prioritized, args);\n    } catch (BlockException e1) {\n        e.exit(count, args);\n        throw e1;\n    } catch (Throwable e1) {\n        RecordLog.info("Sentinel unexpected exception", e1);\n    }\n    return e;\n}\n\n\n现在不知道Context没事，下面就是。其实直到 new CtEntry() 才是重点，new出Entry后直接执行 处理器链，处理器链中有很多个处理器，有统计资源的、限流的、熔断的...如果在处理器链的执行过程中出现被限流、熔断的异常，就会被这个 BlockException 捕获丢出。丢出之前肯定要将 Entry 销毁。\n\n> Entry 与 Node 的区别是啥呢？\n> \n> Node构建之后基本不会动了，除非程序重启宕机啥的。\n> \n> Entry每次请求都会构建。多个Entry就组成了一次调用链\n\n\n# 5. 上下文 Context\n\n很多框架都有一个上下文对象，Sentinel 也不例外。Sentinel 的 ContextUtil 使用 ThreadLocal 持有 Context，Context 存储的信息包括 ：\n\npublic class Context {\n    // Context的name\n    private final String name;\n    // 此次执行的入口节点，都是固定的ROOT下的第一层节点。\n    private DefaultNode entranceNode;\n    // 现在执行到哪个Entry了。\n    private Entry curEntry;\n    private String origin = "";\n    \n    // 我们不讨论异步的情况\n    // private final boolean async;\n}\n\n\n * name：Context 的名称。\n\n * entranceNode：当前调用树的入口节点，类型为 EntranceNode。这个Node比较固定，都是第一层节点。\n   \n   这个节点虽然会在 context 中，但它不会在 Entry 中，因为不参与执行，只参与统计。\n\n * curEntry：当前 Entry（CtEntry），内含当前执行的 node\n\n * origin：调用来源的名称，即服务消费者的名称或者服务消费者的来源 IP，取决于服务消费者是否使用 Sentinel，由 Sentinel 适配层传递过来。例如：服务提供者是 Spring MVC 应用，且服务提供者使用 Sentinel 的 Web MVC 适配，那么 Sentinel 会尝试从请求头获取”S-user”，如果服务消费者有在请求头传递这个参数，那么就能够获取到。\n\npublic class ContextUtil {\n    // 持有 Context\n    private static ThreadLocal<Context> contextHolder = new ThreadLocal<>();\n    // 持有所有 EntranceNode，即所有第一层Node.\n    // 可能包含的: default、mvc、okhttp、grpc、dubbo...\n    private static volatile Map<String, DefaultNode> contextNameNodeMap = new HashMap<>();\n    // 如果当前环境(mvc、dubbo、grpc) 还没有把第一层节点注册到 contextNameNodeMap，那么就加锁开始注册\n    private static final ReentrantLock LOCK = new ReentrantLock();\n}\n\n\n这里要着重说一下 contextNameNodeMap。\n\nContextUtil 会将所有第一层节点存储在 contextNameNodeMap 中，从名字也可以看出来这个Map里面存储的是以 context.name 命名的 node\n\n\n# 5.1 Context 的创建\n\n当 ContextUtil 类加载的时候会执行静态代码块，初始化一个默认的EntranceNode ：sentinel_default_context 放入 contextNameNodeMap 中。\n\nstatic {\n    // Cache the entrance node for default context.\n    initDefaultContext();\n}\n\nprivate static void initDefaultContext() {\n    String defaultContextName = Constants.CONTEXT_DEFAULT_NAME;\n    EntranceNode node = new EntranceNode(new StringResourceWrapper(defaultContextName, EntryType.IN), null);\n    // 将此入口节点挂在 ROOT 下面。\n    Constants.ROOT.addChild(node);\n    contextNameNodeMap.put(defaultContextName, node);\n}\n\n\n所以在写代码的时候 contextNameNodeMap 中就已经有了一个 EntranceNode 了。当然这是题外话了，我们要说的是 Context 的创建。虽然指定了 EntranceNode 但是并未给 EntranceNode 创建 Entry，所以 EntranceNode 不会参与执行。\n\nContextUtil.enter(String contextName) 可以创建一个 Context\n\n// 显式创建 Context\nContextUtil.enter("sentinel_default_context");\nEntry entry = null;\ntry {\n     // 创建资源对应的 entry\n     entry = SphU.entry("/user/get", EntryType.IN);\n     // 执行业务方法\n     return doBusiness();\n} catch (Exception e) {\n     if (!(e instanceof BlockException)) {\n          Tracer.trace(e);\n     }\n     throw e;\n} finally {\n     if (entry != null) {\n         // 销毁此entry, 会将 Context.curEntry改为entry.parent\n         entry.exit(1);\n     }\n     // 销毁 Context\n     ContextUtil.exit();\n}\n\n\nContext 都是由 ContextUtil 显式创建， ContextUtil.enter(String contextName) 最终执行的逻辑 ：\n\n// name : ContextName, Context的名称\n// origin : 来源，比如通过 rpc调用时，rpc服务提供者的origin就是服务调用者\nprotected static Context trueEnter(String name, String origin) {\n    // 从 ContextHolder 中取 Context，如果取不到就创建。\n    // 这里也是我们第一个看到 Sentinel 使用双重检查锁机制，后面还会有很多次。\n    Context context = contextHolder.get();\n    if (context == null) {\n        // contextNameNodeMap 是拥有第一层节点的Map\n        // 比如 sentinel_default_context - EntranceNode\n        Map<String, DefaultNode> localCacheNameMap = contextNameNodeMap;\n        \n        // 如果根据context name 无法找到第一层Node，说明当前环境(mvc、dubbo、grpc...) 还没有把第一层节点注册到 contextNameNodeMap\n    \t// 那么就加锁开始注册\n        DefaultNode node = localCacheNameMap.get(name);\n        // 第一次检查\n        if (node == null) {\n            // 如果第一层节点太多了，返回一个 NullContext\n            if (localCacheNameMap.size() > Constants.MAX_CONTEXT_NAME_SIZE) {\n                setNullContext();\n                return NULL_CONTEXT;\n            } else {\n                // 加锁\n                LOCK.lock();\n                try {\n                    node = contextNameNodeMap.get(name);\n                    // 第二次\n                    if (node == null) {\n                        if (contextNameNodeMap.size() > Constants.MAX_CONTEXT_NAME_SIZE) {\n                            setNullContext();\n                            return NULL_CONTEXT;\n                        } else {\n                            // 这个节点肯定是入口节点\n                            node = new EntranceNode(new StringResourceWrapper(name, EntryType.IN), null);\n                            // 将入口节点加入到ROOT下面\n                            Constants.ROOT.addChild(node);\n\t\t\t\t\t\t\t// 替换更新一下contextNameNodeMap\n                            Map<String, DefaultNode> newMap = new HashMap<>(contextNameNodeMap.size() + 1);\n                            newMap.putAll(contextNameNodeMap);\n                            newMap.put(name, node);\n                            contextNameNodeMap = newMap;\n                        }\n                    }\n                } finally {\n                    LOCK.unlock();\n                }\n            }\n        }\n        // 上面的逻辑是创建ROOT下的第一层节点，不管是否需要创建 EntranceNode ，反正Context 是一定要的。\n        context = new Context(node, name);\n        // 一般来说 origin 为空，但是像被调用的rpc服务，origin就是调用来源\n        context.setOrigin(origin);\n        // 将此context设置到 ContextHolder中\n        contextHolder.set(context);\n    }\n\n    return context;\n}\n\n\n创建Context从整体上看就两步 ：\n\n * 如果这个context没有在 map中注册过，就注册一下\n * 创建context，指定此 Context 的 EntranceNode\n\n重复，创建 context 时并没有给 EntranceNode 创建对应的 Entry 哦，所以 EntranceNode 不会参与执行。\n\n集成 springmvc框架时，Sentinel 在 HandlerInterceptor 中创建 Context ：相应的代码在 sentinel-adapter/sentinel-spring-webmvc-adapter中\n\n@Override\npublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {\n    // 通过子类的实现，获取资源名，如 "/user/{id}"\n    String resourceName = getResourceName(request);\n    // 对资源名进行判空啥的操作，省略掉直接进入核心代码\n\n    // 解析调用来源\n    String origin = parseOrigin(request);\n    // 获取context name, 开始创建上下文\n    String contextName = "sentinel_spring_web_context";\n    ContextUtil.enter(contextName, origin);\n    // 创建Entry\n    Entry entry = SphU.entry(resourceName, ResourceTypeConstants.COMMON_WEB, EntryType.IN);\n    // 将entry放入请求域中，以便在 afterCompletion 中使用\n    request.setAttribute(baseWebMvcConfig.getRequestAttributeName(), entry);\n    return true;\n}\n\n\n总结一下 ：\n\n * ROOT 并不参与 Context 的构建，也不参与Entry的执行。\n * EntranceNode 参与 Context 的创建，但是 EntranceNode 不会参与 Entry 的执行\n * Entry 是调用链\n\n现在我们的Node树就可以变为这样 ：\n\n\n\n\n# 6. 插槽 ProcessorSlot\n\nProcessorSlot 直译就是处理器插槽，是 Sentinel 实现限流降级、熔断降级、系统自适应降级等功能的切入点。Sentinel 提供的 ProcessorSlot 可以分为两类，一类是辅助完成资源指标数据统计的切入点，一类是实现降级功能的切入点。\n\n辅助资源指标数据统计的 ProcessorSlot：\n\n * NodeSelectorSlot：为当前资源创建 DefaultNode，并且将 DefaultNode 赋值给 Context.curEntry.curNode；\n   \n   如果此 DefaultNode 是当前调用链路上第二个Node（因为第一个 Node 是固定的），将该 DefaultNode 添加到的 Context.entranceNode 的子节点，否则添加到 Context.curEntry.parent 的子节点（childList）。有点抽象，我们在分析 NodeSelectorSlot 源码时再详细介绍。\n\n * ClusterBuilderSlot：如果当前资源未创建 ClusterNode，则为资源创建 ClusterNode；将 ClusterNode 赋值给当前资源的 DefaultNode.clusterNode；如果调用来源（origin）不为空，则为调用来源创建 StatisticNode，用于实现按调用来源统计资源的指标数据，ClusterNode 持有每个调用来源的 StatisticNode。\n\n * StatisticSlot：这是 Sentinel 最为重要的类之一，用于实现指标数据统计。先是调用后续的 ProcessorSlot#entry 判断是否放行请求，再根据判断结果进行相应的指标数据统计操作。\n\n实现降级功能的 ProcessorSlot：\n\n * AuthoritySlot：实现黑白名单降级\n * SystemSlot：实现系统自适应降级\n * FlowSlot：实现限流降级\n * DegradeSlot：实现熔断降级\n\nSentinel 使用责任链模式将这些插槽组成了拦截器链条，之前我们称 ProcessorSlot 为拦截器，现在要改口为插槽了\n\n * ProcessorSlot ：插槽，每一个插槽有不同的功能，比如系统限流、黑白名单限流、熔断降级。\n * ProcessorSlotChain ：内含头插槽和尾插槽，将所有插槽组成插槽链执行。\n\n关于每个 ProcessorSlot 是如何组成链表、如何实现的功能，将在后续文章详细分析。',normalizedContent:'# 1. 资源 resourcewrapper\n\n想要做限流、熔断，目标是谁？肯定是资源。资源可以是一个方法、一段代码、一个接口...\n\nsentinel 统计的数据以资源为维度，资源使用 resourcewrapper 表示\n\npublic abstract class resourcewrapper {\n\t// 资源名\n    protected final string name;\n\t// 节点类型，进入或流出\n    protected final entrytype entrytype;\n    // 资源类型，比如mvc、dubbo、grpc..\n    protected final int resourcetype;\n}\n\n\n * name ：资源名\n * entrytype ：此资源表示的节点的类型，即流入流量还是流出流量，通俗一点说就是发起请求还是接收请求。\n * resourcetype ：资源类型，sentinel 集成了很多框架，不同的资源之间还会相互调用，所以要分清楚。\n\nentrytype 是一个枚举类 ：\n\npublic enum entrytype {\n    in("in"),\n    out("out");\n}\n\n\nsentinel1.8.1 支持的 resourcetype 有以下几种 ：\n\npublic final class resourcetypeconstants {\n\n    public static final int common = 0;\n    public static final int common_web = 1;\n    public static final int common_rpc = 2;\n    public static final int common_api_gateway = 3;\n    public static final int common_db_sql = 4;\n\n    private resourcetypeconstants() {}\n}\n\n\n * common ：不集成任何框架\n * common_web ：集成web应用的接口\n * common_rpc ：rpc接口\n * common_api_gateway ：用于 api gateway 网关\n * common_db_sql ：数据库sql操作\n\n综上所述，sentinel 中的资源可能的类型有\n\n * 进入程序的web请求\n * 程序发出的rpc请求\n * 程序发出的sql操作\n * .......\n\n\n# 2. 节点 node\n\nsentinel 中的每一个资源都可以成为一个 node，至于成为哪一个 node 要看使用情况。\n\nnode 作为 sentinel 中持有实时统计数据的接口，它定义了一个节点所需要提供的各项指标数据统计功能，为外部屏蔽统计数据的实现。\n\npublic interface node extends occupysupport, debugsupport {\n    long totalrequest(); // 获取总的请求数\n    long totalpass(); // 获取通过的请求总数\n    long totalsuccess(); // 获取成功的请求总数\n    long blockrequest(); // 获取被 sentinel 拒绝的请求总数\n    long totalexception(); // 获取异常总数\n    double passqps(); // 通过 qps\n    double blockqps(); // 拒绝 qps\n    double totalqps(); // 总 qps\n    double successqps(); // 成功 qps\n    // 最大成功总数 qps（例如秒级滑动窗口的数组大小默认配置为 2，则取数组中最大）\n    double maxsuccessqps(); \n    double exceptionqps(); // 异常 qps\n    double avgrt(); // 平均耗时\n    double minrt(); // 最小耗时\n    int curthreadnum(); // 当前并发占用的线程数\n    double previousblockqps(); // 前一个时间窗口的被拒绝 qps\n    double previouspassqps(); // 前一个时间窗口的通过 qps\n    map<long, metricnode> metrics(); \n    list<metricnode> rawmetricsinmin(predicate<long> timepredicate);\n    void addpassrequest(int count); // 添加通过请求数\n    void addrtandsuccess(long rt, int success); // 添加成功请求数，并且添加处理成功的耗时\n    void increaseblockqps(int count); // 添加被拒绝的请求数\n    void increaseexceptionqps(int count); // 添加异常请求数\n    void increasethreadnum(); // 自增占用线程\n    void decreasethreadnum(); // 自减占用线程\n    void reset(); // 重置滑动窗口\n}\n\n\n为啥 node 是一个接口而不是实现类？因为要将 sentinel 中的 “节点” 按照类型区分开。\n\n比如有三个资源 ：a、b、c\n\n这三个资源有以下调用链 ：\n\na -> b -> c\n\nb -> c -> a\n\na -> b -> a\n\n在三个调用链中，同一个节点充当了不同的角色，比如第三个调用链中，a 既是入口节点也是普通节点。\n\n我们给它起名 ：入口a、普通a\n\n同时如果要统计 “a” 这个资源的总访问量怎么办？难道要将全部的入口a、普通a 一个一个遍历相加？\n\n不，创建一个全局 a ，流量进入 入口a、普通a时将不仅将对应的节点流量加一，还将全局a的数据也加一\n\n现在有了三种节点，它们都是 node 的子类：\n\n * 入口节点 entrancenode\n * 普通节点 defaultnode\n * 全局节点 clusternode\n\nsentinel 将这三种节点的共同属性 ：统计数据功能 抽取出来作为它们三个的父类 ：statisticnode。关系图如下：\n\n\n\n * node ：抽象类，提供规范\n * statisticnode ：提供了统计数据的功能。\n * defaultnode ：普通节点\n * entrancenode ：入口节点\n * clusternode ：全局节点，一个资源只能有一个全局节点。\n\n一个资源可能有多个入口节点或普通节点，但是只能有一个全局节点。clusternode 与 defaultnode 的关系是一对多。\n\n接下来详细介绍各种类型的 node\n\n\n# 2.1 统计节点 ：statisticnode\n\npublic class statisticnode implements node {\n    // 秒级滑动窗口，2 个时间窗口大小为 500 毫秒的 bucket\n    private transient volatile metric rollingcounterinsecond = new arraymetric(2,1000);\n    // 分钟级滑动窗口，60 个 bucket 数组，每个 bucket 统计的时间窗口大小为 1 秒\n    private transient metric rollingcounterinminute = new arraymetric(60, 60 * 1000, false);\n    \n    // 统计并发使用的线程数，可以根据线程数限流。\n    private longadder curthreadnum = new longadder();\n    \n    // 实现了从 node 继承过来的其他统计方法，这里列举几个简单的\n    \n    // 一分钟内成功放心的全部请求数量\n    @override\n    public long totalpass() {\n        return rollingcounterinminute.pass();\n    }\n    \n    // 成功放行了一个请求，加上。\n    @override\n    public void addpassrequest(int count) {\n        rollingcounterinsecond.addpass(count);\n        rollingcounterinminute.addpass(count);\n    }\n\n    // 。。。。。。其他的就不放了，statisticnode实现了node的所有抽象方法。\n}\n\n\n在一般情况下，sentinel 使用滑动窗口算法统计经过每一个 node 的资源。滑动窗口算法会在以后的文章介绍到。\n\n通过实现 node 规定的方法，statisticnode 提供了统计秒级、分钟级成功请求数、失败请求数等等功能。\n\n当然了，现在不会这些很正常，你只需要知道：statisticnode 可以统计流量，所有继承它的 node ，也就是 clusternode、defaultnode、entrancenode 也都可以统计流量。\n\n注意 ：statisticnode 只提供统计数据的功能，它不表示任何资源。\n\n\n# 2.2 普通节点 ：defaultnode\n\npublic class defaultnode extends statisticnode {\n\n    // 这个节点表示的资源\n    private resourcewrapper id;\n\n    // 这个节点的全部子节点\n    private volatile set<node> childlist = new hashset<>();\n\t\n    // 该节点对应的 clusternode\n    private clusternode clusternode;\n\n\n    @override\n    public void increaseblockqps(int count) {\n        super.increaseblockqps(count);\n        this.clusternode.increaseblockqps(count);\n    }\n\n    @override\n    public void increaseexceptionqps(int count) {\n        super.increaseexceptionqps(count);\n        this.clusternode.increaseexceptionqps(count);\n    }\n\n    @override\n    public void addrtandsuccess(long rt, int successcount) {\n        super.addrtandsuccess(rt, successcount);\n        this.clusternode.addrtandsuccess(rt, successcount);\n    }\n\n    @override\n    public void increasethreadnum() {\n        super.increasethreadnum();\n        this.clusternode.increasethreadnum();\n    }\n\n    @override\n    public void decreasethreadnum() {\n        super.decreasethreadnum();\n        this.clusternode.decreasethreadnum();\n    }\n\n    @override\n    public void addpassrequest(int count) {\n        super.addpassrequest(count);\n        this.clusternode.addpassrequest(count);\n    }\n\n    public void printdefaultnode() {\n        visittree(0, this);\n    }\n}\n\n\n * id ：这个节点表示的资源。\n * childlist ：这个节点的全部子节点\n * clusternode ：该节点对应的 clusternode。\n\n资源与 defaultnode 之间是一对多的关系。资源与clusternode之间是一对一的关系。\n\n一个 defaultnode 可以有多个子节点形成如下的结构 ：\n\n（其实最顶端的 a 不是 defaultnode，这里只是做一个比喻）\n\n\n\n多个 defaultnode 就形成了一棵树\n\n注 ：了解 sentinel 的就能看出来这颗树还有很多缺陷，但是现在只是做一个比喻。\n\n同时，通过源码你可能看出来了，defaultnode 在执行放行请求方法时如下：\n\n@override\npublic void addrtandsuccess(long rt, int successcount) {\n    super.addrtandsuccess(rt, successcount);\n    this.clusternode.addrtandsuccess(rt, successcount);\n}\n\n\n先给自己的数据记录一下，再给自己所属的 clusternode 记录一下，跟咱们之前说的一样。\n\n再次提醒 ：所有节点统计数据时都要使用从 statisticnode 继承过来的方法。\n\n\n# 2.3 入口节点 ：entrancenode\n\n入口节点没有变量，功能被 statisticnode 实现了，变量被 defaultnode 拥有了，entrancenode 就特别简洁了：\n\npublic class entrancenode extends defaultnode {\n\n    public entrancenode(resourcewrapper id, clusternode clusternode) {\n        super(id, clusternode);\n    }\n}\n\n\nentrancenode 与 defaultnode 的区别是重写 statisticnode 的方法不一样。\n\n在这里可以剧透一下 ：entrancenode 都是已经规定好的节点，命名方式根据集成的框架变化。比如\n\n * 不集成任何框架时，entrancenode.name = "sentinel_default_context"\n * 集成spring mvc 时，entrancenode.name = "sentinel_spring_web_context"\n\n\n# 2.4 全局节点 ：clusternode\n\npublic class clusternode extends statisticnode {\n\t// 节点名，即资源名，其实应该使用 resourcewrapper的，不知道这里为啥用了string\n    private final string name;\n    // 资源类型\n    private final int resourcetype;\n\n    // 维护每个调用来源的指标数据统计数据（statisticnode）\n    // 在 clusternode 部分会具体说。\n    private map<string, statisticnode> origincountmap = new hashmap<>();\n    \n\t// 控制并发修改 origincountmap 用的锁\n    private final reentrantlock lock = new reentrantlock();\n}\n\n\n * name ：资源名，其实应该使用 resourcewrapper的，不知道这里为啥用了string\n * resourcetype ：资源类型\n * origincountmap ： 维护每个调用来源的指标数据统计数据（statisticnode）\n * lock ：控制并发修改 origincountmap 用的锁\n\n其实它还有一个方法用来操作 origincountmap ：\n\npublic node getorcreateoriginnode(string origin) {\n    statisticnode statisticnode = origincountmap.get(origin);\n    if (statisticnode == null) {\n        lock.lock();\n        try {\n            statisticnode = origincountmap.get(origin);\n            if (statisticnode == null) {\n                statisticnode = new statisticnode();\n                hashmap<string, statisticnode> newmap = new hashmap<>(origincountmap.size() + 1);\n                newmap.putall(origincountmap);\n                newmap.put(origin, statisticnode);\n                origincountmap = newmap;\n            }\n        } finally {\n            lock.unlock();\n        }\n    }\n    return statisticnode;\n}\n\n\n具体是啥意思呢，请看这个图：\n\n\n\nspringmvc 框架中的 /hello1 通过 grpc 远程调用了 /hello2，那么在统计 /hello2 时是不是要标清楚 origin 是 hello1？\n\n所以就通过 origin 创建一个 hello1 节点，放在 hello2 的 clusternode 的 map 中，注意，放入的节点类型为 statisticnode，也就说明这个节点没有实际意义，只负责统计一下流量，方便做“来源限流、关联限流”。\n\n当用户要做 /hello1->/hello2 的来源限流时，将 hello2 的流量取出来，再将 hello2对应的 clusternode 中统计的 hello1 的数据取出来就可以判断是否限流了。\n\n\n# 3. 根节点 constants.root\n\n其实整个程序的 入口节点是固定的，它存放在常量类 constants 中。\n\npublic final class constants {\n    // 默认context的名称\n    public final static string context_default_name = "sentinel_default_context";\n    \n    // 根节点\n    public final static defaultnode root = new entrancenode(\n        new stringresourcewrapper(root_id, entrytype.in),\n        new clusternode(root_id, resourcetypeconstants.common)\n    );\n    \n    // 根节点对应的全局节点\n    public final static clusternode entry_node = new clusternode(\n        total_in_resource_name, \n        resourcetypeconstants.common\n    );\n\n}\n\n\n根节点的第一层子节点，即 entrancenode 也是固定的，这个在前面已经剧透了\n\n也就是说，根节点和第一层节点都是固定的。只有从第二层节点开始才是我们的。\n\n（上面我说的 “第一层” 是指root节点下的第一层，后续在提到 entrancenode 时都会有 “第一层” 代称，请不要认为我说的第一层是root😁）\n\n验证一下，我们不集成任何环境，那么 root 下第一个 entrancenode 就一定是 sentinel_default_context。\n\n将 abc 当作资源的话，abc就会是 sentinel_default_context 的子节点：\n\n\n\n（使用 sentinel-demo/sentinel-demo-basic/flow/flowqpsdemo 测试类）\n\n集成了 web mvc 时，root 的子节点就有俩了：\n\n\n\n(使用 sentinel-demo/sentinel-demo-spring-webmvc/webmvctestcontroller 测试类，需要自己加上 constants.root 去 debug)\n\n更新一下节点树：\n\n\n\n这样做的好处是集成其他环境时很方便，坏处就是不好理解\n\n\n# 4. entry\n\n在认识 资源 和 节点 之后就该 entry 了，entry是由 节点+处理器链 组成。\n\nsentinel 提供的是限流、熔断功能，具体来说就是热点限流、系统限流、来源限流.... 这些功能通过责任链模式组成了一个处理器链，由于每一个资源都需要进行判断，每一个资源要的限流规则都有差别，所以每一个资源都要走一遍处理器链，sentinel 使用 entry 将 节点和处理器链 封装起来。\n\n在 sentinel 中，处理器链也可以称为责任链。\n\n听起来是不是特别麻烦？确实，要做到每一个资源都进行限流确实特别麻烦。\n\npublic abstract class entry implements autocloseable {\n    // 创建时间\n    private long createtime;\n    // 当前节点（defaultnode）\n    private node curnode;\n    // 来源节点\n    private node originnode;\n    // 错误\n    private throwable error;\n    // 资源id\n    protected resourcewrapper resourcewrapper;\n}\n\n\nctentry 是 entry 的直接子类，后面分析源码时，我们所说 entry 皆指 ctentry。ctentry 中声明的字段信息如下代码所示。\n\nclass ctentry extends entry {\n    // 当前 entry 指向的父 entry\n    protected entry parent = null;\n    // 父 entry 指向当前 entry\n    protected entry child = null;\n    // 当前资源的 processorslotchain，责任链模式，也就是很多拦截器\n    protected processorslot<object> chain;\n    // 当前上下文\n    protected context context;\n}\n\n\n为啥 entry 要分 parent、child 关系 ？在 node 章节中我们介绍了，多个 defaultnode 可以组成树，我们一次只需要统计当前一条链路的 node，也就是一个链表，所以这个 parent 和 child 其实也可以称作 pre 和 next。\n\n> 有一个特别需要注意的点 ：入口节点，即 entrancenode 不会被封装为 entry。\n\nentry 是一次调用形成的调用链上的节点。\n\n这张图描述了多个 node 的关系\n\n\n\n现在我们将 a -> b -> f 这条调用链来画一下 entry\n\n\n\n（多个entry是双向链表，多个node是树）\n\n> 这里请你分清 处理器链 和 调用链 的区别。\n> \n>  * 每一个 entry 由 node + 处理器链 组成\n> \n>  * 多个 entry 组成一个调用链\n\nentry是啥时候创建的、怎么创建的呢？所有的资源都要封装为 entry，然后在entry内部的处理器链中封装为node挂在树上。\n\n调用 sphu.entry(string entryname) 即可创建 entry。如果集成了其他框架，比如springmvc，可以使用aop创建。\n\nsphu.entry(string) 最终执行的如下方法：\n\nprivate entry entrywithpriority(resourcewrapper resourcewrapper, \n                                int count, \n                                boolean prioritized, \n                                object... args) throws blockexception {\n    // 获取当前上下文\n    context context = contextutil.getcontext();\n    if (context instanceof nullcontext) {\n        return new ctentry(resourcewrapper, null, context);\n    }\n\t// 如果 context 为空，使用默认 context. (即name为 sentinel_default_context 的context)\n    if (context == null) {\n        context = internalcontextutil.internalenter(constants.context_default_name);\n    }\n\n    // \n    if (!constants.on) {\n        return new ctentry(resourcewrapper, null, context);\n    }\n\t// 加载调用链\n    processorslot<object> chain = lookprocesschain(resourcewrapper);\n\n    // 如果加载的责任链为空\n    if (chain == null) {\n        return new ctentry(resourcewrapper, null, context);\n    }\n\t// 正常情况下上面的代码都不会走到，这里会真正创建一个 ctentry.\n    entry e = new ctentry(resourcewrapper, chain, context, count, args);\n    try {\n        // 开始执行整个责任链\n        chain.entry(context, resourcewrapper, null, count, prioritized, args);\n    } catch (blockexception e1) {\n        e.exit(count, args);\n        throw e1;\n    } catch (throwable e1) {\n        recordlog.info("sentinel unexpected exception", e1);\n    }\n    return e;\n}\n\n\n现在不知道context没事，下面就是。其实直到 new ctentry() 才是重点，new出entry后直接执行 处理器链，处理器链中有很多个处理器，有统计资源的、限流的、熔断的...如果在处理器链的执行过程中出现被限流、熔断的异常，就会被这个 blockexception 捕获丢出。丢出之前肯定要将 entry 销毁。\n\n> entry 与 node 的区别是啥呢？\n> \n> node构建之后基本不会动了，除非程序重启宕机啥的。\n> \n> entry每次请求都会构建。多个entry就组成了一次调用链\n\n\n# 5. 上下文 context\n\n很多框架都有一个上下文对象，sentinel 也不例外。sentinel 的 contextutil 使用 threadlocal 持有 context，context 存储的信息包括 ：\n\npublic class context {\n    // context的name\n    private final string name;\n    // 此次执行的入口节点，都是固定的root下的第一层节点。\n    private defaultnode entrancenode;\n    // 现在执行到哪个entry了。\n    private entry curentry;\n    private string origin = "";\n    \n    // 我们不讨论异步的情况\n    // private final boolean async;\n}\n\n\n * name：context 的名称。\n\n * entrancenode：当前调用树的入口节点，类型为 entrancenode。这个node比较固定，都是第一层节点。\n   \n   这个节点虽然会在 context 中，但它不会在 entry 中，因为不参与执行，只参与统计。\n\n * curentry：当前 entry（ctentry），内含当前执行的 node\n\n * origin：调用来源的名称，即服务消费者的名称或者服务消费者的来源 ip，取决于服务消费者是否使用 sentinel，由 sentinel 适配层传递过来。例如：服务提供者是 spring mvc 应用，且服务提供者使用 sentinel 的 web mvc 适配，那么 sentinel 会尝试从请求头获取”s-user”，如果服务消费者有在请求头传递这个参数，那么就能够获取到。\n\npublic class contextutil {\n    // 持有 context\n    private static threadlocal<context> contextholder = new threadlocal<>();\n    // 持有所有 entrancenode，即所有第一层node.\n    // 可能包含的: default、mvc、okhttp、grpc、dubbo...\n    private static volatile map<string, defaultnode> contextnamenodemap = new hashmap<>();\n    // 如果当前环境(mvc、dubbo、grpc) 还没有把第一层节点注册到 contextnamenodemap，那么就加锁开始注册\n    private static final reentrantlock lock = new reentrantlock();\n}\n\n\n这里要着重说一下 contextnamenodemap。\n\ncontextutil 会将所有第一层节点存储在 contextnamenodemap 中，从名字也可以看出来这个map里面存储的是以 context.name 命名的 node\n\n\n# 5.1 context 的创建\n\n当 contextutil 类加载的时候会执行静态代码块，初始化一个默认的entrancenode ：sentinel_default_context 放入 contextnamenodemap 中。\n\nstatic {\n    // cache the entrance node for default context.\n    initdefaultcontext();\n}\n\nprivate static void initdefaultcontext() {\n    string defaultcontextname = constants.context_default_name;\n    entrancenode node = new entrancenode(new stringresourcewrapper(defaultcontextname, entrytype.in), null);\n    // 将此入口节点挂在 root 下面。\n    constants.root.addchild(node);\n    contextnamenodemap.put(defaultcontextname, node);\n}\n\n\n所以在写代码的时候 contextnamenodemap 中就已经有了一个 entrancenode 了。当然这是题外话了，我们要说的是 context 的创建。虽然指定了 entrancenode 但是并未给 entrancenode 创建 entry，所以 entrancenode 不会参与执行。\n\ncontextutil.enter(string contextname) 可以创建一个 context\n\n// 显式创建 context\ncontextutil.enter("sentinel_default_context");\nentry entry = null;\ntry {\n     // 创建资源对应的 entry\n     entry = sphu.entry("/user/get", entrytype.in);\n     // 执行业务方法\n     return dobusiness();\n} catch (exception e) {\n     if (!(e instanceof blockexception)) {\n          tracer.trace(e);\n     }\n     throw e;\n} finally {\n     if (entry != null) {\n         // 销毁此entry, 会将 context.curentry改为entry.parent\n         entry.exit(1);\n     }\n     // 销毁 context\n     contextutil.exit();\n}\n\n\ncontext 都是由 contextutil 显式创建， contextutil.enter(string contextname) 最终执行的逻辑 ：\n\n// name : contextname, context的名称\n// origin : 来源，比如通过 rpc调用时，rpc服务提供者的origin就是服务调用者\nprotected static context trueenter(string name, string origin) {\n    // 从 contextholder 中取 context，如果取不到就创建。\n    // 这里也是我们第一个看到 sentinel 使用双重检查锁机制，后面还会有很多次。\n    context context = contextholder.get();\n    if (context == null) {\n        // contextnamenodemap 是拥有第一层节点的map\n        // 比如 sentinel_default_context - entrancenode\n        map<string, defaultnode> localcachenamemap = contextnamenodemap;\n        \n        // 如果根据context name 无法找到第一层node，说明当前环境(mvc、dubbo、grpc...) 还没有把第一层节点注册到 contextnamenodemap\n    \t// 那么就加锁开始注册\n        defaultnode node = localcachenamemap.get(name);\n        // 第一次检查\n        if (node == null) {\n            // 如果第一层节点太多了，返回一个 nullcontext\n            if (localcachenamemap.size() > constants.max_context_name_size) {\n                setnullcontext();\n                return null_context;\n            } else {\n                // 加锁\n                lock.lock();\n                try {\n                    node = contextnamenodemap.get(name);\n                    // 第二次\n                    if (node == null) {\n                        if (contextnamenodemap.size() > constants.max_context_name_size) {\n                            setnullcontext();\n                            return null_context;\n                        } else {\n                            // 这个节点肯定是入口节点\n                            node = new entrancenode(new stringresourcewrapper(name, entrytype.in), null);\n                            // 将入口节点加入到root下面\n                            constants.root.addchild(node);\n\t\t\t\t\t\t\t// 替换更新一下contextnamenodemap\n                            map<string, defaultnode> newmap = new hashmap<>(contextnamenodemap.size() + 1);\n                            newmap.putall(contextnamenodemap);\n                            newmap.put(name, node);\n                            contextnamenodemap = newmap;\n                        }\n                    }\n                } finally {\n                    lock.unlock();\n                }\n            }\n        }\n        // 上面的逻辑是创建root下的第一层节点，不管是否需要创建 entrancenode ，反正context 是一定要的。\n        context = new context(node, name);\n        // 一般来说 origin 为空，但是像被调用的rpc服务，origin就是调用来源\n        context.setorigin(origin);\n        // 将此context设置到 contextholder中\n        contextholder.set(context);\n    }\n\n    return context;\n}\n\n\n创建context从整体上看就两步 ：\n\n * 如果这个context没有在 map中注册过，就注册一下\n * 创建context，指定此 context 的 entrancenode\n\n重复，创建 context 时并没有给 entrancenode 创建对应的 entry 哦，所以 entrancenode 不会参与执行。\n\n集成 springmvc框架时，sentinel 在 handlerinterceptor 中创建 context ：相应的代码在 sentinel-adapter/sentinel-spring-webmvc-adapter中\n\n@override\npublic boolean prehandle(httpservletrequest request, httpservletresponse response, object handler) throws exception {\n    // 通过子类的实现，获取资源名，如 "/user/{id}"\n    string resourcename = getresourcename(request);\n    // 对资源名进行判空啥的操作，省略掉直接进入核心代码\n\n    // 解析调用来源\n    string origin = parseorigin(request);\n    // 获取context name, 开始创建上下文\n    string contextname = "sentinel_spring_web_context";\n    contextutil.enter(contextname, origin);\n    // 创建entry\n    entry entry = sphu.entry(resourcename, resourcetypeconstants.common_web, entrytype.in);\n    // 将entry放入请求域中，以便在 aftercompletion 中使用\n    request.setattribute(basewebmvcconfig.getrequestattributename(), entry);\n    return true;\n}\n\n\n总结一下 ：\n\n * root 并不参与 context 的构建，也不参与entry的执行。\n * entrancenode 参与 context 的创建，但是 entrancenode 不会参与 entry 的执行\n * entry 是调用链\n\n现在我们的node树就可以变为这样 ：\n\n\n\n\n# 6. 插槽 processorslot\n\nprocessorslot 直译就是处理器插槽，是 sentinel 实现限流降级、熔断降级、系统自适应降级等功能的切入点。sentinel 提供的 processorslot 可以分为两类，一类是辅助完成资源指标数据统计的切入点，一类是实现降级功能的切入点。\n\n辅助资源指标数据统计的 processorslot：\n\n * nodeselectorslot：为当前资源创建 defaultnode，并且将 defaultnode 赋值给 context.curentry.curnode；\n   \n   如果此 defaultnode 是当前调用链路上第二个node（因为第一个 node 是固定的），将该 defaultnode 添加到的 context.entrancenode 的子节点，否则添加到 context.curentry.parent 的子节点（childlist）。有点抽象，我们在分析 nodeselectorslot 源码时再详细介绍。\n\n * clusterbuilderslot：如果当前资源未创建 clusternode，则为资源创建 clusternode；将 clusternode 赋值给当前资源的 defaultnode.clusternode；如果调用来源（origin）不为空，则为调用来源创建 statisticnode，用于实现按调用来源统计资源的指标数据，clusternode 持有每个调用来源的 statisticnode。\n\n * statisticslot：这是 sentinel 最为重要的类之一，用于实现指标数据统计。先是调用后续的 processorslot#entry 判断是否放行请求，再根据判断结果进行相应的指标数据统计操作。\n\n实现降级功能的 processorslot：\n\n * authorityslot：实现黑白名单降级\n * systemslot：实现系统自适应降级\n * flowslot：实现限流降级\n * degradeslot：实现熔断降级\n\nsentinel 使用责任链模式将这些插槽组成了拦截器链条，之前我们称 processorslot 为拦截器，现在要改口为插槽了\n\n * processorslot ：插槽，每一个插槽有不同的功能，比如系统限流、黑白名单限流、熔断降级。\n * processorslotchain ：内含头插槽和尾插槽，将所有插槽组成插槽链执行。\n\n关于每个 processorslot 是如何组成链表、如何实现的功能，将在后续文章详细分析。',charsets:{cjk:!0},lastUpdated:"2023/12/12, 20:55:52",lastUpdatedTimestamp:1702385752e3},{title:"2. Sentinel 责任链流程",frontmatter:{title:"2. Sentinel 责任链流程",date:"2023-11-29T16:10:15.000Z",permalink:"/pages/51db55/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/60.Sentinel/4.%20Sentinel%20%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%B5%81%E7%A8%8B.html",relativePath:"02.文章/91.框架/60.Sentinel/4. Sentinel 责任链流程.md",key:"v-d47ce5a2",path:"/pages/51db55/",headers:[{level:2,title:"1. 简述",slug:"_1-简述",normalizedTitle:"1. 简述",charIndex:2},{level:2,title:"2. ProcessorSlot",slug:"_2-processorslot",normalizedTitle:"2. processorslot",charIndex:635},{level:2,title:"3. ProcessorSlotChain",slug:"_3-processorslotchain",normalizedTitle:"3. processorslotchain",charIndex:3219},{level:2,title:"4. SlotChainBuilder",slug:"_4-slotchainbuilder",normalizedTitle:"4. slotchainbuilder",charIndex:5365},{level:2,title:"5. 总结",slug:"_5-总结",normalizedTitle:"5. 总结",charIndex:7027},{level:2,title:"6. Sentinel 中的 SPI 机制",slug:"_6-sentinel-中的-spi-机制",normalizedTitle:"6. sentinel 中的 spi 机制",charIndex:7534},{level:3,title:"1. 什么是 SPI",slug:"_1-什么是-spi",normalizedTitle:"1. 什么是 spi",charIndex:7560},{level:3,title:"2. 使用Java的SPI机制",slug:"_2-使用java的spi机制",normalizedTitle:"2. 使用java的spi机制",charIndex:8338},{level:3,title:"3. Sentinel 使用 SPI 机制做了什么",slug:"_3-sentinel-使用-spi-机制做了什么",normalizedTitle:"3. sentinel 使用 spi 机制做了什么",charIndex:9280}],headersStr:"1. 简述 2. ProcessorSlot 3. ProcessorSlotChain 4. SlotChainBuilder 5. 总结 6. Sentinel 中的 SPI 机制 1. 什么是 SPI 2. 使用Java的SPI机制 3. Sentinel 使用 SPI 机制做了什么",content:'# 1. 简述\n\n在上一篇中详细介绍了 Sentinel 中的几个核心类，又简单说了一下 Sentinel 的插槽。\n\n这一篇会稍微详细的讲解插槽，会从整体也就是责任链模式入手介绍 Sentinel 工作的流程，但不会单独讲解某一个插槽的用处。\n\n回忆一下上一篇有关插槽 ProcessorSlot 的知识点 ：\n\nSentinel 使用 责任链模式将所有的 ProcessorSlot 按照一定的顺序串成一个链表。ProcessorSlot 共分为两类：\n\n 1. 统计数据，这种 ProcessorSlor 是有严格的顺序区分的，不能更改。\n    \n    NodeSelectorSlot\n    \n    ClusterBuilderSlot\n    \n    StatisticSlot\n\n 2. 限流/熔断，这种 ProcessorSlot 没有严格严格的顺序要求，可以按需调整。\n    \n    AuthoritySlot\n    \n    SystemSlot\n    \n    FlowSlot\n    \n    DegradeSlot\n\nProcessorSlotChain ：内含ProcessorSlot头节点和尾节点，可以触发整个插槽链的执行。\n\nSlotChainBuilder ：将 ProcessorSlot 组装起来形成 ProcessorSlotChain 并返回给用户。\n\n接下来详细说说 Sentinel 的工作流程\n\n\n# 2. ProcessorSlot\n\nProcessorSlot 是一个接口\n\npublic interface ProcessorSlot<T> {\n\n  \t// 实现自己的业务方法\n    void entry(Context context, ResourceWrapper resourceWrapper, T param, int count, boolean prioritized, Object... args) throws Throwable;\n\n    // 触发下一个slot的业务方法\n    void fireEntry(Context context, ResourceWrapper resourceWrapper, Object obj, int count, boolean prioritized, Object... args) throws Throwable;\n\n\t// 实现自己的退出方法\n    void exit(Context context, ResourceWrapper resourceWrapper, int count, Object... args);\n\n    // 触发下一个slot的退出方法\n    void fireExit(Context context, ResourceWrapper resourceWrapper, int count, Object... args);\n}\n\n\n * context ：当前调用链路上下文\n * resourceWrapper ：资源\n * param ：泛型参数，一般用于传递 DefaultNode\n * count ：申请访问资源的数量，比如访问量、占用线程数量，count 一般为1\n * prioritized ：是否对请求进行优先级排序，一般为false\n * args ：调用方法的参数，用于实现热点参数限流\n\n这里你就会有些疑惑，按照责任链模式，ProcessorChain 应该有一个 next 变量用于串起来所有 ProcessorChain 啊，但是此处并没有，而且也没有提供添加下一个slot、触发下一个slot这些方法，不要慌，其实这些东西在 ProcessorSlot 的实现类中 ：AbstractLinkedProcessorSlot\n\n之所以能够将所有的 ProcessorSlot 构造成一个 ProcessorSlotChain，还是依赖 AbstractLinkedProcessorSlot 类。\n\n每个 AbstractLinkedProcessorSlot 类都有一个指向下一个 AbstractLinkedProcessorSlot 的字段，正是这个字段将 ProcessorSlot 串成一条单向链表。AbstractLinkedProcessorSlot 部分源码如下。\n\npublic abstract class AbstractLinkedProcessorSlot<T> implements ProcessorSlot<T> {\n    // 当前节点的下一个节点\n    private AbstractLinkedProcessorSlot<?> next = null;\n\n    public void setNext(AbstractLinkedProcessorSlot<?> next) {\n        this.next = next;\n    }\n    @Override\n    public void fireEntry(Context context, \n                          ResourceWrapper resourceWrapper, \n                          Object obj, \n                          int count, \n                          boolean prioritized, \n                          Object... args) throws Throwable {\n        if (next != null) {\n            T t = (T) obj; \n            // 调用下一个 ProcessorSlot 的 entry 方法\n            next.entry(context,resourceWrapper,t,count,prioritized,args);\n        }\n    }\n}\n\n\n可以看到，不仅提供了 setNext() 方法用于添加此slot的下一个slot，还提供了 fireEntry() 触发下一个slot。\n\n到时候我们实现的时候只需要这样：\n\npublic class MySlot extends AbstractLinkedProcessorSlot<DefaultNode> {\n\n    @Override\n    public void entry(Context context, \n                      ResourceWrapper resourceWrapper, \n                      DefaultNode node, \n                      int count, \n                      boolean prioritized, \n                      Object... args) throws Throwable {\n        // 执行自己的业务方法...\n        \n        \n        // 执行结束，触发下一个slot的业务方法\n        fireEntry(context, resourceWrapper, node, count, prioritized, args);\n    }\n}\n\n\n\n# 3. ProcessorSlotChain\n\n根据责任链模式的一般实现方式，这个 Chain 会持有所有的slot，Sentinel 的实现方式是持有头节点和尾节点。\n\n（OkHttp的实现方式是持有整个List）\n\npublic class DefaultProcessorSlotChain extends ProcessorSlotChain {\n\n    // 虚拟头节点\n    AbstractLinkedProcessorSlot<?> first = new AbstractLinkedProcessorSlot<Object>() {\n\t\t// 可以看到头节点并没有自己的业务需要实现，所以直接调用 fireEntry 触发next.entry\n        @Override\n        public void entry(Context context, ResourceWrapper resourceWrapper, Object t, int count, boolean prioritized, Object... args)\n            throws Throwable {\n            super.fireEntry(context, resourceWrapper, t, count, prioritized, args);\n        }\n\n        @Override\n        public void exit(Context context, ResourceWrapper resourceWrapper, int count, Object... args) {\n            super.fireExit(context, resourceWrapper, count, args);\n        }\n\n    };\n    // 尾节点\n    AbstractLinkedProcessorSlot<?> end = first;\n\n    // 头插法\n    @Override\n    public void addFirst(AbstractLinkedProcessorSlot<?> protocolProcessor) {\n        protocolProcessor.setNext(first.getNext());\n        first.setNext(protocolProcessor);\n        if (end == first) {\n            end = protocolProcessor;\n        }\n    }\n\n    // 尾插法\n    @Override\n    public void addLast(AbstractLinkedProcessorSlot<?> protocolProcessor) {\n        end.setNext(protocolProcessor);\n        end = protocolProcessor;\n    }\n\n    @Override\n    public void setNext(AbstractLinkedProcessorSlot<?> next) {\n        addLast(next);\n    }\n\n    @Override\n    public AbstractLinkedProcessorSlot<?> getNext() {\n        return first.getNext();\n    }\n\t// entry方法，调用 first.transformEntry()，最终调用到 first.entry，\n    // first.entry没有自己的业务，直接触发first.next.entry()\n    @Override\n    public void entry(Context context, ResourceWrapper resourceWrapper, Object t, int count, boolean prioritized, Object... args)\n        throws Throwable {\n        first.transformEntry(context, resourceWrapper, t, count, prioritized, args);\n    }\n\n    @Override\n    public void exit(Context context, ResourceWrapper resourceWrapper, int count, Object... args) {\n        first.exit(context, resourceWrapper, count, args);\n    }\n}\n\n\n使用 ProcessorSlotChain.entry() 即可触发整个链条。\n\n\n# 4. SlotChainBuilder\n\n根据责任链模式的一般实现方式，构造 slot 链条这件事不会暴露给用户的，所以 Sentintl 使用 SlotChainBuilder 构造 ProcessorSlotChain 并返回。\n\n@Spi(isDefault = true)\npublic class DefaultSlotChainBuilder implements SlotChainBuilder {\n\n    @Override\n    public ProcessorSlotChain build() {\n        ProcessorSlotChain chain = new DefaultProcessorSlotChain();\n\n        List<ProcessorSlot> sortedSlotList = SpiLoader.of(ProcessorSlot.class).loadInstanceListSorted();\n        for (ProcessorSlot slot : sortedSlotList) {\n            if (!(slot instanceof AbstractLinkedProcessorSlot)) {\n                RecordLog.warn("The ProcessorSlot(" + slot.getClass().getCanonicalName() + ") is not an instance of AbstractLinkedProcessorSlot, can\'t be added into ProcessorSlotChain");\n                continue;\n            }\n            chain.addLast((AbstractLinkedProcessorSlot<?>) slot);\n        }\n\n        return chain;\n    }\n}\n\n\n但是打眼一看没这么简单！并没有我们想象的 new 了很多 slot 然后一个一个 add 进去，而是使用 SpiLoader 加载。这是 Java SPI 机制，我们在下面会介绍，这里就丑陋一点一个一个new出来😁\n\n我手动 new 的哈，源码里面没有\n\npublic class DefaultSlotChainBuilder implements SlotChainBuilder {\n    @Override\n    public ProcessorSlotChain build() {\n        ProcessorSlotChain chain = new DefaultProcessorSlotChain();\n        \n        chain.addLast(new NodeSelectorSlot());\n        chain.addLast(new ClusterBuilderSlot());\n        chain.addLast(new LogSlot());\n        chain.addLast(new StatisticSlot());\n        chain.addLast(new AuthoritySlot());\n        chain.addLast(new SystemSlot());\n        chain.addLast(new FlowSlot());\n        chain.addLast(new DegradeSlot());\n        chain.addLast(new DefaultCircuitBreakerSlot());\n        \n        return chain;\n    }\n}\n\n\n\n# 5. 总结\n\n 1. ProcessorSlotChain ：\n    * firstSlot ：first.entry方法直接调用fireEntry方法\n    * endSlot\n    * entry() ：调用firstSlot的entry方法\n 2. ProcessorSlot\n    * nextSlot\n    * entry() ：执行完自己的业务后执行 fireEntry()\n    * fireEntry() ：执行 next.entry()\n\n总流程 ：\n\n 1. 使用 SlotChainBuilder 创建 ProcessorSlotChain\n 2. 使用 ProcessorSlotChain.entry() 方法可以执行整条插槽链 ：\n    * 调用 firstSlot.entry，firstSlot.entry() 中直接执行 fireEntry 方法去执行下一个 slot.entry()\n 3. 下一个 slot.entry() 执行完自己的业务方法后，调用 fireEntry() 去执行下一个 slot.entry()\n 4. ....\n 5. ....\n\n\n# 6. Sentinel 中的 SPI 机制\n\n\n# 1. 什么是 SPI\n\nSPI 全称是 Service Provider Interface，直译就是服务提供者接口，是一种服务发现机制，是 Java 的一个内置标准，允许不同的开发者去实现某个特定的服务。SPI 的本质是将接口实现类的全限定名配置在文件中，由服务加载器读取配置文件，加载实现类，实现在运行时动态替换接口的实现类。\n\n使用 SPI 机制能够实现按配置加载接口的实现类，SPI 机制在阿里开源的项目中被广泛使用，例如 Dubbo、RocketMQ、以及本文介绍的 Sentinel。RocketMQ 与 Sentinel 使用的都是 Java 提供的 SPI 机制，而 Dubbo 则是使用自实现的一套 SPI，与 Java SPI 的配置方式不同，Dubbo SPI 使用 Key-Value 方式配置，目的是实现自适应扩展机制。\n\nJava 的 SPI 机制提供了 ServiceLoader.load(Class<?> clazz) 用于加载指定类的实现类。它加载文件的路径为：\n\nresource/META-INF/services/${接口的全限定类名}.\n\n在文件中也要填接口的实现类的全限定类名，Java将全部的实现类返回给用户 ：\n\ncom.xiaohe.xxxxxx\n\n\nServiceLoader<T> services = ServiceLoader.load(Class<T> clazz);\n\n\n加载步骤为 ：\n\n * 指定 ServiceLoader.load(Class clazz)\n * 通过 clazz 拿到接口的全限定类名，去 resource/META-INF/services目录下寻找对应全限定类名的文件\n * 读取该文件的全部内容（每一个内容以换行符分隔）\n * 以集合的形式返回给用户\n\n\n# 2. 使用Java的SPI机制\n\n假设有很多种登录方式，所以登录接口：\n\npublic interface LoginService{\n  void login(String username,String password);\n}\n\n\n有两个实现类：\n\npublic class ShiroLogin implements LoginService{\n    @Override\n    public void login(String username, String password) {\n        System.out.println("触发 Shiro 的登录功能");\n    }\n}\n\n\npublic class SpringSecurityLogin implements LoginService{\n    @Override\n    public void login(String username, String password) {\n        System.out.println("触发 SpringSecurity 的登录功能");\n    }\n}\n\n\n在 resource/META-INF/services 目录下创建名为 com.xiaohe.spi.LoginService （接口全限定类名）的文件，文件中填入：\n\ncom.xiaohe.spi.SpringSecurityLogin\n\n\n意为只加载 SpringSecurityLogin 的登陆方式。当然也可以填好几个，多个之间使用换行分开。\n\n编写测试类：\n\npublic static void main(String[] args) {\n    ServiceLoader<LoginService> services = ServiceLoader.load(LoginService.class);\n    \n    services.forEach(loginService -> {\n        loginService.login("小明", "123");\n    });\n}\n\n\n打印 ：\n\n触发 SpringSecurity 的登录功能\n\n\n\n# 3. Sentinel 使用 SPI 机制做了什么\n\n想知道哪里使用到了 SPI，最好的方式就是去 resource/META-INF/services目录下查看有多少以全限定类名命名的文件，Sentinel1.8.1 版本有三个：\n\n\n\n第一个没见过暂时不说，但是第二个和第三个就很明显了吧。\n\n使用SPI机制加载 ProcessorSlot 的目的 ：可以在文件中自定义 slot 的执行顺序。\n\n使用SPI机制加载 ProcessorSlotChain 的目的 ：可以在代码中自定义 slot 的执行顺序。\n\n再来瞥一眼 Sentinel 中 DefaultSlotChainBuilder 构建 ProcessorSlotChain 的过程 ：\n\n@Spi(isDefault = true)\npublic class DefaultSlotChainBuilder implements SlotChainBuilder {\n\n    @Override\n    public ProcessorSlotChain build() {\n        ProcessorSlotChain chain = new DefaultProcessorSlotChain();\n\n        List<ProcessorSlot> sortedSlotList = SpiLoader.of(ProcessorSlot.class).loadInstanceListSorted();\n        for (ProcessorSlot slot : sortedSlotList) {\n            // 所有 slot 必须是 AbstractLinkedProcessorSlot 的子类\n            if (!(slot instanceof AbstractLinkedProcessorSlot)) {\n                // 打日志的代码我删了\n                continue;\n            }\n            chain.addLast((AbstractLinkedProcessorSlot<?>) slot);\n        }\n\n        return chain;\n    }\n}\n\n\n再来看看 resource/META-INF/services/ProcessorSlot 文件中的内容 ：\n\ncom.alibaba.csp.sentinel.slots.nodeselector.NodeSelectorSlot\ncom.alibaba.csp.sentinel.slots.clusterbuilder.ClusterBuilderSlot\ncom.alibaba.csp.sentinel.slots.logger.LogSlot\ncom.alibaba.csp.sentinel.slots.statistic.StatisticSlot\ncom.alibaba.csp.sentinel.slots.block.authority.AuthoritySlot\ncom.alibaba.csp.sentinel.slots.system.SystemSlot\ncom.alibaba.csp.sentinel.slots.block.flow.FlowSlot\ncom.alibaba.csp.sentinel.slots.block.degrade.DegradeSlot\ncom.alibaba.csp.sentinel.slots.block.degrade.DefaultCircuitBreakerSlot\n\n\n跟我之前手动 new 的执行顺序一样。后续文章就会对这些 slot 挨个讲解。',normalizedContent:'# 1. 简述\n\n在上一篇中详细介绍了 sentinel 中的几个核心类，又简单说了一下 sentinel 的插槽。\n\n这一篇会稍微详细的讲解插槽，会从整体也就是责任链模式入手介绍 sentinel 工作的流程，但不会单独讲解某一个插槽的用处。\n\n回忆一下上一篇有关插槽 processorslot 的知识点 ：\n\nsentinel 使用 责任链模式将所有的 processorslot 按照一定的顺序串成一个链表。processorslot 共分为两类：\n\n 1. 统计数据，这种 processorslor 是有严格的顺序区分的，不能更改。\n    \n    nodeselectorslot\n    \n    clusterbuilderslot\n    \n    statisticslot\n\n 2. 限流/熔断，这种 processorslot 没有严格严格的顺序要求，可以按需调整。\n    \n    authorityslot\n    \n    systemslot\n    \n    flowslot\n    \n    degradeslot\n\nprocessorslotchain ：内含processorslot头节点和尾节点，可以触发整个插槽链的执行。\n\nslotchainbuilder ：将 processorslot 组装起来形成 processorslotchain 并返回给用户。\n\n接下来详细说说 sentinel 的工作流程\n\n\n# 2. processorslot\n\nprocessorslot 是一个接口\n\npublic interface processorslot<t> {\n\n  \t// 实现自己的业务方法\n    void entry(context context, resourcewrapper resourcewrapper, t param, int count, boolean prioritized, object... args) throws throwable;\n\n    // 触发下一个slot的业务方法\n    void fireentry(context context, resourcewrapper resourcewrapper, object obj, int count, boolean prioritized, object... args) throws throwable;\n\n\t// 实现自己的退出方法\n    void exit(context context, resourcewrapper resourcewrapper, int count, object... args);\n\n    // 触发下一个slot的退出方法\n    void fireexit(context context, resourcewrapper resourcewrapper, int count, object... args);\n}\n\n\n * context ：当前调用链路上下文\n * resourcewrapper ：资源\n * param ：泛型参数，一般用于传递 defaultnode\n * count ：申请访问资源的数量，比如访问量、占用线程数量，count 一般为1\n * prioritized ：是否对请求进行优先级排序，一般为false\n * args ：调用方法的参数，用于实现热点参数限流\n\n这里你就会有些疑惑，按照责任链模式，processorchain 应该有一个 next 变量用于串起来所有 processorchain 啊，但是此处并没有，而且也没有提供添加下一个slot、触发下一个slot这些方法，不要慌，其实这些东西在 processorslot 的实现类中 ：abstractlinkedprocessorslot\n\n之所以能够将所有的 processorslot 构造成一个 processorslotchain，还是依赖 abstractlinkedprocessorslot 类。\n\n每个 abstractlinkedprocessorslot 类都有一个指向下一个 abstractlinkedprocessorslot 的字段，正是这个字段将 processorslot 串成一条单向链表。abstractlinkedprocessorslot 部分源码如下。\n\npublic abstract class abstractlinkedprocessorslot<t> implements processorslot<t> {\n    // 当前节点的下一个节点\n    private abstractlinkedprocessorslot<?> next = null;\n\n    public void setnext(abstractlinkedprocessorslot<?> next) {\n        this.next = next;\n    }\n    @override\n    public void fireentry(context context, \n                          resourcewrapper resourcewrapper, \n                          object obj, \n                          int count, \n                          boolean prioritized, \n                          object... args) throws throwable {\n        if (next != null) {\n            t t = (t) obj; \n            // 调用下一个 processorslot 的 entry 方法\n            next.entry(context,resourcewrapper,t,count,prioritized,args);\n        }\n    }\n}\n\n\n可以看到，不仅提供了 setnext() 方法用于添加此slot的下一个slot，还提供了 fireentry() 触发下一个slot。\n\n到时候我们实现的时候只需要这样：\n\npublic class myslot extends abstractlinkedprocessorslot<defaultnode> {\n\n    @override\n    public void entry(context context, \n                      resourcewrapper resourcewrapper, \n                      defaultnode node, \n                      int count, \n                      boolean prioritized, \n                      object... args) throws throwable {\n        // 执行自己的业务方法...\n        \n        \n        // 执行结束，触发下一个slot的业务方法\n        fireentry(context, resourcewrapper, node, count, prioritized, args);\n    }\n}\n\n\n\n# 3. processorslotchain\n\n根据责任链模式的一般实现方式，这个 chain 会持有所有的slot，sentinel 的实现方式是持有头节点和尾节点。\n\n（okhttp的实现方式是持有整个list）\n\npublic class defaultprocessorslotchain extends processorslotchain {\n\n    // 虚拟头节点\n    abstractlinkedprocessorslot<?> first = new abstractlinkedprocessorslot<object>() {\n\t\t// 可以看到头节点并没有自己的业务需要实现，所以直接调用 fireentry 触发next.entry\n        @override\n        public void entry(context context, resourcewrapper resourcewrapper, object t, int count, boolean prioritized, object... args)\n            throws throwable {\n            super.fireentry(context, resourcewrapper, t, count, prioritized, args);\n        }\n\n        @override\n        public void exit(context context, resourcewrapper resourcewrapper, int count, object... args) {\n            super.fireexit(context, resourcewrapper, count, args);\n        }\n\n    };\n    // 尾节点\n    abstractlinkedprocessorslot<?> end = first;\n\n    // 头插法\n    @override\n    public void addfirst(abstractlinkedprocessorslot<?> protocolprocessor) {\n        protocolprocessor.setnext(first.getnext());\n        first.setnext(protocolprocessor);\n        if (end == first) {\n            end = protocolprocessor;\n        }\n    }\n\n    // 尾插法\n    @override\n    public void addlast(abstractlinkedprocessorslot<?> protocolprocessor) {\n        end.setnext(protocolprocessor);\n        end = protocolprocessor;\n    }\n\n    @override\n    public void setnext(abstractlinkedprocessorslot<?> next) {\n        addlast(next);\n    }\n\n    @override\n    public abstractlinkedprocessorslot<?> getnext() {\n        return first.getnext();\n    }\n\t// entry方法，调用 first.transformentry()，最终调用到 first.entry，\n    // first.entry没有自己的业务，直接触发first.next.entry()\n    @override\n    public void entry(context context, resourcewrapper resourcewrapper, object t, int count, boolean prioritized, object... args)\n        throws throwable {\n        first.transformentry(context, resourcewrapper, t, count, prioritized, args);\n    }\n\n    @override\n    public void exit(context context, resourcewrapper resourcewrapper, int count, object... args) {\n        first.exit(context, resourcewrapper, count, args);\n    }\n}\n\n\n使用 processorslotchain.entry() 即可触发整个链条。\n\n\n# 4. slotchainbuilder\n\n根据责任链模式的一般实现方式，构造 slot 链条这件事不会暴露给用户的，所以 sentintl 使用 slotchainbuilder 构造 processorslotchain 并返回。\n\n@spi(isdefault = true)\npublic class defaultslotchainbuilder implements slotchainbuilder {\n\n    @override\n    public processorslotchain build() {\n        processorslotchain chain = new defaultprocessorslotchain();\n\n        list<processorslot> sortedslotlist = spiloader.of(processorslot.class).loadinstancelistsorted();\n        for (processorslot slot : sortedslotlist) {\n            if (!(slot instanceof abstractlinkedprocessorslot)) {\n                recordlog.warn("the processorslot(" + slot.getclass().getcanonicalname() + ") is not an instance of abstractlinkedprocessorslot, can\'t be added into processorslotchain");\n                continue;\n            }\n            chain.addlast((abstractlinkedprocessorslot<?>) slot);\n        }\n\n        return chain;\n    }\n}\n\n\n但是打眼一看没这么简单！并没有我们想象的 new 了很多 slot 然后一个一个 add 进去，而是使用 spiloader 加载。这是 java spi 机制，我们在下面会介绍，这里就丑陋一点一个一个new出来😁\n\n我手动 new 的哈，源码里面没有\n\npublic class defaultslotchainbuilder implements slotchainbuilder {\n    @override\n    public processorslotchain build() {\n        processorslotchain chain = new defaultprocessorslotchain();\n        \n        chain.addlast(new nodeselectorslot());\n        chain.addlast(new clusterbuilderslot());\n        chain.addlast(new logslot());\n        chain.addlast(new statisticslot());\n        chain.addlast(new authorityslot());\n        chain.addlast(new systemslot());\n        chain.addlast(new flowslot());\n        chain.addlast(new degradeslot());\n        chain.addlast(new defaultcircuitbreakerslot());\n        \n        return chain;\n    }\n}\n\n\n\n# 5. 总结\n\n 1. processorslotchain ：\n    * firstslot ：first.entry方法直接调用fireentry方法\n    * endslot\n    * entry() ：调用firstslot的entry方法\n 2. processorslot\n    * nextslot\n    * entry() ：执行完自己的业务后执行 fireentry()\n    * fireentry() ：执行 next.entry()\n\n总流程 ：\n\n 1. 使用 slotchainbuilder 创建 processorslotchain\n 2. 使用 processorslotchain.entry() 方法可以执行整条插槽链 ：\n    * 调用 firstslot.entry，firstslot.entry() 中直接执行 fireentry 方法去执行下一个 slot.entry()\n 3. 下一个 slot.entry() 执行完自己的业务方法后，调用 fireentry() 去执行下一个 slot.entry()\n 4. ....\n 5. ....\n\n\n# 6. sentinel 中的 spi 机制\n\n\n# 1. 什么是 spi\n\nspi 全称是 service provider interface，直译就是服务提供者接口，是一种服务发现机制，是 java 的一个内置标准，允许不同的开发者去实现某个特定的服务。spi 的本质是将接口实现类的全限定名配置在文件中，由服务加载器读取配置文件，加载实现类，实现在运行时动态替换接口的实现类。\n\n使用 spi 机制能够实现按配置加载接口的实现类，spi 机制在阿里开源的项目中被广泛使用，例如 dubbo、rocketmq、以及本文介绍的 sentinel。rocketmq 与 sentinel 使用的都是 java 提供的 spi 机制，而 dubbo 则是使用自实现的一套 spi，与 java spi 的配置方式不同，dubbo spi 使用 key-value 方式配置，目的是实现自适应扩展机制。\n\njava 的 spi 机制提供了 serviceloader.load(class<?> clazz) 用于加载指定类的实现类。它加载文件的路径为：\n\nresource/meta-inf/services/${接口的全限定类名}.\n\n在文件中也要填接口的实现类的全限定类名，java将全部的实现类返回给用户 ：\n\ncom.xiaohe.xxxxxx\n\n\nserviceloader<t> services = serviceloader.load(class<t> clazz);\n\n\n加载步骤为 ：\n\n * 指定 serviceloader.load(class clazz)\n * 通过 clazz 拿到接口的全限定类名，去 resource/meta-inf/services目录下寻找对应全限定类名的文件\n * 读取该文件的全部内容（每一个内容以换行符分隔）\n * 以集合的形式返回给用户\n\n\n# 2. 使用java的spi机制\n\n假设有很多种登录方式，所以登录接口：\n\npublic interface loginservice{\n  void login(string username,string password);\n}\n\n\n有两个实现类：\n\npublic class shirologin implements loginservice{\n    @override\n    public void login(string username, string password) {\n        system.out.println("触发 shiro 的登录功能");\n    }\n}\n\n\npublic class springsecuritylogin implements loginservice{\n    @override\n    public void login(string username, string password) {\n        system.out.println("触发 springsecurity 的登录功能");\n    }\n}\n\n\n在 resource/meta-inf/services 目录下创建名为 com.xiaohe.spi.loginservice （接口全限定类名）的文件，文件中填入：\n\ncom.xiaohe.spi.springsecuritylogin\n\n\n意为只加载 springsecuritylogin 的登陆方式。当然也可以填好几个，多个之间使用换行分开。\n\n编写测试类：\n\npublic static void main(string[] args) {\n    serviceloader<loginservice> services = serviceloader.load(loginservice.class);\n    \n    services.foreach(loginservice -> {\n        loginservice.login("小明", "123");\n    });\n}\n\n\n打印 ：\n\n触发 springsecurity 的登录功能\n\n\n\n# 3. sentinel 使用 spi 机制做了什么\n\n想知道哪里使用到了 spi，最好的方式就是去 resource/meta-inf/services目录下查看有多少以全限定类名命名的文件，sentinel1.8.1 版本有三个：\n\n\n\n第一个没见过暂时不说，但是第二个和第三个就很明显了吧。\n\n使用spi机制加载 processorslot 的目的 ：可以在文件中自定义 slot 的执行顺序。\n\n使用spi机制加载 processorslotchain 的目的 ：可以在代码中自定义 slot 的执行顺序。\n\n再来瞥一眼 sentinel 中 defaultslotchainbuilder 构建 processorslotchain 的过程 ：\n\n@spi(isdefault = true)\npublic class defaultslotchainbuilder implements slotchainbuilder {\n\n    @override\n    public processorslotchain build() {\n        processorslotchain chain = new defaultprocessorslotchain();\n\n        list<processorslot> sortedslotlist = spiloader.of(processorslot.class).loadinstancelistsorted();\n        for (processorslot slot : sortedslotlist) {\n            // 所有 slot 必须是 abstractlinkedprocessorslot 的子类\n            if (!(slot instanceof abstractlinkedprocessorslot)) {\n                // 打日志的代码我删了\n                continue;\n            }\n            chain.addlast((abstractlinkedprocessorslot<?>) slot);\n        }\n\n        return chain;\n    }\n}\n\n\n再来看看 resource/meta-inf/services/processorslot 文件中的内容 ：\n\ncom.alibaba.csp.sentinel.slots.nodeselector.nodeselectorslot\ncom.alibaba.csp.sentinel.slots.clusterbuilder.clusterbuilderslot\ncom.alibaba.csp.sentinel.slots.logger.logslot\ncom.alibaba.csp.sentinel.slots.statistic.statisticslot\ncom.alibaba.csp.sentinel.slots.block.authority.authorityslot\ncom.alibaba.csp.sentinel.slots.system.systemslot\ncom.alibaba.csp.sentinel.slots.block.flow.flowslot\ncom.alibaba.csp.sentinel.slots.block.degrade.degradeslot\ncom.alibaba.csp.sentinel.slots.block.degrade.defaultcircuitbreakerslot\n\n\n跟我之前手动 new 的执行顺序一样。后续文章就会对这些 slot 挨个讲解。',charsets:{cjk:!0},lastUpdated:"2023/12/11, 23:11:06",lastUpdatedTimestamp:1702307466e3},{title:"3. Sentinel - NodeSelectorSlot",frontmatter:{title:"3. Sentinel - NodeSelectorSlot",date:"2023-12-11T22:10:14.000Z",permalink:"/pages/f4866d/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/60.Sentinel/5.%20Sentinel%20-%20NodeSelectorSlot.html",relativePath:"02.文章/91.框架/60.Sentinel/5. Sentinel - NodeSelectorSlot.md",key:"v-6f97f076",path:"/pages/f4866d/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 源码",slug:"_1-源码",normalizedTitle:"1. 源码",charIndex:190},{level:2,title:"2. map的用处",slug:"_2-map的用处",normalizedTitle:"2. map的用处",charIndex:2225},{level:2,title:"3. 将 Node 挂在树上",slug:"_3-将-node-挂在树上",normalizedTitle:"3. 将 node 挂在树上",charIndex:3578},{level:2,title:"4. Node树的构建",slug:"_4-node树的构建",normalizedTitle:"4. node树的构建",charIndex:4239},{level:2,title:"5. 总结",slug:"_5-总结",normalizedTitle:"5. 总结",charIndex:4403}],headersStr:"0. 前言 1. 源码 2. map的用处 3. 将 Node 挂在树上 4. Node树的构建 5. 总结",content:"# 0. 前言\n\n现在就开始第一个 slot 的讲解了，一般情况下，slot 都在 /sentinel-core/com.alibaba.csp.sentinel.slots 包下；如果有不在的我会标注。\n\nNodeSelectorSlot 的位置 ： /sentinel-core/com.alibaba.csp.sentinel.slots.nodeselector\n\n\n# 1. 源码\n\nNodeSelectorSlot 的源码特别少 ：\n\n@Spi(isSingleton = false, order = Constants.ORDER_NODE_SELECTOR_SLOT)\npublic class NodeSelectorSlot extends AbstractLinkedProcessorSlot<Object> {\n\n    // key : context.name\n    // value : default node\n    // 缓存同一资源为不同调用链路入口创建的 DefaultNode\n    private volatile Map<String, DefaultNode> map = new HashMap<String, DefaultNode>(10);\n\n    @Override\n    public void entry(Context context, \n                      ResourceWrapper resourceWrapper, \n                      Object obj, int count, \n                      boolean prioritized, \n                      Object... args) throws Throwable {\n        // 根据context.name从map中拿 default node\n        // 拿不到说明还没有创建，使用双重检查锁\n        DefaultNode node = map.get(context.getName());\n        if (node == null) {\n            synchronized (this) {\n                node = map.get(context.getName());\n                if (node == null) {\n                    // 创建，放入。\n                    node = new DefaultNode(resourceWrapper, null);\n                    HashMap<String, DefaultNode> cacheMap = new HashMap<String, DefaultNode>(map.size());\n                    cacheMap.putAll(map);\n                    cacheMap.put(context.getName(), node);\n                    map = cacheMap;\n                    // 构建node树，放到叶子节点上。\n                    ((DefaultNode) context.getLastNode()).addChild(node);\n                }\n            }\n        }\n        // 将 context 的当前节点设置为 node\n        context.setCurNode(node);\n        // 开始其他的slot逻辑\n        fireEntry(context, resourceWrapper, node, count, prioritized, args);\n    }\n\n    @Override\n    public void exit(Context context, ResourceWrapper resourceWrapper, int count, Object... args) {\n        fireExit(context, resourceWrapper, count, args);\n    }\n}\n\n\nentry方法的参数 ：\n\n * context ：当前调用链路上下文\n * resourceWrapper ：资源\n * param ：泛型参数，一般用于传递 DefaultNode\n * count ：申请访问资源的数量，比如访问量、占用线程数量，count 一般为1\n * prioritized ：是否对请求进行优先级排序，一般为false\n * args ：调用方法的参数，用于实现热点参数限流\n\n之前其实已经介绍过参数了，这里是为了水字数让你回忆一下。\n\n整个源码最难理解的有两个点 ：\n\n 1. map 的用处\n 2. 将此node挂在树上\n\n\n# 2. map的用处\n\n// key : context name\n// value : node\nprivate volatile Map<String, DefaultNode> map = new HashMap<String, DefaultNode>(10);\n\n\n在之前的介绍中我们已经知道，context.name 一般都是指定的，例如 sentinel_default_context、sentinel_spring_web_context、sentinel_dubbo_context.....\n\n这里为啥将 Node 在 Map 中对应的 key 设置为 context.name 呢？\n\nmap 字段是一个非静态字段，意味着每个 NodeSelectorSlot 都有一个 map。由于一个资源对应一个 ProcessorSlotChain，而一个 ProcessorSlotChain 只创建一个 NodeSelectorSlot，并且 map 缓存 DefaultNode 使用的 key 并非资源 ID，而是 Context.name，所以 map 的作用是缓存针对同一资源在不同调用链路创建的 DefaultNode。\n\n那你说如果同一个调用链中有俩同名的资源咋办？同名资源不会重新创建 Node哦，你看上面的逻辑，如果 map.get() 到了就不会继续创建了，如果没有get到才会继续创建。\n\n@Override\npublic void entry(Context context, \n                  ResourceWrapper resourceWrapper, \n                  Object obj, int count, \n                  boolean prioritized, \n                  Object... args) throws Throwable {\n    // 根据context.name从map中拿 default node\n    // 拿不到说明还没有创建，使用双重检查锁\n    DefaultNode node = map.get(context.getName());\n    if (node == null) {\n        // 省略代码，使用双重检查锁创建 node 并放入 map\n    }\n    // 将 context 的当前节点设置为 node\n    context.setCurNode(node);\n    // 开始其他的slot逻辑\n    fireEntry(context, resourceWrapper, node, count, prioritized, args);\n}\n\n\n是否会创建同名 node 的问题，你可以使用 SentinelResource 声明一个同名资源尝试一下。同时建议使用 sentinel-demo/sentinel-demo-spring-webmvc 进行 debug，因为 sentinel-demo-basic 下的测试类是并发的，所以不好debug，不直观。\n\n\n# 3. 将 Node 挂在树上\n\n // 构建node树，放到叶子节点上。\n((DefaultNode) context.getLastNode()).addChild(node);\n\n\n就是这段代码，获取 context 中的 last node，将此节点当作 last node 的子节点，所以只需要知道 last node 是啥就行了。\n\npublic Node getLastNode() {\n    if (curEntry != null && curEntry.getLastNode() != null) {\n        return curEntry.getLastNode();\n    } else {\n        return entranceNode;\n    }\n}\n\n\n// CtEntry 中的 getLastNode()\n@Override\npublic Node getLastNode() {\n    return parent == null ? null : parent.getCurNode();\n}\n\n\n如果当前是 Entry 执行中第一个资源，那么它的 Entry 肯定是没有 parent 的，所以会返回 entranceNode。也就是将此Node挂在入口节点下。\n\n如果当前是 Entry 执行中的第 n 个资源(n>1)，它的 Entry 一定有parent，会返回上一个 Entry 的node。拿到这个调用链上最后一个节点，将此节点挂上就行了。\n\n\n# 4. Node树的构建\n\n 1. ROOT ：常量，早就创建好了\n 2. EntranceNode ：ContextUtil 在创建 Context 时顺带创建的，先从 map 中找，没找到就创建，创建之后挂在 ROOT 下、放到 map 中。\n 3. DefaultNode ：Entry执行时创建并挂在Node树下\n\n\n# 5. 总结\n\n其实写这篇文章的时候把自己整懵逼了然后回去改了之前的文章，再强调一下 ：\n\n 1. Context 持有 当前调用链路的入口节点 和 当前调用链路Entry\n 2. 但是入口节点并不参与Entry的创建与执行。",normalizedContent:"# 0. 前言\n\n现在就开始第一个 slot 的讲解了，一般情况下，slot 都在 /sentinel-core/com.alibaba.csp.sentinel.slots 包下；如果有不在的我会标注。\n\nnodeselectorslot 的位置 ： /sentinel-core/com.alibaba.csp.sentinel.slots.nodeselector\n\n\n# 1. 源码\n\nnodeselectorslot 的源码特别少 ：\n\n@spi(issingleton = false, order = constants.order_node_selector_slot)\npublic class nodeselectorslot extends abstractlinkedprocessorslot<object> {\n\n    // key : context.name\n    // value : default node\n    // 缓存同一资源为不同调用链路入口创建的 defaultnode\n    private volatile map<string, defaultnode> map = new hashmap<string, defaultnode>(10);\n\n    @override\n    public void entry(context context, \n                      resourcewrapper resourcewrapper, \n                      object obj, int count, \n                      boolean prioritized, \n                      object... args) throws throwable {\n        // 根据context.name从map中拿 default node\n        // 拿不到说明还没有创建，使用双重检查锁\n        defaultnode node = map.get(context.getname());\n        if (node == null) {\n            synchronized (this) {\n                node = map.get(context.getname());\n                if (node == null) {\n                    // 创建，放入。\n                    node = new defaultnode(resourcewrapper, null);\n                    hashmap<string, defaultnode> cachemap = new hashmap<string, defaultnode>(map.size());\n                    cachemap.putall(map);\n                    cachemap.put(context.getname(), node);\n                    map = cachemap;\n                    // 构建node树，放到叶子节点上。\n                    ((defaultnode) context.getlastnode()).addchild(node);\n                }\n            }\n        }\n        // 将 context 的当前节点设置为 node\n        context.setcurnode(node);\n        // 开始其他的slot逻辑\n        fireentry(context, resourcewrapper, node, count, prioritized, args);\n    }\n\n    @override\n    public void exit(context context, resourcewrapper resourcewrapper, int count, object... args) {\n        fireexit(context, resourcewrapper, count, args);\n    }\n}\n\n\nentry方法的参数 ：\n\n * context ：当前调用链路上下文\n * resourcewrapper ：资源\n * param ：泛型参数，一般用于传递 defaultnode\n * count ：申请访问资源的数量，比如访问量、占用线程数量，count 一般为1\n * prioritized ：是否对请求进行优先级排序，一般为false\n * args ：调用方法的参数，用于实现热点参数限流\n\n之前其实已经介绍过参数了，这里是为了水字数让你回忆一下。\n\n整个源码最难理解的有两个点 ：\n\n 1. map 的用处\n 2. 将此node挂在树上\n\n\n# 2. map的用处\n\n// key : context name\n// value : node\nprivate volatile map<string, defaultnode> map = new hashmap<string, defaultnode>(10);\n\n\n在之前的介绍中我们已经知道，context.name 一般都是指定的，例如 sentinel_default_context、sentinel_spring_web_context、sentinel_dubbo_context.....\n\n这里为啥将 node 在 map 中对应的 key 设置为 context.name 呢？\n\nmap 字段是一个非静态字段，意味着每个 nodeselectorslot 都有一个 map。由于一个资源对应一个 processorslotchain，而一个 processorslotchain 只创建一个 nodeselectorslot，并且 map 缓存 defaultnode 使用的 key 并非资源 id，而是 context.name，所以 map 的作用是缓存针对同一资源在不同调用链路创建的 defaultnode。\n\n那你说如果同一个调用链中有俩同名的资源咋办？同名资源不会重新创建 node哦，你看上面的逻辑，如果 map.get() 到了就不会继续创建了，如果没有get到才会继续创建。\n\n@override\npublic void entry(context context, \n                  resourcewrapper resourcewrapper, \n                  object obj, int count, \n                  boolean prioritized, \n                  object... args) throws throwable {\n    // 根据context.name从map中拿 default node\n    // 拿不到说明还没有创建，使用双重检查锁\n    defaultnode node = map.get(context.getname());\n    if (node == null) {\n        // 省略代码，使用双重检查锁创建 node 并放入 map\n    }\n    // 将 context 的当前节点设置为 node\n    context.setcurnode(node);\n    // 开始其他的slot逻辑\n    fireentry(context, resourcewrapper, node, count, prioritized, args);\n}\n\n\n是否会创建同名 node 的问题，你可以使用 sentinelresource 声明一个同名资源尝试一下。同时建议使用 sentinel-demo/sentinel-demo-spring-webmvc 进行 debug，因为 sentinel-demo-basic 下的测试类是并发的，所以不好debug，不直观。\n\n\n# 3. 将 node 挂在树上\n\n // 构建node树，放到叶子节点上。\n((defaultnode) context.getlastnode()).addchild(node);\n\n\n就是这段代码，获取 context 中的 last node，将此节点当作 last node 的子节点，所以只需要知道 last node 是啥就行了。\n\npublic node getlastnode() {\n    if (curentry != null && curentry.getlastnode() != null) {\n        return curentry.getlastnode();\n    } else {\n        return entrancenode;\n    }\n}\n\n\n// ctentry 中的 getlastnode()\n@override\npublic node getlastnode() {\n    return parent == null ? null : parent.getcurnode();\n}\n\n\n如果当前是 entry 执行中第一个资源，那么它的 entry 肯定是没有 parent 的，所以会返回 entrancenode。也就是将此node挂在入口节点下。\n\n如果当前是 entry 执行中的第 n 个资源(n>1)，它的 entry 一定有parent，会返回上一个 entry 的node。拿到这个调用链上最后一个节点，将此节点挂上就行了。\n\n\n# 4. node树的构建\n\n 1. root ：常量，早就创建好了\n 2. entrancenode ：contextutil 在创建 context 时顺带创建的，先从 map 中找，没找到就创建，创建之后挂在 root 下、放到 map 中。\n 3. defaultnode ：entry执行时创建并挂在node树下\n\n\n# 5. 总结\n\n其实写这篇文章的时候把自己整懵逼了然后回去改了之前的文章，再强调一下 ：\n\n 1. context 持有 当前调用链路的入口节点 和 当前调用链路entry\n 2. 但是入口节点并不参与entry的创建与执行。",charsets:{cjk:!0},lastUpdated:"2023/12/11, 23:11:06",lastUpdatedTimestamp:1702307466e3},{title:"4. Sentinel - ClusterBuilderSlot",frontmatter:{title:"4. Sentinel - ClusterBuilderSlot",date:"2023-12-11T22:11:03.000Z",permalink:"/pages/df7ccb/"},regularPath:"/02.%E6%96%87%E7%AB%A0/91.%E6%A1%86%E6%9E%B6/60.Sentinel/6.%20Sentinel%20-%20ClusterBuilderSlot.html",relativePath:"02.文章/91.框架/60.Sentinel/6. Sentinel - ClusterBuilderSlot.md",key:"v-34b36bf8",path:"/pages/df7ccb/",headers:[{level:2,title:"1. 前言",slug:"_1-前言",normalizedTitle:"1. 前言",charIndex:2},{level:2,title:"2. 源码",slug:"_2-源码",normalizedTitle:"2. 源码",charIndex:69}],headersStr:"1. 前言 2. 源码",content:'# 1. 前言\n\n上一篇文章讲解了 NodeSelectorSlot 将节点挂在 Node 树上，这篇讲一下为节点创建全局节点。\n\n\n# 2. 源码\n\n代码特别简单，由于全局节点不用每次都新建，所以我们用 Map 记录已经创建好的全局节点，经过 ClusterBuilderSlot 的 Entry 只需要判断 Map 里面有没有创建好的，有了就用，没有就创建。\n\n@Spi(isSingleton = false, order = Constants.ORDER_CLUSTER_BUILDER_SLOT)\npublic class ClusterBuilderSlot extends AbstractLinkedProcessorSlot<DefaultNode> {\n\t// 保存已创建的全局节点\n    private static volatile Map<ResourceWrapper, ClusterNode> clusterNodeMap = new HashMap<>();\n\t// 操作 clusterNodeMap 时需要并发安全\n    private static final Object lock = new Object();\n\t// 当前 SlotChain 的全局节点。\n    private volatile ClusterNode clusterNode = null;\n\n    @Override\n    public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args)\n        throws Throwable {\n        // 熟悉的配方，熟悉的味道，熟悉的双重检查锁\n        if (clusterNode == null) {\n            synchronized (lock) {\n                if (clusterNode == null) {\n                    // Create the cluster node.\n                    clusterNode = new ClusterNode(resourceWrapper.getName(), resourceWrapper.getResourceType());\n                    HashMap<ResourceWrapper, ClusterNode> newMap = new HashMap<>(Math.max(clusterNodeMap.size(), 16));\n                    newMap.putAll(clusterNodeMap);\n                    newMap.put(node.getId(), clusterNode);\n\n                    clusterNodeMap = newMap;\n                }\n            }\n        }\n        // 将当前遍历到的DefaultNode的Clu挂上。\n        node.setClusterNode(clusterNode);\n\t\t// 如果这个节点有调用来源，拿到调用来源，给它创建一个节点，设置为此次调用的 origin node\n        if (!"".equals(context.getOrigin())) {\n            Node originNode = node.getClusterNode().getOrCreateOriginNode(context.getOrigin());\n            context.getCurEntry().setOriginNode(originNode);\n        }\n\t\t// 执行下一个 slot\n        fireEntry(context, resourceWrapper, node, count, prioritized, args);\n    }\n\n    @Override\n    public void exit(Context context, ResourceWrapper resourceWrapper, int count, Object... args) {\n        fireExit(context, resourceWrapper, count, args);\n    }\n}\n\n\n唯一可能有疑惑的可能是那一段设置 origin node 的代码。举例说明：\n\n\n\n如上，hello1远程调用 hello2，这样 hello2 也就有了 orgin，有了 origin 就要给当前执行的上下文 context 设置OriginNode。所以在 sentinel_grpc_context 这一端会解析到 origin = hello1，通过这个名字拿到对应的节点。\n\n在前面的章节中已经说过，这里就不再详细叙述了。\n\npublic class ClusterNode extends StatisticNode {\n    public Node getOrCreateOriginNode(String origin) {\n        StatisticNode statisticNode = originCountMap.get(origin);\n        if (statisticNode == null) {\n            lock.lock();\n            try {\n                statisticNode = originCountMap.get(origin);\n                if (statisticNode == null) {\n                    statisticNode = new StatisticNode();\n                    HashMap<String, StatisticNode> newMap = new HashMap<>(originCountMap.size() + 1);\n                    newMap.putAll(originCountMap);\n                    newMap.put(origin, statisticNode);\n                    originCountMap = newMap;\n                }\n            } finally {\n                lock.unlock();\n            }\n        }\n        return statisticNode;\n\t}\n}\n\n\n\n然后你会看到有一个变量 ：originCountMap，这个是 ClusterNode 内部的变量，用于缓存 origin 与 StatisticNode 的映射。由于一个 ClusterNode 可能有多个 DefaultNode，使用 Map 记录这些 origin-StatisticNode 键值对，以后再有这种调用就可以直接获取。\n\nprivate Map<String, StatisticNode> originCountMap = new HashMap<>();\n\nprivate final ReentrantLock lock = new ReentrantLock();\n',normalizedContent:'# 1. 前言\n\n上一篇文章讲解了 nodeselectorslot 将节点挂在 node 树上，这篇讲一下为节点创建全局节点。\n\n\n# 2. 源码\n\n代码特别简单，由于全局节点不用每次都新建，所以我们用 map 记录已经创建好的全局节点，经过 clusterbuilderslot 的 entry 只需要判断 map 里面有没有创建好的，有了就用，没有就创建。\n\n@spi(issingleton = false, order = constants.order_cluster_builder_slot)\npublic class clusterbuilderslot extends abstractlinkedprocessorslot<defaultnode> {\n\t// 保存已创建的全局节点\n    private static volatile map<resourcewrapper, clusternode> clusternodemap = new hashmap<>();\n\t// 操作 clusternodemap 时需要并发安全\n    private static final object lock = new object();\n\t// 当前 slotchain 的全局节点。\n    private volatile clusternode clusternode = null;\n\n    @override\n    public void entry(context context, resourcewrapper resourcewrapper, defaultnode node, int count, boolean prioritized, object... args)\n        throws throwable {\n        // 熟悉的配方，熟悉的味道，熟悉的双重检查锁\n        if (clusternode == null) {\n            synchronized (lock) {\n                if (clusternode == null) {\n                    // create the cluster node.\n                    clusternode = new clusternode(resourcewrapper.getname(), resourcewrapper.getresourcetype());\n                    hashmap<resourcewrapper, clusternode> newmap = new hashmap<>(math.max(clusternodemap.size(), 16));\n                    newmap.putall(clusternodemap);\n                    newmap.put(node.getid(), clusternode);\n\n                    clusternodemap = newmap;\n                }\n            }\n        }\n        // 将当前遍历到的defaultnode的clu挂上。\n        node.setclusternode(clusternode);\n\t\t// 如果这个节点有调用来源，拿到调用来源，给它创建一个节点，设置为此次调用的 origin node\n        if (!"".equals(context.getorigin())) {\n            node originnode = node.getclusternode().getorcreateoriginnode(context.getorigin());\n            context.getcurentry().setoriginnode(originnode);\n        }\n\t\t// 执行下一个 slot\n        fireentry(context, resourcewrapper, node, count, prioritized, args);\n    }\n\n    @override\n    public void exit(context context, resourcewrapper resourcewrapper, int count, object... args) {\n        fireexit(context, resourcewrapper, count, args);\n    }\n}\n\n\n唯一可能有疑惑的可能是那一段设置 origin node 的代码。举例说明：\n\n\n\n如上，hello1远程调用 hello2，这样 hello2 也就有了 orgin，有了 origin 就要给当前执行的上下文 context 设置originnode。所以在 sentinel_grpc_context 这一端会解析到 origin = hello1，通过这个名字拿到对应的节点。\n\n在前面的章节中已经说过，这里就不再详细叙述了。\n\npublic class clusternode extends statisticnode {\n    public node getorcreateoriginnode(string origin) {\n        statisticnode statisticnode = origincountmap.get(origin);\n        if (statisticnode == null) {\n            lock.lock();\n            try {\n                statisticnode = origincountmap.get(origin);\n                if (statisticnode == null) {\n                    statisticnode = new statisticnode();\n                    hashmap<string, statisticnode> newmap = new hashmap<>(origincountmap.size() + 1);\n                    newmap.putall(origincountmap);\n                    newmap.put(origin, statisticnode);\n                    origincountmap = newmap;\n                }\n            } finally {\n                lock.unlock();\n            }\n        }\n        return statisticnode;\n\t}\n}\n\n\n\n然后你会看到有一个变量 ：origincountmap，这个是 clusternode 内部的变量，用于缓存 origin 与 statisticnode 的映射。由于一个 clusternode 可能有多个 defaultnode，使用 map 记录这些 origin-statisticnode 键值对，以后再有这种调用就可以直接获取。\n\nprivate map<string, statisticnode> origincountmap = new hashmap<>();\n\nprivate final reentrantlock lock = new reentrantlock();\n',charsets:{cjk:!0},lastUpdated:"2023/12/12, 20:57:13",lastUpdatedTimestamp:1702385833e3},{title:"联系我",frontmatter:{title:"联系我",date:"2020-05-12T15:09:57.000Z",permalink:"/pages/1b12ed",sidebar:!1,article:!1},regularPath:"/06.%E8%81%94%E7%B3%BB%E6%88%91/01.%E8%81%94%E7%B3%BB%E6%88%91.html",relativePath:"06.联系我/01.联系我.md",key:"v-c3e06076",path:"/pages/1b12ed/",headersStr:null,content:"如果您正在阅读这里的笔记并发现有什么不懂的地方，或者发现有任何地方有问题，您可以通过如下任意方式联系我：\n\n联系我\n\nQQ: 3175543112\n邮箱: 3175543112@qq.com",normalizedContent:"如果您正在阅读这里的笔记并发现有什么不懂的地方，或者发现有任何地方有问题，您可以通过如下任意方式联系我：\n\n联系我\n\nqq: 3175543112\n邮箱: 3175543112@qq.com",charsets:{cjk:!0},lastUpdated:"2023/06/09, 22:41:05",lastUpdatedTimestamp:1686321665e3},{title:"博客文章",frontmatter:{archivesPage:!0,title:"博客文章",permalink:"/blog/",article:!1},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-391a0836",path:"/blog/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2020/05/29, 16:33:54",lastUpdatedTimestamp:1590741234e3},{title:"Home",frontmatter:{home:!0,heroImage:"/img/logo.png",heroText:"何",tagline:"🚀瞄准月亮，即使坠落也是在星河之间",actionText:"开始使用 →",actionLink:"/pages/259a4b/",bannerBg:"none",postList:"none"},regularPath:"/",relativePath:"index.md",key:"v-5f6c1111",path:"/",headersStr:null,content:"联系我",normalizedContent:"联系我",charsets:{cjk:!0},lastUpdated:"2023/06/14, 09:41:46",lastUpdatedTimestamp:1686706906e3}],themeConfig:{nav:[{text:"首页",link:"/"},{text:"文章",link:"/pages/259a4b/"},{text:"联系我",link:"/pages/1b12ed/"}],sidebarDepth:2,logo:"/img/logo.png",repo:"https://github.com/2382546457",searchMaxSuggestions:10,lastUpdated:"上次更新",sidebar:{"/02.文章/":[["00.说明.md","说明","/pages/259a4b/"],{title:"Java基础",collapsable:!0,children:[["01.Java基础/100.Java NIO.md","Java NIO","/pages/5c396f/"],["01.Java基础/150.Reactor模式.md","Reator模式","/pages/0c2518/"],["01.Java基础/300.单机定时任务的实现.md","单机定时任务的实现","/pages/d8c9ba/"],["01.Java基础/1000.Java对于零拷贝的实现.md","Java对于零拷贝的实现","/pages/a5b563/"]]},{title:"MySQL",collapsable:!0,children:[["02.MySQL/01.InnoDB - 行格式.md","InnoDB - 行格式","/pages/493ffc/"],["02.MySQL/05.InnoDB - 页结构.md","InnoDB - 页结构","/pages/b3086d/"],["02.MySQL/10.InnoDB - B+树索引.md","InnoDB - B+树索引","/pages/26e2d2/"],["02.MySQL/15.InnoDB - redo log 和 undo log.md","InnoDB - redo log 和 undo log","/pages/495592/"],["02.MySQL/17.InnoDB - Buffer Pool.md","InnoDB - Buffer Pool","/pages/31e077/"],["02.MySQL/20.InnoDB - 锁.md","InnoDB - 锁","/pages/2e3013/"]]},{title:"Redis",collapsable:!0,children:[["10.Redis/10.Redis数据结构与数据类型.md","Redis数据结构与数据类型","/pages/77c4c7/"],["10.Redis/20.Redis 持久化机制.md","Redis 持久化机制","/pages/4e0b96/"],["10.Redis/30.Redis内存回收.md","Redis内存回收","/pages/73749d/"],["10.Redis/40.Redis主从集群原理.md","Redis主从集群原理","/pages/db45e7/"],["10.Redis/50.Redis哨兵集群.md","Redis哨兵集群","/pages/3743cc/"]]},{title:"操作系统",collapsable:!0,children:[["60.操作系统/10.用户态和内核态.md","用户态和内核态","/pages/c6965c/"],["60.操作系统/20.缓存一致性协议：MESI.md","缓存一致性协议：MESI","/pages/ee38bc/"],["60.操作系统/110.零拷贝.md","零拷贝","/pages/dbd03e/"]]},{title:"计算机网络",collapsable:!0,children:[["70.计算机网络/4.计算机网络五层网络模型.md","计算机网络五层网络模型","/pages/71bea1/"],["70.计算机网络/10.TCP、UDP协议.md","TCP、UDP协议","/pages/424c75/"]]},{title:"Java并发",collapsable:!0,children:[["75.Java并发/50.CAS.md","CAS","/pages/56d8fa/"],["75.Java并发/60.AQS源码解析.md","AQS源码解析","/pages/6c8c00/"],["75.Java并发/65.ReentrantLock.md","ReentrantLock 源码解析","/pages/5031c2/"],["75.Java并发/70.ReentrantReadWriteLock.md","ReentrantReadWriteLock 源码解析","/pages/6cfda5/"],["75.Java并发/100.原子类.md","原子类","/pages/0776e3/"],["75.Java并发/200.FutureTask源码解析.md","FutureTask源码解析","/pages/937dd3/"],["75.Java并发/250.FutureTask中的适配器模式.md","FutureTask中的适配器模式","/pages/c1826d/"],["75.Java并发/300.线程池.md","线程池","/pages/671511/"],["75.Java并发/400.线程池源码解析.md","线程池源码解析","/pages/79cb1d/"]]},{title:"算法",collapsable:!0,children:[["85.算法/1.负载均衡算法.md","负载均衡算法","/pages/97a05f/"],["85.算法/20.限流算法.md","限流算法","/pages/5dba8e/"],["85.算法/30.一致性哈希算法.md","一致性哈希算法","/pages/7e25cb/"],["85.算法/40.雪花算法.md","雪花算法","/pages/3fe609/"]]},{title:"框架",collapsable:!0,children:[{title:"理论",collapsable:!0,children:[["91.框架/1.理论/10.CAP理论.md","CAP理论","/pages/db9f45/"],["91.框架/1.理论/20.BASE理论.md","BASE理论","/pages/793cbb/"],["91.框架/1.理论/30.Raft算法.md","Raft算法","/pages/208bb3/"]]},{title:"Spring",collapsable:!0,children:[["91.框架/5.Spring/100.Spring事务.md","Spring事务","/pages/b4dd7e/"]]},{title:"微服务中间件的使用",collapsable:!0,children:[["91.框架/20.微服务中间件的使用/10.Nacos.md","Nacos","/pages/243013/"],["91.框架/20.微服务中间件的使用/20.Ribbon.md","Ribbon","/pages/afe80c/"],["91.框架/20.微服务中间件的使用/30.OpenFeign.md","OpenFeign","/pages/e020ec/"],["91.框架/20.微服务中间件的使用/40.Sentinel.md","Sentinel","/pages/a7a70b/"]]},{title:"Sentinel",collapsable:!0,children:[["91.框架/60.Sentinel/3. Sentinel中的一些概念.md","1. Sentinel中的一些概念与核心类解析","/pages/3d8a71/"],["91.框架/60.Sentinel/4. Sentinel 责任链流程.md","2. Sentinel 责任链流程","/pages/51db55/"],["91.框架/60.Sentinel/5. Sentinel - NodeSelectorSlot.md","3. Sentinel - NodeSelectorSlot","/pages/f4866d/"],["91.框架/60.Sentinel/6. Sentinel - ClusterBuilderSlot.md","4. Sentinel - ClusterBuilderSlot","/pages/df7ccb/"]]},{title:"RocketMQ",collapsable:!0,children:[]},{title:"XXL-JOB",collapsable:!0,children:[["91.框架/100.XXL-JOB/1.XXL-JOB的安装.md","1. XXL-JOB的安装","/pages/bb013b/"],["91.框架/100.XXL-JOB/2.XXL-JOB的使用.md","2. XXL-JOB的使用","/pages/fcb98f/"],["91.框架/100.XXL-JOB/4.XXL-JOB数据库字段讲解.md","4. XXL-JOB数据库字段讲解","/pages/ac1d9d/"],["91.框架/100.XXL-JOB/5.定时任务是如何执行的.md","5. 定时任务是如何执行的","/pages/5531a6/"],["91.框架/100.XXL-JOB/6.执行器端的日志组件.md","6. 执行器端的日志组件","/pages/a25535/"],["91.框架/100.XXL-JOB/20.XXL-JOB负载均衡策略.md","XXL-JOB负载均衡策略","/pages/75326c/"]]}]},{title:"其他",collapsable:!0,children:[["100.其他/5.如何将IP地址存入MySQL.md","如何将IP地址存入MySQL","/pages/ad5a8e/"],["100.其他/100.常用工具类.md","常用工具类","/pages/70ea3d/"],["100.其他/1000.Java学习路线.md","Java学习路线","/pages/7ca562/"]]},{title:"踩坑",collapsable:!0,children:[["200.踩坑/10.xxl job Access token is wrong.md","xxl job Access token is wrong","/pages/65cd6f/"],["200.踩坑/20.国际化时需要返回给前端一段json，json工具不同结果报错.md","国际化时需要返回给前端一段json，json工具不同结果报错","/pages/3cac9b/"],["200.踩坑/30.mp使用@TableField注解未生效反而报错.md","mp使用@TableField注解未生效反而报错","/pages/0e629c/"],["200.踩坑/40.使用@Validated注解进行参数校验时报错：UnexpectedTypeException.md","使用@Validated注解进行参数校验时报错：UnexpectedTypeException","/pages/e96a9e/"],["200.踩坑/50.connection.setReadTimeout.md","connection.setReadTimeout","/pages/4e379b/"]]},{title:"实习小结",collapsable:!0,children:[["1000.实习小结/1.Git踩坑.md","Git踩坑","/pages/f63fe9/"],["1000.实习小结/150.开发规范.md","开发规范","/pages/99f624/"]]}],catalogue:{},"/06.联系我/":[["01.联系我.md","联系我","/pages/1b12ed"]]},updateBar:{showToArticle:!1},pageStyle:"line",category:!1,tag:!1,pageButton:!1,author:{name:"何",href:"https://github.com/2382546457"},social:{icons:[{iconClass:"icon-youjian",title:"发邮件",link:"3175543112@qq.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/2382546457"},{iconClass:"icon-erji",title:"听音乐",link:"https://music.163.com/#/playlist?id=755597173"}]},footer:{createYear:2023,copyrightInfo:"何 | MIT License"},htmlModules:{}}};var ks=t(94),ws=t(95),Ss=t(11);var js={computed:{$filterPosts(){return this.$site.pages.filter(n=>{const{frontmatter:{pageComponent:e,article:t,home:r}}=n;return!(e||!1===t||!0===r)})},$sortPosts(){return(n=this.$filterPosts).sort((n,e)=>{const t=n.frontmatter.sticky,r=e.frontmatter.sticky;return t&&r?t==r?Object(Ss.a)(n,e):t-r:t&&!r?-1:!t&&r?1:Object(Ss.a)(n,e)}),n;var n},$sortPostsByDate(){return(n=this.$filterPosts).sort((n,e)=>Object(Ss.a)(n,e)),n;var n},$groupPosts(){return function(n){const e={},t={};for(let r=0,o=n.length;r<o;r++){const{frontmatter:{categories:o,tags:a}}=n[r];"array"===Object(Ss.n)(o)&&o.forEach(t=>{t&&(e[t]||(e[t]=[]),e[t].push(n[r]))}),"array"===Object(Ss.n)(a)&&a.forEach(e=>{e&&(t[e]||(t[e]=[]),t[e].push(n[r]))})}return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(n){const e=[],t=[];for(let t in n.categories)e.push({key:t,length:n.categories[t].length});for(let e in n.tags)t.push({key:e,length:n.tags[e].length});return{categories:e,tags:t}}(this.$groupPosts)}}};$t.component(ks.default),$t.component(ws.default);function Ts(n){return n.toString().padStart(2,"0")}t(243);$t.component("Badge",()=>Promise.all([t.e(0),t.e(3)]).then(t.bind(null,396))),$t.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,94))),$t.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,95)));t(244);var _s=[({Vue:n,options:e,router:t,siteData:r})=>{r.pages.map(n=>{const{frontmatter:{date:e,author:t}}=n;"string"==typeof e&&"Z"===e.charAt(e.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return`${n.getUTCFullYear()}-${Ts(n.getUTCMonth()+1)}-${Ts(n.getUTCDate())} ${Ts(n.getUTCHours())}:${Ts(n.getUTCMinutes())}:${Ts(n.getUTCSeconds())}`}(e)),t?n.author=t:r.themeConfig.author&&(n.author=r.themeConfig.author)}),n.mixin(js)},{},({Vue:n})=>{n.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},({router:n})=>{"undefined"!=typeof window&&(window._hmt=window._hmt||[],function(){var n=document.createElement("script");n.src="https://hm.baidu.com/hm.js?01293bffa6c3962016c08ba685c79d78";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(n,e)}(),n.afterEach((function(n){_hmt.push(["_trackPageview",n.fullPath])})))}],Cs=[];class Es extends class{constructor(){this.store=new $t({data:{state:{}}})}$get(n){return this.store.state[n]}$set(n,e){$t.set(this.store.state,n,e)}$emit(...n){this.store.$emit(...n)}$on(...n){this.store.$on(...n)}}{}Object.assign(Es.prototype,{getPageAsyncComponent:il,getLayoutAsyncComponent:ll,getAsyncComponent:sl,getVueComponent:cl});var Is={install(n){const e=new Es;n.$vuepress=e,n.prototype.$vuepress=e}};function As(n,e){const t=e.toLowerCase();return n.options.routes.some(n=>n.path.toLowerCase()===t)}var Ps={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(n){const e=this.pageKey||this.$parent.$page.key;return ul("pageKey",e),$t.component(e)||$t.component(e,il(e)),$t.component(e)?n(e):n("")}},Ls={functional:!0,props:{slotKey:String,required:!0},render:(n,{props:e,slots:t})=>n("div",{class:["content__"+e.slotKey]},t()[e.slotKey])},Rs={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Bs=(t(245),t(246),Object(bs.a)(Rs,(function(){var n=this._self._c;return n("span",[n("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[n("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),n("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),n("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),Os={functional:!0,render(n,{parent:e,children:t}){if(e._isMounted)return t;e.$once("hook:mounted",()=>{e.$forceUpdate()})}};$t.config.productionTip=!1,$t.use(Hi),$t.use(Is),$t.mixin(function(n,e,t=$t){!function(n){n.locales&&Object.keys(n.locales).forEach(e=>{n.locales[e].path=e});Object.freeze(n)}(e),t.$vuepress.$set("siteData",e);const r=new(n(t.$vuepress.$get("siteData"))),o=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(r)),a={};return Object.keys(o).reduce((n,e)=>(e.startsWith("$")&&(n[e]=o[e].get),n),a),{computed:a}}(n=>class{setPage(n){this.__page=n}get $site(){return n}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:n={}}=this.$site;let e,t;for(const r in n)"/"===r?t=n[r]:0===this.$page.path.indexOf(r)&&(e=n[r]);return e||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:n}=this.$page.frontmatter;return"string"==typeof n&&n}get $title(){const n=this.$page,{metaTitle:e}=this.$page.frontmatter;if("string"==typeof e)return e;const t=this.$siteTitle,r=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?r?r+" | "+t:t:r||"VuePress"}get $description(){const n=function(n){if(n){const e=n.filter(n=>"description"===n.name)[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(n,e){for(let t=0;t<n.length;t++){const r=n[t];if(r.path.toLowerCase()===e.toLowerCase())return r}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},ys)),$t.component("Content",Ps),$t.component("ContentSlotsDistributor",Ls),$t.component("OutboundLink",Bs),$t.component("ClientOnly",Os),$t.component("Layout",ll("Layout")),$t.component("NotFound",ll("NotFound")),$t.prototype.$withBase=function(n){const e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.2",hash:"adabe31"},async function(n){const e="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:ys.routerBase||ys.base,t=new Hi({base:e,mode:"history",fallback:!1,routes:vs,scrollBehavior:(n,e,t)=>t||(n.hash?!$t.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})});!function(n){n.beforeEach((e,t,r)=>{if(As(n,e.path))r();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){const t=e.path.replace(/\/$/,"")+".html";As(n,t)?r(t):r()}else r();else{const t=e.path+"/",o=e.path+".html";As(n,o)?r(o):As(n,t)?r(t):r()}})}(t);const r={};try{await Promise.all(_s.filter(n=>"function"==typeof n).map(e=>e({Vue:$t,options:r,router:t,siteData:ys,isServer:n})))}catch(n){console.error(n)}return{app:new $t(Object.assign(r,{router:t,render:n=>n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},Cs.map(e=>n(e)))])})),router:t}}(!1).then(({app:n,router:e})=>{e.onReady(()=>{n.$mount("#app")})})}]);